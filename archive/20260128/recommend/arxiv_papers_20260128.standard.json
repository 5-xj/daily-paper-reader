{
  "mode": "standard",
  "generated_at": "2026-01-28T03:58:34.646939+00:00",
  "stats": {
    "mode": "standard",
    "tag_count": 3,
    "deep_divecandidates": 1,
    "deep_cap": 8,
    "deep_selected": 1,
    "quick_candidates": 9,
    "quick_skim_target": 13,
    "quick_selected": 9
  },
  "deep_dive": [
    {
      "id": "2601.19622v1",
      "title": "Algorithmic Prompt-Augmentation for Efficient LLM-Based Heuristic Design for A* Search",
      "abstract": "Heuristic functions are essential to the performance of tree search algorithms such as A*, where their accuracy and efficiency directly impact search outcomes. Traditionally, such heuristics are handcrafted, requiring significant expertise. Recent advances in large language models (LLMs) and evolutionary frameworks have opened the door to automating heuristic design. In this paper, we extend the Evolution of Heuristics (EoH) framework to investigate the automated generation of guiding heuristics for A* search. We introduce a novel domain-agnostic prompt augmentation strategy that includes the A* code into the prompt to leverage in-context learning, named Algorithmic - Contextual EoH (A-CEoH). To evaluate the effectiveness of A-CeoH, we study two problem domains: the Unit-Load Pre-Marshalling Problem (UPMP), a niche problem from warehouse logistics, and the classical sliding puzzle problem (SPP). Our computational experiments show that A-CEoH can significantly improve the quality of the generated heuristics and even outperform expert-designed heuristics.",
      "authors": [
        "Thomas Bömer",
        "Nico Koltermann",
        "Max Disselnmeyer",
        "Bastian Amberg",
        "Anne Meyer"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI",
        "math.OC"
      ],
      "published": "2026-01-27 13:55:58+00:00",
      "link": "https://arxiv.org/pdf/2601.19622v1",
      "tags": [
        "keyword:EAA",
        "keyword:EOH",
        "keyword:LNS"
      ],
      "llm_score": 10.0,
      "llm_evidence": "Directly extends the Evolution of Heuristics framework for automated search design",
      "llm_tags": [
        "keyword:EOH",
        "keyword:EAA"
      ]
    }
  ],
  "quick_skim": [
    {
      "id": "2601.19290v1",
      "title": "MetaGen: Self-Evolving Roles and Topologies for Multi-Agent LLM Reasoning",
      "abstract": "Large language models are increasingly deployed as multi-agent systems, where specialized roles communicate and collaborate through structured interactions to solve complex tasks that often exceed the capacity of a single agent. However, most existing systems still rely on a fixed role library and an execution-frozen interaction topology, a rigid design choice that frequently leads to task mismatch, prevents timely adaptation when new evidence emerges during reasoning, and further inflates inference cost. We introduce MetaGen, a training-free framework that adapts both the role space and the collaboration topology at inference time, without updating base model weights. MetaGen generates and rewrites query-conditioned role specifications to maintain a controllable dynamic role pool, then instantiates a constrained execution graph around a minimal backbone. During execution, it iteratively updates role prompts and adjusts structural decisions using lightweight feedback signals. Experiments on code generation and multi-step reasoning benchmarks show that MetaGen improves the accuracy and cost tradeoff over strong multi-agent baselines.",
      "authors": [
        "Yimeng Wang",
        "Jiaxing Zhao",
        "Hongbin Xie",
        "Hexing Ma",
        "Yuzhen Lei",
        "Shuangxue Liu",
        "Xuan Song",
        "Zichen Zhang",
        "Haoran Zhang"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2026-01-27 07:24:35+00:00",
      "link": "https://arxiv.org/pdf/2601.19290v1",
      "tags": [
        "keyword:EOH"
      ],
      "llm_score": 7.0,
      "llm_evidence": "Self-evolving topologies and role generation for efficient reasoning",
      "llm_tags": [
        "keyword:EOH",
        "keyword:EAA"
      ],
      "quick_tier": "7"
    },
    {
      "id": "2601.19346v1",
      "title": "GeoSSA: Geometric Sparrow Search Algorithm for UAV Path Planning and Engineering Design Optimization",
      "abstract": "The Sparrow Search Algorithm (SSA), characterized by its simple structure and ease of implementation, nevertheless suffers from an insufficient balance between exploration and exploitation, making it prone to premature convergence and slow optimization progress. To address these shortcomings, this paper proposes a Geometric Sparrow Search Algorithm (GeoSSA). By integrating Good Nodes Set initialization, a Sine-Cosine Enhanced Producer position update strategy, and a Triangular-Walk Enhanced Edge Sparrow update strategy, GeoSSA significantly improves the global exploration ability, local exploitation efficiency, and convergence stability of the original SSA. To thoroughly validate the effectiveness of GeoSSA, we conducted ablation studies, qualitative analysis, and comparative experiments on 23 benchmark functions against state-of-the-art algorithms. Experimental results show that GeoSSA achieves the best or near-best performance in terms of average fitness, standard deviation, Wilcoxon tests, and Friedman rankings, with an Overall Effectiveness ($OE$) of 95.65\\%. Its overall performance is significantly superior to all compared algorithms. In three-dimensional UAV path planning tasks, GeoSSA demonstrates excellent stability and superior path quality. In four categories of engineering design optimization problems, GeoSSA consistently attains the highest solution accuracy and strongest stability. GeoSSA not only exhibits outstanding global optimization performance on standard benchmark functions but also shows strong robustness and generalization ability in practical applications such as UAV path planning and engineering design. Therefore, GeoSSA provides an efficient and reliable solution framework for complex optimization problems.",
      "authors": [
        "Junhao Wei",
        "Wenxuan Zhu",
        "Qingyang Xu",
        "Yanxiao Li",
        "Yifu Zhao",
        "Zikun Li",
        "Ran Zhang",
        "Yanzhao Gu",
        "Jinhong Song",
        "Yapeng Wang",
        "Zhiwen Wang",
        "Ngai Cheong",
        "Sio-Kei Im",
        "Xu Yang"
      ],
      "primary_category": "cs.CE",
      "categories": [
        "cs.CE"
      ],
      "published": "2026-01-27 08:26:24+00:00",
      "link": "https://arxiv.org/pdf/2601.19346v1",
      "tags": [
        "keyword:EAA",
        "keyword:LNS"
      ],
      "llm_score": 6.0,
      "llm_evidence": "Enhances metaheuristic search strategies for optimization",
      "llm_tags": [
        "keyword:EOH",
        "keyword:EAA"
      ],
      "quick_tier": "6"
    },
    {
      "id": "2601.19562v1",
      "title": "Tournament Informed Adversarial Quality Diversity",
      "abstract": "Quality diversity (QD) is a branch of evolutionary computation that seeks high-quality and behaviorally diverse solutions to a problem. While adversarial problems are common, classical QD cannot be easily applied to them, as both the fitness and the behavior depend on the opposing solutions. Recently, Generational Adversarial MAP-Elites (GAME) has been proposed to coevolve both sides of an adversarial problem by alternating the execution of a multi-task QD algorithm against previous elites, called tasks. The original algorithm selects new tasks based on a behavioral criterion, which may lead to undesired dynamics due to inter-side dependencies. In addition, comparing sets of solutions cannot be done directly using classical QD measures due to side dependencies. In this paper, we (1) use an inter-variants tournament to compare the sets of solutions, ensuring a fair comparison, with 6 measures of quality and diversity, and (2) propose two tournament-informed task selection methods to promote higher quality and diversity at each generation. We evaluate the variants across three adversarial problems: Pong, a Cat-and-mouse game, and a Pursuers-and-evaders game. We show that the tournament-informed task selection method leads to higher adversarial quality and diversity. We hope that this work will help further advance adversarial quality diversity. Code, videos, and supplementary material are available at https://github.com/Timothee-ANNE/GAME_tournament_informed.",
      "authors": [
        "Timothée Anne",
        "Noah Syrkis",
        "Meriem Elhosni",
        "Florian Turati",
        "Alexandre Manai",
        "Franck Legendre",
        "Alain Jaquier",
        "Sebastian Risi"
      ],
      "primary_category": "cs.NE",
      "categories": [
        "cs.NE"
      ],
      "published": "2026-01-27 12:55:23+00:00",
      "link": "https://arxiv.org/pdf/2601.19562v1",
      "tags": [
        "keyword:EAA",
        "keyword:EOH"
      ],
      "llm_score": 7.0,
      "llm_evidence": "Evolutionary computation and quality diversity methods align with evolution of heuristics",
      "llm_tags": [
        "keyword:EOH"
      ],
      "quick_tier": "7"
    },
    {
      "id": "2601.19367v1",
      "title": "CHEHAB RL: Learning to Optimize Fully Homomorphic Encryption Computations",
      "abstract": "Fully Homomorphic Encryption (FHE) enables computations directly on encrypted data, but its high computational cost remains a significant barrier. Writing efficient FHE code is a complex task requiring cryptographic expertise, and finding the optimal sequence of program transformations is often intractable. In this paper, we propose CHEHAB RL, a novel framework that leverages deep reinforcement learning (RL) to automate FHE code optimization. Instead of relying on predefined heuristics or combinatorial search, our method trains an RL agent to learn an effective policy for applying a sequence of rewriting rules to automatically vectorize scalar FHE code while reducing instruction latency and noise growth. The proposed approach supports the optimization of both structured and unstructured code. To train the agent, we synthesize a diverse dataset of computations using a large language model (LLM). We integrate our proposed approach into the CHEHAB FHE compiler and evaluate it on a suite of benchmarks, comparing its performance against Coyote, a state-of-the-art vectorizing FHE compiler. The results show that our approach generates code that is $5.3\\times$ faster in execution, accumulates $2.54\\times$ less noise, while the compilation process itself is $27.9\\times$ faster than Coyote (geometric means).",
      "authors": [
        "Bilel Sefsaf",
        "Abderraouf Dandani",
        "Abdessamed Seddiki",
        "Arab Mohammed",
        "Eduardo Chielle",
        "Michail Maniatakos",
        "Riyadh Baghdadi"
      ],
      "primary_category": "cs.CR",
      "categories": [
        "cs.CR",
        "cs.LG"
      ],
      "published": "2026-01-27 08:49:09+00:00",
      "link": "https://arxiv.org/pdf/2601.19367v1",
      "tags": [
        "keyword:EAA",
        "keyword:EOH",
        "keyword:LNS"
      ],
      "llm_score": 6.0,
      "llm_evidence": "Automates code optimization using RL instead of predefined heuristics, aligning with evolution of heuristics and efficient algorithms.",
      "llm_tags": [
        "keyword:EOH",
        "keyword:EAA"
      ],
      "quick_tier": "6"
    },
    {
      "id": "2601.19568v1",
      "title": "Learning Adaptive Parallel Execution for Efficient Code Localization",
      "abstract": "Code localization constitutes a key bottleneck in automated software development pipelines. While concurrent tool execution can enhance discovery speed, current agents demonstrate a 34.9\\% redundant invocation rate, which negates parallelism benefits. We propose \\textbf{FuseSearch}, reformulating parallel code localization as a \\textbf{joint quality-efficiency optimization} task. Through defining \\textbf{tool efficiency} -- the ratio of unique information gain to invocation count -- we utilize a two-phase SFT and RL training approach for learning adaptive parallel strategies. Different from fixed-breadth approaches, FuseSearch dynamically modulates search breadth according to task context, evolving from exploration phases to refinement stages. Evaluated on SWE-bench Verified, FuseSearch-4B achieves SOTA-level performance (84.7\\% file-level and 56.4\\% function-level $F_1$ scores) with 93.6\\% speedup, utilizing 67.7\\% fewer turns and 68.9\\% fewer tokens. Results indicate that efficiency-aware training naturally improves quality through eliminating noisy redundant signals, enabling high-performance cost-effective localization agents.",
      "authors": [
        "Ke Xu",
        "Siyang Xiao",
        "Ming Liang",
        "Yichen Yu",
        "Zhixiang Wang",
        "Jingxuan Xu",
        "Dajun Chen",
        "Wei Jiang",
        "Yong Li"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI",
        "cs.SE"
      ],
      "published": "2026-01-27 12:59:31+00:00",
      "link": "https://arxiv.org/pdf/2601.19568v1",
      "tags": [
        "keyword:EAA",
        "keyword:EOH",
        "keyword:LNS"
      ],
      "llm_score": 7.0,
      "llm_evidence": "Proposes adaptive parallel search strategies that evolve from exploration to refinement, relevant to heuristic evolution and efficient search.",
      "llm_tags": [
        "keyword:EOH",
        "keyword:EAA"
      ],
      "quick_tier": "7"
    },
    {
      "id": "2601.19452v1",
      "title": "APC-RL: Exceeding Data-Driven Behavior Priors with Adaptive Policy Composition",
      "abstract": "Incorporating demonstration data into reinforcement learning (RL) can greatly accelerate learning, but existing approaches often assume demonstrations are optimal and fully aligned with the target task. In practice, demonstrations are frequently sparse, suboptimal, or misaligned, which can degrade performance when these demonstrations are integrated into RL. We propose Adaptive Policy Composition (APC), a hierarchical model that adaptively composes multiple data-driven Normalizing Flow (NF) priors. Instead of enforcing strict adherence to the priors, APC estimates each prior's applicability to the target task while leveraging them for exploration. Moreover, APC either refines useful priors, or sidesteps misaligned ones when necessary to optimize downstream reward. Across diverse benchmarks, APC accelerates learning when demonstrations are aligned, remains robust under severe misalignment, and leverages suboptimal demonstrations to bootstrap exploration while avoiding performance degradation caused by overly strict adherence to suboptimal demonstrations.",
      "authors": [
        "Finn Rietz",
        "Pedro Zuidberg dos Martires",
        "Johannes Andreas Stork"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-01-27 10:38:32+00:00",
      "link": "https://arxiv.org/pdf/2601.19452v1",
      "tags": [
        "keyword:EOH"
      ],
      "llm_score": 6.0,
      "llm_evidence": "Adaptive policy composition for RL to refine priors aligns with the evolution of heuristics and efficient automated strategies.",
      "llm_tags": [
        "keyword:EOH",
        "keyword:EAA"
      ],
      "quick_tier": "6"
    },
    {
      "id": "2601.19481v1",
      "title": "Posterior Distribution-assisted Evolutionary Dynamic Optimization as an Online Calibrator for Complex Social Simulations",
      "abstract": "The calibration of simulators for complex social systems aims to identify the optimal parameter that drives the output of the simulator best matching the target data observed from the system. As many social systems may change internally over time, calibration naturally becomes an online task, requiring parameters to be updated continuously to maintain the simulator's fidelity. In this work, the online setting is first formulated as a dynamic optimization problem (DOP), requiring the search for a sequence of optimal parameters that fit the simulator to real system changes. However, in contrast to traditional DOP formulations, online calibration explicitly incorporates the observational data as the driver of environmental dynamics. Due to this fundamental difference, existing Evolutionary Dynamic Optimization (EDO) methods, despite being extensively studied for black-box DOPs, are ill-equipped to handle such a scenario. As a result, online calibration problems constitute a new set of challenging DOPs. Here, we propose to explicitly learn the posterior distributions of the parameters and the observational data, thereby facilitating both change detection and environmental adaptation of existing EDOs for this scenario. We thus present a pretrained posterior model for implementation, and fine-tune it during the optimization. Extensive tests on both economic and financial simulators verify that the posterior distribution strongly promotes EDOs in such DOPs widely existed in social science.",
      "authors": [
        "Peng Yang",
        "Zhenhua Yang",
        "Boquan Jiang",
        "Chenkai Wang",
        "Ke Tang",
        "Xin Yao"
      ],
      "primary_category": "cs.NE",
      "categories": [
        "cs.NE",
        "cs.LG"
      ],
      "published": "2026-01-27 11:15:06+00:00",
      "link": "https://arxiv.org/pdf/2601.19481v1",
      "tags": [
        "keyword:LNS"
      ],
      "llm_score": 6.0,
      "llm_evidence": "Evolutionary dynamic optimization for online parameter calibration",
      "llm_tags": [
        "keyword:EOH",
        "keyword:EAA"
      ],
      "quick_tier": "6"
    },
    {
      "id": "2601.19607v1",
      "title": "ComAgent: Multi-LLM based Agentic AI Empowered Intelligent Wireless Networks",
      "abstract": "Emerging 6G networks rely on complex cross-layer optimization, yet manually translating high-level intents into mathematical formulations remains a bottleneck. While Large Language Models (LLMs) offer promise, monolithic approaches often lack sufficient domain grounding, constraint awareness, and verification capabilities. To address this, we present ComAgent, a multi-LLM agentic AI framework. ComAgent employs a closed-loop Perception-Planning-Action-Reflection cycle, coordinating specialized agents for literature search, coding, and scoring to autonomously generate solver-ready formulations and reproducible simulations. By iteratively decomposing problems and self-correcting errors, the framework effectively bridges the gap between user intent and execution. Evaluations demonstrate that ComAgent achieves expert-comparable performance in complex beamforming optimization and outperforms monolithic LLMs across diverse wireless tasks, highlighting its potential for automating design in emerging wireless networks.",
      "authors": [
        "Haoyun Li",
        "Ming Xiao",
        "Kezhi Wang",
        "Robert Schober",
        "Dong In Kim",
        "Yong Liang Guan"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-01-27 13:43:59+00:00",
      "link": "https://arxiv.org/pdf/2601.19607v1",
      "tags": [
        "keyword:EOH",
        "keyword:LNS"
      ],
      "llm_score": 6.0,
      "llm_evidence": "Agentic framework for autonomous solver generation and optimization bridges to EAA",
      "llm_tags": [
        "keyword:EAA"
      ],
      "quick_tier": "6"
    },
    {
      "id": "2601.19615v1",
      "title": "An adjacency-based algorithm for computing all extreme-supported non-dominated points of a bi-objective combinatorial optimisation problem",
      "abstract": "Generally, multi-objective optimisation problems are solved exactly or approximated by solving a series of scalarisations, for example by dichotomic search. In this paper, we take a different approach and attempt to compute the set of all extreme-supported non-dominated points of a bi-objective combinatorial optimisation problem by using a neighbourhood-based approach. Whether or not this works depends on the definition of adjacency and we provide sufficient conditions that guarantee its success. The resulting generic algorithm is an alternative to dichotomic search in our setting.   We then apply our generic algorithm to a specific example: the bi-objective minimum weight basis problem, in which we are given a matroid and want to find bases of minimum weight. We use the natural definition of adjacency, in which two bases are adjacent if they differ in exactly one element. Since this satisfies our sufficient condition on the adjacency relation, our generic algorithm works in this case and we analyse its running time, showing that it is polynomial. By tailoring this algorithm specifically to matroids, we obtain one that is faster but no longer transitions between adjacent solutions, instead swapping directly from one extreme-supported point to the next in a combinatorial fashion.",
      "authors": [
        "Oliver Bachtler",
        "Felix Fritz",
        "Stefan Ruzika"
      ],
      "primary_category": "math.OC",
      "categories": [
        "math.OC"
      ],
      "published": "2026-01-27 13:45:54+00:00",
      "link": "https://arxiv.org/pdf/2601.19615v1",
      "tags": [
        "keyword:EAA",
        "keyword:EOH",
        "keyword:LNS"
      ],
      "llm_score": 6.0,
      "llm_evidence": "Neighborhood-based approach for combinatorial optimization relates to large neighborhood search concepts",
      "llm_tags": [
        "keyword:LNS"
      ],
      "quick_tier": "6"
    }
  ]
}
{
  "mode": "standard",
  "generated_at": "2026-02-18T04:38:44.571552+00:00",
  "stats": {
    "mode": "standard",
    "tag_count": 3,
    "deep_divecandidates": 0,
    "deep_cap": 8,
    "deep_selected": 0,
    "quick_candidates": 4,
    "quick_skim_target": 13,
    "quick_selected": 4
  },
  "deep_dive": [],
  "quick_skim": [
    {
      "id": "2602.15473v1",
      "title": "POP: Prior-fitted Optimizer Policies",
      "abstract": "Optimization refers to the task of finding extrema of an objective function. Classical gradient-based optimizers are highly sensitive to hyperparameter choices. In highly non-convex settings their performance relies on carefully tuned learning rates, momentum, and gradient accumulation. To address these limitations, we introduce POP (Prior-fitted Optimizer Policies), a meta-learned optimizer that predicts coordinate-wise step sizes conditioned on the contextual information provided in the optimization trajectory. Our model is learned on millions of synthetic optimization problems sampled from a novel prior spanning both convex and non-convex objectives. We evaluate POP on an established benchmark including 47 optimization functions of various complexity, where it consistently outperforms first-order gradient-based methods, non-convex optimization approaches (e.g., evolutionary strategies), Bayesian optimization, and a recent meta-learned competitor under matched budget constraints. Our evaluation demonstrates strong generalization capabilities without task-specific tuning.",
      "authors": [
        "Jan Kobiolka",
        "Christian Frey",
        "Gresa Shala",
        "Arlind Kadra",
        "Erind Bedalli",
        "Josif Grabocka"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-02-17 10:27:07+00:00",
      "link": "https://arxiv.org/pdf/2602.15473v1",
      "tags": [
        "keyword:EAA",
        "keyword:EOH",
        "keyword:LNS"
      ],
      "llm_score": 7.0,
      "llm_evidence": "meta-learned optimizer policies for efficient automatic algorithm design",
      "llm_tags": [
        "keyword:EOH",
        "keyword:EAA"
      ],
      "quick_tier": "7"
    },
    {
      "id": "2602.15459v1",
      "title": "A Quantum Genetic Algorithm with application to Cosmological Parameters Estimation",
      "abstract": "An Amplitude-Encoded Quantum Genetic Algorithm (AEQGA) has been developed to minimize $χ^2$ functions of different cosmological probes (Supernovae Type Ia, Baryon Acoustic Oscillations, Cosmic Microwave Background Radiation), to find the best-fit value for two cosmological parameters, namely the Hubble Constant and the density matter content of the Universe today. Our main aim is to pave the way to testing the adoption of quantum optimization in the inference of the cosmological parameters that describe the universe evolution. AEQGA computes the merit function classically, and then uses a quantum circuit to entangle the population and perform crossover and mutation operations. The results show consistency with the isocontours of the objective functions. We then tested the general behavior of AEQGA as a function of its hyperparameters and compared it with a second quantum genetic algorithm found in the literature as well as with classical algorithms, finding consistent results.",
      "authors": [
        "Giuseppe Sarracino",
        "Vincenzo Fabrizio Cardone",
        "Roberto Scaramella",
        "Giuseppe Riccio",
        "Andrea Bulgarelli",
        "Carlo Burigana",
        "Luca Cappelli",
        "Stefano Cavuoti",
        "Farida Farsian",
        "Irene Graziotti",
        "Massimo Meneghetti",
        "Giuseppe Murante",
        "Niccolò Parmiggiani",
        "Alessandro Rizzo",
        "Francesco Schillirò",
        "Vincenzo Testa",
        "Tiziana Trombetti"
      ],
      "primary_category": "astro-ph.CO",
      "categories": [
        "astro-ph.CO"
      ],
      "published": "2026-02-17 09:48:29+00:00",
      "link": "https://arxiv.org/pdf/2602.15459v1",
      "tags": [
        "keyword:EAA",
        "keyword:EOH"
      ],
      "llm_score": 6.0,
      "llm_evidence": "Quantum genetic algorithm for optimization aligns with evolution of heuristics",
      "llm_tags": [
        "keyword:EOH"
      ],
      "quick_tier": "6"
    },
    {
      "id": "2602.15564v1",
      "title": "Beyond Static Pipelines: Learning Dynamic Workflows for Text-to-SQL",
      "abstract": "Text-to-SQL has recently achieved impressive progress, yet remains difficult to apply effectively in real-world scenarios. This gap stems from the reliance on single static workflows, fundamentally limiting scalability to out-of-distribution and long-tail scenarios. Instead of requiring users to select suitable methods through extensive experimentation, we attempt to enable systems to adaptively construct workflows at inference time. Through theoretical and empirical analysis, we demonstrate that optimal dynamic policies consistently outperform the best static workflow, with performance gains fundamentally driven by heterogeneity across candidate workflows. Motivated by this, we propose SquRL, a reinforcement learning framework that enhances LLMs' reasoning capability in adaptive workflow construction. We design a rule-based reward function and introduce two effective training mechanisms: dynamic actor masking to encourage broader exploration, and pseudo rewards to improve training efficiency. Experiments on widely-used Text-to-SQL benchmarks demonstrate that dynamic workflow construction consistently outperforms the best static workflow methods, with especially pronounced gains on complex and out-of-distribution queries. The codes are available at https://github.com/Satissss/SquRL",
      "authors": [
        "Yihan Wang",
        "Peiyu Liu",
        "Runyu Chen",
        "Wei Xu"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "published": "2026-02-17 13:24:56+00:00",
      "link": "https://arxiv.org/pdf/2602.15564v1",
      "tags": [
        "keyword:EAA",
        "keyword:EOH",
        "keyword:LNS"
      ],
      "llm_score": 6.0,
      "llm_evidence": "Learning dynamic workflows for inference-time adaptation aligns with efficient automatic algorithms",
      "llm_tags": [
        "keyword:EAA"
      ],
      "quick_tier": "6"
    },
    {
      "id": "2602.15635v1",
      "title": "On inferring cumulative constraints",
      "abstract": "Cumulative constraints are central in scheduling with constraint programming, yet propagation is typically performed per constraint, missing multi-resource interactions and causing severe slowdowns on some benchmarks. I present a preprocessing method for inferring additional cumulative constraints that capture such interactions without search-time probing. This approach interprets cumulative constraints as linear inequalities over occupancy vectors and generates valid inequalities by (i) discovering covers, the sets of tasks that cannot run in parallel, (ii) strengthening the cover inequalities for the discovered sets with lifting, and (iii) injecting the resulting constraints back into the scheduling problem instance. Experiments on standard RCPSP and RCPSP/max test suites show that these inferred constraints improve search performance and tighten objective bounds on favorable instances, while incurring little degradation on unfavorable ones. Additionally, these experiments discover 25 new lower bounds and five new best solutions; eight of the lower bounds are obtained directly from the inferred constraints.",
      "authors": [
        "Konstantin Sidorov"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-02-17 15:03:43+00:00",
      "link": "https://arxiv.org/pdf/2602.15635v1",
      "tags": [
        "keyword:EAA",
        "keyword:EOH",
        "keyword:LNS"
      ],
      "llm_score": 6.0,
      "llm_evidence": "preprocessing for scheduling constraints to improve search efficiency",
      "llm_tags": [
        "keyword:LNS",
        "keyword:EAA"
      ],
      "quick_tier": "6"
    }
  ]
}
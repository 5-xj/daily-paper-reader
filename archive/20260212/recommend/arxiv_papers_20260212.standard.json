{
  "mode": "standard",
  "generated_at": "2026-02-12T04:38:15.402716+00:00",
  "stats": {
    "mode": "standard",
    "tag_count": 3,
    "deep_divecandidates": 1,
    "deep_cap": 8,
    "deep_selected": 1,
    "quick_candidates": 8,
    "quick_skim_target": 13,
    "quick_selected": 8
  },
  "deep_dive": [
    {
      "id": "2602.10891v1",
      "title": "Interactive LLM-assisted Curriculum Learning for Multi-Task Evolutionary Policy Search",
      "abstract": "Multi-task policy search is a challenging problem because policies are required to generalize beyond training cases. Curriculum learning has proven to be effective in this setting, as it introduces complexity progressively. However, designing effective curricula is labor-intensive and requires extensive domain expertise. LLM-based curriculum generation has only recently emerged as a potential solution, but was limited to operate in static, offline modes without leveraging real-time feedback from the optimizer. Here we propose an interactive LLM-assisted framework for online curriculum generation, where the LLM adaptively designs training cases based on real-time feedback from the evolutionary optimization process. We investigate how different feedback modalities, ranging from numeric metrics alone to combinations with plots and behavior visualizations, influence the LLM ability to generate meaningful curricula. Through a 2D robot navigation case study, tackled with genetic programming as optimizer, we evaluate our approach against static LLM-generated curricula and expert-designed baselines. We show that interactive curriculum generation outperforms static approaches, with multimodal feedback incorporating both progression plots and behavior visualizations yielding performance competitive with expert-designed curricula. This work contributes to understanding how LLMs can serve as interactive curriculum designers for embodied AI systems, with potential extensions to broader evolutionary robotics applications.",
      "authors": [
        "Berfin Sakallioglu",
        "Giorgia Nadizar",
        "Eric Medvet"
      ],
      "primary_category": "cs.NE",
      "categories": [
        "cs.NE",
        "cs.AI"
      ],
      "published": "2026-02-11 14:21:52+00:00",
      "link": "https://arxiv.org/pdf/2602.10891v1",
      "tags": [
        "keyword:EOH",
        "keyword:LNS"
      ],
      "llm_score": 8.0,
      "llm_evidence": "Evolutionary policy search with automated curriculum generation",
      "llm_tags": [
        "keyword:EOH",
        "keyword:EAA"
      ]
    }
  ],
  "quick_skim": [
    {
      "id": "2602.10561v1",
      "title": "Morphogenetic Assembly and Adaptive Control for Heterogeneous Modular Robots",
      "abstract": "This paper presents a closed-loop automation framework for heterogeneous modular robots, covering the full pipeline from morphological construction to adaptive control. In this framework, a mobile manipulator handles heterogeneous functional modules including structural, joint, and wheeled modules to dynamically assemble diverse robot configurations and provide them with immediate locomotion capability. To address the state-space explosion in large-scale heterogeneous reconfiguration, we propose a hierarchical planner: the high-level planner uses a bidirectional heuristic search with type-penalty terms to generate module-handling sequences, while the low level planner employs A* search to compute optimal execution trajectories. This design effectively decouples discrete configuration planning from continuous motion execution. For adaptive motion generation of unknown assembled configurations, we introduce a GPU accelerated Annealing-Variance Model Predictive Path Integral (MPPI) controller. By incorporating a multi stage variance annealing strategy to balance global exploration and local convergence, the controller enables configuration-agnostic, real-time motion control. Large scale simulations show that the type-penalty term is critical for planning robustness in heterogeneous scenarios. Moreover, the greedy heuristic produces plans with lower physical execution costs than the Hungarian heuristic. The proposed annealing-variance MPPI significantly outperforms standard MPPI in both velocity tracking accuracy and control frequency, achieving real time control at 50 Hz. The framework validates the full-cycle process, including module assembly, robot merging and splitting, and dynamic motion generation.",
      "authors": [
        "Chongxi Meng",
        "Da Zhao",
        "Yifei Zhao",
        "Minghao Zeng",
        "Yanmin Zhou",
        "Zhipeng Wang",
        "Bin He"
      ],
      "primary_category": "cs.RO",
      "categories": [
        "cs.RO"
      ],
      "published": "2026-02-11 06:18:04+00:00",
      "link": "https://arxiv.org/pdf/2602.10561v1",
      "tags": [
        "keyword:LNS"
      ],
      "llm_score": 7.0,
      "llm_evidence": "Hierarchical planner using bidirectional heuristic search for large-scale reconfiguration",
      "llm_tags": [
        "keyword:LNS",
        "keyword:EOH",
        "keyword:EAA"
      ],
      "quick_tier": "7"
    },
    {
      "id": "2602.10794v1",
      "title": "Transport, Don't Generate: Deterministic Geometric Flows for Combinatorial Optimization",
      "abstract": "Recent advances in Neural Combinatorial Optimization (NCO) have been dominated by diffusion models that treat the Euclidean Traveling Salesman Problem (TSP) as a stochastic $N \\times N$ heatmap generation task. In this paper, we propose CycFlow, a framework that replaces iterative edge denoising with deterministic point transport. CycFlow learns an instance-conditioned vector field that continuously transports input 2D coordinates to a canonical circular arrangement, where the optimal tour is recovered from this $2N$ dimensional representation via angular sorting. By leveraging data-dependent flow matching, we bypass the quadratic bottleneck of edge scoring in favor of linear coordinate dynamics. This paradigm shift accelerates solving speed by up to three orders of magnitude compared to state-of-the-art diffusion baselines, while maintaining competitive optimality gaps.",
      "authors": [
        "Benjy Friedmann",
        "Nadav Dym"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "published": "2026-02-11 12:38:12+00:00",
      "link": "https://arxiv.org/pdf/2602.10794v1",
      "tags": [
        "keyword:EAA",
        "keyword:EOH",
        "keyword:LNS"
      ],
      "llm_score": 6.0,
      "llm_evidence": "Neural combinatorial optimization for TSP using geometric flows",
      "llm_tags": [
        "keyword:LNS",
        "keyword:EAA"
      ],
      "quick_tier": "6"
    },
    {
      "id": "2602.11126v1",
      "title": "The Offline-Frontier Shift: Diagnosing Distributional Limits in Generative Multi-Objective Optimization",
      "abstract": "Offline multi-objective optimization (MOO) aims to recover Pareto-optimal designs given a finite, static dataset. Recent generative approaches, including diffusion models, show strong performance under hypervolume, yet their behavior under other established MOO metrics is less understood. We show that generative methods systematically underperform evolutionary alternatives with respect to other metrics, such as generational distance. We relate this failure mode to the offline-frontier shift, i.e., the displacement of the offline dataset from the Pareto front, which acts as a fundamental limitation in offline MOO. We argue that overcoming this limitation requires out-of-distribution sampling in objective space (via an integral probability metric) and empirically observe that generative methods remain conservatively close to the offline objective distribution. Our results position offline MOO as a distribution-shift--limited problem and provide a diagnostic lens for understanding when and why generative optimization methods fail.",
      "authors": [
        "Stephanie Holly",
        "Alexandru-Ciprian Zăvoianu",
        "Siegfried Silber",
        "Sepp Hochreiter",
        "Werner Zellinger"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-02-11 18:38:40+00:00",
      "link": "https://arxiv.org/pdf/2602.11126v1",
      "tags": [
        "keyword:EOH"
      ],
      "llm_score": 7.0,
      "llm_evidence": "Compares generative methods with evolutionary alternatives in multi-objective optimization",
      "llm_tags": [
        "keyword:EOH"
      ],
      "quick_tier": "7"
    },
    {
      "id": "2602.10854v1",
      "title": "Automated Model Design using Gated Neuron Selection in Telecom",
      "abstract": "The telecommunications industry is experiencing rapid growth in adopting deep learning for critical tasks such as traffic prediction, signal strength prediction, and quality of service optimisation. However, designing neural network architectures for these applications remains challenging and time-consuming, particularly when targeting compact models suitable for resource-constrained network environments. Therefore, there is a need for automating the model design process to create high-performing models efficiently. This paper introduces TabGNS (Tabular Gated Neuron Selection), a novel gradient-based Neural Architecture Search (NAS) method specifically tailored for tabular data in telecommunications networks. We evaluate TabGNS across multiple telecommunications and generic tabular datasets, demonstrating improvements in prediction performance while reducing the architecture size by 51-82% and reducing the search time by up to 36x compared to state-of-the-art tabular NAS methods. Integrating TabGNS into the model lifecycle management enables automated design of neural networks throughout the lifecycle, accelerating deployment of ML solutions in telecommunications networks.",
      "authors": [
        "Adam Orucu",
        "Marcus Medhage",
        "Farnaz Moradi",
        "Andreas Johnsson",
        "Sarunas Girdzijauskas"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "published": "2026-02-11 13:40:48+00:00",
      "link": "https://arxiv.org/pdf/2602.10854v1",
      "tags": [
        "keyword:LNS"
      ],
      "llm_score": 6.0,
      "llm_evidence": "Automated neural architecture search for efficient model design",
      "llm_tags": [
        "keyword:EAA"
      ],
      "quick_tier": "6"
    },
    {
      "id": "2602.10872v1",
      "title": "On generating Special Quasirandom Structures: Optimization for the DFT computational efficiency",
      "abstract": "We present our novel evolutionary algorithm for generating Special Quasirandom Structures (SQS) designed to optimize the computational efficiency of Density Functional Theory (DFT) computations. Operating on the premise that symmetry proxies non-randomness, we rigorously filter out 1.P1 candidate structures prior to evaluating correlation functions. Our extinction-based workflow includes the seeding, filtration, evaluation, extinction, and repopulation phases to produce efficient supercells with maximal local environmental distinctness. We compare our results against those generated by established software packages, on the example of the W\\textsubscript{70}Cr\\textsubscript{30} alloy. Although standard tools achieve (marginally) lower correlation errors, our best-performing structures require approximately five times fewer unique displacements for phonon calculations. This approach sacrifices negligible quantitative disorder accuracy to significantly reduce the computational cost of modeling thermal properties.",
      "authors": [
        "Andrzej P. Kądzielawa"
      ],
      "primary_category": "cond-mat.dis-nn",
      "categories": [
        "cond-mat.dis-nn",
        "cond-mat.mtrl-sci"
      ],
      "published": "2026-02-11 14:01:19+00:00",
      "link": "https://arxiv.org/pdf/2602.10872v1",
      "tags": [
        "keyword:EAA"
      ],
      "llm_score": 6.0,
      "llm_evidence": "novel evolutionary algorithm for generating structures with efficient workflow",
      "llm_tags": [
        "keyword:EOH",
        "keyword:EAA"
      ],
      "quick_tier": "6"
    },
    {
      "id": "2602.10874v1",
      "title": "C-MOP: Integrating Momentum and Boundary-Aware Clustering for Enhanced Prompt Evolution",
      "abstract": "Automatic prompt optimization is a promising direction to boost the performance of Large Language Models (LLMs). However, existing methods often suffer from noisy and conflicting update signals. In this research, we propose C-MOP (Cluster-based Momentum Optimized Prompting), a framework that stabilizes optimization via Boundary-Aware Contrastive Sampling (BACS) and Momentum-Guided Semantic Clustering (MGSC). Specifically, BACS utilizes batch-level information to mine tripartite features--Hard Negatives, Anchors, and Boundary Pairs--to precisely characterize the typical representation and decision boundaries of positive and negative prompt samples. To resolve semantic conflicts, MGSC introduces a textual momentum mechanism with temporal decay that distills persistent consensus from fluctuating gradients across iterations. Extensive experiments demonstrate that C-MOP consistently outperforms SOTA baselines like PromptWizard and ProTeGi, yielding average gains of 1.58% and 3.35%. Notably, C-MOP enables a general LLM with 3B activated parameters to surpass a 70B domain-specific dense LLM, highlighting its effectiveness in driving precise prompt evolution. The code is available at https://github.com/huawei-noah/noah-research/tree/master/C-MOP.",
      "authors": [
        "Binwei Yan",
        "Yifei Fu",
        "Mingjian Zhu",
        "Hanting Chen",
        "Mingxuan Yuan",
        "Yunhe Wang",
        "Hailin Hu"
      ],
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "published": "2026-02-11 14:04:47+00:00",
      "link": "https://arxiv.org/pdf/2602.10874v1",
      "tags": [
        "keyword:EAA",
        "keyword:EOH"
      ],
      "llm_score": 6.0,
      "llm_evidence": "Automatic prompt evolution aligns with the evolution of heuristics and efficient automatic algorithms",
      "llm_tags": [
        "keyword:EOH",
        "keyword:EAA"
      ],
      "quick_tier": "6"
    },
    {
      "id": "2602.10885v1",
      "title": "Reinforcing Chain-of-Thought Reasoning with Self-Evolving Rubrics",
      "abstract": "Despite chain-of-thought (CoT) playing crucial roles in LLM reasoning, directly rewarding it is difficult: training a reward model demands heavy human labeling efforts, and static RMs struggle with evolving CoT distributions and reward hacking. These challenges motivate us to seek an autonomous CoT rewarding approach that requires no human annotation efforts and can evolve gradually. Inspired by recent self-evolving training methods, we propose \\textbf{RLCER} (\\textbf{R}einforcement \\textbf{L}earning with \\textbf{C}oT Supervision via Self-\\textbf{E}volving \\textbf{R}ubrics), which enhances the outcome-centric RLVR by rewarding CoTs with self-proposed and self-evolving rubrics. We show that self-proposed and self-evolving rubrics provide reliable CoT supervision signals even without outcome rewards, enabling RLCER to outperform outcome-centric RLVR. Moreover, when used as in-prompt hints, these self-proposed rubrics further improve inference-time performance.",
      "authors": [
        "Leheng Sheng",
        "Wenchang Ma",
        "Ruixin Hong",
        "Xiang Wang",
        "An Zhang",
        "Tat-Seng Chua"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "published": "2026-02-11 14:13:46+00:00",
      "link": "https://arxiv.org/pdf/2602.10885v1",
      "tags": [
        "keyword:EOH"
      ],
      "llm_score": 6.0,
      "llm_evidence": "Self-evolving rubrics for autonomous reasoning align with evolution of heuristics and efficient automatic algorithms",
      "llm_tags": [
        "keyword:EOH",
        "keyword:EAA"
      ],
      "quick_tier": "6"
    },
    {
      "id": "2602.10971v1",
      "title": "A Jointly Efficient and Optimal Algorithm for Heteroskedastic Generalized Linear Bandits with Adversarial Corruptions",
      "abstract": "We consider the problem of heteroskedastic generalized linear bandits (GLBs) with adversarial corruptions, which subsumes various stochastic contextual bandit settings, including heteroskedastic linear bandits and logistic/Poisson bandits. We propose HCW-GLB-OMD, which consists of two components: an online mirror descent (OMD)-based estimator and Hessian-based confidence weights to achieve corruption robustness. This is computationally efficient in that it only requires ${O}(1)$ space and time complexity per iteration. Under the self-concordance assumption on the link function, we show a regret bound of $\\tilde{O}\\left( d \\sqrt{\\sum_t g(τ_t) \\dotμ_{t,\\star}} + d^2 g_{\\max} κ+ d κC \\right)$, where $\\dotμ_{t,\\star}$ is the slope of $μ$ around the optimal arm at time $t$, $g(τ_t)$'s are potentially exogenously time-varying dispersions (e.g., $g(τ_t) = σ_t^2$ for heteroskedastic linear bandits, $g(τ_t) = 1$ for Bernoulli and Poisson), $g_{\\max} = \\max_{t \\in [T]} g(τ_t)$ is the maximum dispersion, and $C \\geq 0$ is the total corruption budget of the adversary. We complement this with a lower bound of $\\tildeΩ(d \\sqrt{\\sum_t g(τ_t) \\dotμ_{t,\\star}} + d C)$, unifying previous problem-specific lower bounds. Thus, our algorithm achieves, up to a $κ$-factor in the corruption term, instance-wise minimax optimality simultaneously across various instances of heteroskedastic GLBs with adversarial corruptions.",
      "authors": [
        "Sanghwa Kim",
        "Junghyun Lee",
        "Se-Young Yun"
      ],
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "stat.ML"
      ],
      "published": "2026-02-11 16:01:06+00:00",
      "link": "https://arxiv.org/pdf/2602.10971v1",
      "tags": [
        "keyword:EAA"
      ],
      "llm_score": 6.0,
      "llm_evidence": "Proposes a computationally efficient and optimal algorithm for bandit problems",
      "llm_tags": [
        "keyword:EAA"
      ],
      "quick_tier": "6"
    }
  ]
}
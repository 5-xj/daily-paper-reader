{
  "mode": "standard",
  "generated_at": "2026-01-27T04:00:23.552682+00:00",
  "stats": {
    "mode": "standard",
    "tag_count": 3,
    "deep_divecandidates": 2,
    "deep_cap": 8,
    "deep_selected": 2,
    "quick_candidates": 3,
    "quick_skim_target": 13,
    "quick_selected": 3
  },
  "deep_dive": [
    {
      "id": "2601.18446v1",
      "title": "Scaling Behaviors of Evolutionary Algorithms on GPUs: When Does Parallelism Pay Off?",
      "abstract": "Evolutionary algorithms (EAs) are increasingly implemented on graphics processing units (GPUs) to leverage parallel processing capabilities for enhanced efficiency. However, existing studies largely emphasize the raw speedup obtained by porting individual algorithms from CPUs to GPUs. Consequently, these studies offer limited insight into when and why GPU parallelism fundamentally benefits EAs. To address this gap, we investigate how GPU parallelism alters the behavior of EAs beyond simple acceleration metrics. We conduct a systematic empirical study of 16 representative EAs on 30 benchmark problems. Specifically, we compare CPU and GPU executions across a wide range of problem dimensionalities and population sizes. Our results reveal that the impact of GPU acceleration is highly heterogeneous and depends strongly on algorithmic structure. We further demonstrate that conventional fixed-budget evaluation based on the number of function evaluations (FEs) is inadequate for GPU execution. In contrast, fixed-time evaluation uncovers performance characteristics that are unobservable under small or practically constrained FE budgets, particularly for adaptive and exploration-oriented algorithms. Moreover, we identify distinct scaling regimes in which GPU parallelism is beneficial, saturates, or degrades as problem dimensionality and population size increase. Crucially, we show that large populations enabled by GPUs not only improve hardware utilization but also reveal algorithm-specific convergence and diversity dynamics that are difficult to observe under CPU-constrained settings. Consequently, our findings indicate that GPU parallelism is not strictly an implementation detail, but a pivotal factor that influences how EAs should be evaluated, compared, and designed for modern computing platforms.",
      "authors": [
        "Xinmeng Yu",
        "Tao Jiang",
        "Ran Cheng",
        "Yaochu Jin",
        "Kay Chen Tan"
      ],
      "primary_category": "cs.NE",
      "categories": [
        "cs.NE"
      ],
      "published": "2026-01-26 12:55:21+00:00",
      "link": "https://arxiv.org/pdf/2601.18446v1",
      "tags": [
        "keyword:EAA",
        "keyword:EOH"
      ],
      "llm_score": 8.0,
      "llm_evidence": "empirical study of evolutionary algorithms and their scaling behaviors",
      "llm_tags": [
        "keyword:EOH"
      ]
    },
    {
      "id": "2601.18542v1",
      "title": "XFit: Global Optimization and Degeneracy Mapping in X-ray Spectral Modeling",
      "abstract": "The standard approach to modeling X-ray spectral data relies on local optimization methods, such as the Levenberg-Marquardt algorithm. While effective for simple models and speedy spectral fitting, these local optimizers are prone to becoming trapped in local minima, particularly in high-dimensional or degenerate parameter spaces, and typically require extensive user intervention. In this work, we introduce XFit, a global optimization method for fitting X-ray data, which makes extensive use of the Ferret evolutionary algorithm. XFit enables automated exploration of complex parameter spaces, efficient mapping of confidence intervals, and identification of degenerate solutions that may be overlooked by local methods. We demonstrate the performance of XFit using two representative X-ray sources: the Central Compact Object in Cassiopeia A and the supernova remnant G41.1-0.3. These examples span both low- and high-dimensional models, allowing us to illustrate the advantages of global optimization. In both cases, XFit produces solutions that are consistent with or improve upon those found with traditional methods, while also revealing alternative fits or degenerate solutions within statistically acceptable confidence levels. The automated mapping of parameter space offered by XFit makes it a powerful complement to existing spectral fitting tools, particularly as models and data quality become increasingly complex. Future work will expand the application of XFit to broader datasets and more physically motivated models.",
      "authors": [
        "Austin MacMaster",
        "Adam Rogers",
        "Jason Fiege",
        "Rebecca Man",
        "Samar Safi-Harb"
      ],
      "primary_category": "astro-ph.HE",
      "categories": [
        "astro-ph.HE",
        "astro-ph.IM"
      ],
      "published": "2026-01-26 14:48:08+00:00",
      "link": "https://arxiv.org/pdf/2601.18542v1",
      "tags": [
        "keyword:EAA"
      ],
      "llm_score": 8.0,
      "llm_evidence": "uses Ferret evolutionary algorithm for global optimization",
      "llm_tags": [
        "keyword:EOH",
        "keyword:EAA"
      ]
    }
  ],
  "quick_skim": [
    {
      "id": "2601.18226v1",
      "title": "Yunjue Agent Tech Report: A Fully Reproducible, Zero-Start In-Situ Self-Evolving Agent System for Open-Ended Tasks",
      "abstract": "Conventional agent systems often struggle in open-ended environments where task distributions continuously drift and external supervision is scarce. Their reliance on static toolsets or offline training lags behind these dynamics, leaving the system's capability boundaries rigid and unknown. To address this, we propose the In-Situ Self-Evolving paradigm. This approach treats sequential task interactions as a continuous stream of experience, enabling the system to distill short-term execution feedback into long-term, reusable capabilities without access to ground-truth labels. Within this framework, we identify tool evolution as the critical pathway for capability expansion, which provides verifiable, binary feedback signals. Within this framework, we develop Yunjue Agent, a system that iteratively synthesizes, optimizes, and reuses tools to navigate emerging challenges. To optimize evolutionary efficiency, we further introduce a Parallel Batch Evolution strategy. Empirical evaluations across five diverse benchmarks under a zero-start setting demonstrate significant performance gains over proprietary baselines. Additionally, complementary warm-start evaluations confirm that the accumulated general knowledge can be seamlessly transferred to novel domains. Finally, we propose a novel metric to monitor evolution convergence, serving as a function analogous to training loss in conventional optimization. We open-source our codebase, system traces, and evolved tools to facilitate future research in resilient, self-evolving intelligence.",
      "authors": [
        "Haotian Li",
        "Shijun Yang",
        "Weizhen Qi",
        "Silei Zhao",
        "Rui Hua",
        "Mingzhu Song",
        "Xiaojian Yang",
        "Chao Peng"
      ],
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "published": "2026-01-26 07:27:47+00:00",
      "link": "https://arxiv.org/pdf/2601.18226v1",
      "tags": [
        "keyword:EOH"
      ],
      "llm_score": 7.0,
      "llm_evidence": "Self-evolving agent system aligns with evolution of heuristics and automated algorithm design",
      "llm_tags": [
        "keyword:EOH",
        "keyword:EAA"
      ],
      "quick_tier": "7"
    },
    {
      "id": "2601.18756v1",
      "title": "Efficient Trotter-Suzuki Schemes for Long-time Quantum Dynamics",
      "abstract": "Accurately simulating long-time dynamics of many-body systems is a challenge in both classical and quantum computing due to the accumulation of Trotter errors. While low-order Trotter-Suzuki decompositions are straightforward to implement, their rapidly growing error limits access to long-time observables. We present a framework for constructing efficient high-order Trotter-Suzuki schemes by identifying their structure and directly optimizing their parameters over a high-dimensional space. This method enables the discovery of new schemes with significantly improved efficiency compared to traditional constructions, such as those by Suzuki and Yoshida. Based on the theoretical efficiency and practical performance, we recommend two novel highly efficient schemes at $4^{\\textrm{th}}$ and $6^{\\textrm{th}}$ order. We also demonstrate the effectiveness of these decompositions on the Heisenberg model and the quantum harmonic oscillator, and find that for a fixed final time they perform better across the computational cost. Even when using large time steps, they surpass established low-order schemes like the Leapfrog. Finally, we investigate the in-practice performance of different Trotter schemes and find the decompositions with more uniform coefficients tend to feature improved error accumulation over long times. We have included this observation into our choice of recommended schemes.",
      "authors": [
        "Marko Maležič",
        "Johann Ostmeyer"
      ],
      "primary_category": "quant-ph",
      "categories": [
        "quant-ph",
        "cond-mat.stat-mech",
        "cond-mat.str-el",
        "hep-lat",
        "physics.comp-ph"
      ],
      "published": "2026-01-26 18:26:08+00:00",
      "link": "https://arxiv.org/pdf/2601.18756v1",
      "tags": [
        "keyword:EAA"
      ],
      "llm_score": 6.0,
      "llm_evidence": "optimizing parameters over high-dimensional space for efficiency",
      "llm_tags": [
        "keyword:EOH",
        "keyword:EAA"
      ],
      "quick_tier": "6"
    },
    {
      "id": "2601.18690v1",
      "title": "AI-Driven Fuzzing for Vulnerability Assessment of 5G Traffic Steering Algorithms",
      "abstract": "Traffic Steering (TS) dynamically allocates user traffic across cells to enhance Quality of Experience (QoE), load balance, and spectrum efficiency in 5G networks. However, TS algorithms remain vulnerable to adversarial conditions such as interference spikes, handover storms, and localized outages. To address this, an AI-driven fuzz testing framework based on the Non-Dominated Sorting Genetic Algorithm II (NSGA-II) is proposed to systematically expose hidden vulnerabilities. Using NVIDIA Sionna, five TS algorithms are evaluated across six scenarios. Results show that AI-driven fuzzing detects 34.3% more total vulnerabilities and 5.8% more critical failures than traditional testing, achieving superior diversity and edge-case discovery. The observed variance in critical failure detection underscores the stochastic nature of rare vulnerabilities. These findings demonstrate that AI-driven fuzzing offers an effective and scalable validation approach for improving TS algorithm robustness and ensuring resilient 6G-ready networks.",
      "authors": [
        "Seyed Bagher Hashemi Natanzi",
        "Hossein Mohammadi",
        "Bo Tang",
        "Vuk Marojevic"
      ],
      "primary_category": "eess.SP",
      "categories": [
        "eess.SP",
        "cs.NI",
        "eess.SY"
      ],
      "published": "2026-01-26 17:06:37+00:00",
      "link": "https://arxiv.org/pdf/2601.18690v1",
      "tags": [
        "keyword:EAA"
      ],
      "llm_score": 7.0,
      "llm_evidence": "genetic algorithm for vulnerability assessment and edge-case discovery",
      "llm_tags": [
        "keyword:EOH",
        "keyword:EAA"
      ],
      "quick_tier": "7"
    }
  ]
}
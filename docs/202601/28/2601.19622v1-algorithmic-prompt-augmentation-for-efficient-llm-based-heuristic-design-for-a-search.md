# Algorithmic Prompt-Augmentation for Efficient LLM-Based Heuristic Design for A* Search
# 针对 A* 搜索的高效大语言模型启发式设计的算法提示词增强

**Authors**: Thomas Bömer, Nico Koltermann, Max Disselnmeyer, Bastian Amberg, Anne Meyer \\
**Date**: 2026-01-27 \\
**PDF**: https://arxiv.org/pdf/2601.19622v1 \\
**Tags**: <span class="tag-label tag-blue">精读区</span> <span class="tag-label tag-pink">keyword:EOH</span> <span class="tag-label tag-pink">keyword:EAA</span> \\
**Score**: 10.0 \\
**Evidence**: Directly extends the Evolution of Heuristics framework for automated search design \\

---

## Abstract
Heuristic functions are essential to the performance of tree search algorithms such as A*, where their accuracy and efficiency directly impact search outcomes. Traditionally, such heuristics are handcrafted, requiring significant expertise. Recent advances in large language models (LLMs) and evolutionary frameworks have opened the door to automating heuristic design. In this paper, we extend the Evolution of Heuristics (EoH) framework to investigate the automated generation of guiding heuristics for A* search. We introduce a novel domain-agnostic prompt augmentation strategy that includes the A* code into the prompt to leverage in-context learning, named Algorithmic - Contextual EoH (A-CEoH). To evaluate the effectiveness of A-CeoH, we study two problem domains: the Unit-Load Pre-Marshalling Problem (UPMP), a niche problem from warehouse logistics, and the classical sliding puzzle problem (SPP). Our computational experiments show that A-CEoH can significantly improve the quality of the generated heuristics and even outperform expert-designed heuristics.

## 摘要
启发式函数对于 A* 等

---

## 论文详细总结（自动生成）

这篇论文探讨了如何利用大语言模型（LLM）自动设计用于 **A* 搜索算法**的启发式函数（Heuristic Functions），并提出了一种通过增强提示词（Prompt）来提升生成质量的方法。

以下是对该论文的深度结构化总结：

### 1. 核心问题与研究动机
*   **核心问题**：传统的 A* 启发式函数依赖专家手工设计，既耗时又需要深厚的领域知识。虽然现有研究已利用 LLM 自动生成贪心算法的启发式规则，但在需要复杂搜索（如 A*）的约束优化问题上，LLM 生成的启发式函数往往表现不佳。
*   **研究动机**：
    *   **填补空白**：针对 A* 搜索的 LLM 自动启发式设计研究较少。
    *   **提升效率**：探索如何通过提供“算法上下文”让 LLM 理解启发式函数在搜索算法中的具体作用。
    *   **模型潜力**：验证小型本地模型（如 Qwen）在特定提示词增强下是否能超越大型通用模型（如 GPT-4o）。

### 2. 方法论：A-CEoH 框架
论文在 **EoH（Evolution of Heuristics）** 进化框架的基础上，提出了 **A-CEoH（Algorithmic-Contextual EoH）**。

*   **核心思想**：在发送给 LLM 的提示词中，不仅包含问题描述，还直接嵌入 **A* 算法的核心代码**（如驱动程序、目标检测、邻居生成等）。通过这种“算法上下文增强”，利用 LLM 的上下文学习（In-Context Learning）能力，使其生成的代码能更好地适配 A* 的搜索动力学。
*   **关键技术细节**：
    *   **进化流程**：初始化种群 -> 评估（计算 Fitness）-> 选择优秀个体 -> 变异/交叉（由 LLM 执行）-> 迭代。
    *   **提示词策略**：
        *   **P-CEoH**：加入详细的问题背景描述。
        *   **A-CEoH**：加入 A* 算法的 Python 代码片段。
        *   **PA-CEoH**：结合上述两者。
    *   **适应度函数（Fitness）**：计算生成的启发式函数在测试实例上所需的移动步数与理论下界（Lower Bound）的平均相对偏差。偏差越小，性能越好。

### 3. 实验设计
*   **实验场景**：
    1.  **UPMP（单元载荷预排序问题）**：一种新兴的仓库物流问题，专家设计的启发式算法极少。
    2.  **SPP（滑动拼图问题）**：经典的 20×20 大规模拼图。在此规模下，传统的模式数据库（PDB）因计算开销过大而失效。
*   **对比基准（Benchmark）**：
    *   **算法框架对比**：原始 EoH、P-CEoH、A-CEoH、PA-CEoH。
    *   **模型对比**：GPT-4o、Qwen2.5-Coder-32B、Gemma2-27B。
    *   **人类专家对比**：与文献中已发表的最优 A* 启发式算法进行性能和耗时对比。

### 4. 资源与算力
*   **硬件环境**：使用 AMD EPYC 7401P 处理器，64 GB RAM。
*   **模型部署**：
    *   GPT-4o 通过 API 调用。
    *   Qwen2.5-Coder-32B 和 Gemma2-27B 为本地部署。
*   **实验规模**：每个实验运行 20 代，每代生成 80 个候选启发式函数，总计每个实验运行约 1600 次提示词请求。

### 5. 实验数量与充分性
*   **实验量**：UPMP 每个模型做 10 组实验，SPP 每个模型做 5 组实验。
*   **充分性**：
    *   涵盖了从“冷门领域”到“经典领域”的跨度。
    *   进行了消融实验（对比不同提示词增强的效果）。
    *   使用了独立的训练集（10 个实例）和测试集（30 个实例）来验证泛化性。
    *   **评价**：实验设计较为严谨，通过多轮运行减少了 LLM 生成随机性带来的偏差。

### 6. 主要结论与发现
*   **算法上下文至关重要**：引入 A* 代码（A-CEoH）显著提升了启发式函数的质量，尤其是在搜索空间复杂的 SPP 问题上。
*   **小模型逆袭**：经过算法增强的 **Qwen2.5-Coder-32B** 在多个指标上优于参数量更大的 GPT-4o，证明了针对性提示词对特定任务的巨大增益。
*   **超越人类专家**：在 UPMP 问题中，LLM 生成的启发式函数在保持最优性的同时
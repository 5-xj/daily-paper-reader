Title: MetaGen: Self-Evolving Roles and Topologies for Multi-Agent LLM Reasoning

URL Source: https://arxiv.org/pdf/2601.19290v1

Published Time: Wed, 28 Jan 2026 01:38:14 GMT

Number of Pages: 9

Markdown Content:
# MetaGen: Self-Evolving Roles and Topologies for Multi-Agent LLM Reasoning 

Yimeng Wang 1* , Jiaxing Zhao 2* , Hongbin Xie 2 , Hexing Ma 1

Yuzhen Lei 1 , Shuangxue Liu 1 , Xuan Song 1,2† , Zichen Zhang 3 and Haoran Zhang 3†

> 1

School of Artificial Intelligence, Jilin University 

> 2

Department of Computer Science and Engineering, Southern University of Science and Technology 

> 3

School of Urban Planning and Design, Peking University 

{yimeng24, jiaxing25, hxma24, leiyz25, sxliu25 }@mails.jlu.edu.cn, 12131108@mail.sustech.edu.cn, songxuan@jlu.edu.cn, {zhangzc9752, h.zhang }@pku.edu.cn 

Abstract 

Large language models are increasingly deployed as multi-agent systems, where specialized roles communicate and collaborate through structured interactions to solve complex tasks that often ex-ceed the capacity of a single agent. However, most existing systems still rely on a fixed role library and an execution-frozen interaction topology, a rigid design choice that frequently leads to task mis-match, prevents timely adaptation when new ev-idence emerges during reasoning, and further in-flates inference cost. We introduce MetaGen , a training-free framework that adapts both the role space and the collaboration topology at inference time, without updating base model weights. Meta-Gen generates and rewrites query-conditioned role specifications to maintain a controllable dynamic role pool, then instantiates a constrained execution graph around a minimal backbone. During execu-tion, it iteratively updates role prompts and adjusts structural decisions using lightweight feedback sig-nals. Experiments on code generation and multi-step reasoning benchmarks show that MetaGen im-proves the accuracy and cost tradeoff over strong multi-agent baselines. 

1 Introduction 

Large language models (LLMs) are rapidly evolving from single-turn conversational responders into general-purpose problem solvers that can plan, critique, write code, and interact with external tools[Du et al. , 2023; Shinn et al. ,2023]. A natural next step is to organize multiple LLM in-stances into Multi-Agent Systems (MAS)[Li et al. , 2023; Wu et al. , 2024; Tang et al. , 2024; Chen et al. , 2024a; Liu et al. , 2025], where specialized roles collaborate to de-compose complex tasks and cross-check intermediate con-clusions. Recent systems have shown that role-playing and structured collaboration can substantially outperform single-agent prompting on reasoning, tool use, and software engi-neering workflows [Chen et al. , 2024b; Hong et al. , 2023]. 

> *

Equal contribution. 

> †

Corresponding author. 

Figure 1: Overview and positioning of MetaGen. Unlike fixed-role/fixed-topology multi-agent systems and training-based topol-ogy designers with execution-frozen graphs, MetaGen enables training-free, query-conditioned role generation and self-evolving topology adjustment entirely at inference time. 

At the same time, prompting paradigms such as debate, re-flection, and search-based reasoning point to a broader les-son: the interaction structure—who speaks, what is pro-duced, and how signals are aggregated—can be as influential as the base model itself [Du et al. , 2023; Yao et al. , 2022; Besta et al. , 2024]. Despite this progress, many deployed MAS still follow a rigid preset design. Developers typically maintain a fixed role pool (e.g., planner/solver/verifier) and hard-code an execution-frozen message-passing protocol [Qian et al. ,2024b] (e.g., chain, star, or fully connected chat). Such rigid-ity leads to three recurring issues. First, task mismatch arises because task granularity, tool preferences, and error modes vary widely, while a fixed role set is often brittle under distri-bution shift. Second, structural closure occurs when a topol-ogy determined once cannot be revised mid-run in response to new evidence or contradictions. Third, cost suffers because tailoring prompts and interaction structures to each task re-

> arXiv:2601.19290v1 [cs.CL] 27 Jan 2026

quires manual engineering. An increasing line of work treats collaboration topology as a key lever and seeks to automate it [Yue et al. , 2025; Zhang 

et al. , 2025b]. Graph-based views model agents as nodes and communications as directed edges, enabling orchestra-tion search, pruning, and topology optimization [Zhuge et al. , 2024; Liu et al. , 2024b; Zhang et al. , 2024a]. Recent topology designers learn or generate task-adaptive graphs, for example by predicting edges with graph models [Zhang et al. , 2024b] or autoregressively generating a team and its links from a query [Li et al. , 2025]. While these approaches reduce manual engineering, two assumptions remain common at in-ference time: roles are drawn from a pre-defined library, and the instance-specific graph is typically frozen once execution begins. These observations motivate a central question: can an MAS generate the roles it needs and update its collabora-tion structure during inference, while keeping cost bounded? We present MetaGen , a training-free framework that adapts both the role space and the collaboration topology at test time (Figure 1). MetaGen introduces an Architect that synthesizes and revises query-conditioned role specifications to form a controllable dynamic role pool. It then constructs an initial execution graph around a minimal backbone and it-eratively updates role prompts and structural decisions using lightweight feedback signals, without modifying backbone weights. To prevent unrestricted chatter, MetaGen enforces explicit controls, including schema/validity checks for gen-erated roles, constrained graph construction, selective activa-tion and edge gating, and cost-aware stopping. MetaGen is designed to be effective and inspectable. It logs generated roles, selected participants, structural edits, and the feedback that triggers each update, supporting reproducibil-ity and diagnosis beyond ad hoc orchestration. This combi-nation of dynamic roles, inference-time evolution, and struc-tured control targets the core limitations of rigid MAS while retaining the engineering advantages of graph-based collabo-ration. In summary, our contributions are: • We propose MetaGen , a training-free framework that improves multi-agent collaboration by adapting role specifications and communication topology during in-ference. • We introduce query-conditioned role generation and re-vision with lightweight validity constraints, yielding a controllable dynamic role pool. • We develop an inference-time evolution loop that up-dates prompts and structural decisions under explicit constraints to bound cost and maintain auditability. • Extensive experiments demonstrate that MetaGen con-sistently improves the accuracy–cost trade-off over com-petitive multi-agent baselines, and ablations confirm the complementary benefits of dynamic roles, within-instance refinement, and cross-instance accumulation. 

2 Related Work 

2.1 Multi-agent collaboration with LLMs. 

A growing body of work solves complex tasks via LLM-based multi-agent collaboration [Akata et al. , 2025; Guo et al. , 2024; Zhao et al. , 2024; Hao et al. , 2025], where multiple agents exchange intermediate results to reduce single-agent blind spots and improve reliability. Common paradigms in-clude discussion-style coordination that aggregates diverse perspectives and iteratively refines candidate solutions [Saha 

et al. , 2024], and debate-style protocols that surface con-tradictions and encourage self-correction through adversar-ial critique [Xiong et al. , 2023]. Another line of work em-phasizes specialization by assigning distinct roles (e.g., plan-ner, executor, verifier) and organizing them into hierarchi-cal pipelines for decomposition and verification [Zhang et al. , 2025a]. Beyond pipelines, structured collaboration pat-terns such as chain and star orchestration [Hong et al. , 2023; Qian et al. , 2024a; Zhou et al. , 2023] and richer tree/graph-structured interaction [Zhang et al. , 2024d; Zhao et al. , 2024; Ishibashi and Nishimura, 2024; Qian et al. , 2024b; Zhuge et al. , 2024; Zhao et al. , 2025] have been adopted to better cap-ture information dependencies and multi-step reasoning. De-spite these advances, most systems assume a pre-defined role pool and adopt an interaction topology that is fixed or drawn from a small set of templates, remaining largely execution-frozen once inference begins. As a result, the collaboration strategy often cannot be tailored to instance-specific needs, and mismatched roles or redundant interactions can waste computation and hinder robustness under distribution shift. 

2.2 Multi-Agents as Graphs 

Graph-structured formulations are a natural fit for multi-agent collaboration, as they explicitly model information dependen-cies and interaction constraints among agents[Zhang et al. ,2025b]. Representative systems such as MacNet [Qian et al. , 2024b] and GPTSwarm [Zhuge et al. , 2024] treat agent interaction as an optimizable graph. Recent work further moves toward dynamic topology construction. DyLAN [Liu 

et al. , 2024b] selects and routes agents by filtering an ini-tially large set based on instance-level importance signals, G-Designer [Zhang et al. , 2024b] synthesizes communica-tion graphs with a learned generator to adapt connectivity patterns, and ARG-Designer [Li et al. , 2025] autoregres-sively constructs agent groups together with their links under task conditioning. Unlike topology-centric designers that pri-marily generate interaction graphs over fixed/retrieved roles, MetaGen treats both role specifications and topology as ed-itable inference-time objects, enabling coupled intra-instance refinement and cross-instance accumulation. 

3 Method 

MetaGen is a training-free framework for multi-agent col-laboration that models role specifications and communica-tion topology as first-class, editable entities during inference. It enables structured adaptation via query-conditioned role generation and revision, coupled with a self-evolving graph orchestration loop subject to explicit structural constraints. Under this formulation, collaboration structures are pro-gressively refined to meet task-specific requirements, while bounding computational cost and preserving auditable inter-action traces, thereby improving adaptability, reproducibility, and reasoning performance in multi-agent systems. Figure 2: MetaGen framework overview. Given a query, an Architect generates and filters candidate roles, then performs novelty-driven role selection and hybrid graph initialization to form an initial DAG Ginit . MetaGen supports intra-task evolution by updating role prompts and structure using execution feedback, and inter-task evolution by accumulating cross-instance priors and solidifying verified roles for future reuse. 

3.1 Problem Formulation 

Given a task input x (e.g., code generation or complex rea-soning), MetaGen employs an Architect Agent during in-ference to automatically generate a set of candidate agent roles {ˆri}Ni=1 , from which a directed acyclic graph (DAG) 

G = ( V, E ) is constructed to model the multi-agent collabo-ration process. Each node v ∈ V corresponds to a specific agent role, and each directed edge e = ( u → v) ∈ E represents a message flow between roles, capturing information dependencies and collaboration pathways during multi-agent reasoning. Each role ri is formally defined as a tuple: 

ri = ( Ni, D i, S i, U i, C i), (1) where Ni denotes the role name, Di denotes the semantic description of the role, Si denotes the system-level prompt template, Ui denotes the user-level prompt template, and Ci

denotes the set of capabilities or tools available to the role. Without updating the underlying large language model pa-rameters, the core objective of MetaGen is to regulate the multi-agent inference process through joint optimization of role specifications and collaboration structure by minimizing the following composite objective: 

min   

> arch ,roles

L = λ1Lacc (y, y ∗) + λ2Lcost (τ )+ λ3Lsparse (G), (2) where Lacc quantifies the prediction error between the sys-tem output y and the ground-truth target y∗, Lcost penalizes the cumulative token usage and inference latency over the rea-soning trajectory τ , and Lsparse serves as a structural regular-izer that promotes sparsity in the communication graph, im-proving interpretability and controllability. During inference, MetaGen does not access y∗; it relies on naturally observable execution signals to trigger edits and updates only lightweight selection priors from the pass/cost summary. 

3.2 Generative Role Space 

To address task mismatch and distribution shift, MetaGen im-plements a dynamic Generative Role Space . We employ an Architect Agent to synthesize a raw candidate set Cr condi-tioned on the query. To ensure the role space is both ex-ecutable and non-redundant, we enforce a formalized two-stage validation process. 

Constraint-Based Filtering. We first refine the raw gener-ations into a valid candidate set C by imposing strict structural Method Dyn. T-free Evol. GSM8K HumanEval MMLU AQuA MNLI Average 

Vanilla 4 2 4 89.3 65.2 87.1 69.7 77.6 77.8 CoT (zero-shot) 4 2 4 93.1 ↑3.8 89.0 ↑23.8 89.5 ↑2.4 70.9 ↑1.2 82.3 ↑4.7 85.0 CoT (few-shot) 4 2 4 95.8 ↑6.5 92.1 ↑26.9 91.5 ↑4.4 84.6 ↑14.9 85.4 ↑7.8 89.9 SC (K=3) 4 2 4 94.2 ↑4.9 86.0 ↑20.8 90.8 ↑3.7 72.0 ↑2.3 83.8 ↑6.2 85.4 SC (K=10) 4 2 4 93.9 ↑4.6 84.1 ↑18.9 92.2 ↑5.1 77.2 ↑7.5 84.0 ↑6.4 86.3 Chain 4 2 4 92.0 ↑2.7 90.2 ↑25.0 91.5 ↑4.4 79.1 ↑9.4 77.2 ↓0.4 86.0 Star 4 2 4 94.5 ↑5.2 89.6 ↑24.4 90.2 ↑3.1 83.5 ↑13.8 69.9 ↓7.7 85.5 Tree 4 2 4 77.5 ↓11.8 93.9 ↑28.7 77.1 ↓10.0 83.9 ↑14.2 55.3 ↓22.3 77.5 Complete Graph 4 2 4 94.6 ↑5.3 89.0 ↑23.8 92.2 ↑5.1 86.2 ↑16.5 83.3 ↑5.7 89.1 Random Graph 4 2 4 95.4 ↑6.1 92.1 ↑26.9 91.8 ↑4.7 78.7 ↑9.0 84.2 ↑6.6 88.4 LLM-Debate 4 2 4 94.2 ↑4.9 89.6 ↑24.4 92.2 ↑5.1 85.8 ↑16.1 79.7 ↑2.1 88.3 GPTSwarm 4 4 4 – 69.6 ↑4.4 60.1 ↓27.0 – – 64.9 AFlow 4 4 ⊟ 94.3 ↑5.0 90.9 ↑25.7 – – – 92.6 G-Designer 4 4 ⊟ 96.3 ↑7.0 94.2 ↑29.0 93.5 ↑6.4 89.0 ↑9.3 – 93.3 ARG-Designer 2 4 ⊟ 96.1 ↑6.8 90.9 ↑25.7 89.5 ↑2.4 90.6 ↑20.9 – 91.8 

MetaGen 2 2 2 96.4 ↑7.1 95.1 ↑29.9 93.5 ↑6.4 95.7 ↑26.0 94.8 ↑17.2 95.1 

Table 1: Main results on five benchmarks using DeepSeek-V3. Dyn. indicates whether a method uses a dynamic role pool. T-free indicates whether it avoids training model weights for role or topology design. Evol. indicates whether the interaction topology evolves during infer-ence. 2means yes. 4means no. ⊟means partial. All numbers are means over three independent runs. 

and safety constraints. Let T (c) denote the prompt template of candidate c, and W(c) be its token set. We define the valid set as: 

C = {c ∈ C r | (T (c) |= Φ) ∧ (W(c) ∩ V b = ∅)} , (3) where Φ represents the required schema (e.g., placeholders), 

|= denotes schema satisfaction, and Vb is a set of restricted keywords. 

Embedding-Based Diversity Gating. To avoid semantic redundancy, we project roles into a dense vector space to en-force diversity. Let E : X → Rd denote a semantic encoder that maps the textual description of a role c to its embedding vector ec:

ec = E(desc (c)) 

∥E (desc (c)) ∥2

. (4) To prevent semantic redundancy, we employ an embedding-based ranking mechanism. Let d(c, r ) denote the semantic distance between two roles in the embedding space. For each candidate c ∈ C , we calculate a Marginal Utility Score S(c) that balances external novelty against the histor-ical library RL and internal distinctiveness relative to other candidates: 

S(c) = λ min 

> r∈R L

d(c, r ) + (1 − λ) min  

> r′∈C\{ c}

d(c, r ′), (5) where λ controls the trade-off weight. Finally, we construct the incremental role set ∆R by selecting the top-K candi-dates that exceed a minimum novelty threshold δ:

∆R = Top K ({c ∈ C | S(c) > δ }) . (6) This selection strategy ensures that the instantiated roles are not only valid but also semantically unique and non-redundant. 

3.3 Task-Adaptive Graph Construction 

To balance structural regularization with semantic flexibil-ity, we propose a hybrid graph construction strategy. It an-chors reasoning to a minimal functional backbone, expands it through score-based selection over a hybrid role pool, and supports evolution at two levels: intra-task refinement within an instance and inter-task accumulation across instances. 

Hybrid Graph Initialization. We first instantiate a task-type backbone chain Gskel = ( Vskel , E skel ) to guarantee the fundamental execution flow. For code generation, the chain is 

Eskel = {(vhub → vprog ), (vprog → veval )}. (7) Here vhub dispatches the request, vprog produces code, and 

veval verifies it. To handle requirements beyond the backbone, we form a hybrid candidate pool Vpool = Vaccum ∪ V gen , where 

Vaccum contains accumulated generalist and previously effec-tive roles, and Vgen contains query-conditioned roles synthe-sized by the Architect for the current instance. Each candidate role r is represented by a feature vector 

ϕ(r) that combines lexical cues from the role name/prompt template, capability indicators, semantic relevance to the query via E, and optional historical statistics when avail-able. Each candidate directed edge (u → v) is represented by ψ(u → v), which combines endpoint features with simple structural signals and optional co-occurrence statistics. We compute linear priority scores 

sr = w⊤

> role

ϕ(r), su→v = w⊤

> edge

ψ(u → v), (8) and select a Top-K committee with an ϵ-greedy strategy. Edges are added to form Ginit when their scores exceed a threshold δ, subject to DAG constraints. Intra-task Evolution. Starting from Ginit , MetaGen per-forms lightweight within-instance refinement over multiple rounds. We denote by F the feedback collected during in-ference and tool execution, consisting of naturally observable signals such as runtime logs, compilation/test outcomes, for-mat validators, and self-consistency checks. This feedback is available without introducing additional supervision and serves as the trigger for instance-level edits. Given F, MetaGen applies two types of edits that oper-ate only on textual role specifications and a constrained sub-set of structural choices. First, role prompt rewrite targets a low-utility role whose messages are consistently unhelp-ful (e.g., redundant, unstable, or verbose) under the current instance. Using the feedback traces (error messages, failed checks, or inconsistency patterns), MetaGen revises the role’s system/user templates to better align the role behavior with the instance requirements. Second, prior-filtered edge explo-ration updates topology within the instance in a conservative manner. MetaGen first filters candidate non-critical edges us-ing current priors and structural constraints (e.g., preserving at least one path to the exit/judge node and avoiding cycles), then selectively deactivates or swaps one edge to encourage simpler, more informative communication. Across rounds, these edits allow the collaboration process to react to ob-served failure modes while keeping the execution stable and auditable. 

Inter-task Evolution. While intra-task evolution adapts be-havior for a single instance, MetaGen also improves future decisions by maintaining lightweight state across instances. After an instance completes, we summarize its overall out-come into a scalar reward that trades off success and cost, 

R = I(pass ) − λcost · C token , (9) where I(pass ) is a task-specific pass indicator produced by the evaluator and Ctoken is the total token usage. We then update the parameters that govern role/edge scoring with a reward-weighted linear rule: 

w ← w + η R f , (10) where f is the feature vector for the decision that was used, i.e., f = ϕ(r) for a selected role (updating wrole ) or f =

ψ(u → v) for an activated edge (updating wedge ). Intuitively, decisions that lead to successful, low-cost executions receive positive updates and become more likely under similar con-texts, whereas costly or unsuccessful executions yield weaker (or negative) reinforcement. This mechanism is deliberately lightweight: it updates only shallow priors used by the selec-tor/wiring module and remains fully decoupled from back-bone LLM weight training. 

Verified Role Solidification and Reuse. In addition to up-dating priors, MetaGen maintains a growing pool of reusable roles. During intra-task evolution, the Architect may syn-thesize new roles or substantially rewrite prompts to better match the instance. To retain effective transient roles, we so-lidify roles only when the final execution passes task-specific checks. Concretely, we extract a small Top-K set of ef-fective non-builtin roles from the executed graph (after de-duplication and basic validity checks), serialize their spec-ifications, and store them in a persistent Role Cache. In 

Algorithm 1 MetaGen: inference-time evolution of roles and topology 

Input : task input x, role library RL, skeleton Gskel 

Parameter : Top-K, ϵ, δ, Tmax , η, λcost 

Output : answer y, trace τ , updated library 

R′ 

> L
> 1:

C ← ARCHITECT (x); C ← FILTER VALID (C) 

> 2:

∆R ← SELECT NOVEL (C, RL); V ← R L ∪ ∆R 

> 3:

VK ← EPS GREEDY SELECT (V; wrole , K, ϵ ) 

> 4:

Ginit ← Gskel ∪ ADD EDGES (VK ; wedge , δ ) 

> 5:

Ginit ← ENFORCE DAG (Ginit ) 

> 6:

for t = 1 to Tmax do  

> 7:

(τ, y ) ← EXECUTE (Ginit , x ) 

> 8:

F ← FEEDBACK (τ ); p ← PASS (F) 

> 9:

if p = 1 then  

> 10:

break  

> 11:

end if  

> 12:

V ← PROMPT REWRITE (V, F) 

> 13:

Ginit ← PRIOR FILTERED EXPLORE (Ginit , F; w) 

> 14:

end for  

> 15:

R ← p − λcost · TOKEN COST (τ ) 

> 16:

w ← UPDATE PRIORS (w, R, τ ) 

> 17:

R′ 

> L

← R L 

> 18:

if p = 1 then  

> 19:

R′ 

> L

← SOLIDIFY TOP K(RL, τ ) 

> 20:

end if  

> 21:

return y, τ, R′                                            

> L
> Method #Training Token #Inference Token #Overall Token
> Complete –9.8×10 69.8×10 6
> DyLAN 9.6×10 61.3×10 72.2×10 7
> GPTSwarm 5.5×10 68.4×10 61.4×10 7
> G-Designer 2.7×10 58.2×10 68.5×10 6
> MetaGen –1.2×10 61.2×10 6
> Table 2: Token cost comparison measured with GPT-4.

subsequent instances, the cache is loaded and merged into the role library as a high-priority candidate pool, enabling reuse of verified role templates rather than regenerating them from scratch. Over time, this reward-conditioned retention expands the role library with task-relevant specialists and im-proves cold-start behavior under recurring patterns, without any backbone fine-tuning. 

4 Experiments and Analyses 

4.1 Experimental Setup 

Datasets and Metrics. We evaluate MetaGen on five widely used benchmarks that cover multi-step mathematical reasoning (GSM8K [Cobbe et al. , 2021]), code generation (HumanEval [Chen, 2021]), broad knowledge and reasoning (MMLU [Hendrycks et al. , 2020]), algebraic word problems (AQuA [Ling et al. , 2017]), and natural language inference (MNLI [Williams et al. , 2018]). For each dataset, we follow the official evaluation split and report the standard accuracy-based metric: exact-match accuracy for GSM8K and AQuA, 1600 2000 2400 2800 3200 3600 0.89 0.90 0.91 0.92 0.93 0.94 0.95 0.96 Ours  (1869 chars, 5 roles, 4 edges) Auto-Design(w/o Online)  (768 chars, 5 roles, 4 edges) Generic-only  (768 chars, 5 roles, 4 edges) Minimal Manual  (1538 chars, 5 roles, 5 edges) Full Manual  (2816 chars, 5 roles, 9 edges) Accuracy Manual Prompt Size (chars)  Ours  Auto-Design(w/o Online)  Generic-only  Minimal Manual  Full Manual Humaneval 400 800 1200 1600 2000 2400 2800 3200 0.89 0.90 0.91 0.92 0.93 0.94 0.95 Ours  (768 chars, 2 edges) Auto-Design(w/o Online)  (768 chars, 2 edges) Generic-only  (768 chars, 2 edges) Minimal Manual  (1538 chars, 2 edges) Full Manual  (2816 chars, 8 edges) Accuracy Manual Prompt Size (chars)  Ours  Auto-Design(w/o Online)  Generic-only  Minimal Manual  Full Manual MMLU Figure 3: Accuracy versus manual prompt size on HumanEval (left) and MMLU (right). Each point corresponds to a different design budget variant, illustrating the trade-off between engineering effort and performance. 

classification accuracy for MMLU and MNLI, and pass@1 for HumanEval under the provided unit tests. Our main com-parison is summarized in Table 1, where we also report the average score across the five datasets. 

Baselines. We compare against both single-agent prompt-ing and multi-agent orchestration baselines. For single-agent prompting, we include a vanilla prompt, zero-shot and few-shot Chain-of-Thought[Wei et al. , 2022] prompt-ing, and Self-Consistency[Wang et al. , 2022] with multiple sampled rationales. For fixed-topology multi-agent baselines, we instantiate common communication patterns, including Chain, Star, Tree[Qian et al. , 2024b], Complete Graph, Ran-dom Graph, as well as an LLM debate-style protocol[Du 

et al. , 2023]. We further compare with representative au-tomated topology design and multi-agent frameworks, in-cluding GPTSwarm[Zhuge et al. , 2024], AFlow[Zhang et al. , 2024c], G-Designer[Zhang et al. , 2024b], and ARG-Designer[Li et al. , 2025]. When a baseline does not support a dataset in its original setting or public implementation, we mark the corresponding entry as missing in Table 1. 

Implementation Details. All methods use the same back-bone model, DeepSeek-V3 [Liu et al. , 2024a], to isolate the effect of role generation and topology control. For the seman-tic encoder used in role relevance scoring and diversity con-trol, we use SentenceTransformer all-MiniLM-L6-v2 [Wang 

et al. , 2020]. Unless otherwise specified, the Architect gen-erates three candidate roles per instance and the selector in-stantiates a top-K committee with K=2 . For online decision making, we use an ϵ-greedy exploration strategy with ϵ=0 .15 

and update step size η=0 .15 . The reward trades off task suc-cess and cost as R = I(pass ) − λcost · C token with λcost =0 .001 .

4.2 Main Results 

Table 1 shows that MetaGen delivers the best overall perfor-mance, with a 1.8% ↑ average accuracy improvement over the strongest baseline G-Designer. On AQuA, MetaGen ex-ceeds ARG-Designer by 5.1% ↑, demonstrating clear bene-fits from role adaptation and inference-time topology evolu-tion on multi-step reasoning. On MNLI, MetaGen improves over the best reported baseline CoT few-shot by 9.4% ↑, in-dicating substantially stronger task-conditional collaboration on NLI. On HumanEval, MetaGen surpasses G-Designer by 0.9% ↑, and on GSM8K it provides a further 0.1% ↑ gain, while matching the best MMLU result. 

Figure 4: Cold-start recovery after distribution shifts. Accuracy (top) and average tokens (bottom) on the first 20 examples imme-diately after each shift, comparing Frozen, Random, and MetaGen. MetaGen achieves the strongest cold-start accuracy with lower to-ken cost. 95.4 94.3%(-1.1) 93.5%(-1.9) 92.1%(-3.3) 93.7%(-1.7) 94.5 92.5%(-2.0) 92.7%(-1.8) 91.8%(-2.7) 91.5%(-3.0) 0.00 0.05 0.10 0.15 0.20 0.25 0.30 0.35 0.40 91 92 93 94 95 96 <Humaneval Baseline 94.5> <MMLU Baseline 95.4> Mean Accuracy (%) Noise proportion  p  MMLU Accuracy %  Humaneval Accuracy % 93.5 (-1.9pp) 94.1 (-1.3pp) 93.5 (-1.9pp) 92.3 (-2.2pp) 90.9 (-3.6pp) 91.4 (-3.1pp) 01290 91 92 93 94 95 96 <<Humaneval Baseline 94.5>> <<MMLU Baseline 95.4>> Accuracy(%) Noise strength s(p=0.40)  MMLU(mean over s)  HumanEval(mean over s) 

Figure 5: Robustness to noisy nodes and edges. Left: varying the noise proportion p (fraction of corrupted nodes and optional edges). Right: varying the noise strength level s with fixed p=0 .4.

4.3 Cost Efficiency 

We evaluate cost from two complementary perspectives, run-time token cost and human authoring cost. 

Runtime token cost. Table 2 shows that MetaGen uses 

1.2 × 10 6 inference tokens. This yields an 85.4% reduc-tion relative to G-Designer, an 87.8% reduction relative to Complete, an 85.7% reduction relative to GPTSwarm, and a 90.8% reduction relative to DyLAN. Overall, MetaGen achieves 7.1 × to 18.3 × fewer end-to-end tokens than prior multi-agent systems, while requiring no training tokens for role or topology design. 

Human authoring cost. Figure 3 shows that MetaGen con-sistently improves the accuracy versus manual prompt size frontier on both HumanEval and MMLU. At the same manual budget, MetaGen attains higher accuracy, and it reaches near-saturated performance with substantially less hand-written specification. The advantage is most pronounced in the low-budget regime, indicating that online selection and evolution are the key drivers that recover accuracy when manual engi-neering is limited. 

4.4 Adaptation and Robustness 

Non-stationary Stream Adaptation. We evaluate non-stationary adaptation on a 150-instance stream with three consecutive segments, consisting of 50 examples from MMLU, then 50 from MNLI, and finally 50 from Hu-manEval. We compare MetaGen with Frozen, which keeps Method Overall 1–150 Segment 1 MMLU 1–50 Segment 2 MNLI 51–100 Segment 3 HumanEval 101–150 Acc AvgTok Acc AvgTok Acc AvgTok Acc AvgTok 

Frozen 90.0% 2673 92.0% 3030 80.0% 2782 94.0% 2208 Random 90.7% 2787 90.0% 3110 84.0% 3043 96.0% 2207 

MetaGen 92.7% 2483 94.0% 3062 88.0% 2190 100.0% 2196 

> Table 3: Non-stationary stream evaluation on a 150-instance sequence. The stream proceeds from Segment 1 MMLU, to Segment 2 MNLI, and then Segment 3 HumanEval. We report accuracy and average total tokens per question for the full stream and each segment.

roles and topology fixed across the stream, and Random, which perturbs topology without learning. Table 3 shows that MetaGen improves overall accuracy by 3 points over Frozen and by 2 points over Random, while reducing average tokens by 7.1% and 10.9%. The advantage is most pronounced on the shifted MNLI segment, where MetaGen improves accu-racy by 8 points over Frozen and by 4 points over Random, with 21.3% to 28.0% fewer tokens. On the final HumanEval segment, MetaGen reaches perfect accuracy, improving by 6 points over Frozen and by 4 points over Random without in-creasing tokens. 

Cold-start Recovery After Distribution Shifts. Figure 4 further isolates the first 20 examples immediately after each distribution shift. After the first shift, MetaGen improves cold-start accuracy by 10 points over Frozen and by 5 points over Random, while reducing tokens by 11.8% and 22.2%. After the second shift, MetaGen maintains perfect cold-start accuracy with no extra token overhead. These results indi-cate that MetaGen not only adapts over the stream but also exhibits strong cold-start capability right after shifts. 

Noise robustness. We test robustness by injecting corrup-tion into both agent nodes and optional communication edges, controlled by a corruption ratio p and a corruption strength 

s. Figure 5 shows that MetaGen remains stable under both widespread and stronger perturbations. As p increases, ac-curacy decreases gradually rather than collapsing, indicating that MetaGen does not hinge on any single critical node or edge and can preserve performance through redundant rea-soning routes. Notably, the degradation remains limited even at high corruption levels, suggesting that the evolving collab-oration structure can compensate for partial failures by re-weighting or bypassing unreliable components. When fixing 

p=0 .4 and increasing s, performance exhibits only mild ad-ditional drops, implying that the system is resilient not only to the amount of noise but also to its severity. 

4.5 Ablation Study 

We evaluate four MetaGen variants by disabling one mecha-nism at a time. (1) w/o Role Generation uses a fixed role set without query-conditioned role synthesis. (2) w/o Learned Policy replaces learning-based selection and wiring with ran-dom or relevance-only heuristics, and does not use persis-tent statistics or policy states for decision making. (3) w/o Intra-task Evolution disables within-instance updates so the system executes Ginit without prompt rewriting or topology adjustment. (4) w/o Cross-instance Memory disables per-sistence across instances by stopping verified role write-back 

Variant HumanEval MMLU 

vanilla MetaGen 95.1 93.5 w/o Role Generation 92.1 ↓3.0 91.1 ↓2.4 

w/o Learned Policy 93.9 ↓1.2 92.8 ↓0.7 

w/o Intra-task Evolution 92.7 ↓2.4 91.7 ↓1.8 

w/o Cross-instance Memory 92.7 ↓2.4 92.6 ↓0.9 

> Table 4: Ablation study. Each variant removes one component from MetaGen.

and resetting selection and wiring states so each instance cold-starts. Table 4 shows that each component matters and the full MetaGen performs best. Removing role generation yields the most pronounced degradation, for example drop-ping HumanEval from 95.1 to 92.1, which highlights the im-portance of query-conditioned role instantiation. Replacing the learned policy also reduces accuracy, such as to 92.8 on MMLU, indicating that learned decision rules for selecting participants and optional connections are beneficial beyond having a larger candidate set. Disabling intra-task evolution lowers performance to 91.7 on MMLU, suggesting that re-fining prompts and structure within an instance materially improves solution quality. Finally, removing cross-instance memory degrades results to 92.7 on HumanEval, showing that persistent accumulation of verified roles and selection statistics improves robustness across instances. 

5 Conclusion 

We propose MetaGen , a training-free multi-agent frame-work that improves accuracy while reducing both inference-token cost and manual prompt engineering by generating and refining roles and collaboration structure at inference time. With a DeepSeek-V3 backbone, MetaGen achieves the strongest overall performance across five benchmarks against single-agent prompting, fixed-topology orchestration, and topology-design baselines. Further analyses show that MetaGen degrades gracefully under noisy agents and per-turbed edges, benefits from each core component, and adapts to non-stationary task streams with strong cold-start recov-ery after distribution shifts. Overall, these results highlight inference-time optimization of text-level roles and discrete collaboration structure as a practical path toward scalable and adaptive MAS without modifying backbone weights. References 

[Akata et al. , 2025] Elif Akata, Lion Schulz, Julian Coda-Forno, Seong Joon Oh, Matthias Bethge, and Eric Schulz. Playing repeated games with large language models. Na-ture Human Behaviour , pages 1–11, 2025. [Besta et al. , 2024] Maciej Besta, Nils Blach, Ales Ku-bicek, Robert Gerstenberger, Michal Podstawski, Lukas Gianinazzi, Joanna Gajda, Tomasz Lehmann, Hubert Niewiadomski, Piotr Nyczyk, et al. Graph of thoughts: Solving elaborate problems with large language models. In Proceedings of the AAAI conference on artificial intel-ligence , volume 38, pages 17682–17690, 2024. [Chen et al. , 2024a] Justin Chen, Swarnadeep Saha, and Mo-hit Bansal. Reconcile: Round-table conference improves reasoning via consensus among diverse llms. In Pro-ceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers) ,pages 7066–7085, 2024. [Chen et al. , 2024b] Weize Chen, Yusheng Su, Jingwei Zuo, Cheng Yang, Chenfei Yuan, Chi-Min Chan, Heyang Yu, Yaxi Lu, Yi-Hsin Hung, Chen Qian, et al. Agentverse: Facilitating multi-agent collaboration and exploring emer-gent behaviors. In ICLR , 2024. [Chen, 2021] Mark Chen. Evaluating large language models trained on code. arXiv preprint arXiv:2107.03374 , 2021. [Cobbe et al. , 2021] Karl Cobbe, Vineet Kosaraju, Moham-mad Bavarian, Mark Chen, Heewoo Jun, Lukasz Kaiser, Matthias Plappert, Jerry Tworek, Jacob Hilton, Reiichiro Nakano, et al. Training verifiers to solve math word prob-lems. arXiv preprint arXiv:2110.14168 , 2021. [Du et al. , 2023] Yilun Du, Shuang Li, Antonio Torralba, Joshua B Tenenbaum, and Igor Mordatch. Improving fac-tuality and reasoning in language models through multi-agent debate. In Forty-first International Conference on Machine Learning , 2023. [Guo et al. , 2024] Taicheng Guo, Xiuying Chen, Yaqi Wang, Ruidi Chang, Shichao Pei, Nitesh V Chawla, Olaf Wiest, and Xiangliang Zhang. Large language model based multi-agents: A survey of progress and challenges. arXiv preprint arXiv:2402.01680 , 2024. [Hao et al. , 2025] Rui Hao, Linmei Hu, Weijian Qi, Qingliu Wu, Yirui Zhang, and Liqiang Nie. Chatllm network: More brains, more intelligence. AI Open , 6:45–52, 2025. [Hendrycks et al. , 2020] Dan Hendrycks, Collin Burns, Steven Basart, Andy Zou, Mantas Mazeika, Dawn Song, and Jacob Steinhardt. Measuring massive multitask lan-guage understanding. arXiv preprint arXiv:2009.03300 ,2020. [Hong et al. , 2023] Sirui Hong, Mingchen Zhuge, Jonathan Chen, Xiawu Zheng, Yuheng Cheng, Jinlin Wang, Ceyao Zhang, Zili Wang, Steven Ka Shing Yau, Zijuan Lin, et al. Metagpt: Meta programming for a multi-agent collabora-tive framework. In The Twelfth International Conference on Learning Representations , 2023. [Ishibashi and Nishimura, 2024] Yoichi Ishibashi and Yoshi-masa Nishimura. Self-organized agents: A llm multi-agent framework toward ultra large-scale code generation and optimization. arXiv preprint arXiv:2404.02183 , 2024. [Li et al. , 2023] Guohao Li, Hasan Hammoud, Hani Itani, Dmitrii Khizbullin, and Bernard Ghanem. Camel: Com-municative agents for” mind” exploration of large lan-guage model society. Advances in Neural Information Pro-cessing Systems , 36:51991–52008, 2023. [Li et al. , 2025] Shiyuan Li, Yixin Liu, Qingsong Wen, Chengqi Zhang, and Shirui Pan. Assemble your crew: Automatic multi-agent communication topology design via autoregressive graph generation. arXiv preprint arXiv:2507.18224 , 2025. [Ling et al. , 2017] Wang Ling, Dani Yogatama, Chris Dyer, and Phil Blunsom. Program induction by rationale gener-ation: Learning to solve and explain algebraic word prob-lems. arXiv preprint arXiv:1705.04146 , 2017. [Liu et al. , 2024a] Aixin Liu, Bei Feng, Bing Xue, Bingx-uan Wang, Bochao Wu, Chengda Lu, Chenggang Zhao, Chengqi Deng, Chenyu Zhang, Chong Ruan, et al. Deepseek-v3 technical report. arXiv preprint arXiv:2412.19437 , 2024. [Liu et al. , 2024b] Zijun Liu, Yanzhe Zhang, Peng Li, Yang Liu, and Diyi Yang. A dynamic llm-powered agent net-work for task-oriented agent collaboration. In First Con-ference on Language Modeling , 2024. [Liu et al. , 2025] Jun Liu, Zhenglun Kong, Changdi Yang, Fan Yang, Tianqi Li, Peiyan Dong, Joannah Nan-jekye, Hao Tang, Geng Yuan, Wei Niu, et al. Rcr-router: Efficient role-aware context routing for multi-agent llm systems with structured memory. arXiv preprint arXiv:2508.04903 , 2025. [Qian et al. , 2024a] Chen Qian, Wei Liu, Hongzhang Liu, Nuo Chen, Yufan Dang, Jiahao Li, Cheng Yang, Weize Chen, Yusheng Su, Xin Cong, et al. Chatdev: Communica-tive agents for software development. In Proceedings of the 62nd Annual Meeting of the Association for Computa-tional Linguistics (Volume 1: Long Papers) , pages 15174– 15186, 2024. [Qian et al. , 2024b] Chen Qian, Zihao Xie, Yifei Wang, Wei Liu, Kunlun Zhu, Hanchen Xia, Yufan Dang, Zhuoyun Du, Weize Chen, Cheng Yang, et al. Scaling large language model-based multi-agent collaboration. arXiv preprint arXiv:2406.07155 , 2024. [Saha et al. , 2024] Swarnadeep Saha, Omer Levy, Asli Ce-likyilmaz, Mohit Bansal, Jason Weston, and Xian Li. Branch-solve-merge improves large language model eval-uation and generation. In Proceedings of the 2024 Confer-ence of the North American Chapter of the Association for Computational Linguistics: Human Language Technolo-gies (Volume 1: Long Papers) , pages 8352–8370, 2024. [Shinn et al. , 2023] Noah Shinn, Federico Cassano, Ashwin Gopinath, Karthik Narasimhan, and Shunyu Yao. Reflex-ion: Language agents with verbal reinforcement learn-ing. Advances in Neural Information Processing Systems ,36:8634–8652, 2023. [Tang et al. , 2024] Xiangru Tang, Anni Zou, Zhuosheng Zhang, Ziming Li, Yilun Zhao, Xingyao Zhang, Arman Cohan, and Mark Gerstein. Medagents: Large language models as collaborators for zero-shot medical reasoning. In Findings of the Association for Computational Linguis-tics: ACL 2024 , pages 599–621, 2024. [Wang et al. , 2020] Wenhui Wang, Furu Wei, Li Dong, Hangbo Bao, Nan Yang, and Ming Zhou. Minilm: Deep self-attention distillation for task-agnostic compression of pre-trained transformers. Advances in neural information processing systems , 33:5776–5788, 2020. [Wang et al. , 2022] Xuezhi Wang, Jason Wei, Dale Schu-urmans, Quoc Le, Ed Chi, Sharan Narang, Aakanksha Chowdhery, and Denny Zhou. Self-consistency improves chain of thought reasoning in language models. arXiv preprint arXiv:2203.11171 , 2022. [Wei et al. , 2022] Jason Wei, Xuezhi Wang, Dale Schuur-mans, Maarten Bosma, Fei Xia, Ed Chi, Quoc V Le, Denny Zhou, et al. Chain-of-thought prompting elicits reasoning in large language models. Advances in neural information processing systems , 35:24824–24837, 2022. [Williams et al. , 2018] Adina Williams, Nikita Nangia, and Samuel Bowman. A broad-coverage challenge corpus for sentence understanding through inference. In Proceedings of the 2018 conference of the North American chapter of the association for computational linguistics: human lan-guage technologies, volume 1 (long papers) , pages 1112– 1122, 2018. [Wu et al. , 2024] Qingyun Wu, Gagan Bansal, Jieyu Zhang, Yiran Wu, Beibin Li, Erkang Zhu, Li Jiang, Xiaoyun Zhang, Shaokun Zhang, Jiale Liu, et al. Autogen: En-abling next-gen llm applications via multi-agent conversa-tions. In First Conference on Language Modeling , 2024. [Xiong et al. , 2023] Kai Xiong, Xiao Ding, Yixin Cao, Ting Liu, and Bing Qin. Examining inter-consistency of large language models collaboration: An in-depth analysis via debate. arXiv preprint arXiv:2305.11595 , 2023. [Yao et al. , 2022] Shunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak Shafran, Karthik R Narasimhan, and Yuan Cao. React: Synergizing reasoning and acting in language mod-els. In The eleventh international conference on learning representations , 2022. [Yue et al. , 2025] Yanwei Yue, Guibin Zhang, Boyang Liu, Guancheng Wan, Kun Wang, Dawei Cheng, and Yiyan Qi. Masrouter: Learning to route llms for multi-agent systems. 

arXiv preprint arXiv:2502.11133 , 2025. [Zhang et al. , 2024a] Guibin Zhang, Yanwei Yue, Zhixun Li, Sukwon Yun, Guancheng Wan, Kun Wang, Dawei Cheng, Jeffrey Xu Yu, and Tianlong Chen. Cut the crap: An economical communication pipeline for llm-based multi-agent systems. arXiv preprint arXiv:2410.02506 , 2024. [Zhang et al. , 2024b] Guibin Zhang, Yanwei Yue, Xiangguo Sun, Guancheng Wan, Miao Yu, Junfeng Fang, Kun Wang, Tianlong Chen, and Dawei Cheng. G-designer: Architect-ing multi-agent communication topologies via graph neu-ral networks. arXiv preprint arXiv:2410.11782 , 2024. [Zhang et al. , 2024c] Jiayi Zhang, Jinyu Xiang, Zhaoyang Yu, Fengwei Teng, Xionghui Chen, Jiaqi Chen, Mingchen Zhuge, Xin Cheng, Sirui Hong, Jinlin Wang, et al. Aflow: Automating agentic workflow generation. arXiv preprint arXiv:2410.10762 , 2024. [Zhang et al. , 2024d] Yusen Zhang, Ruoxi Sun, Yanfei Chen, Tomas Pfister, Rui Zhang, and Sercan Arik. Chain of agents: Large language models collaborating on long-context tasks. Advances in Neural Information Processing Systems , 37:132208–132237, 2024. [Zhang et al. , 2025a] Cong Zhang, Xin Deik Goh, Dexun Li, Hao Zhang, and Yong Liu. Planning with multi-constraints via collaborative language agents. In Proceedings of the 31st International Conference on Computational Linguis-tics , pages 10054–10082, 2025. [Zhang et al. , 2025b] Guibin Zhang, Luyang Niu, Junfeng Fang, Kun Wang, Lei Bai, and Xiang Wang. Multi-agent architecture search via agentic supernet. arXiv preprint arXiv:2502.04180 , 2025. [Zhao et al. , 2024] Jun Zhao, Can Zu, Hao Xu, Yi Lu, Wei He, Yiwen Ding, Tao Gui, Qi Zhang, and Xuanjing Huang. Longagent: scaling language models to 128k context through multi-agent collaboration. arXiv preprint arXiv:2402.11550 , 2024. [Zhao et al. , 2025] Jiaxing Zhao, Hongbin Xie, Yuzhen Lei, Xuan Song, Zhuoran Shi, Lianxin Li, Shuangxue Liu, and Haoran Zhang. Connecting the dots: A chain-of-collaboration prompting framework for llm agents. arXiv preprint arXiv:2505.10936 , 2025. [Zhou et al. , 2023] Zihao Zhou, Bin Hu, Chenyang Zhao, Pu Zhang, and Bin Liu. Large language model as a policy teacher for training reinforcement learning agents. arXiv preprint arXiv:2311.13373 , 2023. [Zhuge et al. , 2024] Mingchen Zhuge, Wenyi Wang, Louis Kirsch, Francesco Faccio, Dmitrii Khizbullin, and J¨ urgen Schmidhuber. Gptswarm: Language agents as optimiz-able graphs. In Forty-first International Conference on Machine Learning , 2024.
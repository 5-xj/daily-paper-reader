Title: GeoSSA: Geometric Sparrow Search Algorithm for UAV Path Planning and Engineering Design Optimization

URL Source: https://arxiv.org/pdf/2601.19346v1

Published Time: Wed, 28 Jan 2026 01:48:11 GMT

Number of Pages: 39

Markdown Content:
# GEO SSA: G EOMETRIC SPARROW SEARCH ALGORITHM FOR 

# UAV P ATH PLANNING AND ENGINEERING DESIGN 

# OPTIMIZATION âˆ—

Junhao Wei 

Faculty of Applied Sciences Macao Polytechnic University Macao, China 

p2312195@mpu.edu.mo 

Wenxuan Zhu 

Faculty of Applied Sciences Macao Polytechnic University Macao, China 

p2525620@mpu.edu.mo 

Qingyang Xu 

Faculty of Applied Sciences Macao Polytechnic University Macao, China 

p2311371@mpu.edu.mo 

Yanxiao Li 

Faculty of Applied Sciences Macao Polytechnic University Macao, China 

P2525981@mpu.edu.mo 

Yifu Zhao 

Faculty of Applied Sciences Macao Polytechnic University Macao, China 

p2523269@mpu.edu.mo 

Zikun Li 

School of Economics and Management South China Normal University Guangzhou, China 

20190731013@m.scnu.edu.cn 

Ran Zhang 

Faculty of Applied Sciences Macao Polytechnic University Macao, China 

P2512396@mpu.edu.mo 

Yanzhao Gu 

Faculty of Applied Sciences Macao Polytechnic University Macao, China 

p2311998@mpu.edu.mo 

Jinhong Song 

Faculty of Applied Sciences Macao Polytechnic University Macao, China 

p2315937@mpu.edu.mo 

Yapeng Wang 

Faculty of Applied Sciences Macao Polytechnic University Macao, China 

yapengwang@mpu.edu.mo 

Zhiwen Wang 

School of Nursing Peking University Beijing, China 

wzwjing@bjmu.edu.cn 

Ngai Cheong 

Faculty of Applied Sciences Macao Polytechnic University Macao, China 

ncheong@mpu.edu.mo 

Sio-Kei Im 

Macao Polytechnic University Macao, China 

marcusim@mpu.edu.mo 

Xu Yang* 

Faculty of Applied Sciences Macao Polytechnic University Macao, China 

xuyang@mpu.edu.mo 

ABSTRACT 

Metaheuristic algorithms have been widely applied to complex optimization problems due to their independence from gradient information, strong global search capability, and robust performance. The Sparrow Search Algorithm (SSA), characterized by its simple structure and ease of implementation, nevertheless suffers from an insufficient balance between exploration and exploitation, making it prone to premature convergence and slow optimization progress. To address these shortcomings, this paper proposes a Geometric Sparrow Search Algorithm (GeoSSA). By integrating Good Nodes 

> âˆ—

The supports provided by Macao Polytechnic University (MPU Grant no: RP/FCA-03/2022; RP/FCA-06/2022) and Macao Science and Technology Development Fund (FDCT Grant no: 0044/2023/ITP2) enabled us to conduct data collection, analysis, and interpretation, as well as cover expenses related to research materials and participant recruitment. MPU and FDCT investment in our work have significantly contributed to the quality and impact of our research findings. : Authors. Title. Pages.... DOI:000000/11111. 

> arXiv:2601.19346v1 [cs.CE] 27 Jan 2026

Running Title for Header Set initialization, a Sine-Cosine Enhanced Producer position update strategy, and a Triangular-Walk Enhanced Edge Sparrow update strategy, GeoSSA significantly improves the global exploration ability, local exploitation efficiency, and convergence stability of the original SSA. To thoroughly validate the effectiveness of GeoSSA, we conducted ablation studies, qualitative analysis, and comparative experiments on 23 benchmark functions against state-of-the-art algorithms. Experimental results show that GeoSSA achieves the best or near-best performance in terms of average fitness, standard deviation, Wilcoxon tests, and Friedman rankings, with an Overall Effectiveness ( OE ) of 95.65%. Its overall performance is significantly superior to all compared algorithms. In three-dimensional UAV path planning tasks, GeoSSA demonstrates excellent stability and superior path quality. In four categories of engineering design optimization problems, GeoSSA consistently attains the highest solution accuracy and strongest stability. GeoSSA not only exhibits outstanding global optimization performance on standard benchmark functions but also shows strong robustness and generalization ability in practical applications such as UAV path planning and engineering design. Therefore, GeoSSA provides an efficient and reliable solution framework for complex optimization problems. 

Keywords Sparrow Search Algorithm Â· triangular walk Â· metaheuristic Â· path planning Â· engineering design 

1 Introduction 

In the field of optimization, metaheuristic algorithms have received sustained attention due to their efficiency and adaptability in solving complex, nonlinear, and multimodal optimization problems. As an advanced extension of heuristic algorithms, metaheuristics typically integrate randomized mechanisms with local search strategies, leveraging the synergy between global exploration and local exploitation to search for optimal or near-optimal solutions in vast and structurally complex search spaces. In this process, exploration aims to broadly investigate the entire search domain to prevent premature stagnation in local regions, whereas exploitation focuses on intensively refining promising solution areas to accelerate convergence and enhance solution quality. Benefiting from their independence from strict mathematical models and suitability for black-box and highly complex systems, metaheuristic algorithms are capable of addressing high-dimensional, multi-constraint, and non-convex problems that are challenging for traditional optimization methods. Although these algorithms do not guarantee strict global optimality, they are typically able to produce high-quality solutions efficiently within reasonable computational time. In recent years, owing to their strong optimization capability, generalizability, and ease of implementation, metaheuristic algorithms have been widely applied across various engineering and intelligent system domains, including path planning, engineering structural design optimization, WSN coverage optimization, neural network parameter learning, and feature selection. In 1995, Kennedy and Eberhart introduced Particle Swarm Optimization (PSO), inspired by the foraging behavior of birds [ 1]. In 2005, Karaboga et al. proposed the Artificial Bee Colony algorithm (ABC), modeled after the foraging behavior of honeybees [ 2]. In 2014, Seyedali Mirjalili et al. developed the Grey Wolf Optimizer (GWO), inspired by the leadership hierarchy and collaborative hunting mechanism of grey wolves [ 3]. In 2019, Elhamifar et al. proposed Harris Hawks Optimization (HHO), based on the cooperative predation strategies of Harris hawks [ 4 ]. In 2023, Jia et al. introduced the Crayfish Optimization Algorithm (COA), inspired by the foraging, heat dissipation, and competitive behaviors of crayfish [ 5]. In 2024, Fu et al. proposed the Red-billed Blue Magpie Optimizer (RBMO), inspired by the speciesâ€™ food-searching and predatory behaviors [ 6]. Most recently, in 2025, Wang et al. developed the Cuckoo Catfish Optimizer (CCO), modeled after the searching, predation, and brood parasitism behaviors of cuckoo catfish [7]. Despite the remarkable success of these methods over the past decades, several inherent limitations remain, including premature convergence, insufficient exploration capability, slow convergence speed, and search stagnation in high-dimensional landscapes. To address these challenges, numerous improved strategies have been proposed, such as hybrid algorithmic frameworks, dynamic balancing of exploration and exploitation, memory-based mechanisms, chaotic perturbation schemes, and more realistic nature-inspired behavioral models, thereby continuously advancing the development of metaheuristic algorithms for complex optimization tasks. In 2022, Zhang et al. introduced LMRAOA, which enhances global search capability using a Multi-Leader Wandering Search strategy, improves local search efficiency via a Random High-Speed Jumping strategy, and avoids local stagnation through an adaptive lens opposition-based learning mechanism with dynamic parameter tuning [ 8 ]. In 2023, Yu et al. proposed HGWODE, a hybrid algorithm integrating GWO and Differential Evolution, which effectively balances exploration and exploitation [ 9]. In 2024, Wei et al. incorporated tent-mapping initialization, Levy flight, and adaptive 

t-distribution into PSO, formulating IPSO, which achieves faster convergence and stronger escape capability from local optima compared with PSO [ 10 ]. In 2025, Lu et al. proposed MRBMO by combining Good Nodes Set initialization with Levy flight, demonstrating outstanding performance in antenna S-parameter optimization [ 11 ]. Table 1 summarizes representative classical and emerging metaheuristic algorithms. 2Running Title for Header Table 1: Research on the metaheuristic algorithms. Algorithm Year Author Source of inspiration PSO [1] 1995 Kennedy et al. Behavior of birds. ABC [2] 2005 Karaboga et al. Foraging behavior of honeybees GWO [3] 2014 Seyedali Mirjalili et al. Leadership hierarchy and collaborative hunting mechanism of grey wolves. HHO [4] 2019 Elhamifar et al. Cooperative predation strategies of Harris hawks. COA [5] 2023 Jia et al. Foraging, heat dissipation, and competitive behaviors of crayfish. RBMO [6] 2024 Fu et al. Food-searching and predatory behaviors of Red-billed Blue Magpie. CCO [7] 2025 Wang et al. Searching, predation, and brood parasitism behaviors of cuckoo catfish. LMRAOA [8] 2022 Zhang et al. Multi-Leader Wandering Search strategy, LIOBL. HGWODE [9] 2023 Yu et al. Grey Wolf Optimizer, Differential Evolution. IPSO [10] 2024 Wei et al. Tent mapping, Levy flight, adaptive 

t-distribution MRBMO [11] 2025 Lu et al. Good Nodes Set, Levy flight, LIOBL. The Sparrow Search Algorithm (SSA), proposed by Xue et al. in 2020, is a metaheuristic optimization method inspired by the collective intelligence of sparrow populations [ 12 ]. SSA features a relatively simple structure, making it easy to understand and implement. However, SSA suffers from poor balance between exploration and exploitation, and the population quality tends to degrade during iterations, leading to weak global exploration and premature convergence to local optima. These limitations hinder the competitiveness of SSA in solving complex real-world optimization problems. To address these issues, this paper proposes a Geometric Sparrow Search Algorithm (GeoSSA), which effectively balances exploration and exploitation through the integration of geometric initialization and enhanced update mecha-nisms. Experimental results demonstrate that GeoSSA successfully avoids premature convergence and achieves superior performance in UAV path planning and engineering design optimization tasks. 

2 Current Research on UAV Path Planning 

With the rapid development of the low-altitude economy, unmanned aerial vehicle (UAV) systems have witnessed growing demand across various domains, including intelligent logistics, precision agriculture, disaster inspection, and military reconnaissance. According to forecasts by the International Association for Unmanned Systems, the global commercial UAV market size is expected to exceed USD 120 billion by 2025. However, reliable path-planning capability in complex environments remains a key technological bottleneck restricting the large-scale deployment of UAVs. Existing studies indicate that approximately 23% of potential UAV missions fail to be executed due to instability in path planning, insufficient computational efficiency, or poor adaptability to dynamic environments. In urban canyons, mountainous terrains, forested areas, and dynamically regulated airspaces, traditional path-planning approaches rely primarily on two-dimensional geometric constraint models, lacking adequate representation of three-dimensional spatial structures and time-varying obstacles. Consequently, these methods often suffer from delayed response, limited obstacle-avoidance capability, and suboptimal path quality during real-world deployment. 3Running Title for Header In the early development of UAV path planning, deterministic geometric planning methods dominated the research landscape, including A*, D*, Rapidly-Exploring Random Trees (RRT), and their improved variants. The A* algorithm conducts heuristic search through a cost function and has proven effective for shortest-path planning in grid-based environments. D* extends this capability by supporting environmental updates, making it suitable for partially dynamic settings. Meanwhile, RRT and its variants (e.g., RRT*) perform incremental sampling to efficiently explore high-dimensional spaces, forming an important class of algorithms for handling complex obstacle environments [ 13 ] [ 14 ]. Nevertheless, these techniques heavily rely on accurate environmental modeling and tend to experience declining search efficiency, slow path refinement, or difficulty in guaranteeing global optimality when applied to high-dimensional or strongly dynamic environments. With the advancement of intelligent optimization, researchers have increasingly recognized the unique advantages of metaheuristic algorithms for UAV path planning. metaheuristic algorithms do not require explicit mathematical formulations, are well suited for complex non-convex search spaces, and naturally accommodate multi-constraint and multi-objective optimization. Thus, they can more effectively address the demands of UAV navigation in rugged terrain, unstructured environments, and scenarios involving dynamic obstacles. Extensive studies have demonstrated that metaheuristic methods such as Particle Swarm Optimization (PSO), Genetic Algorithms (GA) [ 15 ], Ant Colony Optimization (ACO) [ 16 ] and Grey Wolf Optimizer (GWO) can generate high-quality paths within limited computation time by balancing exploration and exploitation. These methods significantly enhance path smoothness, safety, and global optimality. Compared with traditional deterministic algorithms, metaheuristic approaches exhibit stronger robustness and flexibility in high-dimensional search, redundant path avoidance, navigation in multi-obstacle environments, and complex constraint handling, thereby becoming a prominent research direction in UAV path planning. In recent years, driven by progress in deep learning and reinforcement learning, researchers have also explored learning-based frameworks for UAV path planning, such as Deep Q-Networks (DQN), imitation learning, and policy gradient methods. Although learning-based approaches reveal new opportunities concerning generalization and online decision-making in complex environments, their reliance on extensive training data, sensitivity to model stability, and limited interpretability pose significant challenges for engineering applications. For these reasons, metaheuristic algorithms continue to play a central role in UAV path planning. Particularly in scenarios requiring a balance among safety, robustness, computational efficiency, and engineering feasibility, metaheuristic approaches demonstrate irreplaceable advantages. 

3 Current Research on Engineering Design 

Before the advent of computer technology, engineering design relied predominantly on experience and manual calculations. Designers completed complex structural designs through extensive trial-and-error processes and repeated adjustments, drawing heavily on their professional knowledge and intuition. This traditional approach was not only inefficient but also susceptible to limitations imposed by the designerâ€™s personal expertise and subjective judgment, leading to uncertainty in design outcomes and an inability to guarantee optimality. With continuous advancements in science and technology, the introduction of mathematical methods marked a new stage in engineering design. Designers began to employ mathematical models and equations to describe design problems more precisely-such as using finite element analysis (FEA) to evaluate structural strength and stability, or applying optimization techniques to search for optimal design solutions. Nonetheless, these approaches still relied on manual derivations and computations, which were time-consuming, resource-intensive, and restricted to relatively simple design problems. The rapid development of computer technology ushered engineering design into the digital era. The integration of computers significantly accelerated the design process and enabled complex calculations and simulations to become feasible. Engineers began utilizing computer-aided design (CAD), computer-aided engineering (CAE), and computer-aided manufacturing (CAM) systems to support design, analysis, and production workflows. Computers not only facilitated large-scale numerical computations and simulations but also empowered designers to explore broader design spaces. However, as engineering problems grew increasingly complex with more intricate constraints, traditional computational methods faced bottlenecks in computational resources and optimization efficiency. For multi-objective, nonlinear, or highly constrained engineering design problems, computer-aided design tools alone remained insufficient to consistently deliver optimal solutions. In the 21st century, the rise of metaheuristic algorithms brought another major breakthrough to engineering design optimization. Metaheuristic algorithmsâ€”such as Genetic Algorithms (GA), Particle Swarm Optimization (PSO), Ant Colony Optimization (ACO), and Simulated Annealing (SA) [ 17 ]â€”draw inspiration from biological swarm behaviors or physical processes, enabling efficient searches within complex design spaces to identify global or near-global optima. Unlike traditional mathematical optimization techniques, metaheuristic algorithms do not rely on explicit analytical formulations and can handle high-dimensional, nonlinear, multi-objective, and constrained design problems while 4Running Title for Header avoiding premature convergence to local minima. As a result, they have been widely applied to structural optimization, mechanical design, electronic circuit design, aerospace engineering, and many other domains, becoming essential tools for solving complex engineering design tasks. Their strong global search capability and flexibility are particularly advantageous in large-scale, multi-variable, and difficult-to-model design scenarios. With the rapid progress of machine learning and artificial intelligence, an increasing number of engineering design problems have begun adopting learning-based optimization approaches. Techniques such as deep learning and reinforcement learning enable computational systems to autonomously learn from large volumes of data and experience, thereby improving their ability to address highly complex design challenges. Machine learning methods can perform design optimization through data modeling and pattern recognition and can dynamically adjust optimization strategies to achieve adaptive design decision-making. However, despite their promising capabilities, machine learning approaches face challenges including heavy dependence on large datasets, high model complexity, and expensive training costs. Consequently, while machine learning provides unique advantages for certain design tasks, it cannot fully replace traditional optimization techniques, especially in scenarios involving limited samples, high-dimensional search spaces, or complex constraints. Against this background, metaheuristic algorithms continue to play a crucial role in engineering design optimization. Compared to machine learning, metaheuristic algorithms do not require large training datasets and can effectively handle uncertainty and various types of constraints. When addressing complex multi-objective optimization tasks or navigating high-dimensional design spaces, metaheuristic algorithms balance global exploration and local exploitation, thereby avoiding the risks of local stagnation and overfitting while offering strong robustness and flexibility. These advantages are particularly significant in the early stages of design, where sample data are often scarce. Therefore, although machine learning methods hold valuable potential in certain application fields, metaheuristic algorithms remain indispensable tools for engineering design optimizationâ€”especially when tackling complex, highly constrained, or dynamically changing optimization problems, where their distinctive strengths become even more evident. 

4 SSA 

The Sparrow Search Algorithm (SSA), which was proposed by Xue et al. in 2020, is an innovative population-based optimization method inspired by the foraging and anti-predation behaviors of sparrow flocks [ 12 ]. By simulating the natural behaviors of sparrows, SSA is capable of performing efficient global search and finding optimal solutions. SSA introduces two main roles: producers and scroungers, while also adopting a feedback-based strategy to optimize the balance between exploration and exploitation. The original SSA algorithm initializes the population using a pseudo-random number method: 

Xi,j = ( ub âˆ’ lb ) Â· Rand + lb (1) where Xi,j denotes the position of the ith sparrow in the jth dimension; ub and lb represent the upper and lower bounds of the search space; Rand is a random number uniformly distributed within [0,1]. In SSA, producers (the current optimal solution), which have higher fitness values, are more likely to lead the flock in searching for food. Since producers are responsible for foraging and guiding the entire populationâ€™s movement, they are capable of searching for food in a broader area compared to scroungers. In each iteration, the position of the producer is updated as follows: 

Xi,j t+1 =

 Xi,j t Â· exp  âˆ’i Â· Î±T

 if R2 < ST Xi,j t + Q Â· L if R2 â‰¥ ST (2) where Xi,j t represents the current position of the sparrow in the jth dimension at iteration t; T is the maximum number of iterations; a âˆˆ (0 , 1] is a random number used to control the range of the search; R2 âˆˆ [0 , 1] is the alarm value; 

ST âˆˆ [0 .5, 1] is the safety threshold; Q is a random number following a normal distribution; L is a matrix with all elements equal to 1. When R2 < ST , it indicates that no predator has been detected, and producers enter a broad-range search mode. Conversely, when R2 â‰¥ ST , predators are perceived, and the producersâ€”along with other members of the popula-tionâ€”rapidly relocate to a safer region. Scroungers acquire food by monitoring the position of the producers. If a scrounger successfully finds a better food source, it will update its position according to the following rule: 5Running Title for Header 

Xi,j t+1 =

(

Q Â· exp 

 Xworst t âˆ’Xi,j t

> i2



if i > n

> 2

XPt+1 + |Xi,j t âˆ’ XPt+1 | Â· A+ Â· L otherwise (3) where Xworst represents the current global worst position; XP is the best position of the producer; Ais a matrix with elements either 1 or -1, randomly assigned to control the direction; L is a matrix consisting of ones, used to adjust the step size of the forager. If i > n 

> 2

, it indicates that the current scrounger has relatively poor fitness and may be in a starving state. Consequently, it needs to search for new food sources more frequently. When sparrows are located at the edge of the flock, they will fly towards a safe area to avoid predator attacks. The update rule for this behavior is as follows: 

Xi,j t+1 =

(Xbest + Î² Â· | Xi,j t âˆ’ Xbest | if fi > f g

Xi,j t + K Â·



|Xi,j t âˆ’ Xworst t | Â· (fiâˆ’fw ) 

> fi

+ Ïµ



if fi = fg

(4) where Xbest is the current global best position; fi is the fitness value of the current sparrow, and fg is the global best fitness; Î² is a random distribution constant that controls the step size; K âˆˆ [âˆ’1, 1] is a random number that determines the direction of the step; Ïµ is a constant used to prevent division by zero errors. The behavioral strategy of edge sparrows is determined by comparing their fitness with the global best fitness to adjust their positions. These individuals tend to move closer to the center of the group to increase their safety. The pseudocode of the original SSA is presented in Algorithm 1. 

Algorithm 1 Sparrow Search Algorithm 

Begin 

Input: 

T : the maximum iterations; 

P D : the number of producers; 

SD : the number of sparrows who perceive the danger; 

R2: tthe alarm value; 

n: the number of sparrows; Initialize a population of n sparows and define its relevant parameters. 

While t < T 

Rank the fitness values and find the current best individual and the current worst individual; 

for i = 1 : P D 

Using Eq. 2 update the sparrowâ€™s location; 

end for for i = ( P D + 1) : n

Using Eq. 3 update the sparrowâ€™s location; 

end for for l = 1 : SD 

Using Eq. 4 update the sparrowâ€™s location; 

end for 

Get the current new location; If the new location is better than before,update it; 

t = t + 1 

end while return Xbest , fg

End 

5 The Proposed GeoSSA 

5.1 Good Nodes Set Initialization 

The traditional Sparrow Search Algorithm (SSA) employs Pseudo-Random Numbers initialization to generate the population. Although Pseudo-Random Numbers initialization is straightforward and exhibits strong randomness, the resulting individuals are often unevenly distributed across the search space. This uneven distribution can lead 6Running Title for Header 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1                                                                                

> X
> 0
> 0.1
> 0.2
> 0.3
> 0.4
> 0.5
> 0.6
> 0.7
> 0.8
> 0.9
> 1
> Y
> Good Nodes Set initialization
> 00.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1
> X
> 0
> 0.1
> 0.2
> 0.3
> 0.4
> 0.5
> 0.6
> 0.7
> 0.8
> 0.9
> 1
> Y
> Good Nodes Set initialization
> 00.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1
> X
> 0
> 0.1
> 0.2
> 0.3
> 0.4
> 0.5
> 0.6
> 0.7
> 0.8
> 0.9
> 1
> Y
> Good Nodes Set initialization
> 00.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1
> x
> 0
> 0.1
> 0.2
> 0.3
> 0.4
> 0.5
> 0.6
> 0.7
> 0.8
> 0.9
> 1
> y
> Pseudo -Random Number Initialization
> 00.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1
> x
> 0
> 0.1
> 0.2
> 0.3
> 0.4
> 0.5
> 0.6
> 0.7
> 0.8
> 0.9
> 1
> y
> Pseudo -Random Number Initialization
> 00.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1
> x
> 0
> 0.1
> 0.2
> 0.3
> 0.4
> 0.5
> 0.6
> 0.7
> 0.8
> 0.9
> 1
> y
> Pseudo -Random Number Initialization
> 00.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1
> X
> 0
> 0.1
> 0.2
> 0.3
> 0.4
> 0.5
> 0.6
> 0.7
> 0.8
> 0.9
> 1
> Y
> Tent Map Initialization
> 00.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1
> X
> 0
> 0.1
> 0.2
> 0.3
> 0.4
> 0.5
> 0.6
> 0.7
> 0.8
> 0.9
> 1
> Y
> Tent Map Initialization
> 00.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1
> X
> 0
> 0.1
> 0.2
> 0.3
> 0.4
> 0.5
> 0.6
> 0.7
> 0.8
> 0.9
> 1
> Y
> Tent Map Initialization

Figure 1: Comparison of different initialization methods. (a) Population initialized using Pseudo-Random Numbers when N =150; (b) Population initialized using Tent Mapping when N =150; (c) Population initialized using Good Nodes Set method when N =150. to population clustering effects, thereby reducing population diversity. Consequently, SSA is prone to premature convergence and diminished exploration efficiency during the search process. As illustrated in the left panel of Fig. 1, when the population size is set to N =150, the Pseudo-Random Numbers initialization produces a distribution with clearly observable clustered regions and large vacant areas. To address the limitations of Pseudo-Random Numbers initialization, researchers have proposed various chaotic-mapping-based strategies, such as Tent mapping shown in in the middle panel of Fig. 1. However, Tent mapping is essentially a Pseudo-Random Numbers distribution approach derived from chaotic sequences, and its uniformity cannot be strictly guaranteed, particularly in high-dimensional spaces. To overcome the above limitations, GeoSSA adopts the Good Nodes Set method for population initialization [ 18 ] [ 11 ][ 19 ]. The concept of the Good Nodes Set was introduced by Hua Luogeng, aiming to generate point sets with more uniform spatial distribution. A key advantage of this method is that its construction is dimension-independentâ€”meaning that it maintains uniformity not only in two-dimensional spaces but also in high-dimensional environments. As shown on the right side of Fig. 1, the population generated by the Good Nodes Set exhibits a more homogeneous distribution compared to Pseudo-Random Number initialization. This effectively avoids population clustering, increases coverage of the search space, and strengthens global exploration performance during early iterations. Let U D denote the unit hypercube in a D-dimensional Euclidean space. The Good Nodes Set can be defined as: 

P Mr = {p(k) = ( {kr }, {kr 2}, ..., {kr D })|k = 1 , 2, ..., M } (5) where {x} denotes the fractional part of x, M is the number of nodes, r > 0 is an offset parameter, C(r, Îµ ) is a constant depending on r, and Îµ > 0 is a given constant. When mapping the Good Nodes Set to the actual search space, suppose the lower and upper bounds of the ith dimension are xmin i and xmax i , respectively. The mapping is performed as follows: 

xik = ximin + pi(k) Â· (ximax âˆ’ ximin ) (6) 

5.2 Sine-Cosine Enhanced Producer Position Update 

In the Sparrow Search Algorithm (SSA), the traditional position-update mechanism for producer individuals relies on simple exponential decay functions or Gaussian-based updates. However, this strategy depends too heavily on local 7Running Title for Header search, causing individuals to easily fall into local optima. This issue becomes more pronounced in high-dimensional or complex search spaces, where the global exploration capability of the algorithm is significantly limited. To overcome this limitation, this study proposes a new producer position update strategy, called Sine-Cosine Enhanced Producer Position Update strategy [ 20 ]. By integrating both sine and cosine functions, this strategy enhances the position-update mechanism of producers and improves the global search ability of the traditional SSA. Specifically, the Sine-Cosine Strategy introduces a decision logic based on the value of r2: when r2 is smaller than the predefined threshold ST , the sine function is used to control the producerâ€™s position update; when r2 is greater than ST , the cosine function is applied instead. The core formula of this strategy is as follows: 

Xi,j t+1 =

(

Ï‰ Â· Xi,j t + r1 Â· sin( r2) Â· | r3 Â· Xbest âˆ’ Xi,j t |, if R2 < ST Ï‰ Â· Xi,j t + r1 Â· cos( r2) Â· | r3 Â· Xbest âˆ’ Xi,j t |, if R2 â‰¥ ST (7) where Ï‰ is the inertia weight based on the sigmoid function; r1 and r2 are random numbers; Xbest is the current global best position; r3 is a coefficient that adjusts the global exploration range; and Xbest represents the current global best position. The update rule for the inertia weight Ï‰ is as follows: 

Ï‰ = 11 + eâˆ’25( tT âˆ’0.5) (8) where t is the current iteration count; T is the maximum number of iterations. 

5.3 Triangular Walk Enhanced Edge Sparrow Position Update 

In the traditional SSA, the position update of edge sparrows (i.e., local optima individuals) typically relies on simple shifts based on the global optimal solution and random disturbances. While this position update mechanism can guide edge sparrows toward the global optimum, its update process is overly simplistic, making it prone to getting trapped in local optima. Furthermore, it lacks sufficient diversity and randomness in complex problems, leading to slow convergence and premature convergence of the algorithm. To address this drawback, we proposed Triangular Walk Enhanced Edge Sparrow Position Update strategy. This strategy introduces the Triangular Walk to improve the position update of edge sparrows, enhancing the local search capability and diversity [ 21 ]. Specifically, the Triangular Walk is combined with the original position update mechanism to adjust the update strategy. The fundamental idea is to introduce a dynamic adjustment factor rg during the update process, which is defined as: 

rg = 0 .1 âˆ’ 0.1 Â· tT (9) 

r = rg Â· Rand (10) Then, we introduce a random disturbance mechanism based on the Triangular Walk during the position update, as follows: 

L = Xbest âˆ’ Xi,j t (11) 

LP = L Â· Rand (12) 

Î± = L2 + LP 2 âˆ’ 2 Â· L Â· LP Â· cos (2 Ï€ Â· Rand ) (13) 

Xi,j t+1 = XPt+1 Â· L + r Â· Î± (14) where L represents the difference between the local optimal solution and the current individual; LP is a random disturbance; Î± is a new position adjustment factor calculated using trigonometric functions, shown in Fig. 2; and r is a random coefficient controlled by rg .Compared with traditional position update strategies, the Triangular Walk Enhanced Edge Sparrow Position Update mechanism offers significant advantages. First, the introduction of triangular walk increases the randomness of the position update process, breaking the limitation of single-direction perturbations. This allows the algorithm to move more flexibly across the solution space and reduces the likelihood of becoming trapped in local optima due to overly localized updates. Second, the dynamically adjusted factor rg ensures wide-range exploration during the early stages of 8Running Title for Header ð€ 1

# ð€ 2

# ð€ 

# ð€ 

Figure 2: Adjustment factor Î± of Triangular Walk. iteration, while gradually guiding the algorithm toward convergence in later stages, thereby improving convergence speed. Finally, the triangular-walk-based update mechanism substantially enhances the global search capability. In particular, when dealing with high-dimensional and complex optimization problems, it demonstrates stronger robustness and superior optimization performance compared with the traditional SSA. The Triangular Walk Enhanced Edge Sparrow Position Update strategy strengthens the position update process of locally optimal individuals by incorporating the triangular-walk mechanism, enabling the sparrow search algorithm to maintain a better balance between global exploration and local exploitation. This significantly improves solution quality and convergence efficiency, and its advantages become especially prominent in complex, high-dimensional optimization tasks. The pseudocode of GeoSSA is presented in Algorithm 2. 

6 Experiments 

The experiments in this study were conducted on a system equipped with Windows 11 (64-bit), an Intel(R) Core(TM) i5-8300H CPU @ 2.30 GHz processor, 8 GB RAM, and MATLAB R2023a as the simulation platform. To evaluate the performance and effectiveness of the proposed GeoSSA , the following experiments were designed: â€¢ Experiment 1: An ablation study in which the proposed improvement strategies were removed from GeoSSA and evaluated independently on the 23 benchmark functions shown in Table 2; â€¢ Experiment 2: A qualitative analysis experiment in which GeoSSA was applied to 23 benchmark functions to comprehensively assess its performance, robustness, and exploration-exploitation balance. The evaluation includes analysis of convergence behavior, population diversity, and exploration-exploitation dynamics; â€¢ Experiment 3: A comparative experiment between GeoSSA and several standard metaheuristic algorithms, advanced SSA variant, and state-of-the-art (SOTA) improved metaheuristic algorithms on the 23 benchmark functions. 

6.1 Ablation study 

In the ablation study, the three proposed strategies were individually removed or replaced with their original SSA counterparts: â€¢ GeoSSA1: GeoSSA1 denotes the variant in which the Good Nodes Set Initialization is replaced with pseudo-random initialization. â€¢ GeoSSA2: GeoSSA2 denotes the variant in which the proposed Sine-Cosine Enhanced Producer Position Update is replaced with the original producer update strategy. 9Running Title for Header 

Algorithm 2 The proposed GeoSSA 

Begin 

Input: 

T : the maximum iterations; 

P D : the number of producers; 

SD : the number of sparrows who perceive the danger; 

R2: tthe alarm value; 

n: the number of sparrows; Initialize a population of n sparows using Good Nodes Set method and define its relevant parameters. 

While t < T 

Rank the fitness values and find the current best individual and the current worst individual; 

for i = 1 : P D 

Using Eq. 7 update the sparrowâ€™s location; 

end for for i = ( P D + 1) : n

Using Eq. 3 update the sparrowâ€™s location; 

end for for l = 1 : SD 

Using Eq. 14 update the sparrowâ€™s location; 

end for 

Get the current new location; If the new location is better than before,update it; 

t = t + 1 

end while return Xbest , fg

End 

Table 2: Standard Benchmark Functions [22]. Function Functionâ€™s Name Type Dimension Best Value F1 Sphere Uni-modal, Scalable 30 0F2 Schwefelâ€™s Problem 2.22 Uni-modal, Scalable 30 0F3 Schwefelâ€™s Problem 1.2 Uni-modal, Scalable 30 0F4 Schwefelâ€™s Problem 2.21 Uni-modal, Scalable 30 0F5 Generalized Rosenbrockâ€™s Function Uni-modal, Scalable 30 0F6 Step Function Uni-modal, Scalable 30 0F7 Quartic Function Uni-modal, Scalable 30 0F8 Generalized Schwefelâ€™s Function Multi-modal, Scalable 30 -12569.5 F9 Generalized Rastriginâ€™s Function Multi-modal, Scalable 30 0F10 Ackleyâ€™s Function Multi-modal, Scalable 30 0F11 Generalized Griewankâ€™s Function Multi-modal, Scalable 30 0F12 Generalized Penalized Function 1 Multi-modal, Scalable 30 0F13 Generalized Penalized Function 2 Multi-modal, Scalable 30 0F14 Shekelâ€™s Foxholes Function Multi-modal, Unscalable 2 0.998 F15 Kowalikâ€™s Function Composition, Unscalable 4 0.0003075 F16 Six-Hump Camel-Back Function Composition, Unscalable 2 -1.0316 F17 Branin Function Composition, Unscalable 2 0.398 F18 Goldstein-Price Function Composition, Unscalable 2 3F19 Hartmanâ€™s Function 1 Composition, Unscalable 3 -3.8628 F20 Hartmanâ€™s Function 2 Composition, Unscalable 6 -3.32 F21 Shekelâ€™s Function 1 Composition, Unscalable 4 -10.1532 F22 Shekelâ€™s Function 2 Composition, Unscalable 4 -10.4029 F23 Shekelâ€™s Function 3 Composition, Unscalable 4 -10.5364 10 Running Title for Header â€¢ GeoSSA3: GeoSSA3 denotes the variant in which the Triangular Walk Enhanced Edge Sparrow Position Update is replaced with the original edge-sparrow update mechanism. For consistency, the number of iterations was set to T =500 and the population size to N =30. Each algorithm was independently executed 30 times on the 23 benchmark functions to validate the effectiveness of each proposed strategy. The experimental results are presented in Fig. 3 and Table 3. The Friedman test results demonstrate that GeoSSA ranks first among all variants in the ablation study. Moreover, the results clearly show that each of the proposed modules contributes significantly to improving the performance of GeoSSA. Table 3: Friedman Test Results of the Algorithms in Ablation Study. AF V indicates Average Friedman Value. Functions GeoSSA1 GeoSSA2 GeoSSA3 GeoSSA F1 2.5000 2.5000 2.5000 2.5000 F2 2.5000 2.5000 2.5000 2.5000 F3 2.5000 2.5000 2.5000 2.5000 F4 2.5000 2.5000 2.5000 2.5000 F5 2.5667 2.0333 3.4667 1.9333 F6 2.2667 2.1000 3.6000 2.0333 F7 2.6333 3.4333 1.6333 2.3000 F8 3.4000 2.6000 2.7333 1.2667 F9 2.5000 2.5000 2.5000 2.5000 F10 2.5000 2.5000 2.5000 2.5000 F11 2.5000 2.5000 2.5000 2.5000 F12 2.0667 2.2667 3.3333 2.3333 F13 2.1000 2.2000 3.5333 2.1667 F14 2.7167 2.2167 2.9000 2.1667 F15 2.4333 2.6333 2.5667 2.3667 F16 2.4667 2.3167 2.7667 2.4500 F17 2.5000 2.5000 2.5000 2.5000 F18 2.2167 2.8333 2.3667 2.5833 F19 2.4500 2.3333 2.8167 2.4000 F20 2.9000 2.1333 2.7000 2.2667 F21 2.9167 2.0333 2.3167 2.7333 F22 2.9000 2.0500 2.2833 2.7667 F23 2.8833 2.1833 2.3833 2.5500 

AF V 2.5616 2.4072 2.6696 2.3616 

Rank 3 2 4 1

First, the Good Nodes Set Initialization generates a more uniformly distributed sparrow population in the initial stage, expanding the coverage of the search space and preventing the formation of population clusters that would otherwise create search blind spots. This mechanism exhibits strong global exploration capability, particularly for complex multimodal functions (e.g., F20-F23), enabling the algorithm to more effectively identify promising regions. Second, the Sine-Cosine Enhanced Producer Position Update substantially improves search diversity during the exploration phase, allowing producers to make wider jumps in the solution space and rapidly locate the global optimum. This results in faster convergence on functions such as F1-F4 and F9-F11. The incorporation of sine and cosine operators enhances the algorithmâ€™s exploratory behavior, enabling effective avoidance of persistent local optima. Furthermore, this update mechanism considers not only the distance between individuals and the global optimum but also the relative distances among individuals, thereby further reinforcing global search capability. Thus, GeoSSA demonstrates superior performance on complex functions such as F5-F7. Finally, the Triangular Walk Enhanced Edge Sparrow Position Update introduces additional randomness while its dynamic factor ensures a balanced transition between global exploration and local exploitation. This allows the algorithm to converge quickly on simple functions (e.g., F1-F4) and effectively escape local optima on more difficult functions (e.g., F5-F7 and F12-F13). The three improvement modules complement one another, jointly enhancing global exploration, local exploitation, and population diversity maintenance. As a result, GeoSSA exhibits faster convergence and higher solution accuracy across different categories of benchmark functions, fully validating the effectiveness and robustness of the proposed strategies. 11 Running Title for Header 20 40 60 80 100 120 

10 -300 

10 -200 

10 -100 

10 0

> Fitness

F1 

Iteration 

20 40 60 80 100 120 

10 -300 

10 -200 

10 -100 

10 0

> Fitness

F1 

Iteration 

50 100 150 200 250 

10 -300 

10 -200 

10 -100 

10 0

> Fitness

F2 

Iteration 

50 100 150 200 250 

10 -300 

10 -200 

10 -100 

10 0

> Fitness

F2 

Iteration 

20 40 60 80 100 120 

10 -300 

10 -200 

10 -100 

10 0

> Fitness

F3 

Iteration 

20 40 60 80 100 120 

10 -300 

10 -200 

10 -100 

10 0

> Fitness

F3 

Iteration 

50 100 150 200 250 

10 -300 

10 -250 

10 -200 

10 -150 

10 -100 

10 -50 

> Fitness

F4 

Iteration 

50 100 150 200 250 

10 -300 

10 -250 

10 -200 

10 -150 

10 -100 

10 -50 

> Fitness

F4 

Iteration 

50 100 150 200 250 300 350 400 450 500 

Iteration 

10 -4

10 -2

10 0

10 2

> Fitness

F5 

50 100 150 200 250 300 350 400 450 500 

Iteration 

10 -4

10 -2

10 0

10 2

> Fitness

F5 

50 100 150 200 250 300 350 400 450 500 

Iteration 

10 -10 

10 -8

10 -6

10 -4

10 -2

10 0

> Fitness

F6 

50 100 150 200 250 300 350 400 450 500 

Iteration 

10 -10 

10 -8

10 -6

10 -4

10 -2

10 0

> Fitness

F6 

50 100 150 200 250 300 350 400 450 500 

Iteration 

10 -3

10 -2

10 -1

10 0

> Fitness

F7 

50 100 150 200 250 300 350 400 450 500 

Iteration 

10 -3

10 -2

10 -1

10 0

> Fitness

F7 

50 100 150 200 250 300 350 400 450 500 

Iteration 

-12000 

-11000 

-10000 

-9000 

-8000 

-7000 

-6000 

-5000 

> Fitness

F8 

50 100 150 200 250 300 350 400 450 500 

Iteration 

-12000 

-11000 

-10000 

-9000 

-8000 

-7000 

-6000 

-5000 

> Fitness

F8 

5 10 15 20 25 30 35 40 45 50 

Iteration 

10 -10 

10 -5

10 0

> Fitness

F9 

5 10 15 20 25 30 35 40 45 50 

Iteration 

10 -10 

10 -5

10 0

> Fitness

F9 

50 100 150 200 250 300 350 400 450 500 

Iteration 

10 -15 

10 -10 

10 -5

10 0

> Fitness

F10 

50 100 150 200 250 300 350 400 450 500 

Iteration 

10 -15 

10 -10 

10 -5

10 0

> Fitness

F10 

10 20 30 40 50 60 

Iteration 

10 -15 

10 -10 

10 -5

> Fitness

F11 

10 20 30 40 50 60 

Iteration 

10 -15 

10 -10 

10 -5

> Fitness

F11 

50 100 150 200 250 300 350 400 450 500 

Iteration 

10 -10 

10 -8

10 -6

10 -4

10 -2

> Fitness

F12 

50 100 150 200 250 300 350 400 450 500 

Iteration 

10 -10 

10 -8

10 -6

10 -4

10 -2

> Fitness

F12 

50 100 150 200 250 300 350 400 450 500 

Iteration 

10 -10 

10 -8

10 -6

10 -4

10 -2

10 0

> Fitness

F13 

50 100 150 200 250 300 350 400 450 500 

Iteration 

10 -10 

10 -8

10 -6

10 -4

10 -2

10 0

> Fitness

F13 

50 100 150 200 250 300 350 400 450 500 

Iteration 

10 0

10 1

> Fitness

F14 

50 100 150 200 250 300 350 400 450 500 

Iteration 

10 0

10 1

> Fitness

F14 

50 100 150 200 250 300 350 400 450 500 

Iteration 

10 -3

10 -2

> Fitness

F15 

50 100 150 200 250 300 350 400 450 500 

Iteration 

10 -3

10 -2

> Fitness

F15 

50 100 150 200 250 300 350 400 450 500 

Iteration 

10 -3

10 -2

> Fitness

F15 

50 100 150 200 250 300 350 400 450 500 

Iteration 

-1

-0.9 

-0.8 

-0.7 

-0.6 

-0.5 

-0.4 

> Fitness

F16 

50 100 150 200 250 300 350 400 450 500 

Iteration 

-1

-0.9 

-0.8 

-0.7 

-0.6 

-0.5 

-0.4 

> Fitness

F16 

50 100 150 200 250 300 350 400 450 500 

Iteration 

-1

-0.9 

-0.8 

-0.7 

-0.6 

-0.5 

-0.4 

> Fitness

F16 

50 100 150 200 250 300 350 400 450 500 

Iteration 

10 0

> Fitness

F17 

50 100 150 200 250 300 350 400 450 500 

Iteration 

10 0

> Fitness

F17 

50 100 150 200 250 300 350 400 450 500 

Iteration 

10 0

> Fitness

F17 

50 100 150 200 250 300 350 400 450 500 

Iteration 

5

10 

15 

20 

25 

30 

35 

40 

> Fitness

F18 

50 100 150 200 250 300 350 400 450 500 

Iteration 

5

10 

15 

20 

25 

30 

35 

40 

> Fitness

F18 

50 100 150 200 250 300 350 400 450 500 

Iteration 

-3.8 

-3.7 

-3.6 

-3.5 

-3.4 

-3.3 

-3.2 

-3.1 

-3

> Fitness

F19 

50 100 150 200 250 300 350 400 450 500 

Iteration 

-3.8 

-3.7 

-3.6 

-3.5 

-3.4 

-3.3 

-3.2 

-3.1 

-3

> Fitness

F19 

50 100 150 200 250 300 350 400 450 500 

Iteration 

-3.8 

-3.7 

-3.6 

-3.5 

-3.4 

-3.3 

-3.2 

-3.1 

-3

> Fitness

F19 

50 100 150 200 250 300 350 400 450 500 

Iteration 

-3.2 

-3

-2.8 

-2.6 

-2.4 

-2.2 

-2

-1.8 

> Fitness

F20 

50 100 150 200 250 300 350 400 450 500 

Iteration 

-3.2 

-3

-2.8 

-2.6 

-2.4 

-2.2 

-2

-1.8 

> Fitness

F20 

50 100 150 200 250 300 350 400 450 500 

Iteration 

-10 

-9

-8

-7

-6

-5

-4

> Fitness

F21 

50 100 150 200 250 300 350 400 450 500 

Iteration 

-10 

-9

-8

-7

-6

-5

-4

> Fitness

F21 

50 100 150 200 250 300 350 400 450 500 

Iteration 

-10 

-9

-8

-7

-6

-5

-4

-3

> Fitness

F22 

50 100 150 200 250 300 350 400 450 500 

Iteration 

-10 

-9

-8

-7

-6

-5

-4

-3

> Fitness

F22 

50 100 150 200 250 300 350 400 450 500 

Iteration 

-10 

-9

-8

-7

-6

-5

-4

> Fitness

F23 

50 100 150 200 250 300 350 400 450 500 

Iteration 

-10 

-9

-8

-7

-6

-5

-4

> Fitness

F23 

GeoSSA1 

GeoSSA2 

GeoSSA3 

GeoSSA 

Figure 3: Iteration curves of the GeoSSAs in ablation study 12 Running Title for Header 

6.2 Qualitative Analysis 

In the qualitative analysis experiment, the number of iterations was set to T =500 and the population size to N =30. GeoSSA was independently executed on the 23 benchmark functions listed in Table 2 to analyze its search history, exploration-exploitation ratio, and population diversity. To facilitate comparison and interpretation, function landscapes and convergence curves were also provided. The qualitative analysis results are shown in Fig. 4, Fig. 5, Fig. 6 and include the following components: â€¢ Landscapes of the benchmark functions; â€¢ Search history of the sparrow population; â€¢ Exploration-exploitation ratio curves; â€¢ Population diversity curves; â€¢ Convergence curves. The search history plots depict the spatial distribution of sparrow individuals during the search process. In these plots, red circles represent the global optimum, whereas blue circles indicate individual search trajectories. The results clearly show that GeoSSA is able to effectively explore the entire search space. For unimodal functions (e.g., F1-F6), GeoSSA demonstrates extremely fast convergence; individuals rapidly cluster near the optimal region within a small number of iterations. For more complex functions (e.g., F7-F8, F14-F17-F23), which contain numerous local optima, GeoSSA performs rapid early-stage global exploration followed by finely tuned exploitation in later stages. The results indicate that sparrow individuals traverse most of the search space, with their trajectories ultimately concentrating near the global optimum. Regarding exploration-exploitation balance, GeoSSA exhibits excellent dynamic regulation capability. For functions such as F1-F7 and F9-F13, GeoSSA maintains a high exploration ratio during early iterations and then quickly intensifies exploitation, highlighting its strong global search ability. For more challenging functions (e.g., F17-F23), GeoSSA begins with moderately high exploitation and gradually stabilizes the exploration-exploitation trend, demonstrating robust global and local search capabilities. Moreover, for multimodal functions such as F8-F23, the population diversity curves show that GeoSSA maintains significant fluctuation at a relatively high level throughout the search. This indicates that GeoSSA effectively preserves population diversity, preventing premature convergence caused by population clustering. Overall, GeoSSA exhibits strong performance in exploration depth, convergence speed, and stability, achieving an excellent balance between global exploration and local exploitation. 

6.3 Comparative Experiment 

To validate the superiority of GeoSSA, it was compared with the Attraction-Repulsion Optimization Algorithm (AROA) [23 ], Whale Optimization Algorithm (WOA) [ 24 ], IWOA [ 25 ], MWOA [ 26 ], IPSO [ 10 ], ISSA [ 27 ], and SSA on the benchmark functions listed in Table 2. The parameter settings for each algorithm are shown in Table 4. The number of iterations was set to T =500 and the population size to N =30. Each algorithm was independently executed 30 times on the 23 benchmark functions, and both parametric and nonparametric statistical tests were performed. The performance metrics include the average fitness ( Ave ), standard deviation ( Std ), p-values from the Wilcoxon signed-rank test, and Friedman ranks. The results are illustrated in Fig. 7, Table 5 and Table 6. The results demonstrate that GeoSSA achieves the best overall performance among all algorithms and provides signifi-cant improvements over the original SSA. GeoSSA also shows strong competitiveness against classical metaheuristic algorithms, high-performance SSA variants, and advanced improved metaheuristics. According to Fig. 7 and Table 5, GeoSSA obtains the best average fitness ( Ave ) and standard deviation ( Std ) on most benchmark functions. GeoSSA consistently converges rapidly to the optimal solution with high accuracy, indicating strong adaptability and robustness across diverse optimization tasks. However, on F7, GeoSSA performs slightly worse than MWOA. This observation is consistent with the â€™No Free Lunch Theoremâ€™, which states that no single algorithm can outperform all others on every optimization problem. Although GeoSSA achieves excellent overall performance, certain algorithms may outperform it on specific tasks, underscoring the importance of developing specialized strategies for different categories of optimization problems. From the Wilcoxon signed-rank test results in Table 6, GeoSSA exhibits statistically significant differences compared with AROA and IWOA on all benchmark functions. GeoSSA shows comparable performance to some algorithms on a few functions, where differences are not statistically significant. For example, GeoSSA and MWOA achieve nearly 13 Running Title for Header 

Figure 4: Results of qualitative analysis experiment (F1-F8). 14 Running Title for Header 

Figure 5: Results of qualitative analysis experiment (F9-F16). 15 Running Title for Header 

Figure 6: Results of qualitative analysis experiment (F17-F23). 16 Running Title for Header Table 4: Parameter settings for different metaheuristic algorithms Algorithm Parameter Value AROA [23] Attraction factor c 0.95 Local search scaling factor 1 0.15 Local search scaling factor 2 0.6 Attraction probability 1 0.2 Local search probability 0.8 Expansion factor 0.4 Local search threshold 1 0.9 Local search threshold 2 0.85 Local search threshold 3 0.9 WOA [24] Convergence factor a 2 decrease to 0 Spiral factor b 1IWOA [25] Convergence Factor a 2 decrease to 0 Spiral Factor b 1MWOA [26] Convergence Factor a 2 decreasing to 0 Spiral Factor b 1

CF 1 2.5 

CF 2 2.5 IPSO [10] Inertia Weight Ï‰ 0.9 decreasing to 0 

C1 2

C2 2ISSA [27] ST 0.7 

numberof theproducers 0.3 SSA [12] ST 0.7 

numberof theproducers 0.3 GeoSSA ST 0.7 

numberof theproducers 0.3 identical results on F1 and F3. Similarly, GeoSSA and IPSO perform almost identically on F1-F4, indicating that these algorithms are capable of quickly converging to the global optimum within the given iteration budget. For F9-F11, GeoSSA demonstrates no significant difference relative to MWOA, IPSO, and ISSA, reflecting convergence similarities near optimal regions. Finally, for F7, the p-value for MWOA exceeds 0.05, indicating that GeoSSA performs worse than MWOA on this function. Based on the results of Friedman tests in Table 6, GeoSSA achieves an average rank of 1.9514, the best among all algorithms. ISSA ranks second (2.9594), followed by SSA (3.3239). IPSO, IWOA, and WOA rank fourth, fifth, and sixth with average Friedman values of 5.0362, 5.1906, and 5.1978, respectively. MWOA and AROA rank seventh and eighth with scores of 5.3739 and 6.9667. These results clearly show that GeoSSA significantly outperforms other SOTA metaheuristic algorithms. 

6.4 Overall Effectiveness 

Table 7 summarizes all performance results of GeoSSA and other competitors by a useful metric named overall effectiveness ( OE ). In Table 7, w indicates win, t indicates tie and l indicates loss. The OE of each algorithm is computed by Eq. 15 [28]. 

OE = N âˆ’ LN Â· 100% (15) where N is the total number of tests; L is the total number of losing tests for each algorithm. The results show that GeoSSA achieves an OE value of 95.65%, demonstrating strong competitiveness across all benchmark functions. Overall, GeoSSA is the most effective algorithm among all competitors. 17 Running Title for Header 50 100 150 200 250 300 350 400 450 500 

10 -300 

10 -200 

10 -100 

10 0

> Fitness

F1 

Iteration 

50 100 150 200 250 300 350 400 450 500 

10 -300 

10 -200 

10 -100 

10 0

> Fitness

F1 

Iteration 

50 100 150 200 250 300 350 400 450 500 

10 -300 

10 -200 

10 -100 

10 0

> Fitness

F2 

Iteration 

50 100 150 200 250 300 350 400 450 500 

10 -300 

10 -200 

10 -100 

10 0

> Fitness

F2 

Iteration 

50 100 150 200 250 300 350 400 450 500 

10 -300 

10 -200 

10 -100 

10 0

> Fitness

F3 

Iteration 

50 100 150 200 250 300 350 400 450 500 

10 -300 

10 -200 

10 -100 

10 0

> Fitness

F3 

Iteration 

50 100 150 200 250 300 350 400 450 500 

10 -300 

10 -200 

10 -100 

10 0

> Fitness

F4 

Iteration 

50 100 150 200 250 300 350 400 450 500 

10 -300 

10 -200 

10 -100 

10 0

> Fitness

F4 

Iteration 

50 100 150 200 250 300 350 400 450 500 

Iteration 

10 0

10 5

> Fitness

F5 

50 100 150 200 250 300 350 400 450 500 

Iteration 

10 0

10 5

> Fitness

F5 

50 100 150 200 250 300 350 400 450 500 

Iteration 

10 -10 

10 -5

10 0

10 5

> Fitness

F6 

50 100 150 200 250 300 350 400 450 500 

Iteration 

10 -10 

10 -5

10 0

10 5

> Fitness

F6 

50 100 150 200 250 300 350 400 450 500 

Iteration 

10 -4

10 -2

10 0

10 2

> Fitness

F7 

50 100 150 200 250 300 350 400 450 500 

Iteration 

10 -4

10 -2

10 0

10 2

> Fitness

F7 

50 100 150 200 250 300 350 400 450 500 

Iteration 

-12000 

-11000 

-10000 

-9000 

-8000 

-7000 

-6000 

-5000 

-4000 

-3000 

> Fitness

F8 

50 100 150 200 250 300 350 400 450 500 

Iteration 

-12000 

-11000 

-10000 

-9000 

-8000 

-7000 

-6000 

-5000 

-4000 

-3000 

> Fitness

F8 

50 100 150 200 250 300 350 400 450 500 

Iteration 

10 -10 

10 -5

10 0

> Fitness

F9 

50 100 150 200 250 300 350 400 450 500 

Iteration 

10 -10 

10 -5

10 0

> Fitness

F9 

50 100 150 200 250 300 350 400 450 500 

Iteration 

10 -15 

10 -10 

10 -5

10 0

> Fitness

F10 

50 100 150 200 250 300 350 400 450 500 

Iteration 

10 -15 

10 -10 

10 -5

10 0

> Fitness

F10 

50 100 150 200 250 300 350 400 450 500 

Iteration 

10 -15 

10 -10 

10 -5

10 0

> Fitness

F11 

50 100 150 200 250 300 350 400 450 500 

Iteration 

10 -15 

10 -10 

10 -5

10 0

> Fitness

F11 

50 100 150 200 250 300 350 400 450 500 

Iteration 

10 -10 

10 -5

10 0

10 5

> Fitness

F12 

50 100 150 200 250 300 350 400 450 500 

Iteration 

10 -10 

10 -5

10 0

10 5

> Fitness

F12 

50 100 150 200 250 300 350 400 450 500 

Iteration 

10 -10 

10 -5

10 0

10 5

> Fitness

F13 

50 100 150 200 250 300 350 400 450 500 

Iteration 

10 -10 

10 -5

10 0

10 5

> Fitness

F13 

50 100 150 200 250 300 350 400 450 500 

Iteration 

10 0

10 1

10 2

> Fitness

F14 

50 100 150 200 250 300 350 400 450 500 

Iteration 

10 0

10 1

10 2

> Fitness

F14 

50 100 150 200 250 300 350 400 450 500 

Iteration 

10 -3

10 -2

10 -1

10 0

> Fitness

F15 

50 100 150 200 250 300 350 400 450 500 

Iteration 

10 -3

10 -2

10 -1

10 0

> Fitness

F15 

50 100 150 200 250 300 350 400 450 500 

Iteration 

-1

-0.8 

-0.6 

-0.4 

-0.2 

0

0.2 

0.4 

0.6 

> Fitness

F16 

50 100 150 200 250 300 350 400 450 500 

Iteration 

-1

-0.8 

-0.6 

-0.4 

-0.2 

0

0.2 

0.4 

0.6 

> Fitness

F16 

50 100 150 200 250 300 350 400 450 500 

Iteration 

-1

-0.8 

-0.6 

-0.4 

-0.2 

0

0.2 

0.4 

0.6 

> Fitness

F16 

50 100 150 200 250 300 350 400 450 500 

Iteration 

10 0

> Fitness

F17 

50 100 150 200 250 300 350 400 450 500 

Iteration 

10 0

> Fitness

F17 

50 100 150 200 250 300 350 400 450 500 

Iteration 

10 1

> Fitness

F18 

50 100 150 200 250 300 350 400 450 500 

Iteration 

10 1

> Fitness

F18 

50 100 150 200 250 300 350 400 450 500 

Iteration 

-3.5 

-3

-2.5 

-2

-1.5 

-1

> Fitness

F19 

50 100 150 200 250 300 350 400 450 500 

Iteration 

-3.5 

-3

-2.5 

-2

-1.5 

-1

> Fitness

F19 

50 100 150 200 250 300 350 400 450 500 

Iteration 

-10 0

> Fitness

F20 

50 100 150 200 250 300 350 400 450 500 

Iteration 

-10 0

> Fitness

F20 

50 100 150 200 250 300 350 400 450 500 

Iteration 

-10 1

-10 0

> Fitness

F21 

50 100 150 200 250 300 350 400 450 500 

Iteration 

-10 1

-10 0

> Fitness

F21 

50 100 150 200 250 300 350 400 450 500 

Iteration 

-10 1

-10 0

> Fitness

F22 

50 100 150 200 250 300 350 400 450 500 

Iteration 

-10 1

-10 0

> Fitness

F22 

50 100 150 200 250 300 350 400 450 500 

Iteration 

-10 1

-10 0

> Fitness

F23 

50 100 150 200 250 300 350 400 450 500 

Iteration 

-10 1

-10 0

> Fitness

F23 

AROA 

WOA 

IWOA 

MWOA 

IPSO 

ISSA 

SSA 

GeoSSA 

Figure 7: Iterative curves of the algorithms in the comparative experiment. 18 Running Title for Header Table 5: Parametric results of the algorihms in the comparative experiment. Function  Metrics  AROA  WOA  IWOA  MWOA  IPSO  ISSA  SSA  GeoSSA F1  Ave  4.0514E+00  9.1772E-75  2.6908E-73  0.0000E+00  0.0000E+00  7.6437e-186  2.0231e-65  0.0000E+00 Std  2.4914E+00  2.8932E-74  1.0220E-72  0.0000E+00  0.0000E+00  8.4520E-186  1.1067E-64  0.0000E+00 F2  Ave  6.4229E-01  1.5238E-50  5.7738E-51  1.2639E-229  0.0000E+00  2.2066E-91  3.2283E-29  0.0000E+00 Std  1.6465E-01  7.7098E-50  1.8475E-50  2.4524E-229  0.0000E+00  1.0365E-90  1.6139E-28  0.0000E+00 F3  Ave  2.3001E+02  4.9269E+04  1.0891E+04  0.0000E+00  0.0000E+00  1.0357E-60  9.2475E-30  0.0000E+00 Std  2.6737E+02  1.2059E+04  1.5699E+04  0.0000E+00  0.0000E+00  5.6684E-60  5.0259E-29  0.0000E+00 F4  Ave  1.6317E+00  5.0922E+01  1.6369E+01  1.0452E-200  0.0000E+00  1.4676E-94  4.5398E-36  0.0000E+00 Std  4.9537E-01  2.5849E+01  1.4501E+01  2.3521E-200  0.0000E+00  5.5654E-94  2.4581E-35  0.0000E+00 F5  Ave  1.0455E+02  2.8104E+01  2.7792E+01  2.8715E+01  2.8932E+01  2.6692E-04  3.2808E-05  1.8574E-05 Std  9.3119E+01  4.7737E-01  4.3899E-01  1.3051E-01  9.1355E-02  3.6679E-04  6.7227E-05  4.1676E-05 F6  Ave  1.0953E+01  4.1545E-01  3.7757E-01  1.2468E+00  5.8354E+00  1.2349E-10  1.6312E-10  5.4264E-11 Std  3.0083E+00  2.3947E-01  2.5550E-01  4.0110E-01  5.6576E-01  2.0486E-10  5.4238E-10  1.4801E-10 F7  Ave  2.6707E-02  4.3968E-03  1.5294E-03  6.2096E-05  1.0627E-04  6.7477E-04  1.7292E-03  9.9504E-05 Std  1.7806E-02  3.9177E-03  1.6834E-03  6.0112E-05  1.1830E-04  4.8201E-04  1.4339E-03  1.0421E-04 F8  Ave  -4.8004E+03  -1.0315E+04  -1.0616E+04  -5.1360E+03  -2.8207E+03  -9.3704E+03  -8.5760E+03  -1.2569E+04 Std  5.5412E+02  1.7152E+03  1.8129E+03  1.9636E+03  7.9845E+02  9.0770E+02  7.2792E+02  5.2754E-05 F9  Ave  4.0975E+01  5.6843E-15  5.6843E-15  0.0000E+00  0.0000E+00  0.0000E+00  0.0000E+00  0.0000E+00 Std  5.8011E+01  2.2884E-14  1.7345E-14  0.0000E+00  0.0000E+00  0.0000E+00  0.0000E+00  0.0000E+00 F10  Ave  7.8930E-01  4.4705E-15  4.7073E-15  4.4409E-16  4.4409E-16  4.4409E-16  4.4409E-16  4.4409E-16 Std  3.1087E-01  2.7572E-15  2.3603E-15  0.0000E+00  0.0000E+00  0.0000E+00  0.0000E+00  0.0000E+00 F11  Ave  9.9819E-01  1.6368E-02  1.6339E-02  0.0000E+00  0.0000E+00  0.0000E+00  0.0000E+00  0.0000E+00 Std  1.0866E-01  5.0668E-02  5.2652E-02  0.0000E+00  0.0000E+00  0.0000E+00  0.0000E+00  0.0000E+00 F12  Ave  1.2626E+00  3.4146E-02  3.4287E-02  7.1081E-02  7.5448E-01  4.5857E-12  1.7784E-12  5.8568E-13 Std  3.0490E-01  3.8896E-02  2.7267E-02  4.9211E-02  1.8488E-01  6.0585E-12  2.9346E-12  1.0975E-12 F13  Ave  3.8194E+00  6.4092E-01  5.2446E-01  7.1072E-01  2.8750E+00  6.8132E-11  1.7852E-10  5.2094E-11 Std  4.1069E-01  3.2259E-01  3.3007E-01  1.9087E-01  1.4062E-01  1.5112E-10  6.8525E-10  1.4162E-10 F14  Ave  5.9912E+00  3.2233E+00  2.6354E+00  6.3416E+00  2.7051E+00  3.5309E+00  6.4528E+00  9.9800E-01 Std  5.0892E+00  3.3554E+00  2.9515E+00  4.2913E+00  2.6083E+00  4.6861E+00  5.5831E+00  1.2709E-16 F15  Ave  3.7645E-03  5.9536E-04  1.0184E-03  5.3728E-04  7.5151E-03  3.5019E-04  3.1686E-04  3.1304E-04 Std  6.1855E-03  2.9886E-04  6.8929E-04  1.6152E-04  8.7506E-03  2.1575E-04  5.1327E-05  3.0416E-05 F16  Ave  -1.0316E+00  -1.0316E+00  -1.0316E+00  -9.8473E-01  -1.0292E+00  -1.0316E+00  -1.0316E+00  -1.0316E+00 Std  1.2819E-04  1.4022E-09  1.4561E-09  3.8021E-02  5.7122E-03  5.2156e-16  5.2964E-16  4.6467E-16 F17  Ave  3.9885E-01  3.9789E-01  3.9790E-01  4.2206E-01  4.0478E-01  3.9789E-01  3.9789E-01  3.9789E-01 Std  3.7027E-03  8.1458E-06  8.1458E-06  3.1797E-02  8.3924E-03  3.2434E-16  0.0000E+00  0.0000E+00 F18  Ave  3.0005E+00  3.0000E+00  3.0001E+00  9.5037E+00  3.0038E+00  3.0000E+00  3.9000E+00  3.0000E+00 Std  9.1161E-04  6.5608E-05  2.0970E-04  1.1091E+01  7.1699E-03  1.9963E-15  4.9295E+00  1.9428E-15 F19  Ave  -3.8590E+00  -3.8513E+00  -3.8561E+00  -3.7812E+00  -3.8557E+00  -3.8628E+00  -3.8628E+00  -3.8628E+00 Std  4.7376E-03  1.7870E-02  9.8997E-03  7.2325E-02  3.7930E-03  2.2599E-15  2.3061e-15  2.0927E-15 F20  Ave  -3.1934E+00  -3.2299E+00  -3.1699E+00  -2.9755E+00  -2.9614E+00  -3.2782E+00  -3.2705E+00  -3.3141E+00 Std  9.5412E-02  1.0302E-01  6.9113E-02  1.8864E-01  1.9826E-01  6.6370E-02  5.9923E-02  3.0164E-02 F21  Ave  -5.9550E+00  -8.0223E+00  -7.0654E+00  -4.6152E+00  -1.0123E+01  -1.0153E+01  -8.9637E+00  -1.0153E+01 Std  2.8343E+00  2.6676E+00  2.5051E+00  6.5956E-01  2.5959E-02  2.8558E-10  2.1931E+00  4.7114E-15 F22  Ave  -6.3714E+00  -7.8768E+00  -6.8151E+00  -4.6617E+00  -1.0366E+01  -1.0403E+01  -9.5170E+00  -1.0403E+01 Std  3.3719E+00  2.9662E+00  2.4909E+00  5.2371E-01  1.9359E-02  2.6798E-15  2.0147E+00  1.4752E-15 F23  Ave  -5.0240E+00  -7.4556E+00  -6.7415E+00  -4.6137E+00  -1.0503E+01  -1.0536E+01  -9.2673E+00  -1.0536E+01 Std  3.0601E+00  3.1778E+00  2.5068E+00  3.4342E-01  2.0370E-02  6.4302E-15  2.3227E+00  2.9133E-15 19 Running Title for Header Table 6: Non-parametric results of the algorihms in the comparative experiment. Algorithm Rank Average Friedman Value +/=/-AROA 8 6.9667 23/0/0 WOA 6 5.1978 23/0/0 IWOA 5 5.1906 23/0/0 MWOA 7 5.3739 17/5/1 IPSO 4 5.0362 16/7/0 ISSA 2 2.9594 20/3/0 SSA 3 3.3239 19/4/0 GeoSSA 1 1.9514 -Table 7: Effectiveness of GeoSSA and other competitors. Metrics AROA WOA IWOA MWOA IPSO ISSA SSA GeoSSA 

w/t/l 0/0/23 0/0/23 0/0/23 1/5/17 0/7/16 0/3/20 0/4/19 14/8/1 

OE 0.00% 0.00% 0.00% 26.09% 30.43% 13.04% 17.39% 95.65% 

7 UAV Path Planning 

The core objective of 3D path planning for drones is typically to minimize the path length while successfully avoiding obstacles and satisfying the droneâ€™s dynamic constraints. To facilitate the comparison of different metaheuristic optimizersâ€™ search capabilities using a single-objective optimization algorithm, this study employs a weighted composite single-objective function Ftc , which integrates three key performance metrics into a scalar objective: 

Ftc = w1Fpc + w2Fhc + w3Fsc (16) where Fpc represents the path length cost, Fhc denotes the height cost, and Fsc represents the droneâ€™s dynamic constraint cost. The weight coefficients satisfy wi â‰¥ 0 and w1 + w2 + w3 = 1 .In all experiments, to maintain a balance between path efficiency and flight stability, the weights are uniformly set to 

w1=0.5, w2=0.3, w3=0.2. This weighted strategy allows the constraints on path length, flight height, and trajectory smoothness to be addressed within the single-objective framework, enabling comparisons among all the algorithms based on the same scalar criterion. Mathematically, the discretized path is represented by g waypoints: 

P = {P1, . . . , P g } (17) The path length cost term is defined as: 

Fpc =

> gâˆ’1

X

> m=1

âˆ¥Pm+1 âˆ’ Pmâˆ¥2 (18) The height cost term is defined as the standard deviation of the height samples: 

Fhc =

vuut 1

g

> g

X

> m=1

(zm âˆ’ Â¯z)2 (19) The dynamic constraint cost is expressed by the cumulative angle between adjacent segments: 

Fsc =

> gâˆ’2

X

> m=1

arccos 

 (Pm+1 âˆ’ Pm) Â· (Pm+2 âˆ’ Pm+1 )

âˆ¥Pm+1 âˆ’ Pmâˆ¥âˆ¥ Pm+2 âˆ’ Pm+1 âˆ¥



(20) The obstacle constraint is incorporated into the objective function through a penalty term (assigning a large penalty value to solutions that conflict with obstacles), leading to the final optimization problem formulation: 

min  

> P

F (P ) = Ftc (P ) + Î¦ obs (P ), (21) 20 Running Title for Header where the penalty term Î¦obs uses a combination of distance threshold and squared penalties to prioritize feasible solutions. In this study, the starting point is set as (20,20,20) and the destination as (180,180,20). Several irregular static obstacles are arranged in the 3D scene to simulate complex terrain. Fig. 8 is the terrain information of the UAV path planning problem. The proposed GeoSSA is compared with selected algorithms, including AROA, WOA, IWOA, MWOA, IPSO, ISSA and SSA. The number of iterations is set to T =500, and the population size is N =30. The parameter settings for each algorithm are shown in Table 4. To evaluate the stability and statistical performance of the algorithms, each algorithm is independently repeated 30 times. The performance metric is the Ftc value obtained from each run, and the average fitness ( Ave ) and standard deviation ( Std ) of each algorithm are recorded to compare their optimization quality and robustness. 

Figure 8: Terrain information of the UAV path planning problem. As shown in Tabel 8, Fig. 9, Fig. 10, Fig. 11 and Fig. 12, the experimental results indicate that GeoSSA achieves the best average performance (74.8472) and the smallest standard deviation (0.95654), demonstrating that the algorithm not only attains lower objective values across multiple independent runs but also exhibits outstanding stability and robustness. In comparison, IPSO, ISSA, and SSA produce reasonably good solutions in most trials (with average values concentrated in the 77-80 range), yet their standard deviations are consistently higher than that of GeoSSA, indicating greater variability in their results. Furthermore, AROA, WOA, and MWOA show noticeably higher means and variances. Notably, IWOA presents an extremely large mean (3.33E+31) and variance (1.83E+32), suggesting that this method is prone to premature convergence or entrapment in local optima when addressing UAV path-planning tasks, resulting in poor or even unacceptable trajectory solutions. Additional analyses based on convergence curves and trajectory visualizations further confirm that GeoSSA exhibits a rapid early-stage convergence rate while remaining stable in later iterations, indicating a well-balanced trade-off between exploration and exploitation under the weighted objective. The trajectory plots also show that GeoSSA produces shorter flight paths with smoother turns, successfully avoids obstacles, and simultaneously satisfies both dynamic and altitude constraints. Overall, GeoSSA demonstrates superior optimization capability and the highest stability in solving UAV path planning problems. 

8 Engineering Design Optimization 

Engineering design optimization aims to identify design solutions that achieve optimal performance, minimal cost, or the most rational structural configuration for practical engineering applications while satisfying specified constraints. Because engineering design problems frequently involve complex nonlinear constraints, coexisting discrete and continuous variables, multimodal landscapes, and nondifferentiable objective functions, classical analytical and gradient-based optimization methods face substantial limitations when solving such problems. Consequently, meta-heuristic algorithmsâ€”characterized by strong global search capability, no requirement for gradient information, and high robustnessâ€”are widely employed for the analysis and solution of these problems. 21 Running Title for Header 

Figure 9: comparison of the paths generated by the algorithms. Table 8: Comparison results of the algorithms in UAV Path Planning. 

Algorithm Metrics Value 

AROA Ave 98.3896 Std 35.0485 WOA Ave 92.431 Std 39.8221 IWOA Ave 3.33E+31 Std 1.83E+32 MWOA Ave 110.4649 Std 22.6079 IPSO Ave 79.7978 Std 1.9662 ISSA Ave 77.8496 Std 21.2555 SSA Ave 77.8214 Std 11.2765 GeoSSA Ave 74.8472 

Std 0.95654 

In this study, constraint handling in all engineering design optimization problems is performed using the Penalty Function Method, which is one of the most widely adopted and effective techniques in meta-heuristic optimization. Specifically, constrained optimization problems are transformed into unconstrained ones by augmenting the original objective function with penalty terms corresponding to constraint violations. When a candidate solution violates one or more constraints, a sufficiently large penalty is imposed, thereby discouraging infeasible solutions and guiding the search process toward the feasible region. The penalty coefficients are selected as fixed large constants, following common practice in the related literature, to ensure that feasibility is strictly prioritized over objective improvement without introducing excessive numerical instability. To comprehensively evaluate the applicability and advantages of the proposed GeoSSA algorithm in realistic engi-neering design scenarios, this section selects four representative engineering design optimization problems for testing: Corrugated Bulkhead design problem, Piston Lever design problem, Reactor Network design problem, and an Industrial Refrigeration System design problem. These problems span mechanical structures, chemical process design, and industrial equipment, each exhibiting strong constraints, high coupling, and pronounced nonlinearity, thereby providing a thorough assessment of algorithm stability and solution capability across diverse practical settings. The experiments in this study were conducted on a system equipped with Windows 11 (64-bit), an Intel(R) Core(TM) i5-8300H CPU @ 2.30 GHz processor, 8 GB RAM, and MATLAB R2023a as the simulation platform. GeoSSA is compared against 22 Running Title for Header The path generated by IWOA 

> The path generated by MWOA
> The path generated by AROA
> The path generated by WOA

Figure 10: Paths generated by the algorithms in solving the UAV path planning problem. 23 Running Title for Header The path generated by SSA 

> The path generated by GeoSSA
> The path generated by IPSO
> The path generated by ISSA

Figure 11: Paths generated by the algorithms in solving the UAV path planning problem (Continued). 24 Running Title for Header 0 50 100 150 200 250 300 350 400 450 500 

Iteration           

> 80
> 100
> 120
> 140
> 160
> 180
> 200
> Fitness
> AROA
> WOA
> IWOA
> MWOA
> IPSO
> ISSA
> SSA
> GeoSSA
> 050 100 150 200 250 300 350 400 450 500

Iteration 

> 80
> 100
> 120
> 140
> 160
> 180
> 200
> Fitness
> AROA
> WOA
> IWOA
> MWOA
> IPSO
> ISSA
> SSA
> GeoSSA

Figure 12: Iteration curves of the algorithms in solving the UAV path planning problem. AROA, WOA, IWOA, MWOA, IPSO, ISSA, and SSA. The parameter settings for all algorithms are listed in Table 4. All algorithms were run with a unified configuration of T = 500 iterations and population size N = 30 . Each algorithm was independently executed 30 times on every engineering design problem, and the average fitness ( Ave ) and standard deviation ( Std ) were recorded for performance evaluation. The experimental results are presented in Fig. 14, Fig. 16, Fig. 18, Fig. 20 and Table 9. The following subsections describe the mathematical models and constraints for each engineering design problem in detail and provide a thorough analysis of the solution performance of GeoSSA relative to the comparison algorithms. 

8.1 Corrugated Bulkhead 

The design of corrugated bulkheads plays a crucial role in chemical plant design, particularly in the design of chemical storage tanks, reactors, pressure vessels, and other equipment. Corrugated bulkheads are typically used in containers that must withstand high pressure during storage, transportation, and chemical reactions, and are primarily intended to enhance the structural strength and stability, as shown in Fig. 13. Compared to traditional flat bulkheads, in the chemical plant environment, which is often exposed to numerous vibration sources, corrugated bulkheads increase the load-bearing capacity by distributing the special corrugated shape, thus reducing the risk of structural fatigue, deformation, and rupture. By optimizing the structure of the corrugated bulkhead, the safety, strength, durability, and cost-effectiveness of the equipment can be further improved, which in turn enhances the overall design efficiency of the chemical plant and ensures the stability and safety of the production process. The focus of the corrugated bulkhead design task is to determine the optimal shape that maximizes compressive strength. Through parameter optimization, including the length, width, height, and material thickness of the corrugation, metaheuristic algorithms seek a design that achieves maximum compressive strength with minimal material usage. This task involves four variables: length x1, width x2, height x3, and thickness x4 of the corrugations. There are six inequality constraints to ensure physical properties suitable for real-world use, such as maximum material strength, allowable deformation, and manufacturing limitations. The optimized corrugated bulkhead design achieves improved material utilization, lower production costs, and enhanced structural performance, meeting safety and durability standards. The mathematical modeling of Corrugated Bulkhead (CB) design problem is as follows: 25 Running Title for Header Deck 

Bottom 

Figure 13: The structure of a corrugated bulkhead 

Variable: 

x = [ x1, x 2, x 3, x 4]

Minimize: 

f (x) = 5.885 Â· x4 Â· (x1 + x3)

x1 + p|x23 âˆ’ x22| + punishment 

Subject to: 

g1 = âˆ’x4 Â· x2 Â· (0 .4 Â· x1 + x3

6 ) + 8 .94 Â· (x1 +

q

|x23 âˆ’ x22|) â‰¤ 0; (22) 

g2 = âˆ’x4 Â· x22 Â· (0 .2 Â· x1 + x3

12 ) + 2 .2 Â·



8.94 Â· (x1 +

q

|x23 âˆ’ x22|)

 43

â‰¤ 0; (23) 

g3 = âˆ’x4 + 0 .0156 Â· x1 + 0 .15 â‰¤ 0; (24) 

g4 = âˆ’x4 + 0 .0156 Â· x3 + 0 .15 â‰¤ 0; (25) 

g5 = âˆ’x4 + 1 .05 â‰¤ 0; (26) 

g6 = âˆ’x3 + x2 â‰¤ 0; (27) 

Variable range: 

1 â‰¤ x1 â‰¤ 100; 1 â‰¤ x2 â‰¤ 100; 1 â‰¤ x3 â‰¤ 100; 1 â‰¤ x4 â‰¤ 5; 

26 Running Title for Header 

Where: 

punishment = 10 3Â·

> 6

X

> i=1

max (0 , g i)2

The experimental results are presented in Fig. 14 and Table 9. As shown in Table 9, in the Corrugated Bulkhead design problem, GeoSSA exhibits significantly higher stability than all other algorithms, and its optimization accuracy is the best among the compared methods. This demonstrates that GeoSSA possesses substantial advantages when addressing this type of engineering optimization problem. 0 50 100 150 200 250 300 350 400 450 500 

Iteration           

> 10 0
> 10 2
> 10 4
> 10 6
> 10 8
> 10 10
> Fitness
> AROA
> WOA
> IWOA
> MWOA
> IPSO
> ISSA
> SSA
> GeoSSA
> 050 100 150 200 250 300 350 400 450 500

Iteration           

> 10 0
> 10 2
> 10 4
> 10 6
> 10 8
> 10 10
> Fitness
> AROA
> WOA
> IWOA
> MWOA
> IPSO
> ISSA
> SSA
> GeoSSA
> 050 100 150 200 250 300 350 400 450 500

Iteration 

> 10 0
> 10 2
> 10 4
> 10 6
> 10 8
> 10 10
> Fitness
> AROA
> WOA
> IWOA
> MWOA
> IPSO
> ISSA
> SSA
> GeoSSA

Figure 14: Iteration curves of the algorithms in solving the Corrugated Bulkhead design problem. 

8.2 Piston Lever 

Piston levers are critical components in various important pieces of equipment, such as pumps and compressors, where their performance directly impacts the reliability and efficiency of the entire system. The Piston Lever (PL) design problem focuses on determining the optimal piston dimensions and material selection to ensure maximum performance in transmission systems. This design influences the efficiency, stability, and durability of mechanical systems. The optimization task seeks to balance dimensions, weight, material choice, and manufacturing cost in order to find the optimal piston size and material that maximize system efficiency and cost-effectiveness. Therefore, the Piston Lever design problem is of paramount importance in chemical plant design, and optimizing these key components is essential to ensuring the optimal performance of the system. As shown in Fig. 15, the optimization task involves four variables: piston length x1, piston diameter x2, material property x3, and transmission rod length x4, which affect the systemâ€™s mechanical properties, dynamic performance, and cost. The Piston Lever design problem can be described as: 

Variable: 

x = [ x1, x 2, x 3, x 4]

27 Running Title for Header P 

> Q
> L
> X
> L2 L1
> B
> R
> H
> Î¸
> Q
> D

Figure 15: The structure of a piston lever [29]. 

Minimize: 

f (x) = 0 .25 Ï€x 23(L2 âˆ’ L1) + punishment (28) 

Subject to: 

g1 = QL cos Î¸ âˆ’ RF â‰¤ 0; (29) 

g2 = Q(L âˆ’ x4) âˆ’ Mmax â‰¤ 0; (30) 

g3 = 1 .2( L2 âˆ’ L1) âˆ’ L1 â‰¤ 0; (31) 

g4 = x3

2 âˆ’ x2 â‰¤ 0; (32) 

Where: 

Q = 10000; P = 1500; L = 240; F = 0 .25 Ï€P x 23;

Mmax = 1 .8 Ã— 10 6; L1 =

q

(x4 âˆ’ x2)2 + x21;

L2 = p(x4 sin Î¸ + x1)2 + ( x2 âˆ’ x4 cos Î¸)2;

R = | âˆ’ x4(x4 sin Î¸ + x1) + x1(x2 âˆ’ x4 cos Î¸)|

p(x4 âˆ’ x2)2 + x21

;

28 Running Title for Header 

punishment = 10 3Â·

> 4

X

> i=1

max (0 , g i)2

Variable range: 

0.05 â‰¤ x1 â‰¤ 500; 0.05 â‰¤ x2 â‰¤ 500; 0.05 â‰¤ x3 â‰¤ 120; 0.05 â‰¤ x4 â‰¤ 500; 

The experimental results are presented in Fig. 16 and Table 9. As shown in Table 9, in the Piston Lever design problem, GeoSSA exhibits significantly higher stability than all other algorithms, and its optimization accuracy is the best among the compared methods. This demonstrates that GeoSSA possesses substantial advantages when addressing this type of engineering optimization problem. 0 50 100 150 200 250 300 350 400 450 500           

> Iteration
> 10 0
> 10 5
> 10 10
> 10 15
> Fitness
> AROA
> WOA
> IWOA
> MWOA
> IPSO
> ISSA
> SSA
> GeoSSA
> 050 100 150 200 250 300 350 400 450 500
> Iteration
> 10 0
> 10 5
> 10 10
> 10 15
> Fitness
> AROA
> WOA
> IWOA
> MWOA
> IPSO
> ISSA
> SSA
> GeoSSA

Figure 16: Iteration curves of the algorithms in solving the Piston Lever design problem. 

8.3 Reactor Network 

The Reactor Network (RN) design problem aims to optimize the configuration of chemical reactors within a chemical plant to achieve more efficient reaction processes. This involves selecting reactor types, determining their arrangement, and allocating fluid flow rates, with the objective of maximizing product concentration. By adjusting reactor configu-rations and operating conditions, the reaction efficiency can be improved, energy consumption reduced, and product quality enhanced. As shown in Fig. 17, the problem involves four variables representing the concentrations at different reaction stages: x1

denotes the reactant concentration in the first reactor, x2 the product concentration in the first reactor, x3 the reactant concentration in the second reactor, and x4 the final product concentration. The constraint conditions h1 to h4 are defined as follows: h1 represents the balance between reactants and products in the first reactor; h2 enforces mass conservation between the first and second reactors; h3 maintains the concentration balance of reactants between reactors; and h4 ensures mass conservation between intermediate and final products. 29 Running Title for Header Motor 

> Motor
> Agitator
> Agitator
> ð€ 1
> ð€ 2
> ð€ 1&ð€ 2
> ð€ 3&ð€ 4
> ð€ 1
> ð€ 2
> ð€ 3
> ð€ 2
> ð€ 4

Figure 17: The structure of a reactor network The mathematical model of the reactor network design problem is given as follows. 

Variable: 

x = [ x1, x 2, x 3, x 4, x 5, x 6]

Minimize: 

f (x) = x4 + punishment (33) 

Subject to: 

g = âˆšx5 + âˆšx6 âˆ’ 4 â‰¤ 0; (34) 

h1(x) = x1 + k1 Â· x2 Â· x5 âˆ’ 1 = 0; (35) 

h2 = x2 âˆ’ x1 + k2 Â· x2 Â· x6 = 0; (36) 

h3(x) = x3 + x1 + k3 Â· x3 Â· x5 âˆ’ 1 = 0; (37) 

h4 = x4 âˆ’ x3 + x2 âˆ’ x1 + k4 Â· x4 Â· x6 = 0; (38) 

Where: 

k1 = 0 .09755988; k2 = 0 .99 Â· k1; k3 = 0 .0391908; 

k4 = 0 .9 Â· k3;

punishment = 10 3 Â· max (0 , g )2

Variable range: 

0.00001 â‰¤ x1 â‰¤ 1; 0.00001 â‰¤ x2 â‰¤ 1; 0.00001 â‰¤ x3 â‰¤ 1; 0.00001 â‰¤ x4 â‰¤ 1; 0.00001 â‰¤ x5 â‰¤ 16; 0.00001 â‰¤ x6 â‰¤ 16; 

The experimental results are presented in Fig. 18 and Table 9. As shown in Table 9, in the Reactor Network design problem, GeoSSA exhibits significantly higher stability than all other algorithms, and its optimization accuracy is the best among the compared methods. This demonstrates that GeoSSA possesses substantial advantages when addressing this type of engineering optimization problem. 30 Running Title for Header 0 50 100 150 200 250 300 350 400 450 500 

Iteration           

> 10 -1
> 10 0
> 10 1
> 10 2
> 10 3
> Fitness
> AROA
> WOA
> IWOA
> MWOA
> IPSO
> ISSA
> SSA
> GeoSSA
> 050 100 150 200 250 300 350 400 450 500

Iteration 

> 10 -1
> 10 0
> 10 1
> 10 2
> 10 3
> Fitness
> AROA
> WOA
> IWOA
> MWOA
> IPSO
> ISSA
> SSA
> GeoSSA

Figure 18: Iteration curves of the algorithms in solving the Reactor Network design problem. 

8.4 Industrial Refrigeration System 

In chemical industries, the industrial refrigeration system is one of the key auxiliary facilities and is widely used in various stages of chemical production. Temperature control and heat exchange are essential in operations such as chemical reactions, storage, transportation, and refining. Chemical plants typically require substantial cooling and temperature regulation to maintain reaction stability, ensure product quality, reduce energy consumption and emissions, and guarantee the safe and reliable operation of equipment. The Industrial Refrigeration System (IRS) design problem aims to minimize energy consumption and operating cost while ensuring efficient cooling performance, as illustrated in Fig. 19. The objective is to configure system componentsâ€”such as compressors, condensers, and evaporatorsâ€”to achieve the lowest operational cost and optimal heat-exchange efficiency. This problem involves fourteen decision variables: compressor power x1 and x2; refrigerant flow rates and mass flow rates x3 to x6; condenser and evaporator characteristics x7 and x8; compression ratios x9 and x10; temperature-related parameters x11 and x12; and flow parameters x13 and x14. Specifically, compressor power x1 and x2 determine the cooling capacity; refrigerant flow and mass flow variables x3-x6 describe refrigerant movement through the condenser, evaporator, and receiver; x7 and x8 represent condenser and evaporator sizing parameters; x9 and x10 define the compression ratio and compressor efficiency; x11 and x12 govern temperature differences for heat exchange; and x13

and x14 regulate cooling-water or refrigerant flow rates, thereby influencing the overall system performance. The mathematical formulation of the industrial refrigeration system design problem is presented as follows. 

Variable: 

x = [ x1, x 2, x 3, x 4, x 5, x 6, x 7, x 8, x 9, x 10 , x 11 , x 12 , x 13 , x 14 ]

Minimize: 

y = f (x) + punishment (39) 

Subject to: 

31 Running Title for Header Mass Flow Meter 

Throttling Value 

Cooler 

Evaporator 

Dock 

Evaporator 

Freezer 

Evaporator 

> Hot Gas Defrost

Condenser 

dx oil cooler 

Recip. 

Compressor 

ð€ ð€ 

Int. Pressure 

Receiver 

High Pressure 

Receiver 

Oil cooler 

Screw 

Compressor 

ð€ ð€ 

Low pressure 

Receiver 

subcooler 

Banana/Tomato Room Evaporators 

Under Floor Heating 

Heat Exchanger 

ð€ ð€ 

ð€ ð€ 

Figure 19: The structure of an industrial refrigeration system [30] [31]. 

g1 = 1.524 

x7

âˆ’ 1 â‰¤ 0; (40) 

g2 = 1.524 

x8

âˆ’ 1 â‰¤ 0; (41) 

g3 = 0 .07789 Â· x1 âˆ’ 2 Â· x9

x7

âˆ’ 1 â‰¤ 0; (42) 

g4 = 7.05305 Â· x21 Â· x10 

x9 Â· x8 Â· x2 Â· x14 

âˆ’ 1 â‰¤ 0; (43) 

g5 = 0.0833 Â· x14 

x13 

âˆ’ 1 â‰¤ 0; (44) 

g6 = 47 .136 x0.333 2 x12 

x10 

âˆ’ 1.333 x8 x2.1195 13 

+ 62 .08 x2.1195 13 x0.28

x12 x10 

âˆ’ 1 â‰¤ 0; 

(45) 

g7 = 0 .04771 Â· x10 Â· x1.8812 8 Â· x0.3424 12 âˆ’ 1 â‰¤ 0; (46) 

g8 = 0 .0488 Â· x9 Â· x1.893 7 Â· x0.316 11 âˆ’ 1 â‰¤ 0; (47) 

g9 = 0.0099 Â· x1

x3

âˆ’ 1 â‰¤ 0; (48) 32 Running Title for Header 

g10 = 0.0193 Â· x2

x4

âˆ’ 1 â‰¤ 0; (49) 

g11 = 0.0298 Â· x1

x5

âˆ’ 1 â‰¤ 0; (50) 

g12 = 0.056 Â· x2

x6

âˆ’ 1 â‰¤ 0; (51) 

g13 = 2

x9

âˆ’ 1 â‰¤ 0; (52) 

g14 = 2

x10 

âˆ’ 1 â‰¤ 0; (53) 

g15 = x12 

x11 

âˆ’ 1 â‰¤ 0; (54) 

Where: 

f (x) = 63098 .88 x2x4x12 + 5441 .5 x22x12 

+ 115055 .5 x1.664 2 x6 + 6172 .27 x22x6

+ 63098 .88 x1x3x11 + 5441 .5 x21x11 

+ 115055 .5 x1.664 1 x5 + 6172 .27 x21x5

+ 140 .53 x1x11 + 281 .29 x3x11 

+ 70 .26 x21 + 281 .29 x1x3 + 281 .29 x23

+ 14437 x1.8812 8 x0.3424 12 x10 x21

x7

x14 x9

+ 20470 .2 x2.893 7 x0.316 11 x12 

(55) 

punishment = 10 3Â·

> 15

X

> i=1

max (0 , g i)2

Variable range: 

0.001 < x 1 < 5; 0.001 < x 2 < 5; 0.001 < x 3 < 5; 0.001 < x 4 < 5; 0.001 < x 5 < 5; 0.001 < x 6 < 5; 0.001 < x 7 < 5; 0.001 < x 8 < 5; 0.001 < x 9 < 5; 0.001 < x 10 < 5; 0.001 < x 11 < 5; 0.001 < x 12 < 5; 0.001 < x 13 < 5; 0.001 < x 14 < 5; 

33 Running Title for Header Table 9: Parametric results of the algorithms in solving engineering design optimization problems. 

> Problem  Metrics  AROA  WOA  IWOA  MWOA  IPSO  ISSA  SSA  GeoSSA
> CB  Ave  7.295368  7.357594  96.141137  6.894230  7.472589  6.837589  6.865600  6.837589
> Std  0.397969  0.594874  619.597995  0.121083  0.477882  0.000000  0.198068  0.000000
> PL  Ave  310.340350  47.978511  117.195106  6.604381  432.790325  45.434656  50.981842  1.057175
> Std  270.966089  91.674448  118.894881  30.383292  734.372867  74.849797  77.564892  0.000000
> RN  Ave  10.449519  2.719602  2.157282  0.455302  4.659719  0.657043  0.439659  0.251777
> Std  14.145690  2.622095  1.645170  0.697369  2.191879  1.240103  0.906919  0.103145
> IRS  Ave  9344.680233  32.306197  84.404992  8.106376  2458.347947  8.302475  1912.056286  7.941763
> Std  6050.531715  23.789994  73.284109  0.548582  5004.605495  0.827212  6019.376919  0.438531

34 Running Title for Header 0 50 100 150 200 250 300 350 400 450 500           

> Iteration
> 10 0
> 10 5
> 10 10
> 10 15
> Fitness
> AROA
> WOA
> IWOA
> MWOA
> IPSO
> ISSA
> SSA
> GeoSSA
> 050 100 150 200 250 300 350 400 450 500
> Iteration
> 10 0
> 10 5
> 10 10
> 10 15
> Fitness
> AROA
> WOA
> IWOA
> MWOA
> IPSO
> ISSA
> SSA
> GeoSSA

Figure 20: Iteration curves of the algorithms in solving the Industrial Refrigeration System design problem. The experimental results are presented in Fig. 20 and Table 9. As shown in Table 9, in the Industrial Refrigeration System design problem, GeoSSA exhibits significantly higher stability than all other algorithms, and its optimization accuracy is the best among the compared methods. This demonstrates that GeoSSA possesses substantial advantages when addressing this type of engineering optimization problem. GeoSSA achieves theoretical optimal or near-optimal results in all engineering design optimization problems. The algorithm yields the lowest average fitness values ( Ave ) and the smallest standard deviations ( Std ), fully reflecting its significant advantages in terms of accuracy, stability, and convergence speed. Therefore, the experimental results demonstrate that GeoSSA not only maintains strong global search capabilities on standard benchmark functions but also exhibits outstanding stability, precision, and versatility in engineering design optimization problems. It effectively addresses practical engineering optimization tasks characterized by complex constraints and nonlinear features. 

9 Discussion 

Future research will focus on several potential extensions of GeoSSA. These include expanding GeoSSA to multi-objective optimization through the incorporation of Pareto-front maintenance strategies; adapting it to dynamic or online optimization where objectives or constraints vary over time; and developing discrete or combinatorial variants tailored to specific encoding schemes and neighborhood structures. Moreover, integrating GeoSSA with deep learning [ 32 ] or reinforcement learning techniques may further enhance its capability in complex policy optimization and hyperparameter tuning. In addition, leveraging parallel computing and GPU acceleration is expected to improve its scalability for large-scale optimization problems. 

10 Conclusions 

In this study, we addressed several inherent limitations of the original Sparrow Search Algorithm (SSA) when dealing with complex optimization tasks and proposed a Geometric Sparrow Search Algorithm (GeoSSA). GeoSSA significantly enhances the overall optimization performance through three complementary improvement strategies. First, the Good Nodes Set initialization ensures well-distributed population coverage across the search domain, alleviating clustering 35 Running Title for Header and blind-spot issues caused by pseudo-random initialization, thereby strengthening early global exploration. Second, the Sine-Cosine Enhanced Producer Position Update strategy employs hybrid sine-cosine update dynamics together with an adaptive inertia weight to regulate the exploration-exploitation trade-off. This enables large-scale exploratory jumps in the early stages and promotes stable convergence in later iterations. Third, the Triangular Walk Enhanced Edge Sparrow Position Update introduces a scale-controlled triangular-walk perturbation for edge individuals, enhancing local search accuracy and improving the algorithmâ€™s ability to escape local optima. These three mechanismsâ€”spanning initialization, producer update, and edge-sparrow updateâ€”each address different aspects of SSAâ€™s deficiencies while jointly improving population diversity, convergence speed, and solution quality. Extensive experiments were conducted to validate the effectiveness of GeoSSA. Ablation studies on 23 classical benchmark functions demonstrated that removing any single module leads to clear performance degradation on several functions, confirming the necessity and contribution of each component. In comprehensive benchmark testing across 23 functions, GeoSSA outperformed all comparison algorithmsâ€”including AROA, WOA, IWOA, MWOA, IPSO, ISSA, and the original SSAâ€”in terms of average fitness and standard deviation, and achieved statistically significant superiority in the Wilcoxon non-parametric test and Friedman ranking test, with an Overall Effectiveness (OE) of 95.65%. In a UAV 3D path planning task, GeoSSA achieved the shortest and smoothest trajectories with the highest obstacle-avoidance safety and consistently demonstrated the best stability (lowest Std ) across 30 independent runs. Furthermore, in four engineering design problems (Corrugated Bulkhead, Piston Lever, Reactor Network, and Industrial Refrigeration System), GeoSSA achieved the highest accuracy and stability, showing strong adaptability to engineering constraints and multivariable coupling, and thereby confirming its practical applicability. Overall, GeoSSA provides an efficient and extensible framework for tackling complex optimization challenges in engineering applications and path planning tasks. 

11 Acknowledgment 

The supports provided by Macao Polytechnic University (MPU Grant no: RP/FCA-03/2022; RP/FCA-06/2022) and Macao Science and Technology Development Fund (FDCT Grant no: 0044/2023/ITP2) enabled us to conduct data collection, analysis, and interpretation, as well as cover expenses related to research materials and participant recruitment. MPU and FDCT investment in our work have significantly contributed to the quality and impact of our research findings. 

A Abbreviations 

The following abbreviations are used in this manuscript: Ave Average fitness Std Standard deviation OE overall effectiveness CB Corrugated Bulkhead PL Piston Lever RN Reactor Network IRS Industrial Refrigeration System 

B Benchmark Functions 

The details of the benchmark functions used in this research are shown in Table 10. 36 Running Title for Header Table 10: Standard Benchmark Functions [22] Function Functionâ€™s Name Best Value 

F1 (x) = Pni=1 x2 

> i

Sphere 0

F2 (x) = 

> n

X

> i=1

|xi| +

> n

Y

> i=1

|xi| Schwefelâ€™s Problem 2.22 0

F3 (x) = Pni=1 

Pijâˆ’1 xj

2

Schwefelâ€™s Problem 1.2 0

F4(x) = max  

> 1â‰¤iâ‰¤n

{| xi|} Schwefelâ€™s Problem 2.21 0

F5(x) = Pnâˆ’1 

> i=1

[100( xi+1 âˆ’ x2 

> i

)2 + ( xi âˆ’ 1) 2] Generalized Rosenbrockâ€™s Function 0

F6(x) = Pni=1 (âŒŠxi + 0 .5âŒ‹)2 Step Function 0

F7(x) = Pni=1 ix 4 

> i

+ random [0 , 1) Quartic Function 0

F8(x) = Pni=1 âˆ’xi sin( p|xi|) Generalized Schwefelâ€™s Function -12569.5 

F9(x) = Pni=1 [x2 

> i

âˆ’ 10 cos(2 Ï€x i) + 10)] Generalized Rastriginâ€™s Function 0

F10 (x) = âˆ’20 exp 

ï£«ï£­âˆ’0.2

vuut 1

n

> n

X

> i=1

x2

> i

ï£¶ï£¸ âˆ’ exp 1

n

> n

X

> i=1

cos 2 Ï€x i

!

+ 20 + e

Ackleyâ€™s Function 0

F11 (x) = 14000 

Pni=1 x2 

> i

âˆ’ Qni=1 cos 

 xiâˆši



+ 1 Generalized Griewankâ€™s Function 0

F12 (x) = Ï€n

(

10 sin 2(Ï€y i) + 

> nâˆ’1

X

> i=1

(yi âˆ’ 1) 2[1 + 10 sin 2(Ï€y i+1 )] + ( yn âˆ’ 1) 2o

+

> n

X

> i=1

u(xi, 10 , 100 , 4) ,yi = 1 + 14 (xi + 1) 

u (xi, a, k, m ) = 

( k(xi âˆ’ a)m, xi > a, 

0, âˆ’a â‰¤ xi â‰¤ a, k(âˆ’xi âˆ’ a)m, xi < âˆ’a. 

Generalized Penalized Function 1 0

F13 (x) = 0 .1

(

sin 2(3 Ï€x 1) + 

> nâˆ’1

X

> i=1

(xi âˆ’ 1) 2[1 + sin 2(3 Ï€x i+1 )] +( xn âˆ’ 1) 2[1 + sin 2(2 Ï€x n)] +

> n

X

> i=1

u(xi, 5, 100 , 4) 

Generalized Penalized Function 2 0

F14 (x) = 

h 1500 + P25   

> j=1 1
> j+P2
> i=1 (xiâˆ’aij )6

iâˆ’1

Shekelâ€™s Foxholes Function 0.998 

F15 (x) = P11 

> i=1



ai âˆ’ x1(b2 

> i+bix2

) 

> b2
> i+bix3+x4

2

Kowalikâ€™s Function 0.0003075 

F16 (x) = 4 x21 âˆ’ 2.1x41 + 13 x61 + x1x2 âˆ’ 4x22 + 4 x42 Six-Hump Camel-Back Function -1.0316 

F17 (x) =  x2 âˆ’ 5.14Ï€2 x21 + 5 

> Ï€

x1 âˆ’ 62 + 10  1 âˆ’ 18Ï€

 cos x1 + 10 Branin Function 0.398 

F18 (x) = [1 + ( x1 + x2 + 1) 2(19 âˆ’ 14 x1 + 3 x21 âˆ’ 14 x2

+ 6 x1x2 + 3 x22)] Ã— [30 + (2 x1 âˆ’ 3x2)2(18 âˆ’ 32 x

+ 12 x21 + 48 x2 âˆ’ 36 x1x2 + 27 x22)] 

Goldstein-Price Function 3

F19 (x) = âˆ’ P4 

> i=1

ci exp 

h

âˆ’ P4 

> j=1

aij (xj âˆ’ pij )2i

Hartmanâ€™s Function 1 -3.8628 

F20 (x) = âˆ’ P4 

> i=1

ci exp 

h

âˆ’ P6 

> j=1

aij (xj âˆ’ pij )2

i

Hartmanâ€™s Function 2 -3.32 

F21 (x) = âˆ’ P5

> i=1

(x âˆ’ ai)( x âˆ’ ai)T + ci

âˆ’1 Shekelâ€™s Function 1 -10.1532 

F22 (x) = âˆ’ P7

> i=1

(x âˆ’ ai)( x âˆ’ ai)T + ci

âˆ’1 Shekelâ€™s Function 2 -10.4029 

F23 (x) = âˆ’ P11 

> i=1

(x âˆ’ ai)( x âˆ’ ai)T + ci

âˆ’1 Shekelâ€™s Function 3 -10.5364 37 Running Title for Header 

References 

[1] James Kennedy and Russell Eberhart. Particle swarm optimization. In Proceedings of ICNNâ€™95-international conference on neural networks , volume 4, pages 1942â€“1948. ieee, 1995. [2] Dervis Karaboga and Bahriye Akay. A comparative study of artificial bee colony algorithm. Applied mathematics and computation , 214(1):108â€“132, 2009. [3] Seyedali Mirjalili, Seyed Mohammad Mirjalili, and Andrew Lewis. Grey wolf optimizer. Advances in engineering software , 69:46â€“61, 2014. [4] Ali Asghar Heidari, Seyedali Mirjalili, Hossam Faris, Ibrahim Aljarah, Majdi Mafarja, and Huiling Chen. Harris hawks optimization: Algorithm and applications. Future generation computer systems , 97:849â€“872, 2019. [5] Heming Jia, Honghua Rao, Changsheng Wen, and Seyedali Mirjalili. Crayfish optimization algorithm. Artificial Intelligence Review , 56(Suppl 2):1919â€“1979, 2023. [6] Shengwei Fu, Ke Li, Haisong Huang, Chi Ma, Qingsong Fan, and Yunwei Zhu. Red-billed blue magpie optimizer: a novel metaheuristic algorithm for 2d/3d uav path planning and engineering design problems. Artificial Intelligence Review , 57(6):134, 2024. [7] Tian-Lei Wang, Shao-Wei Gu, Ren-Ju Liu, Le-Qing Chen, Zhu Wang, and Zhi-Qiang Zeng. Cuckoo catfish optimizer: a new meta-heuristic optimization algorithm. Artificial Intelligence Review , 58(10):326, 2025. [8] Yu-Jun Zhang, Yu-Fei Wang, Yu-Xin Yan, Juan Zhao, and Zheng-Ming Gao. Lmraoa: An improved arithmetic optimization algorithm with multi-leader and high-speed jumping based on opposition-based learning solving engineering and numerical problems. Alexandria Engineering Journal , 61(12):12367â€“12403, 2022. [9] Xiaobing Yu, Nijun Jiang, Xuming Wang, and Mingyuan Li. A hybrid algorithm based on grey wolf optimizer and differential evolution for uav path planning. Expert Systems with Applications , 215:119327, 2023. [10] Junhao Wei, Yanzhao Gu, KL Eddie Law, and Ngai Cheong. Adaptive position updating particle swarm optimization for uav path planning. In 2024 22nd International Symposium on Modeling and Optimization in Mobile, Ad Hoc, and Wireless Networks (WiOpt) , pages 124â€“131. IEEE, 2024. [11] Baili Lu, Zhanxi Xie, Junhao Wei, Yanzhao Gu, Yuzheng Yan, Zikun Li, Shirou Pan, Ngai Cheong, Ying Chen, and Ruishen Zhou. Mrbmo: An enhanced red-billed blue magpie optimization algorithm for solving numerical optimization challenges. Symmetry , 17(8):1295, 2025. [12] Jiankai Xue and Bo Shen. A novel swarm intelligence optimization approach: sparrow search algorithm. Systems science & control engineering , 8(1):22â€“34, 2020. [13] Zhanxi Xie, Baili Lu, Yanzhao Gu, Zikun Li, Junhao Wei, and Ngai Cheong. Research on uav applications in public administration: Based on an improved rrt algorithm. arXiv preprint arXiv:2508.14096 , 2025. [14] Junhao Wei, Yanzhao Gu, Ran Zhang, Wenxuan Zhu, Shuai Wu, Yapeng Wang, Ngai Cheong, Zhiwen Wang, Sio-Kei Im, and Xu Yang. Ahrrt: An enhanced rapidly-exploring random tree algorithm with heuristic search for uav urban path planning. Preprints , November 2025. [15] John H Holland. Genetic algorithms. Scientific american , 267(1):66â€“73, 1992. [16] Marco Dorigo, Mauro Birattari, and Thomas Stutzle. Ant colony optimization. IEEE computational intelligence magazine , 1(4):28â€“39, 2007. [17] Peter JM Van Laarhoven and Emile HL Aarts. Simulated annealing. In Simulated annealing: Theory and applications , pages 7â€“15. Springer, 1987. [18] Junhao Wei, Yanzhao Gu, Ran Zhang, Yanxiao Li, Wenxuan Zhu, Yapeng Wang, Xu Yang, and Ngai Cheong. An enhanced whale optimization algorithm with log-normal distribution for optimizing coverage of wireless sensor networks. arXiv preprint arXiv:2511.15970 , 2025. [19] Junhao Wei, Yanzhao Gu, Ran Zhang, Mingjing Huang, Jinhong Song, Yanxiao Li, Wenxuan Zhu, Yapeng Wang, Zikun Li, Zhiwen Wang, et al. Nawoa-xgboost: A novel model for early prediction of academic potential in computer science students. arXiv preprint arXiv:2512.04751 , 2025. [20] Yanzhao Gu, Junhao Wei, Zikun Li, Baili Lu, Shirou Pan, and Ngai Cheong. Gwoa: A multi-strategy enhanced whale optimization algorithm for engineering design optimization. Plos one , 20(9):e0322494, 2025. [21] Junhao Wei, Yanzhao Gu, Yuzheng Yan, Yapeng Wang, Zikun Li, Baili Lu, Shirou Pan, and Ngai Cheong. Tswoa: An enhanced woa with triangular walk and spiral flight for engineering design optimization. In 2025 8th International Conference on Advanced Algorithms and Control Engineering (ICAACE) , pages 186â€“194. IEEE, 2025. 38 Running Title for Header [22] Ponnuthurai N Suganthan, Nikolaus Hansen, Jing J Liang, Kalyanmoy Deb, Ying-Ping Chen, Anne Auger, and Santosh Tiwari. Problem definitions and evaluation criteria for the cec 2005 special session on real-parameter optimization. KanGAL report , 2005005(2005):2005, 2005. [23] Karol Cymerys and Mariusz Oszust. Attractionâ€“repulsion optimization algorithm for global optimization problems. 

Swarm and Evolutionary Computation , 84:101459, 2024. [24] Seyedali Mirjalili and Andrew Lewis. The whale optimization algorithm. Advances in engineering software ,95:51â€“67, 2016. [25] Zhiyou Liu, Xinbin Li, Zhigang Lu, and Xianhui Meng. Iwoa-rnn: An improved whale optimization algorithm with recurrent neural networks for traffic flow prediction. Alexandria Engineering Journal , 117:563â€“576, 2025. [26] J Anitha, S Immanuel Alex Pandian, and S Akila Agnes. An efficient multilevel color image thresholding based on modified whale optimization algorithm. Expert Systems with Applications , 178:115003, 2021. [27] Kai Du. Research on gas hazard level prediction in coal mines based on improved sparrow search algorithm. In 

2025 2nd International Conference on Intelligent Computing and Robotics (ICICR) , pages 390â€“395. IEEE, 2025. [28] Mohammad H Nadimi-Shahraki, Shokooh Taghian, Seyedali Mirjalili, and Hossam Faris. Mtde: An effective multi-trial vector-based differential evolution algorithm and its applications for engineering design problems. 

Applied Soft Computing , 97:106761, 2020. [29] Junhao Wei, Yanzhao Gu, Yuzheng Yan, Zikun Li, Baili Lu, Shirou Pan, and Ngai Cheong. Lsewoa: An enhanced whale optimization algorithm with multi-strategy for numerical and engineering design optimization problems. 

Sensors , 25(7):2054, 2025. [30] Junhao Wei, Yanzhao Gu, Zhanxi Xie, Yuzheng Yan, Baili Lu, Zikun Li, Ngai Cheong, Jiafeng Zhang, and Song Zhang. Lswoa: An enhanced whale optimization algorithm with levy flight and spiral flight for numerical and engineering design optimization problems. Plos one , 20(9):e0322058, 2025. [31] Junhao Wei, Yanzhao Gu, Baili Lu, and Ngai Cheong. Rwoa: A novel enhanced whale optimization algorithm with multi-strategy for numerical optimization and engineering design problems. PloS one , 20(4):e0320913, 2025. [32] Yanzhao Gu, Junhao Wei, and Ngai Cheong. Credit card fraud detection based on minikm-svmsmote-xgboost model. In Proceedings of the 2024 8th International Conference on Big Data and Internet of Things , pages 252â€“258, 2024. 39
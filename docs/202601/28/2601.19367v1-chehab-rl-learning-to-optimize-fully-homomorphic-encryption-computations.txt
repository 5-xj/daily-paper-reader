Title: CHEHAB RL: Learning to Optimize Fully Homomorphic Encryption Computations

URL Source: https://arxiv.org/pdf/2601.19367v1

Published Time: Wed, 28 Jan 2026 01:44:04 GMT

Number of Pages: 27

Markdown Content:
# CHEHAB RL: Learning to Optimize Fully Homomorphic Encryption Computations 

## Bilel Sefsaf 

New York University Abu Dhabi Abu Dhabi, United Arab Emirates Ecole Superieure dâ€™Informatique Algiers, Algeria 

kb_sefsaf@esi.dz 

## Abderraouf Dandani 

New York University Abu Dhabi Abu Dhabi, United Arab Emirates Ecole Superieure dâ€™Informatique Algiers, Algeria 

ka_dandani@esi.dz 

## Abdessamed Seddiki 

New York University Abu Dhabi Abu Dhabi, United Arab Emirates Ecole Superieure dâ€™Informatique Algiers, Algeria 

ka_seddiki@esi.dz 

## Arab Mohammed 

New York University Abu Dhabi Abu Dhabi, United Arab Emirates Ecole Superieure dâ€™Informatique Algiers, Algeria 

km_arab@esi.dz 

## Eduardo Chielle 

Center for Cyber Security New York University Abu Dhabi Abu Dhabi, United Arab Emirates 

ec126@nyu.edu 

## Michail Maniatakos 

Center for Cyber Security New York University Abu Dhabi Abu Dhabi, United Arab Emirates 

mm6446@nyu.edu 

## Riyadh Baghdadi 

New York University Abu Dhabi Abu Dhabi, United Arab Emirates 

rb4792@nyu.edu 

## Abstract 

Fully Homomorphic Encryption (FHE) enables computations directly on encrypted data, but its high computational cost remains a significant barrier. Writing efficient FHE code is a complex task requiring cryptographic expertise, and finding the optimal sequence of program transformations is often intractable. In this paper, we propose CHEHAB RL, a novel framework that leverages deep reinforcement learning (RL) to automate FHE code optimization. Instead of relying on predefined heuristics or combinatorial search, our method trains an RL agent to learn an effective policy for apply-ing a sequence of rewriting rules to automatically vectorize scalar FHE code while reducing instruction latency and noise growth. The proposed approach supports the optimization of both structured and unstructured code. To train the agent, we synthesize a diverse dataset of computations using a large language model (LLM). We integrate our proposed approach into the CHEHAB FHE compiler and evaluate it on a suite of benchmarks, comparing its performance against Coyote, a state-of-the-art vectorizing FHE compiler. The results show that our approach generates code that is 5.3Ã— faster in exe-cution, accumulates 2.54 Ã— less noise, while the compilation process itself is 27 .9Ã— faster than Coyote (geometric means). 

CCS Concepts: â€¢ Software and its engineering â†’ Com-pilers .

> This work is licensed under a Creative Commons Attribution 4.0 Interna-tional License.

Keywords: Automatic Code Optimization, Compiler, FHE, Fully Homomorphic Encryption, Reinforcement Learning 

## 1 Introduction 

In Fully Homomorphic Encryption (FHE), computations are performed directly on encrypted data without decryption. This enables a client to transmit data to a third party that pro-cesses it and returns the result without performing decryp-tion. As a result, sensitive information remains protected. Despite notable recent progress and increasing practical adoption [ 35 , 41 , 46 , 48 , 72 ], FHE remains computationally ex-pensive. For example, a ciphertext 1 multiplication takes 10 6

times longer than its plaintext counterpart 2. This disparity is due to the inherent complexity of homomorphic operations, as a single ciphertext multiplication entails multiple n-order polynomial multiplications. Reducing the execution time of FHE applications is essential for their practical adoption. Consequently, experts devote substantial effort to optimizing FHE implementations. Writing efficient code for FHE is tedious, though. It re-quires a considerable amount of expertise in writing low-level code for the target scheme. This makes writing code for FHE applications time-consuming and error-prone and hinders its wide adoption [ 21 , 72 ]. To address this problem, the research community has explored the development of compilers for FHE applications [ 21 , 23 , 26 , 27 , 49 , 52 , 72 ]. HECO [ 72 ], for example, focuses on efficiently transforming 

> 1Ciphertext: encrypted data; Plaintext: clear data.
> 2Evaluation done on the BFV scheme, for 128-bit security, using Microsoft SEAL [57] and running on a modern multicore CPU.
> arXiv:2601.19367v1 [cs.CR] 27 Jan 2026 Bilel Sefsaf et al.

structured code into the FHE paradigm with SIMD instruc-tions (structured code, a.k.a. regular code, stands for code with loops). In a similar way, CHET [ 27 ] focuses on the vectorization of structured computations over packed ten-sors (such as neural networks). However, neither of these compilers supports vectorizing unstructured code (arbitrary, non-loop-based code). More recent work, such as Coyote [ 52 ] and Porcupine [ 23 ], proposes compilers that support vectorization of both struc-tured and unstructured code. However, both Coyote and Porcupine frame vectorization as search over a combinato-rial design space: which subexpressions to pack, how to lay out data in wide ciphertext vectors, where to insert rota-tions and masks, etc. In such a complex space, local choices have non-local effects (e.g., a packing decision can increase later rotations or depth), so simple heuristics or greedy rule application often get trapped in poor local optima. To mit-igate this, Coyote couples hand-tuned heuristics with an ILP solver to select packs, while Porcupine uses program synthesis to enumerate and check candidates [ 23 , 52 ]. These strategies are effective, but they are limited in their scalabil-ity: exploring or solving over large candidate sets becomes computationally expensive as programs grow in size. In this paper, we argue that Reinforcement Learning (RL) provides a better solution: we treat FHE code optimization as sequential decision-making and use RL to learn a policy that composes sequences of rewriting rules to minimize la-tency and noise. By optimizing a single global cost, the RL policy makes global decisions without explicit combinatorial enumeration or ILP, yielding high-quality transformations with substantially lower compile time. More concretely, we propose CHEHAB RL, a novel frame-work that leverages reinforcement learning (RL) to automat-ically optimize code for the field of FHE. It supports both structured and unstructured code and scales better than exist-ing approaches. CHEHAB RL automatically vectorizes code while minimizing noise growth and circuit latency. This is achieved through a policy network that selects a sequence of rewriting rules to apply to code to vectorize it while minimiz-ing rotations, circuit depth, multiplicative depth, and other FHE operations. Because our approach selects the sequence of rewriting rules using a policy network, it avoids computa-tionally expensive search methods used in state-of-the-art FHE compilers, and therefore scales better. Bringing RL into this setting is nontrivial and requires addressing several FHE-specific challenges: 1) Large action space. The agent chooses from an extensive set of rules, each applicable to multiple locations. This makes the action space large. To address this challenge, we propose a multi-discrete hierarchical policy supported by a position network where the agent first decides about which transformation to apply, then decides about where to apply it. We show that this design outperforms a flat action space. 2) Fast, FHE-aware reward. Running FHE code during training to obtain a reward is prohibitively slow. To address this challenge, we introduce an analytical reward function tailored to the FHE domain. It combines operation cost, circuit depth, and multiplicative depth and captures both performance and noise growth, while enabling fast training. 3) LLM-Synthesized dataset. Since no dataset of optimizable FHE programs exists, we build an LLM-based synthesis pipeline and use it to generate data and show that training on this data yields much better agents than training on random programs. We integrate our proposed approach into the CHEHAB FHE compiler and evaluate it on a set of kernels, comparing it to Coyote, a state-of-the-art FHE compiler, and demonstrate that it produces higher-quality code and scales better. The contributions of the paper are as follows: 1. We formulate the problem of FHE code optimization as a sequential decision-making problem, and propose to learn a policy using RL to solve it. 2. We propose CHEHAB RL, a novel framework that leverages RL to automatically vectorize structured and unstructured FHE code and minimize noise growth and circuit latency while scaling better compared to state-of-the-art. To the best of our knowledge, this is the first use of RL to solve this problem. 3. We use an LLM-guided synthesis pipeline to generate a large training dataset of FHE expressions (15,855 expressions), and show that training on this dataset outperforms training on randomly generated FHE ex-pressions. 4. We compare CHEHAB RL to Coyote and show that it generates code that is 5.3Ã— faster, accumulates 2.54 Ã—

less noise, while it takes 27 .9Ã— less time in compilation. 5. We release CHEHAB RL to the community 3.

## 2 Motivating Example 

Vectorization in FHE is challenging as it introduces rotations, masking, and data packing. Poor vectorization can increase the number of rotations and circuit depth, severely impacting performance and increasing noise in the circuit. Thus, effec-tive FHE vectorization must maximize code vectorization while minimizing rotation overhead and circuit depth. Consider this unstructured (non-loop-based) code:                      

> ğ‘¥ =( ( ( ğ‘£ 1Â·ğ‘£ 2) Â· ( ğ‘£ 3Â·ğ‘£ 4) ) + ( ( ğ‘£ 3Â·ğ‘£ 4) Â· ( ğ‘£ 5Â·ğ‘£ 6) ) ) Â· ( ( ğ‘£ 7Â·ğ‘£ 8) Â· ( ğ‘£ 9Â·ğ‘£ 10 ) ) (1)

Fig. 1 represents the code as a circuit (a common repre-sentation of code in the FHE literature). This expression is not trivial to vectorize. To vectorize it, we use a Term Rewriting System (TRS) consisting of a set of rules. For illustration, we show only three rules, but the TRS has more.                                

> R1: multiplication_commutativity ,ğ‘ Â·ğ‘ â‡’ğ‘ Â·ğ‘
> R2: comm_factor ,ğ‘ Â·ğ‘ +ğ‘ Â·ğ‘ â‡’ğ‘ Â· ( ğ‘ +ğ‘ )
> R3: vectorization ,(ğ‘ Â·ğ‘ ) + ( ğ‘ Â·ğ‘‘ ) â‡’ Vec (ğ‘, ğ‘ ) Â· Vec (ğ‘, ğ‘‘ )
> 3https://github.com/Modern-Compilers-Lab/CHEHAB CHEHAB RL: Learning to Optimize Fully Homomorphic Encryption Computations

Figure 1. Example of an unstructured scalar code.                                    

> [1,2]=[ğ‘£ 1, ğ‘£ 5] Â· [ ğ‘£ 2, ğ‘£ 6][3,_]=[1,_] + [ 2,_][4,_]=[ğ‘£ 3,_] Â· [ ğ‘£ 4,_][5,_]=[3,_] Â· [ 4,_][6,7]=[ğ‘£ 7, ğ‘£ 9] Â· [ ğ‘£ 8, ğ‘£ 10 ][8,_]=[6,_] Â· [ 7,_][ğ‘¥, _]=[5,_] Â· [ 8,_]

(a) First approach.                                                              

> [1,2,3]=[ğ‘£ 1, ğ‘£ 5, ğ‘£ 6] Â· [ ğ‘£ 2,1,1][4,_,_]=[2,_,_] Â· [ 3,_,_][5,_,_]=[1,_,_] + [ 4,_,_][6,_,_]=[ğ‘£ 3,_,_] Â· [ ğ‘£ 4,_,_][7,_,_]=[5,_,_] Â· [ 6,_,_][8,9,_]=[ğ‘£ 7, ğ‘£ 9,_] Â· [ ğ‘£ 8, ğ‘£ 10 ,_][10 ,_,_]=[8,_,_] Â· [ 9,_,_][ğ‘¥, _,_]=[7,_,_] Â· [ 10 ,_,_]

(b) Second approach. 

Figure 2. Vectorization approaches. We first apply the rules R1 then R2 , yielding:                   

> ğ‘¥ =( ( ğ‘£ 3Â·ğ‘£ 4) Â· ( ( ğ‘£ 1Â·ğ‘£ 2) + ( ğ‘£ 5Â·ğ‘£ 6) ) ) Â· ( ( ğ‘£ 7Â·ğ‘£ 8) Â· ( ğ‘£ 9Â·ğ‘£ 10 ) ) (2)

From this transformed expression, we can apply other rewriting rules to vectorize the code. There are many ways to vectorize it (also called vectorization strategies). We show two examples in Fig. 2 (intermediate values are named using numbers). Each vectorization strategy is obtained by apply-ing a different sequence of rewriting rules. The key challenge is determining the sequence of rewriting rules that yields the best vectorization strategy while minimizing the number of rotations and depth of the circuit (multiplicative depth, more precisely, as we illustrate later). We omit showing the rotation and masking instructions in the example for brevity. For example, in Fig. 2a, in order to calculate the operands of the 2nd statement ( [1, _] and 

[2, _]), rotations and masking should be applied on the result of the 1st statement as follows 4:                

> [1,_]=[1,2]&[ğ¹, _][2,_]=( [ 1,2]<< 1)&[ğ¹, _]

but we omit showing these rotations and maskings. Let us compare the two vectorizations in Fig. 2 using an approximate cost model that assigns a relative latency to each operation: multiplications and rotations have a latency of 1, while additions have a latency of 0.1 (these values are toy values chosen for simplicity only, to illustrate the ex-ample). The original scalar expression has 9 multiplications and 1 addition, yielding a total cost of 9.1. The vectorization in Fig. 2a reduces the number of multiplications to 6 and additions to 1 but introduces 2 rotations, resulting in a total cost of 8.1. In contrast, the vectorization in Fig. 2b involves 7 

> 4We assume 4-bit numbers in the example for simplicity, and we use _ to denote a zero-valued slot.

multiplications, 3 rotations, and 1 addition, yielding a 10.1 cost. These results highlight that not all vectorizations are equally beneficial. Moreover, applying R1 prior to R2 is essential to obtain the expression in Eq. 2, which can then be vectorized by applying R3 . In contrast, starting with R2 followed by 

R1 yields Eq. 1, where R3 is no longer applicable, thereby eliminating vectorization opportunities. This limitation high-lights the importance of carefully selecting which rules to apply and in which order. To address this, we employ a policy network, trained via RL. The policy determines an ordered sequence of rules that optimize the code to achieve the best global vectorization, rather than relying on local improve-ments alone. 

Vectorization in FHE. Vectorization in FHE is different from classical vectorization. While many code vectorization methods have been studied in the literature [ 10 , 12 , 19 , 45 , 47 ,53 , 68 ], such methods are not well-suited for vectorizing FHE code. First, since FHE does not support loops or condition-als, computations must be expressed as arithmetic circuits (unstructured code), preventing the direct use of classical loop-based vectorization methods. FHE vectorization differs from classical SLP-based approaches (Superword-level par-allelism) [ 19 , 47 , 53 ] due to the large vector sizes in FHE (thousands of slots vs a few in hardware registers) and the in-ability to index ciphertext vectors directly. Instead, expensive rotation operations simulate indexed accesses. In addition, rotations in FHE are computationally expensive and increase noise in the circuit, so vectorization strategies must mini-mize their use. These differences make classical SLP-based methods unsuitable for FHE, as we discuss in Sec. 8. Because ciphertext vectors are wider in FHE compared to traditional hardware vector registers, FHE vectorization yields signifi-cant speedups because a single ciphertext operation (add or multiply) applies element-wise to every packed slot in the ciphertext, so one operation can replace thousands of scalar steps, far beyond the 4â€“8-lane limits of hardware SIMD. 

## 3 Background 

3.1 Fully Homomorphic Encryption 

FHE allows computations on encrypted data directly (i.e., without decrypting the data). For a function ğ‘“ and a mes-sage ğ‘š , FHE allows the possibility of computing bğ‘¦ = ğ‘“ ( bğ‘š ),without knowing ğ‘š . Here, bğ‘š represents the encryption of 

ğ‘š , and bğ‘¦ is the encrypted output, which must be decrypted by the owner of ğ‘š to obtain the output bğ‘¦ â†¦ â†’ ğ‘¦ in plaintext. FHE hence helps to achieve privacy-preserving computation in situations where sensitive data needs to be shared with third parties for computation offloading. The Brakerski/Fan-Vercauteren (BFV) encryption scheme [ 14 , 32 ] is an FHE scheme that provides primitives for mod-ular addition and multiplication along with primitives for Bilel Sefsaf et al. 

noise management and ciphertext maintenance (i.e., relin-earization, modulus switching, and bootstrapping). BFV op-erates within plaintext and ciphertext spaces. Plaintexts and ciphertexts are large order polynomials defined by the param-eters {ğ‘›, ğ‘¡, ğ‘ }. The degree ğ‘› corresponds to the polynomial modulus ğ‘¥ ğ‘› +1, while the parameters ğ‘¡ and ğ‘ are the plaintext modulus and ciphertext modulus. Encryption introduces noise for security, which grows with operations on ciphertexts or between a ciphertext and a plaintext. Its growth is limited by ğ‘ and ğ‘¡ (defined in A.2.1); exceeding this limit corrupts the data, leading to incorrect decryption (a user sets a noise budget for their circuit, and the circuit has to run without exceeding that noise budget). 

Bootstrapping can reset noise but has high computational costs. Instead, FHE applications typically limit operations to a predefined depth. Supporting deeper circuits requires increasing ğ‘ and adjusting ğ‘› for security. This is especially important for circuits with high multiplicative depth, as mul-tiplications cause exponential noise growth, while additions increase it linearly. However, larger ğ‘ and ğ‘› also introduce performance overheads due to larger polynomials and coeffi-cients. Therefore, one of the goals when optimizing an FHE circuit is to minimize the multiplicative depth to be able to use the smallest ğ‘ and ğ‘› that still respect the noise budget in the circuit. This, in turn, makes FHE operations run faster and reduces the overall circuit latency. Vectorization in FHE (a.k.a., batching ) is a technique that encodes a vector of ğ‘› integers in a single plaintext polyno-mial using the Chinese Remainder Theorem (CRT). Vectors in FHE are large (thousands of slots). With vectorization, additions and multiplications are executed slot-wise in a Single-Instruction Multiple-Data (SIMD) fashion. Moreover, BFV supports rotations of the encoded vector to move data (and perform data packing). Rotation as a function takes a ciphertext (vector) and a rotation step and returns the ci-phertext (vector) with slots shifted in a cyclic manner. For example, the rotation [1, 2, 3] << 1 returns [2, 3, 1]. Note that FHE supports only additions, multiplications, and rotations and does not support branches or loops. See Appendix A.2 for a formal definition of FHE concepts. 

3.1.1 Circuit Depth and Multiplicative Depth. 

Circuit Depth. An FHE program can also be represented as a circuit. A circuit is a DAG (Directed Acyclic Graph) representation of the program that captures its dataflow. Cal-culating the depth of the circuit is important for estimating noise. The depth of a circuit (DAG) represents the maximum number of consecutive operations performed on an input to compute the output. The depth of a node ğ‘£ in the DAG is defined as the length of the longest path between ğ‘£ and an input node. This depth is usually used to quantify the noise in the circuit. However, it does not provide any information on the type of operations involved (which is necessary to determine how the noise grows). Since multiplication has the most significant impact on noise, one should compute the multiplicative depth of the circuit to estimate noise better. 

Multiplicative Depth of a Circuit. Similar to circuit depth, except that we consider counting the number of mul-tiplications only, since multiplications increase noise expo-nentially. The multiplicative depth of a node ğ‘£ is defined as the length of the longest path, when counting multiplication operations alone, between ğ‘£ and an input node. 

## 4 CHEHAB RL Overview 

This section provides an overview of CHEHAB RL and its components. We first show the overall design of the CHEHAB compiler and then discuss its major components, includ-ing our RL agent for code optimization. CHEHAB defines a domain-specific language (DSL) for FHE. The CHEHAB DSL is the compilerâ€™s starting point. An intermediate rep-resentation (IR) is first generated from the CHEHAB DSL. This IR is then optimized by a Reinforcement learning (RL) agent, which learns a policy to apply a sequence of trans-formations. These transformations are drawn from a set of rewriting rules that include rules for both code vectorization and for simplification to reduce noise growth and instruction latency (i.e., rewrite complex arithmetic expressions into sim-pler expressions that have a smaller number of operations and depth). Next, the compiler performs the rotation key selection. This pass generates the necessary rotation keys for rotation operations found in the optimized code. Finally, the code generator generates a sequence of vectorized oper-ations implemented in C++ and targeting Microsoft SEALâ€™s backend [ 57 ] for BFV. The key new contribution introduced by this paper is CHEHAB RL, the RL-guided term rewriting system, which we integrate into the CHEHAB compiler as shown in Fig. 3. We present the RL agent in detail in the paper, while we present the rotation key selection method in Appendix B. 

4.1 CHEHAB Domain Specific Language (DSL) 

FHE performance and correctness critically depend on man-aging the encryption parameters and rotation keys. Manag-ing these keys and parameters manually is a time-consuming task that requires expertise. The CHEHAB DSL is designed to manage this complexity automatically, and thus improves the productivity of the developer. The developer expresses their code using a simple, high-level C++ code, while CHEHAB takes care of lowering that code to the FHE paradigm and takes care of generating and managing all the FHE-related objects (such as the encryption keys). CHEHAB is embed-ded in C++, allowing users to leverage C++ features (e.g., templates) while extending it by defining the Plaintext and Ciphertext types. It also overloads basic operations for these types, mapping them to native FHE operations. One of the guiding principles in designing CHEHAB is the clear separa-tion between computations and implementation details. In CHEHAB RL: Learning to Optimize Fully Homomorphic Encryption Computations 

Figure 3. CHEHAB RL overview (our contribution: RL TRS ). particular, it allows computations to be specified indepen-dently from encryption parameters, offering greater flexibil-ity in exploiting potential optimization opportunities. A program written in CHEHAB has three parts: (1) Input declaration: This section defines the inputs of the program. An input can be either a ciphertext or a plaintext. It can also be either a scalar or a vector. (2) Computations: This section specifies the computations, whether arithmetic or rotation operations, using standard C++ operators ( +, -, *, Â«). These operators are mapped to either vector or scalar operators depending on the type of their operands. (3) Outputs: This section declares the outputs. The following example shows how to express the moti-vating example in our DSL. The list of operations supported by CHEHAB is presented in Table 3 in the appendix.  

> Ciphertext motivating_example() { Ciphertext v1,v2,v3,v4,v5,v6,v7,v8,v9,v10; //Inputs Ciphertext x = (((v1 * v2) * (v3 * v4)) + ((v3 * v4) * (v5 * v6))) * ((v7 * v8) * (v9 * v10)); //Computations x.set_output(); //Outputs
> return x; }

4.2 CHEHAB Intermediate Representation (IR) 

The DSL program is compiled into an intermediate repre-sentation (IR) in the form of an AST (Abstract Syntax Tree), as is commonly done in compilers. Fig. 1 shows an example of an AST representation of the motivating example. From this representation, we extract a dataflow graph representa-tion (DAG) of the code when needed (e.g., to calculate the multiplicative depth). To lower the DSL to the IR, we follow the same approach of Halide [ 62 ] and Tiramisu [ 10 ]. The approach relies on the use of templates and staging in C++. 

4.3 Code Optimizations 

After generating the IR, the next stage is code optimization. CHEHAB RL uses an RL agent to optimize code. The agent chooses a sequence of rules from its rule set. This set includes rules for vectorization , which group scalar operations into vector ones, and rules for simplification , which minimize noise growth and latency in the circuit. To further optimize code, the original CHEHAB compiler applies classic compiler optimizations, including common subexpression elimination (CSE), constant folding, and dead code elimination. 

4.4 Code generation 

In the final stage, CHEHAB generates code that targets the SEAL API [ 57 ] by mapping each node in the IR (operator) to its equivalent API call in SEAL. During code generation, we also generate the necessary masking operations, private keys, public keys, and relinearization keys. More details about code generation in Appendix D. 

## 5 FHE Circuit Optimization 

The core of the CHEHAB RL framework is a Term Rewriting System (TRS) that uses RL to transform an initial Intermedi-ate Representation (IR) into an efficient one. We frame the optimization task as a sequential decision-making problem, formally a Markov Decision Process (MDP). Our RL framework uses the actor-critic RL architecture and is defined by the following key components: 1) State representation (detailed in Sec. 5.1): provides a representation of the program being optimized; 2) Action space (Sec. 5.2): 

defines the set of rewriting rules that the agent can apply to the program being optimized; 3) Reward model (Sec. 5.3): 

provides a function that scores the quality of actions, guiding the agent toward actions that produce FHE circuits that are more efficient and have less noise; 4) Actor-critic networks (Sec. 5.4): the actor selects the next rewriting rule to apply given the current program state, and selects where to apply it, while the critic estimates the expected return and provides the learning signal for policy optimization during training (the critic is only used during training to train the policy). We train our proposed RL agent on an LLM-generated dataset (described in Sec. 6) using the PPO learning algorithm 

(Sec. 7.1). The following sections describe these components. 

5.1 State Representation 

The goal of the state representation is to produce a fixed-length vector embedding, ğ‘  ğ‘ƒ , that represents a given program IR, ğ‘ƒ . To extract the program representation, we first tokenize the program being optimized. We use a simple method that we call Identifier and Constant Invariant (ICI) tokenization. Conceptually, ICI is a form of alpha-renaming [ 2 ] combined with simple program canonicalization. ICI produces a canon-ical token sequence that is invariant to identifier names and to the concrete values of constants. For each program P, we rename variables such that the first distinct variable is mapped to v0, the second to v1, and so on. For example, the two semantically equivalent expressions (+ a (+ b c)) and 

(+ x (+ y z)) are both mapped to the exact same canonical sequence: (+ v0 (+ v1 v2)) . This normalization has a few practical benefits for learning: (i) it collapses programs that differ only by identifier naming or by value-agnostic con-stants into the same representation, reducing the effective vocabulary and simplifying generalization; (ii) it produces a stable canonical form that we reuse for dataset deduplication, avoiding redundant near-duplicate training samples; (iii) ICI tokenization is computationally lightweight: it is a single lin-ear scan with ğ‘‚ (1) expected-time hash map operations per new symbol. This contrasts with learned subword tokenizers such as Byte Pair Encoding (BPE) [ 65 ], which repeatedly Bilel Sefsaf et al. 

applies merge rules and performs large-vocabulary prefix searches, adding nontrivial overhead. More precisely, ICI uses a small fixed vocabulary for IR operators (e.g., +, *, VecAdd ) and delimiters/parentheses, and builds per-program hash maps for identifiers and constants in a single left-to-right pass. For each program ğ‘ƒ , the first distinct variable is mapped to v0 , the second to v1 , and so on. Numerical constants are mapped similarly to c0 , c1 , . . . with one important exception: the integers 0 and 1 are kept as literal tokens because they play a special semantic role in many rewrite rules (additive/multiplicative identities). For all other constants, we discard the literal value but preserve (i) that the token is a constant and (ii) whether two constant occurrences in the same expression are equal (e.g., the same constant reused in multiple positions receives the same c# to-ken). This is sufficient for our term-rewriting system because our rewrite rules do not branch on specific numeric values beyond special cases such as 0/1. In practice, programs that differ only in identifier names or non-(0/1) constant values are typically optimized by the same rewrite strategy. After tokenization, the program ğ‘ƒ is represented by a variable-length sequence of tokens, ğ‘‡ (ğ‘ƒ ) = [ğ‘¡ 1, ğ‘¡ 2, . . . , ğ‘¡ ğ‘˜ ].We then convert this sequence into a fixed-length vector that captures the long-range dependencies and hierarchical struc-ture implied by the tokens. For this, we use a Transformer encoder [ 70 ] that learns automatically a short, fixed-length embedding for the tokenized program. We chose this archi-tecture because its self-attention mechanism is designed to model long-distance dependencies inherent in source code, a capability validated by state-of-the-art code models such as CodeBERT [ 33 ]. This is critical for processing the long to-ken sequences that represent unrolled FHE programs. Early in the project, we compared the Transformer architecture to recurrent architectures, including LSTMs and GRUs, but they did not provide satisfactory results. The Transformer encoder follows a standard architecture, consisting of a stack of 4 identical layers. Each layer employs a multi-head at-tention mechanism with 8 attention heads. The input token embeddings are summed with absolute positional encodings to preserve sequence order, and the encoder processes this se-quence to generate a 256-dimensional vector for each token (we use the CLS special token as a placeholder to summa-rize the entire input sequence, as is commonly done in the literature [28]). 

5.2 Action Space 

The action space defines the set of valid transformations the agent can perform on the current program state. In our framework, an action corresponds to a rewriting rule selected from a set of predefined rewriting rules. A challenge in designing the action space is handling the location of rule application. A single rule might match multiple sub-expressions within the IR. To address this, the agent needs to select both a rule and a location. To enable this, we propose a hierarchical action space composed of two steps: the agent first picks a rule to apply, then picks the location where to apply it. To implement this, we propose a 

rule selection network used to pick an action, and a location 

selection network used to pick a location. We compare this hierarchical formulation to a flat rule/location action space in Sec. 7.6, and show that the hierarchical agent learns faster and achieves higher average rewards in training compared to a flat action space (Fig. 13). To allow the agent to control the length of the optimization process, the action space also includes a special END action. Selecting this action terminates the current optimization episode, allowing the agent to learn not only which rules to apply, but also when to stop. In total, our TRS consists of 84 rewrite rules, in addition to the END action. To design these rules, we began by collecting rules from Halideâ€™s TRS [ 58 , 62 ], and excluded rules that are not compatible with FHE (comparison, division, etc.). We then added new rules designed to reduce circuit depth, multi-plicative depth, rotations, and the total number of operations. More details about the rewriting rules in Appendix E. 

5.3 Reward Model 

The agent learns via a reward signal designed to guide it toward producing FHE circuits that have minimal latency and noise. This signal is derived from an FHE-aware cost function that evaluates the quality of a given IR. We will first show the cost function, and then show how it is used to compute the reward. 

5.3.1 FHE Cost Function. The goal of this cost function is to capture the metrics that we aim to minimize: number of FHE operations, multiplicative depth, and depth of the circuit. We also want to minimize the use of scalar operations in favor of vector operations. By minimizing the previous metrics, we minimize latency and noise. To achieve our goal, we define the cost function of an IR expression, e, as the weighted sum of the metrics that we want to minimize:              

> Cost (e)=ğ‘¤ ops Â·ğ¶ ops (e) + ğ‘¤ depth Â·ğ· circuit (e) + ğ‘¤ mult Â·ğ· mult (e)

Where ğ¶ ops is the cost of operations, ğ· circuit is its circuit depth, and ğ· mult is its multiplicative depth. The weights ğ‘¤ ops ,

ğ‘¤ depth , and ğ‘¤ mult reflect the importance of each metric in the cost function. For our experiments, we set all weights to 1. We study sensitivity to these weights in Sec. 7.6 and show that this configuration enables the RL agent to generate code that has minimal execution time. The components of the cost function are defined below. 

Operations Cost ( ğ¶ ops ): This term quantifies the compu-tational cost of all of the operators used in the expression. We assign a numerical cost to each operator. These numeri-cal costs reflect its relative performance compared to other operators in the BFV scheme. The relative order of these operations is guided by former empirical studies on the cost CHEHAB RL: Learning to Optimize Fully Homomorphic Encryption Computations 

of FHE operations [ 43 ]. The costs are structured to incen-tivize vectorization: 1) Vector Additions/Subtractions: These have the lowest cost (1), as they represent the most efficient parallel operations. 2) Vector Multiplications: These have a higher cost than vector additions/subtractions, and usually cost 100 Ã— the cost of vector additions, and therefore we as-sign a cost of (100) to them. 3) Rotations ( << ): Rotations typically have a cost that is 0.5Ã— to 1Ã— of the cost of a vector multiplication (depending on the parameters). We assign a cost of (50) to rotations, reflecting that rotations might be cheaper than multiplications but always more expensive than additions. This incentivizes rotations over multiplications, since they have a cost that is usually less than or equal to the cost of multiplications. 4) Scalar Operations (+,-,*): These are assigned a high cost (250) to reflect their inefficiency. While in this particular case, the value 250 is not derived empirically, we chose this high cost for scalar operations to incentivize the RL to generate vectorized code. The total ğ¶ ops is the sum of the costs of all the nodes in the expression tree. 

Circuit Depth ( ğ· circuit ). A greater depth implies more sequential operations are performed on a ciphertext, which leads to a larger accumulation of noise. Minimizing depth is therefore critical, as it directly impacts the noise. 

Multiplicative Depth ( ğ· mult ): This metric is critical as noise growth in the BFV scheme is directly proportional to the multiplicative depth. Therefore, to minimize the noise, we aim to minimize the multiplicative depth. The three terms have different numerical ranges: ğ¶ ops can be in the hundreds, while ğ· circuit and ğ· mult are typically in the single digits. As a result, even with equal weights the objective tends to prioritize reducing operation cost (run-time). Increasing ğ‘¤ depth and ğ‘¤ mult shifts the policy toward circuits with lower noise growth, but this often comes at the cost of additional operations, leading to slower execution. We quantify this speed/noise trade-off in Sec. 7.6. 

5.3.2 Reward Structure. To guide the agentâ€™s learning process, the reward signal is composed of two parts. The first is an immediate reward provided after every action dur-ing training, which guides local, incremental improvements. The second is a terminal reward provided once the entire optimization sequence for a given expression has ended (end of episode), and which guides the agent toward a globally optimal solution. 

i) Step Reward ( ğ‘… step ): After each action, the agent receives an immediate reward calculated as the relative percentage improvement in the cost function. If the cost of the expres-sion before the action is ğ¶ ğ‘¡ and after is ğ¶ ğ‘¡ +1, the reward of the step is: ğ‘… step = ğ¶ ğ‘¡ âˆ’ ğ¶ ğ‘¡ +1

> ğ¶ ğ‘¡

ii) Terminal Reward ( ğ‘… final ): The reward is given at the end of an episode (when the agent selects the END action, or the pre-defined maximum steps limit for the episode is reached). This reward is based on the total percentage reduction in cost from the initial state of the expression ( ğ¶ initial ) to its final state ( ğ¶ final ):      

> ğ‘… final =
> ğ¶ initial âˆ’ğ¶ final
> ğ¶ initial
> 
> Ã—100

Terminal reward motivation. We initially trained the CHEHAB RL agent using only the step reward and found that the policy often became locally greedy: it favored rewrite sequences that yield small early improvements and avoided transformations that temporarily increase cost but unlock larger gains later. This behavior is expected because PPO optimizes discounted returns, which biases learning toward immediate improvements. To better handle delayed credit in rewrite optimization, we add a terminal reward based solely on the final optimized expression, which encourages sequences that optimize end-to-end circuit quality rather than only short-horizon gains. We quantify the impact of removing ğ‘… final (i.e., using only the immediate reward) in Sec. 7.6, showing that the com-bined immediate +terminal reward yields better end-to-end execution time compared to step-only reward. 

5.4 Actor-Critic Networks 

In this work, we adopt the actor-critic RL architecture. To manage the complexity of the action space, we learn a hi-erarchical stochastic policy (actor), which decomposes the action ğ‘ into two components: a rewrite rule ğ‘Ÿ and an appli-cation location ğ‘ . This policy is defined by two conditional probability distributions: ğœ‹ ğœƒ 1 (ğ‘Ÿ | ğ‘  ) for rule selection and 

ğœ‹ ğœƒ 2 (ğ‘ | ğ‘ , ğ‘Ÿ ) for location selection. Alongside the policy, we learn a value function (critic) ğ‘‰ ğœ™ (ğ‘  ), which estimates the expected return from a given state ğ‘  . The policy and critic networks are implemented as separate deep neural networks. 

5.4.1 Rule Selection Network. The first network of the actor is the rule selection network. It is a Multi-Layer Percep-tron (MLP) that takes, as input, the 256-dimensional state em-bedding generated by the Transformer encoder (Section 5.1). The network consists of two fully connected hidden layers with 128 and 64 neurons, respectively, each using the ReLU activation function. The networkâ€™s final output layer is fol-lowed by a softmax, which produces a probability for each available action from the action space. After invalid actions (non-matching rules) are masked, the agent samples from this resulting probability distribution to select its next action. 

5.4.2 Location Selection Network. Once the rule net-work selects a rewriting rule, the Location Network selects the location within the IR for its application. The network selects whether the rule is applied to its 1st match in the IR, 2nd match, 3rd match, etc. It is implemented as an MLP that takes two inputs: the 256-dimensional state embedding and the output from the actor network representing the chosen rule. Its architecture consists of two fully connected hidden Bilel Sefsaf et al. 

Figure 4. Architecture of the Policy Network layers, each with 64 neurons, followed by ReLU activation. The final output layer produces a probability distribution over locations, from which the final position is sampled. 

5.4.3 The Critic (Value Network). The critic network es-timates the value function, ğ‘‰ (ğ‘  ), which predicts the expected cumulative future reward from the current state. It is an MLP that takes the state embedding as input. Its architecture con-sists of 3 fully-connected hidden layers with 256, 128, and 64 neurons, respectively, each with a ReLU. The final layer is a linear output layer that produces a single scalar value representing the value estimate, ğ‘‰ (ğ‘  ). This estimate is used during training to assess the actorâ€™s actions and guide the learning. 

## 6 Training Data 

A key challenge for training an effective CHEHAB RL agent is the absence of datasets for FHE programs. Consequently, we need to generate a dataset of expressions that are both diverse and contain realistic code patterns that appear in practice. 

Limitations of Random Data Generation. Training on purely random expressions is not ideal. Randomly generated expressions do not follow the same distribution of programs encountered in practice. They often lack the specific com-putational patterns that appear in practice (e.g., common sub-expressions, opportunities for factorization, and struc-tured arithmetic that can be vectorized). 

LLM-guided Generation. To address the previous lim-itation, we use Large Language Models (LLMs) to generate the training data, This design choice is important in prac-tice: Sec. 7.6 shows that training on LLM-generated programs yields substantially better policies than training on randomly generated programs.The full prompt template and a link to the generated training dataset are provided in Appendix F. We guide the LLM to synthesize a dataset that is diverse and rich in optimizable code patterns. Since the LLM is trained on a large corpus of realistic code, it tends to generate code that follows the same distribution of realistic code. For our data generation, we used the Gemini 2.5 Flash model. The prompt provided to the LLM is structured to give it sufficient context about the problem domain, and includes: 

i) Syntax and Semantics: A formal description and multiple examples of the CHEHAB IR, covering scalar operations, vec-tor constructors ( Vec ), and vector operations (e.g., VecAdd ). 

ii) Rewrite Rule Examples: Examples of the rewrite rules from our TRS are included to guide the LLM on the specific patterns we intend to optimize. 

iii) Real World Examples: To ground the synthesis process in practical computations, the prompt contains real-world kernels as examples. Examples provided in the prompt in-clude: a) Union Cardinality: Computes the cardinality of the bitwise OR of two 4-bit vectors; b) Squared Difference: Com-putes the element-wise squared error between two vectors; c) 4x4 Matrix Addition: A common linear algebra kernel that performs element-wise addition between two matrices. The provided examples do not include any of the benchmarks used in the evaluation. 

iv) High-Level Goal: A description of the optimization ob-jective and an explicit request for structural diversity in the generated expressions. 

Synthesizing CHEHAB IR Directly. We also considered generating CHEHAB DSL programs (embedded in C++) and then lowering them through the compiler to CHEHAB IR. In practice, directly generating CHEHAB IR was more reliable and easier to validate: the IR has a small, closed vocabu-lary and simple typing constraints, making it easier for the LLM to produce syntactically valid programs. In contrast, generating CHEHAB DSL (which is embedded in C++) re-quires emitting compilable code (including boilerplate C++ code), and validating each sample requires invoking a C++ toolchain and running DSL-to-IR lowering, which signifi-cantly slows the generation loop. Direct IR generation also simplifies deduplication and benchmark exclusion, since we can directly parse and canonicalize each program before adding it to the corpus. 

Post Processing. Expressions generated by the LLM are filtered to ensure their validity and uniqueness: 

i) Parsing and Validation: Expressions that cannot be parsed by our IR parser (due to syntactic errors) are discarded. 

ii) Uniqueness Filtering: To ensure diversity and avoid re-dundancy, we implement a uniqueness filter based on the canonical representation of expressions. This canonical rep-resentation is obtained using our Identifier and Constant Invariant (ICI) tokenization. Generated expressions may be semantically equivalent but use different variable names (e.g., (Vec (+ x (* y z))) and (Vec (+ a (* b c))) ). After ICI tokenization, they become equivalent. A newly generated expression is added to the dataset only if its canonical form was not generated before. CHEHAB RL: Learning to Optimize Fully Homomorphic Encryption Computations 

iii) Exclusion of Benchmarks: To avoid training the RL agent on programs identical to those found in the benchmark, we remove any generated expression that is identical to one of the benchmarks. This ensures the evaluation measures generalization to unseen programs. To do this, we compute the canonical form of each program in our benchmark suite (Sec. 7) using ICI tokenization. Any expression in the gener-ated dataset that matches a benchmark is removed. Our approach ensures that the dataset is not only syn-tactically correct but also semantically relevant and rich in the patterns our agent needs to learn to optimize. We gener-ated 15,855 unique expressions using the LLM and used this dataset to train the RL agent. 

Generalizability and benchmark separation. We strictly separate training and evaluation. The LLM-generated train-ing dataset contains 15,855 unique expressions. Each expres-sion is parsed and converted to its ICI canonical form, which normalizes away differences in identifiers and constants and collapses common syntactic variants. We use this canonical form to deduplicate the dataset and to remove any gener-ated expression whose canonical form matches a benchmark expression. This ensures that no benchmark program (or a trivially rewritten variant) appears in the training data, so evaluation reflects generalization to unseen programs. 

## 7 Evaluation 

We evaluate our proposed approach in three ways: 

Quality of Programs Generated. We compare code gen-erated by CHEHAB RL with that produced by the Coyote [ 52 ]compiler. The comparison focuses on the execution time of the generated circuit, the number of homomorphic opera-tions, the depth, the multiplicative depth, and noise (noise accumulated by the benchmark, which we want to mini-mize).The definition of the noise metric and details about how we measure it are in Appendix H.1.We limit our eval-uation to FHE compilers that support unstructured code. Porcupine [ 23 ] is excluded as it is not publicly available (we reached out to its authors but could not obtain a copy). 

Compilation Efficiency. We report the end-to-end com-pilation time for CHEHAB RL and Coyote. 

Ablation Study. We perform an ablation study to evalu-ate the following: LLM-generated vs random data; 2) CHEHAB RL vs CHEHAB; 3) ICI vs BPE tokenization; 4) Flat vs hierar-chical action space; 5) GRU vs Transformer encoder. 

7.1 RL Agent Training 

We use the Proximal Policy Optimization (PPO) algorithm to train the agent [ 64 ] used by CHEHAB RL. We train it for 2 million timesteps (43 hours), on a single multi-core CPU. More details about the training and the hyperparameters in Appendix G and Table 4. 

7.2 Benchmarks 

We evaluate CHEHAB RL on three benchmark suites. For each benchmark in the benchmark suites, we vary the input size to evaluate the scalability of the compiler. The larger the input is, the larger the program is, since FHE code is fully unrolled. The three benchmark suites are: 

Porcupine Benchmark Suite. This is a set of kernels com-monly used in linear algebra, machine learning, and image processing. They were used to evaluate Porcupine [ 23 ]. They include image processing filters: Box Blur, the x and y gradi-ents of an image ( Gx and Gy ), and Robert Cross ( Rob. Cross. ). The Porcupine benchmark suite also includes Dot Product, Hamming Distance ( Hamm. Dist. ), L2 Distance, Linear Re-gression ( Linear Reg. ), and Polynomial Regression ( Poly. Reg. ), which are building blocks for ML applications. We include all of the benchmarks that were used to evaluate Porcupine. 

Coyote Benchmark Suite. It includes kernels that were used to evaluate Coyote [ 52 ]. These kernels are: 1) matrix multiplication ( Mat. Mul. ); 2) a sorting algorithm ( Sort ) that sorts a list of elements; This sorting algorithm is an unstruc-tured code that implements sorting using a tree (as described by Malik et al. [52]). 3) Max kernel. This is an unstructured code that finds the maximum element in a list. Coyote also includes three other kernels, which are the dot product, the L2 distance, and a convolution, but these are common with the Porcupine benchmark suite, and therefore, we do not evaluate them again. All of the benchmarks that were used to evaluate Coyote are included in our benchmark suite. 

Randomly Generated Irregular Polynomials. The Coy-ote compiler also uses a set of randomly generated unstruc-tured polynomials for evaluation. We use the same method-ology for evaluation. This set of polynomials is a stress test to further investigate the ability of the compiler to vectorize code in the absence of a regular structure in the code. Several polynomials are generated as random arithmetic expression trees. In these polynomials, a polynomial is named tree-X-Y-Z, where high values for X-Y indicate that the polynomial tree is full, complete, and well-balanced, making it easier to vectorize, while low values for X-Y indicate that the tree is sparse and imbalanced, making it harder to vectorize. Z indicates the depth of the tree of the polynomial.We provide more details about these polynomials in Appendix H.3. 

7.3 Input Layout Transformation Before Encryption 

Vectorization often requires rearranging the layout of the input data so that operands line up in the same ciphertext slots. If performed after encryption, this layout transforma-tion translates into extra ciphertext rotations (and masking), which are expensive. CHEHAB therefore moves this step to the client: inputs are permuted/packed in plaintext and only then encrypted, so the server-side computation starts from ciphertexts already in the desired layout and avoids the Bilel Sefsaf et al. 

Figure 5. Semi-log plot of execution time of the benchmarks, comparing code generated using our compiler and Coyote. 

Figure 6. Semi-log plot of compilation time of the benchmarks using our compiler and Coyote. 

Figure 7. Semi-log plots comparing the Consumed Noise Budget in Coyote and CHEHAB RL. corresponding homomorphic rotations. Unless stated other-wise, the evaluation reports results with this optimization enabled, and we provide results without this optimization in the appendix. 

7.4 Environment Setup 

We evaluate our benchmarks on a 2.40 GHz Intel(R) Xeon(R) CPU E5-2680 v4 with 256 GB DDR4 of memory running Cen-tOS Linux 8. The encryption parameters for CHEHAB and Coyote are set as follows: n = 16384 (polynomial modulus degree) and q is the default coefficient modulus proposed by the SEAL library for a standard 128-bit security level. We disable the CHEHAB pass for automatic rotation key selection(presented in Appendix B), since Coyote does not have a similar pass. We also disable the use of the blocking technique [ 52 ] for both compilers, CHEHAB and Coyote, since both of them perform blocking in the same way. Block-ing is a technique that involves vectorizing smaller kernels separately and then composing the resulting vectorized pro-grams. While this technique enables the two compilers to scale to larger programs, our goal is to compare the funda-mental algorithms proposed by each compiler on a single block. Since the blocking method is identical in the two com-pilers, comparing on a single block will better illustrate the fundamental differences between the two approaches. By default, CHEHAB transforms the data layout of input data before encryption (as described in Sec. 7.3). Results when the data layout of input data is transformed after encryption are presented in the appendix in Table 6. We also use the same SEAL library in both compilers (SEAL version 4.1). We run all the experiments 30 times and report the median execution times and compilation times. The compilation timeout for both compilers was 7200 seconds. 

7.5 Evaluation on the Benchmarks 

We compare CHEHAB RL with Coyote on our benchmark suite, measuring the execution time of optimized code (Fig. 5), compilation time (Fig. 6), and consumed noise budget (Fig. 7). Fig. 5 shows that CHEHAB RL produces faster code than Coyote for most benchmarks. On average, CHEHAB RL gen-erates code that is 5.3Ã— faster in execution (geometric mean) than Coyote. For example, on Poly. Reg. 32 , code gen-erated by CHEHAB RL is 50 Ã— faster than code generated by Coyote, and faster by 114 Ã— on Linear Reg. 32 . This speedup is due to having fewer operations in code gen-erated by CHEHAB RL, for example, in Poly. Reg. 32 ,CHEHAB RL generated a circuit with just 3 additions and 2 ct-ct multiplications (ciphertext-ciphertext multiplications). CHEHAB RL: Learning to Optimize Fully Homomorphic Encryption Computations 

In contrast, Coyote generates a much larger circuit with 12 additions, 2 ct-ct multiplications, 1 subtraction, 173 ct-pt mul-tiplications (ciphertext-plaintext multiplications), and 134 rotations. Coyote appears to generate a complex data layout that requires extensive rotations and ct-pt multiplications to execute, where CHEHAB RL finds a simpler, more direct vectorization. This pattern holds for Linear Reg. 32 as well, where the agent produces a circuit with 2 additions, 1 ct-ct multiplication, and 1 ct-pt multiplication, while Coy-ote generates one with 4 additions, 1 ct-ct multiplication, 3 subtractions, 46 ct-pt multiplications, and 44 rotations. Image-processing kernels also show substantial gains: code generated by CHEHAB RL for Gx 5x5 is 42 Ã— faster than Coyote. In this benchmark, Coyote over-rotates data, leading to a higher number of operations and a slower circuit. For 

Tree 50-50-10 , Coyote generates a circuit that runs faster; this is due to the high number of expensive ct-ct multipli-cations that CHEHAB RL generates. The generated circuits that Coyote generates, despite having a higher number of total operations (21 adds, 19 plaintext multiplications, 7 ro-tations), require only 7 ct-ct multiplications. In contrast, the circuit produced by CHEHAB RL, while more compact (18 adds, 2 rotations), requires 15 ct-ct multiplications. Fig. 6 shows that despite producing circuits that are faster to execute, the compilation time for CHEHAB RL is also consistently faster than Coyoteâ€™s. On average, the CHEHAB RL compilation process is 27 .9Ã— faster (geometric mean) than Coyote. A notable exception to this trend is the Tree 50-50-5 and Linear Reg. 4 benchmarks, where Coyoteâ€™s compilation time is faster than CHEHAB RL. These bench-marks are small, so Coyoteâ€™s search algorithm can rapidly explore the small search space. In contrast, our RL agent requires a series of steps to apply its learned policy. The overhead of invoking the neural network for each of these sequential steps results in a longer compilation time for these small benchmarks. However, as demonstrated across the rest of the benchmark suite, this overhead for the RL agent is outweighed by its higher scalability to larger circuits. Fig. 7 compares the noise budget consumed by the cir-cuits generated by CHEHAB RL and Coyote. The results show that code generated by CHEHAB RL consistently con-sumes less noise budget compared to Coyote. On average, code generated by CHEHAB RL consumes 2.54 Ã— less noise budget (geometric mean) compared to Coyote. For example, code generated by CHEHAB RL for Poly. Reg. 32 con-sumes only 73 bits from the available noise budget (which is 369 bits), leaving a remaining budget of 296 bits, while Coyoteâ€™s much larger and complex circuit consumes 210 bits. In different benchmarks such as Sort 4 and two of the Polynomial Tree benchmarks, the circuit generated by Coyote exhausts the entire noise budget and fails to execute, while CHEHAB RL successfully produces valid, runnable circuits for all benchmarks, leaving a safe remaining noise budget in each case.                        

> (ğ‘¤ ops , ğ‘¤ depth , ğ‘¤ mult )Exec. time ( Ã—vs. (1,1,1))Noise ( Ã—vs. (1,1,1))
> (1,50 ,50 )1.426 Ã—0.941 Ã—(1,100 ,100 )1.487 Ã—0.935 Ã—(1,150 ,150 )1.396 Ã—0.911 Ã—

Table 1. Reward weight sensitivity. A more detailed comparison, including operation counts for all benchmarks, is available in Table 6 in Appendix I. 

7.6 Ablation Study 

Step vs. step +terminal reward. Our reward signal is composed of an immediate step reward and a terminal re-ward (Sec. 5.3.2), where the step reward provides local feed-back after each rewrite and the terminal reward provides a global signal at the end of the optimization episode. We ab-late this design by training an agent with only the immediate reward (step wise) and comparing it to our default agent us-ing immediate + terminal rewards. Using both components is beneficial: immediate +terminal achieves a 1.291 Ã— better execution time (geometric mean) than using the immediate reward alone. This shows that the terminal reward is nec-essary to align the policy with end-to-end circuit quality, whereas purely local feedback can over-emphasize short-horizon improvements that do not translate into the best final circuit. Figure 9 shows the per-benchmark execution time. 

Reward weight sensitivity. We further ablate the re-ward design by varying the weights of the cost function in Sec. 5.3.1, i.e., (ğ‘¤ ops , ğ‘¤ depth , ğ‘¤ mult ). We compare the default 

(1, 1, 1) against a set of new weights: (1, 50 , 50 ), (1, 100 , 100 )

and (1, 150 , 150 ). We include configurations with large ğ‘¤ depth 

and ğ‘¤ mult because operation costs in ğ¶ ops are already numer-ically large, and thus depth-based penalties must be scaled to have a comparable influence when explicitly biasing the policy toward lower-depth circuits. While the new weight variants have a slightly lower noise consumption (they con-sume 0.911 -0.941 Ã— the noise of (1, 1, 1)), our default weight configuration, (1, 1, 1), yields significantly better runtime: it is 1.396 -1.487 Ã— faster in execution time (geometric mean) than the other variants. This is summarized in Table 1. 

LLM-generated vs. Random Data. To quantify the ef-fectiveness of using an LLM to generate data, we compare the performance of our RL agent (trained on LLM-generated data) against the same agent trained on a dataset of ran-domly generated data. The random code generator uses a standard approach to generate code with a uniform distribu-tion (described in Appendix H.2). Fig. 8 compares the two approaches. The agent trained on LLM-generated data pro-duces FHE circuits that are faster. For instance, on the L2 Distance 32 benchmark, CHEHAB RL trained on LLM-generated data produces code that is 13 Ã— faster compared to CHEHAB RL trained on randomly generated data. Similar performance gaps of an order of magnitude are observed Bilel Sefsaf et al. 

Figure 8. Semi-log plots comparing the execution times when using an RL agent trained with randomly generated data and an RL agent trained with data generated by an LLM 

Figure 9. Semi-log plot of benchmark execution time, comparing an agent trained with step-only reward against our step +terminal reward. across the larger instances of Hamm. Dist. and Dot Prod-uct . This difference in performance is due to the quality of the learned policies. The agent trained on LLM-generated data learns to generate more efficient circuits with fewer expensive homomorphic operations. For example, in the L2 Distance 32 case, the circuit generated by the LLM-trained agent contains only 5 additions and 1 multiplication, com-pared to 28 additions and 28 multiplications in the circuit generated by the agent trained on random data. This demon-strates that the LLM-generated data helps the RL agent learn a policy that performs better on realistic programs, since it provides expressions with relevant, optimizable structures, that more closely mirror real program distributions. 

CHEHAB RL vs CHEHAB. To ensure that the improve-ments in reducing latency in CHEHAB RL are due to the RL TRS, and not to other optimizations in the original CHEHAB, we compare the execution times of code generated by the original CHEHAB and CHEHAB RL. Fig. 12 (Appendix) shows the results. As we see, in most cases, code generated by CHEHAB RL is faster. In some instances, most notably Gx 3x3 , the original CHEHAB is better than CHEHAB RL due to a sub-optimal decision made by the learned policy. An examination of the generated circuit shows that the RL agent chose to apply one rotation to align data for the vectorization of two ct-pt multiplications. While the CHEHAB RL success-fully vectorized the operations, the computational cost of the required rotation was greater than the performance benefit gained from vectorizing the two ct-pt multiplications. 

ICI vs. BPE Tokenization. We also evaluate the use of the Identifier and Constant Invariant (ICI) tokenization for tok-enizing the inputs of the embedding model. This experiment compares our agent, which uses ICI tokenization, against the same agent that uses a standard Byte-Pair Encoding (BPE) tokenizer. The BPE tokenizer was trained on a corpus of 5 million randomly generated IR expressions to build its vo-cabulary (details about random IR code generation are in Appendix H.2). Once the BPE tokenizer is trained, we train the two agents using our dataset of LLM-generated data. Fig. 10 in the appendix shows that the RL agent that uses ICI tokenization finishes its 2 million steps training in 43 hours, compared to the RL agent trained with BPE, which takes 68 hours, showing that our tokenization helps accelerate the training. 

Flat vs. Hierarchical Action Spaces. We also compared the hierarchical action space against a flat one that enumer-ates rule-location pairs (i.e, each rule is duplicated multi-ple times, once for each location). The learning curves in Fig.13 in the appendix show consistently higher rewards and quicker learning for the hierarchical agent. 

GRU vs Transformer. To validate our choice of a Trans-former encoder for the state representation, we compared its encoding capabilities against a baseline recurrent architec-ture, the Gated Recurrent Unit (GRU). Our experiments show that the transformer architecture was able to learn a better representation with less training compute. Details about this experiment are in Appendix I.1. 

## 8 Related Work 

This section compares CHEHAB RL and state-of-the-art com-pilers. Table 2 summarizes the differences, which we discuss in detail in this section. In addition, we discuss the use of RL in compilers, tokenization methods, and random data generation methods in Appendix J. CHEHAB RL: Learning to Optimize Fully Homomorphic Encryption Computations 

Table 2. Comparison with related work.                                           

> Feature CHEHAB RL HECO Porcupine Coyote Ramparts EVA HECATE Vec. struct. code âœ“âœ“âœ“âœ“Ã—Ã—Ã—
> Vec. unstruct. code âœ“Ã—âœ“âœ“Ã—Ã—Ã—
> Reduce mul. depth âœ“âœ“âœ“Ã—âœ“Ã—Ã—
> Auto datalayout âœ“âœ“Ã—âœ“âœ“âœ“âœ“
> Data driven âœ“Ã—Ã—Ã—Ã—Ã—Ã—
> Scheme BFV BFV BFV BFV BFV CKKS CKKS CKKS BGV

FHE Compilers for Automatic Vectorization. Recent work [ 23 , 27 , 52 , 72 ] focuses on the problem of transform-ing FHE programs that use scalar variables into vectorized programs (batching). Our work is similar to these compil-ers since it also takes a scalar code and vectorizes it. Unlike HECO [ 72 ], CHET [ 27 ], ANT-ACE [ 50 ], Orion [ 30 ], HEIR [ 4 ]and Qiwu [ 75 ] which only support the vectorization of struc-tured (loop-based) code, CHEHAB RL is designed to support both structured and unstructured code. Compared to Coy-ote [ 52 ], our approach scales better. Unlike Porcupine, in which the user has to manually provide the data layout of the vectorized code, our approach computes the best data layout automatically. 

FHE Compilers for Circuit Optimization. These com-pilers do not vectorize their input code. They focus on ap-plying other optimizations (other than vectorization). These compilers include EVA [ 26 ], Ramparts [ 5 ] and HECATE [ 49 ]. The main challenges that they target are automatic parame-ter selection, the scheduling of ciphertext-maintenance op-erations, reducing the multiplicative depth of circuits, and reducing the number of operations in a circuit. Our approach is complementary to the above compilers. First, it supports code vectorization, and therefore, code vectorized by our approach can be passed to these compilers for further op-timization. Our approach also offers the ability to reduce the depth of circuits, which they do not address. Appendix J provides a more detailed comparison with these compilers. 

General Purpose Vectorization in non-FHE Programs. 

Superword-Level Parallelism is a classical technique used for code vectorization [ 47 ]. It processes a sequence of scalar instructions to create vector packs or groups of isomorphic instructions that can be packed together into vectors. Since it does not depend on the presence of data-parallel loops in the code, it is well-suited for vectorizing unstructured code. However, while creating vector packs, SLP does not consider the high cost of rotations in FHE programs, which results in code that has a high number of rotations, making it impractical for the domain of FHE, where rotations are expensive. goSLP [ 53 ] is a state-of-the-art SLP approach that formulates the vectorization problem as an Integer Linear Programming (ILP) problem. However, it operates at a level closely tied to the target architecture, where the vectors are restricted to a maximum width of four elements. One of its key limitations is that while it efficiently handles the pair-wise packing of statements, extending this to pack more than two statements makes the problem intractable for current solvers. In contrast, our approach for FHE supports signifi-cantly larger vectors (in the thousands), which is necessary for the domain of FHE since vectors in FHE are significantly larger. VeGen [ 19 ] extends SLP by introducing lane-level parallelism, tracking how individual lanes execute compu-tations. This enables VeGen to account for rotation costs when constructing vector packs. However, this reasoning is local, as VeGen does not consider the impact of instruction packing on subsequent rotations. Other work [ 31 , 60 , 63 ]also addresses code vectorization but is not designed for the field of FHE and does not assume a high cost for rotations. In addition, in this work, our goal is to develop an FHE compiler that not only vectorizes code but also reduces the instruction latency and noise growth while being more scalable. 

RL for Code Optimization. RL has been explored for compiler code optimization [ 10 , 16 , 25 , 36 , 59 , 69 , 71 , 74 ]. Sys-tems such as Halide RL [59 ] train agents to select schedules for image processing code, while Tiramisu RL [ 10 ] applies polyhedral transformations to computational kernels using an RL-based policy. More specialized approaches include 

NeuroVectorizer [36 ], which learns to select the optimal vec-torization and interleaving factors for loops on SIMD archi-tectures using learned code embeddings, and Polygym [16 ], which frames affine loop transformation in the polyhedral model as a Markov Decision Process. Frameworks such as 

CompilerGym [25 ] have provided RL environments for tasks such as LLVM phase ordering. While previous work ad-dresses traditional code optimizations, it does not consider the unique constraints of Fully Homomorphic Encryption. Our work is the first to formulate FHE optimization as an RL problem, where the agent must learn a policy that nav-igates the trade-offs between vectorization, cryptographic noise accumulation, and the cost of operations. Appendix J provides more details on using RL for code optimization. 

Automatic Code Optimization in Compilers. Auto-matic code optimization for loop nests has been widely ex-plored. Examples of state-of-the-art methods include the use of the polyhedral model and deep-learning-based meth-ods [ 7 , 8, 11 , 13 , 18 , 34 , 38 , 42 , 54 , 67 , 76 ]. Such work does not address FHE code optimization, though. 

## 9 Conclusion 

This paper introduces a novel framework that leverages RL to automate FHE code optimization. Our proposed approach trains an RL agent to learn a policy for applying a sequence of rewriting rules to automatically vectorize scalar FHE code while reducing instruction latency and noise growth. We Bilel Sefsaf et al. 

show that our approach generates code that is 5.3Ã— faster than Coyote, accumulates 2.54 Ã— less noise, while it takes 

27 .9Ã— less time in compiling code, enabling better scalability. 

## Acknowledgment 

This research was partly supported by the Center for Cyber Security (CCS) at New York University Abu Dhabi. It was also partly supported by the Center for Artificial Intelligence and Robotics (CAIR) at New York University Abu Dhabi, funded by Tamkeen under the NYUAD Research Institute Award CG010. It was also partly supported by the Federation of Arab Scientific Research Council under contract number ARICA23_787 . The research was carried out on the High-Performance Computing resources at New York University Abu Dhabi. CHEHAB RL: Learning to Optimize Fully Homomorphic Encryption Computations 

## A More Detailed Background 

A.1 Term Rewriting System (TRS) A term rewriting system (TRS) is a set of rewrite rules that transform an expression to a new form (rewrite it into a new expression). Let us take a simple example of a TRS system to illustrate how it works. Let us assume that we want to simplify arithmetic expressions and let us assume that we have the following rule set ğ‘† = {ğ‘¡ âˆ’ ğ‘¡ â†’ 0, ğ‘¡ + 0 â†’ ğ‘¡ }. Let us use this rule set ğ‘† to rewrite and simplify the expression 

ğ‘ + ( ğ‘ âˆ’ ğ‘ ). The rule ğ‘¡ âˆ’ ğ‘¡ â†’ 0 can be applied to simplify the expression ğ‘ âˆ’ ğ‘ . After applying the rule, we get the new expression: ğ‘ + 0. Now we can apply the rule ğ‘¡ + 0 â†’ ğ‘¡ to simplify the previous expression into ğ‘ .

A.2 Fully Homomorphic Encryption 

Fully Homomorphic Encryption (FHE) enables computations directly on encrypted data [ 6 , 20 ]. A homomorphism is a function between two groups that preserves their structure [ 29 ]. In the context of FHE, these groups correspond to el-ements in the plaintext space P and the ciphertext space 

C. Let us define the encryption and decryption functions as 

ğ¸ (Â·) : P â†¦ â†’ C and ğ· (Â·) : C â†¦ â†’ P , respectively. Given an operation â—¦ on plaintexts and its homomorphic counterpart 

âŠš on ciphertexts, for plaintexts ğ‘š ğ‘ , ğ‘š ğ‘ âˆˆ P with encryptions 

ğ‘ ğ‘ = ğ¸ (ğ‘š ğ‘ ), ğ‘ ğ‘ = ğ¸ (ğ‘š ğ‘ ) âˆˆ C , the homomorphic property ensures that operations on encrypted data remain consistent with their plaintext counterparts, i.e., ğ‘š ğ‘ â—¦ ğ‘š ğ‘ = ğ· (ğ‘ ğ‘ âŠš ğ‘ ğ‘ ).

A.2.1 BFV Scheme. The BFV encryption scheme [ 32 ] is an FHE scheme based on the Ring-Learning With Errors (RLWE) problem [ 51 ]. In BFV, the plaintext space is defined as P = ğ‘… ğ‘¡ = Zğ‘¡ [ğ‘¥ ]/( ğ‘¥ ğ‘› + 1), while the ciphertext space is 

C = ğ‘… ğ‘ Ã— ğ‘… ğ‘ , where ğ‘… ğ‘ = Zğ‘ [ğ‘¥ ]/( ğ‘¥ ğ‘› + 1). Here, ğ‘› is the polynomial modulus degree, and ğ‘¡ , ğ‘ , and ğ‘¥ ğ‘› + 1 denote the plaintext, ciphertext, and polynomial moduli. Typical values for ğ‘¡ range from 16 to 32 bits, while ğ‘ varies between 100 and 900 bits. The degree ğ‘› is usually a power of two, commonly between 210 and 216 , as recommended by the Homomorphic Encryption Standard [3]. 

A.2.2 FHE Batching. Batching enables evaluation of a function on ğ‘› blocks of data [ 15 ] at once by encoding a vector of ğ‘› messages in a single plaintext polynomial in ğ‘… ğ‘¡ .Under the assumption ğ‘¡ â‰¡ 1 mod 2ğ‘› , ğ‘¥ ğ‘› + 1 factors into linear polynomials modulo ğ‘¡ , i.e. ğ‘¥ ğ‘› + 1 â‰¡ Ãğ‘› ğ‘– =1 (ğ‘¥ âˆ’ ğ‘ ğ‘– )

mod ğ‘¡ , with ğ‘ ğ‘– = ğ‘ 2ğ‘– âˆ’1 being the 2ğ‘› th primitive root of unity modulo ğ‘¡ , and ğ‘¡ = Ãğ‘› ğ‘– =1 ğ‘¡ ğ‘– where ğ‘¡ ğ‘– are prime ideals with basis (ğ‘¡, ğ‘¥ âˆ’ ğ‘ ğ‘– ). Using CRT on ideals, we have the following isomorphism: 

ğ‘… ğ‘¡ = ğ‘… /( ğ‘¡ ) ğ¶ğ‘…ğ‘‡ 

 ğ‘… /ğ‘¡ 1 Ã— Â· Â· Â· Ã— ğ‘… /ğ‘¡ ğ‘› 

Thus, evaluating a function once over ğ‘… /( ğ‘¡ ) evaluates the same function on smaller plaintext spaces ğ‘… /ğ‘¡ 1, . . . , ğ‘… /ğ‘¡ ğ‘› .

## B Selection of Rotation Keys 

B.1 Importance of Selecting the Rotation Keys 

Galois keys (a.k.a. rotation keys) are essential for perform-ing rotation operations in FHE. Each distinct rotation step requires its own keyâ€”for example, rotating a ciphertext by 

ğ‘  1 and another by ğ‘  2 (where ğ‘  1 â‰  ğ‘  2) necessitates two sepa-rate rotation keys. When a program involves many unique rotation steps, generating and transmitting all keys becomes costly, as each key is several megabytes in size. A common approach to mitigate this is to generate a subset of rotation keys and express other rotations as combinations of these. For instance, generating only the rotation key for step ğ‘  = 1

allows any rotation to be performed as repeated single-step rotations. This reduces key generation and communication costs but significantly increases execution time and noise for large rotation steps. A better trade-off is to balance the costs of key generation and communication, as well as the cost of executing rotations during homomorphic operations. 

B.2 Method for Selecting Rotation Keys 

After code optimizations, CHEHAB generates an IR contain-ing the necessary rotations for which keys must be generated. Previous work [ 5, 23 , 49 , 72 ] does not address automatic ro-tation key selection, relying instead on the FHE libraryâ€™s default, which generates 2 log 2 (ğ‘› ) keys. This approach can be suboptimal, as some applications may require fewer than 

2 log 2 (ğ‘› ) rotation keys. Instead, CHEHAB selects the rota-tion keys to be generated and ensures that the number of keys does not exceed a user-defined upper bound ğ›½ , which defaults to 2 log 2 (ğ‘› ).Let ğœ’ be the set of all rotation steps used in the program. Our goal is to decompose the steps in ğœ’ . We use the non-adjacent form (NAF) representation of each step ğ‘  in ğœ’ to decompose it. For example, possible decompositions of a step ğ‘  = 3 are obtained by calculating ğ‘ ğ´ğ¹ (3). The NAF representation writes s as a sum of powers of two, where each coefficient is either +1 or -1, and no two nonzero digits are adjacent. For example, NAF(3) = 4 - 1; NAF(5) = 4 + 1. Once we calculate the NAF representation for each step s, we collect the decompositions of the steps. For each rotation step ğ‘  , let Î“ğ‘  denote the set of decompositions of s obtained from its NAF (e.g., for ğ‘  = 3 we get Î“3 = {âˆ’ 1, 4}). We then select a subset Î© of the rotation steps in ğœ’ that will be decomposed via their NAF. The remaining rotation steps that are not decomposed form another set, denoted ğœ’ ğ‘“ .The final set of rotation keys to be generated is the union of the keys for the non-decomposed rotations and those derived from the NAF decompositions. Consider the following example:                          

> ğœ’ ={1,2,3,4,5,6,7,9,10 ,12 ,11 ,13 ,15 }
> ğ‘› =16 ,2Ã—log 2(ğ‘› )=8,ğ›½ =9Bilel Sefsaf et al.

The NAF decompositions of steps in ğœ’ are as follows:                                                                                                                  

> ğ‘ ğ´ğ¹ (1)=1,ğ‘ ğ´ğ¹ (2)=2,ğ‘ ğ´ğ¹ (3)=âˆ’1+4
> ğ‘ ğ´ğ¹ (4)=4,ğ‘ ğ´ğ¹ (5)=1+4,ğ‘ ğ´ğ¹ (6)=âˆ’2+8
> ğ‘ ğ´ğ¹ (7)=âˆ’1+8,ğ‘ ğ´ğ¹ (9)=1+8,ğ‘ ğ´ğ¹ (10 )=2+8
> ğ‘ ğ´ğ¹ (12 )=âˆ’4+16 ,ğ‘ ğ´ğ¹ (11 )=âˆ’1âˆ’4+16
> ğ‘ ğ´ğ¹ (13 )=1âˆ’4+16 ,ğ‘ ğ´ğ¹ (15 )=âˆ’1+16
> Î“1={1},Î“2={2},Î“3={âˆ’ 1,4}
> Î“4={4},Î“5={1,4},Î“6={âˆ’ 2,8}
> Î“7={âˆ’ 1,8},Î“9={1,8},Î“10 ={2,8}
> Î“12 ={âˆ’ 4},Î“11 ={âˆ’ 1,âˆ’4}
> Î“13 ={1,âˆ’4},Î“15 ={âˆ’ 1}

A valid set of rotation steps selected for decomposition is:            

> Î©={1,2,3,4,5,6,7,9,12 ,15 }

In that case, the final state is:              

> ğœ’ ğ‘“ ={10 ,11 ,13 }
> Î“ğ‘¡ğ‘œğ‘¡ =
> Ã˜
> ğ‘  âˆˆÎ©
> Î“ğ‘  ={1,2,4,âˆ’1,âˆ’4,8}

where Î“ğ‘¡ğ‘œğ‘¡ is the set of decompositions of steps in ğœ’ selected for decomposition. At the end, we end up with a smaller number of rotation keys to generate, since we just need to generate 9 keys (a key for each step in ğœ’ ğ‘“ âˆª Î“ğ‘¡ğ‘œğ‘¡ ), instead of generating 13 keys (a key for each rotation step in ğœ’ ). 

## C CHEHAB DSL syntax and semantics. 

CHEHAB is an embedded DSL implemented via C++ oper-ator overloading on Ciphertext and Plaintext . Although CHEHAB programs are written in C++, only a restricted subset of C++ expressions and helper functions constitutes the DSL. We therefore summarize this practical DSL subset 

as a compact grammar for readability, while keeping the full operator list in Table 3 as a reference. 

C.1 Core expression grammar (pseudo-grammar). Programs in CHEHAB construct expression graphs over 

Ciphertext or Plaintext values: 

ğ‘’ :: = ğ‘¥ | ğ‘˜ | ( ğ‘’ ) | ğ‘’ âŠ• ğ‘’ | âˆ’ ğ‘’ | ğ‘’ ğœŒ ğ‘˜ 

| ğ‘“ (ğ‘’ ) | ğ‘” ({ ğ‘’ 1, . . . , ğ‘’ ğ‘› }) | ğ‘’. set_output ("name" )

where ğ‘¥ is an identifier, ğ‘˜ is an integer literal, âŠ• âˆˆ {+ , âˆ’, âˆ—} ,and ğœŒ âˆˆ { Â«, Â»}.The supported helper functions are: 

ğ‘“ âˆˆ { square , reduce_add , reduce_mul , SumVec , encrypt },ğ‘” âˆˆ { add_many , mul_many }.

Pseudo-semantics. Expressions are typed as Ciphertext 

or as Plaintext . Binary operators denote the corresponding homomorphic operations (ct-ct or ct-pt variants depending on operand types), unary - denotes negation, and Â«/Â» de-note slot rotations by a constant offset. Helper functions expand into compositions of these primitives (e.g., square 

and exponentiate as repeated multiplication, add_many and 

mul_many as reductions over a set of expressions, while 

reduce_add , reduce_mul and SumVec as structured reduc-tions). Integer literals are permitted in expressions via im-plicit Plaintext construction (and encrypt when needed). Finally, set_output("name") marks an expression as a pro-gram output for compilation. 

C.2 List of Operations in the CHEHAB DSL 

Table 3 provides the full list of operations in the CHEHAB DSL as well as their signatures and descriptions. 

Table 3. Operations of the CHEHAB domain-specific lan-guage (ct: ciphertext, pt: plaintext, int: integer).                                                                         

> Op. Signature Description
> +ct Ã—ct â†’ct Element-wise addition ct Ã—pt â†’ct pt Ã—ct â†’ct +ct Ã—int â†’ct Add int value to all elements of ct -ct Ã—ct â†’ct Element-wise subtraction ct Ã—pt â†’ct pt Ã—ct â†’ct -ct Ã—int â†’ct Subtract int value from all elements of ct -ct â†’ct Negation of each element of the argument << ct Ã—int â†’ct Rotation of ciphertext to the left with the given step >> ct Ã—int â†’ct Rotation of the ciphertext to the right with the given step *ct Ã—ct â†’ct Element-wise multiplication ct Ã—pt â†’ct pt Ã—ct â†’ct *ct Ã—int â†’ct Multiply all ciphertext elements by an int

## D Code Generation 

To reduce memory consumption, CHEHAB minimizes the creation of temporary ciphertext and plaintext objects using the primitive inplace provided by the SEAL API. This primi-tive enforces the reuse of memory occupied by dead objects, similar to how a compound assignment operator works. To compile a program, the user runs the DSL code. When the DSL code is run, it creates the IR AST, runs the compiler passes on the IR, and generates optimized code at the end (C++ code). This code is further compiled using a C++ com-piler. The generated binary code is the final outcome of the compilation process and can be run like any other binary. This approach is common in implementing DSLs embedded in C++. 

## E Rewriting Rules 

The transformations available to the RL agent are defined as a set of rewriting rules. These rules include rules for vector-ization, algebraic simplification, and rotation. CHEHAB RL: Learning to Optimize Fully Homomorphic Encryption Computations 

Vectorization Rules for Isomorphic Subexpressions. 

These rules pack scalar arithmetic operations into single vec-tor instructions. They search for isomorphic element -wise scalar expressions and rewrite them as a single vector in-struction. For example, a vectorization rule for addition is:   

> (Vec (+ a b) (+ c d)) â‡’(VecAdd (Vec a c) (Vec b d))

This rewriting rule replaces two scalar additions (left-hand side) with one vector addition operating on newly constructed vectors of the operands (right-hand side). Similar rules exist for multiplication, subtraction, and negation. 

Vectorization Rules for Non-isomorphic Subexpres-sions. While powerful, the previous vectorization rules re-quire isomorphic subexpressions. To handle common pat-terns of non-isomorphic subexpressions, our set of rules also includes general rules for vectorizing such non-isomorphic patterns. For each arithmetic operation op , we have a rule that matches whenever an expression contains a mix of op-erations (non-isomorphic subexpressions), provided that the operation op appears more than once. The rule then vec-torizes all instances of the operation op . It also moves any non-matching sub-expression (containing operators other than op ) into the first operand vector. It then pads the second operand vector with the appropriate identity element (e.g., 1 for multiplication, 0 for addition). For example:  

> (Vec (* a b) (* c d) (- f g)) â‡’
> (VecMul (Vec a c (- f g)) (Vec b d 1))

Here, the non-isomorphic vectorization rule for multiplica-tion matches because there are two * operations. It packs the two multiplications into a single vector multiplication operation, and leaves (- f g) in the 1st operand, and pads the second operand vector with 1, the multiplicative identity. Since the RL agent is trained to predict rewriting rules that maximize the global reward, it automatically weights the cost and benefit of applying this type of vectorization and selects this class of rules only if they are beneficial. 

Simplification and Algebraic Rules: This category in-cludes standard algebraic rules that simplify expressions, reduce computational complexity, or transform expressions into a different form (that will be useful in later simplifi-cations). These rules aim to lower the circuitâ€™s depth and minimize the number of operations. Examples include: 

â€¢ Arithmetic Simplification: These rules simplify arith-metic expressions, replacing complex or multiple op-erations with simpler, equivalent ones. Examples of these rules include factorization   

> (+ (* x y) (* x z)) â‡’(* x (+ y z)) ,

identity elimination   

> (x * 1) â‡’x,

absorption rules   

> (x * 0) â‡’0,

plaintext consolidation   

> (* (pt a) (* (pt b) x)) â‡’(* (pt (a*b)) x) ,

where a and b are plaintexts. 

â€¢ Arithmetic Transformations: These rules transform arithmetic expressions in a way that enables their simplification later. Examples include commutativity, associativity, and distribution rules. 

â€¢ Circuit Balancing: These rules balance expression trees, reducing their depth (and noise accumulation). For example, a left-leaning tree of multiplications can be balanced to reduce the multiplicative depth:  

> (VecMul x (VecMul y (VecMul z t))) â‡’
> (VecMul (VecMul x y) (VecMul z t))

Rotation Rules: Data alignment is critical in FHE, and rotations are the primary mechanism for moving data within a packed ciphertext. A naive approach to vectorizing unstruc-tured code would require the RL agent to discover a long and potentially inefficient sequence of low-level rotation, masking, and arithmetic operations to correctly align data. To address this, our set includes rules that transform high-level computational patterns directly into efficient, composite dataflow structures . These rules encapsulate what would oth-erwise be multiple low-level steps into a single, high-level transformation. For example, we consider this expression: 

> (Vec ( (+ (* a b) (* c d)) (+ (* e f) (* g h)) ) )

A standard vectorization strategy, without leveraging ro-tations, would result in the following structure: 

> (VecAdd (VecMul (Vec a e ) (Vec b f) ) (VecMul ( Vec c g ) (Vec d h ) ) )

This optimized expression requires two vector multiplica-tion operations and one vector addition operation. However, a more sophisticated strategy, enabled by our rotation-based rules, can find a more efficient solution:  

> (VecAdd V (<< V 2))
> where V: (VecMul (Vec a c e g) (Vec b d f h))

The final result can then be computed by adding this vec-tor V to a rotated version of itself, which effectively sums the required pairs of products into the first two slots. This alternative strategy requires only one vector multiplication operation, one vector addition, and one rotation. Since a vec-tor rotation is cheaper than a vector multiplication in FHE, this second approach is better. By including such compos-ite transformation rules, they help the RL agent to discover these globally optimal strategies that a simpler vectorizer would miss. 

E.1 How did we design our rewriting rules? 

To construct the rules for the TRS, we began by collecting the rules from Halideâ€™s TRS [ 58 , 62 ]. Halide is an industrial compiler used for the optimization of image processing and deep learning pipelines. Halideâ€™s expression space includes operations that are not natively supported by fully homo-morphic encryption (FHE), such as comparison, division, and modulo operations. Additionally, performance consid-erations and optimization goals in Halide differ from ours, Bilel Sefsaf et al. 

as it operates on plaintext data. Therefore, we selected only the rules that are compatible with FHE. Next, we expanded this initial ruleset manually and developed new rules aimed at reducing the number of operations, rotations, depth, and multiplicative depth in FHE programs. 

## F LLM Prompt Template for CHEHAB IR Synthesis 

The full prompt template used to synthesize CHEHAB IR expressions is presented below. The template encodes (i) CHEHAB IR syntax and validity checks, (ii) explicit con-straints on vector width and expression depth, (iii) a structural-diversity requirement beyond alpha-renaming, and (iv) worked examples and rewrite-rule context to bias generation toward expressions that benefit from rewrite-based optimization. Synthesis Prompt 

[SYSTEM ROLE] You are a rigorous validator for CHEHAB IR expressions. First ANALYZE then GENERATE. Enforce structural uniqueness beyond variable renaming. [GENERATION PROTOCOL] ###### CHEHAB IR Generation Protocol ###### You will output **5 structurally unique** `(Vec ...) ` expressions for RL training. Every expression **must** honour all rules below. If any check fails, discard the draft and regenerate before replying. 1. Core Vector Form --------------------------------------------------------------- Start with `(Vec ` and contain **exactly {vec_size} sub-expressions**. Skeleton -> `(Vec expr0 expr1 ... expr_n) `.- No nested `(Vec ...) ` inside a sub-expression. - Sub-expression depth: **4 <= depth <= 20**. 2. Syntax / Operator Rules --------------------------------------------------------------- Balanced parentheses. - Operators: `+` and `*` are strictly binary; `-` may be unary or binary. - Variables match `[a-z][0-9]_*[0-9]* ` (e.g. `in_1_0 `). - **No numeric literal 0** anywhere. - No degenerate single-term parentheses such as `(x) `.3. Semantic / Structural Rules --------------------------------------------------------------- **Structural uniqueness** after canonicalising w.r.t. history/examples. - **Operation asymmetry**: avoid identical operator trees across siblings. - Expressions must not be trivially vectorisable; a sequence of rewrite rules (see Sec 7) should improve depth or multiplicative depth. 4. Mandatory Generation Checklist --------------------------------------------------------------1. Draft 5 candidate `(Vec ...) ` lines. 2. Count elements == {vec_size}. 3. Validate parentheses & operator set. 4. Compute depths & variable counts. 5. Canonicalise and check for structural duplicates. 6. Output the clean expressions--one per line, no commentary. 7. At least 3 expressions must have depth > 10. 5. Worked Example Breakdown (Real World Motifs) --------------------------------------------------------------Below are full CHEHAB IR programs illustrating real computations. *Do NOT copy or trivially rename them.* - Union-Cardinality (size 1): (Vec (+ (+ (+ ( - ( + v1_0 v2_0 ) ( * v1_0 v2_0 ) ) ... ))) - Squared Difference (size 4): (Vec ( * ( - v1_0 v2_0 ) ( - v1_0 v2_0 ) ) ... ) 6. Rewrite Rules Context --------------------------------------------------------------[The LLM is provided with the following rules to bias generation toward optimizable patterns:] Rewrite { name: "add-vectorize-2", searcher: (Vec (+ ?a0 ?b0) (+ ?a1 ?b1)), applier: (VecAdd (Vec ?a0 ?a1) (Vec ?b0 ?b1)) } Rewrite { name: "mul-vectorize-4", searcher: (Vec (* ?a0 ?b0) (* ?a1 ?b1)), ... } Rewrite { name: "comm-factor-1", searcher: (+ (* ?a ?b) (* ?a ?c)), applier: (* ?a (+ ?b ?c)) } ... [84 total rules provided] ... 7. Final Output --------------------------------------------------------------- Produce **exactly 5** valid, structurally distinct (Vec ...) expressions. - At least 3 of the generate expressions **Must have a depth > 6**. - The Generated expressions where they match vectorization rules , or rules that enables vectorization. - The Generated expressions must match real world computations and programs or similair **not fully random computations**. - One expression **per line**, raw text-no numbering, comments, or styling. - Range them from moderately simple to deeply nested. - If any candidate breaks Â§Â§1-3, discard & regenerate before responding.""" 

Prompt refinement. We refined the prompt iteratively by manually reviewing generated programs and adding con-straints to reduce invalid outputs and duplicates. Using this protocol, we generated a training dataset of 15,855 unique ex-pressions, which is available at: https://raw.githubusercontent. com/Modern-Compilers-Lab/CHEHAB/refs/heads/main/ RL/fhe_rl/datasets/final_llm_dataset.txt .

## G Training Details 

The agent was trained on the LLM-generated dataset. We used a single node with a 2.40 GHz Intel(R) Xeon(R) CPU E5-2680 v4 (14 cores) and 256 GB DDR4 of memory running Cen-tOS Linux 8 for the training. We used the Stable-Baselines3 library [61 ] to implement our RL training. To accelerate the collection of experience, we leverage parallel environments. We run multiple independent instances of the optimization environment in parallel (8 in our case), allowing the agent to collect a diverse batch of trajectories simultaneously. To implement this, we leverage multi-processing where each environment runs in its own process, and multiple episodes are collected in parallel across processes. This speeds up the training process. Each training episode corresponds to the optimization of a single expression and is limited to a maximum length of 75 steps. We found this limit to be sufficient, as the optimization sequences for the majority of expressions in our training and evaluation sets finished well before reaching 75 steps. The CHEHAB RL: Learning to Optimize Fully Homomorphic Encryption Computations 

agent was trained for a total of 2 million timesteps, and the training took 43 hours. 

Table 4. PPO Hyperparameters for Training.            

> Hyperparameter Value
> Learning Rate 1Ã—10 âˆ’4
> Discount Factor ( ğ›¾ )0.99 GAE Lambda ( ğœ† )0.95 PPO Clip Range ( ğœ– )0.2 Update Epochs 20 Steps per Update 2048 Batch Size 256 Number of Environments 8

## H More Details about the Evaluation 

H.1 Noise Measurement 

A freshly encrypted ciphertext begins with a large noise budget, and each homomorphic operation consumes a part of it. When the budget reaches zero, decryption fails. Our goal is to minimize the noise budget consumed by code. To measure the noise budget consumed in each bench-mark, we use the Decryptor::invariant_noise_budget 

function provided by the Microsoft SEAL library. In the BFV scheme, every ciphertext carries an error term (noise) that grows as homomorphic operations are performed. SEAL re-ports the remaining noise budget (in bits). In our setup, using a polynomial modulus degree of 16384, a freshly encrypted ciphertext has an initial noise budget of 369 bits. After running each benchmark, we query the remaining noise budget and measure the difference from the initial value. The difference is the consumed noise that we report (in bits). We use a 20-bit plaintext modulus and select the coefficient modulus using SEALâ€™s helper 

CoeffModulus::BFVDefault(poly_modulus_degree) 

This returns a coefficient modulus with a total size of 389 bits ( total_coeff_modulus_bits = 389 ), which is con-sistent with a theoretical maximum initial noise budget of 

389 âˆ’ 20 = 369 bits (i.e., total_coeff_modulus_bits -plain_modulus_bits ). 

H.2 Random Code Generation 

Our random code generator recursively constructs IR ex-pressions. We control this construction by two parameters: maximum depth and vector size. The generator builds ex-pressions by sampling a mixture of scalar operations, vector operations, rotations, and vector constructors. Sampling is balanced across all combinations of depth (1â€“15) and vector size (1â€“32), so the model encounters a wide range of shapes and packing patterns. Concretely, the generator works as follows: 1. It samples a target vector size ğ‘› and a depth budget ğ‘‘ .2. Starting from a root, it grows an expression tree until the tree depth budget is reached. 

Table 5. Notation.         

> Symbol Description
> âˆªdepth including all operations
> âˆªâŠ—multiplicative depth
> âŠ•# of ciphertext additions
> âŠ—# of ciphertext-ciphertext multiplications
> âŠ™# of ciphertext-plaintext multiplications
> âŠ # of ciphertext squares
> âŸ³# of rotations

3. At each node, it picks an operator from { scalar op ,

vector op , Vec constructor} that is type-compatible and respects the chosen vector size ğ‘› .4. Leaves are instantiated with variables or integer con-stants. 5. The resulting expression is parsed and type-checked into the compiler IR; invalid samples are discarded. 

H.3 Randomly Generated Unstructured Kernels 

We borrow the following description of the randomly gen-erated irregular polynomials from the original Coyote [ 52 ]paper, which proposed the benchmark. Several polynomials are randomly generated to evaluate as arbitrary arithmetic expression trees. The trees are generated according to three different regimes to cover different kinds of programs: 

â€¢ Dense, homogeneous: The expression tree is both full and complete, and all the operations are isomorphic. In principle, this represents a best case for vectorization. We refer to these as tree-100-100. 

â€¢ Dense, nonhomogeneous: The expression tree is both full and complete, each operation has a 50/50 chance of being an add or a multiply. Hence, while the trees are structurally similar, the heterogeneity of operations means that vectorization opportunities are restricted. We refer to these as tree-100-50. 

â€¢ Sparse: Many operations have one leaf node input; the tree is not very balanced. In principle, this represents a worst case for vectorization, where Coyote must work hard to find vectorizable computation. We refer to these as tree-00-50. The last number in the names of the polynomials indicates the depth of the tree. For example, tree-100-100-5 indicates a dense, homogeneous tree with a depth equal to 5. 

## I Benchmark Evaluation Results 

Table 6 presents several metrics regarding the depth and number of operations for three cases: 1) the initial (naive) implementation of the benchmarks 2) CHEHAB RLâ€™s gener-ated code for each one of the benchmarks, and 3) Coyoteâ€™s generated code. The table compares the three cases in terms of circuit depth ( âˆª), multiplicative depth ( âˆªâŠ— ), number of ciphertext-ciphertext multiplications ( âŠ—), number of rota-tions ( âŸ³), number of ciphertext-plaintext multiplications (âŠ™), and number of ciphertext additions ( âŠ•). We also report CHEHABâ€™s and Coyoteâ€™s compilation times CT (s) and their Consumed Noise budget (CN), where lower values are better. Bilel Sefsaf et al. 

Figure 10. Graph comparing Episode Mean Reward Over Training Time of the CHEHAB RL with ICI tokenization and CHEHAB RL with BPE (both trained for 2 million steps). The notation used in Table 6 is presented in Table 5. The most important columns in the table are the multiplicative depth ( âˆªâŠ— ), the number of rotations ( âŸ³), the compilation time (CT) for the two compilers, and the Consumed Noise budget (CN). We highlight them in bold. 

I.1 GRU vs. Transformer Encoder 

To validate our choice of a Transformer encoder for the state representation, we conducted an experiment to compare its encoding capabilities against a baseline recurrent architec-ture, the Gated Recurrent Unit (GRU). For this comparison, we constructed complete autoencoders for both architec-tures. The quality of the reconstruction serves as a direct measure of the quality of embedding learned by the encoder; a perfect reconstruction implies that the encoder has pre-served all necessary structural information of the program IR. Our RL agent uses only the encoder component, but this autoencoder setup allows us to empirically verify its ability to learn an embedding for the input program. 

Experimental Setup. Both autoencoders were trained on the same dataset of 1.4 million randomly generated IR expressions. We use the same methodology described in Sec. H.2 to generate this dataset. The GRU baseline used a 4-layer bidirectional encoder and a 4-layer decoder. The Transformer autoencoder also used 4 encoder and 4 decoder layers, with both models using identical optimizer settings and batch sizes. 

Results. The training curves in Fig. 11 and the final test results in Table 7 show a clear distinction in performance. The Transformer autoencoder not only learns significantly faster but also achieves 100% exact-match reconstruction accuracy on the test set. The GRU model, however, plateaus at 98.92% exact-match accuracy. 

Figure 11. Validation loss and accuracy comparison between the Transformer and GRU-based autoencoders. RNN-AE in the figure represents the GRU-based auto-encoder. 

Table 7. Autoencoder reconstruction accuracy on the vali-dation and test set.            

> Model Validation Test
> Exact (%) Token (%) Exact (%) Token (%) GRU Autoencoder 98.91 99.54 98.92 99.52 Transformer Autoenc. 100.00 100.00 100.00 100.00

Analysis of Results. The primary source of failure for the GRU was ordering errors, where it produced the correct set of tokens but in an incorrect order. A detailed analysis showed that 9.8% of the GRUâ€™s reconstructions had a non-zero edit distance from the ground truth, typically due to misplaced parentheses or swapped sibling nodes in the ex-pression tree. This confirms the hypothesis that the GRUâ€™s sequential processing and fixed-length hidden state are in-sufficient to reliably preserve the long-range structural in-formation of complex IRs. The Transformerâ€™s self-attention mechanism, in contrast, processes all tokens in parallel, al-lowing it to directly model these dependencies and achieve lossless reconstruction. These results validate our choice of the Transformer encoder for state representation. CHEHAB RL: Learning to Optimize Fully Homomorphic Encryption Computations 

Table 6. Comparison between four configurations: 1) an initial, naive, implementation of the benchmarks; 2) CHEHAB RL; 3) Coyote; 4) CHEHAB RL with data layout transformation applied after encryption. We compare them in terms of circuit depth ( âˆª) and multiplicative depth ( âˆªâŠ— ), number of ciphertext-ciphertext multiplications ( âŠ—), number of rotations ( âŸ³), number of ciphertext-plaintext multiplications ( âŠ™), and number of ciphertext additions ( âŠ•). We also report CHEHABâ€™s and Coyoteâ€™s compilation times CT (s) and their Consumed Noise (CN). The important columns in the Table are in bold. 

Kernel Initial CHEHAB RL Coyote CHEHAB RL with data layout transformed after encryption 

âˆª âˆªâŠ— âŠ— âŸ³ âŠ™ âŠ• âˆª âˆªâŠ— âŠ— âŸ³ âŠ™ âŠ• CN CT âˆª âˆªâŠ— âŠ— âŸ³ âŠ™ âŠ• CN CT âˆª âˆªâŠ— âŠ— âŸ³ âŠ™ âŠ• CT 

Box Blur 3 Ã— 3 9 0 0 0 0 31 6 0 0 1 0 6 13.0 9.57 25 0 0 18 45 24 141.0 471.991 16 1 30 13 30 35 10.568 Box Blur 4 Ã— 4 9 0 0 0 0 74 5 0 0 1 0 5 12.0 10.146 36 0 0 51 111 26 247.0 926.780 15 1 31 13 31 34 9.997 Box Blur 5 Ã— 5 9 0 0 0 0 135 4 0 0 0 0 8 10.0 10.457 36 0 0 100 204 27 250.0 1553.897 10 1 29 8 29 33 10.129 Dot Product 4 5 1 4 0 0 4 6 1 1 3 0 2 45.0 9.826 7 1 1 2 4 4 42.0 106.571 13 2 7 8 6 7 9.21 Dot Product 8 9 1 8 0 0 8 8 1 1 4 0 3 47.0 9.864 9 1 1 3 4 6 93.0 179.196 15 2 7 9 6 8 9.417 Dot Product 16 17 1 16 0 0 16 10 1 1 5 0 4 47.0 11.068 15 1 1 10 14 11 119.0 324.983 29 2 19 22 18 21 11.162 Dot Product 32 33 1 32 0 0 32 11 1 1 5 0 5 44.0 20.492 22 1 1 21 34 16 145.0 629.485 21 2 19 21 18 21 20.536 Hamm. Dist. 4 7 2 8 0 4 8 8 2 2 4 0 3 74.0 9.421 3 2 2 0 0 1 99.0 144.852 14 3 16 12 14 16 9.319 Hamm. Dist. 8 11 2 16 0 8 16 10 2 2 5 0 4 74.0 11.416 4 2 2 3 0 1 73.0 282.906 16 3 16 13 14 17 11.365 Hamm. Dist. 16 19 2 32 0 16 32 12 2 2 6 0 5 75.0 29.736 12 2 2 21 42 12 233.0 520.420 30 3 40 30 38 42 29.816 Hamm. Dist. 32 35 2 64 0 32 64 14 2 3 5 0 7 76.0 178.241 12 2 2 69 92 8 156.0 1054.597 24 3 41 21 38 43 176.251 L2 Distance 4 5 1 4 0 0 3 8 1 1 4 0 2 45.0 9.445 8 1 1 2 4 4 68.0 158.341 21 2 13 15 12 13 9.321 L2 Distance 8 9 1 8 0 0 7 9 1 1 4 0 3 45.0 10.35 11 1 2 3 9 9 122.0 276.027 16 2 13 14 12 13 10.351 L2 Distance 16 17 1 16 0 0 15 11 1 1 5 0 4 46.0 20.696 22 1 2 23 52 18 176.0 574.150 28 2 33 35 32 34 20.735 L2 Distance 32 33 1 32 0 0 31 12 1 1 5 0 5 45.0 95.935 26 1 1 73 101 17 179.0 1170.184 22 2 19 21 18 21 95.549 Linear Reg. 4 3 1 4 0 4 8 5 1 1 2 0 2 41.0 9.36 3 1 1 0 0 0 41.0 2.278 8 2 3 3 2 4 8.995 Linear Reg. 8 3 1 8 0 8 16 5 1 1 2 0 2 41.0 9.469 6 1 1 1 6 3 66.0 197.718 8 2 3 3 2 4 9.312 Linear Reg. 16 3 1 16 0 16 32 4 1 1 1 0 2 41.0 9.547 12 1 1 17 25 7 122.0 500.449 7 2 3 2 2 4 9.283 Linear Reg. 32 3 1 32 0 32 64 3 1 1 0 1 2 10.0 9.778 12 1 1 44 46 4 124.0 963.687 4 2 3 0 3 2 9.466 Poly. Reg. 4 5 2 12 0 0 12 8 2 2 3 0 3 74.0 10.139 16 2 3 4 19 10 153.0 238.869 14 3 8 8 6 9 9.955 Poly. Reg. 8 5 2 24 0 0 24 7 2 2 2 0 3 73.0 9.786 20 2 2 21 38 12 205.0 501.163 10 3 5 4 3 5 9.694 Poly. Reg. 16 5 2 48 0 0 48 6 2 2 1 0 3 73.0 9.993 20 2 2 56 79 12 208.0 961.519 9 3 7 5 5 7 10.06 Poly. Reg. 32 5 2 96 0 0 96 5 2 2 0 0 3 73.0 10.145 20 2 2 134 173 12 210.0 1896.952 6 3 7 0 5 3 9.952 Gx 3 Ã— 3 4 1 24 0 24 36 8 2 4 1 2 6 66.0 9.463 16 1 1 27 57 11 150.0 594.926 12 3 18 9 16 20 9.363 Gx 4 Ã— 4 4 1 48 0 48 64 6 1 3 1 1 4 42.0 10.743 16 1 1 59 112 11 150.0 1061.439 12 2 16 9 14 17 10.599 Gx 5 Ã— 5 4 1 80 0 80 100 5 1 3 0 2 5 40.0 10.646 16 1 1 105 182 12 154.0 1673.958 9 2 16 6 15 16 10.675 Gy 3 Ã— 3 4 1 24 0 24 33 6 1 3 1 1 3 41.0 9.68 16 1 1 29 54 10 149.0 595.976 14 2 20 11 18 20 9.737 Gy 4 Ã— 4 4 1 48 0 48 64 6 1 3 1 0 3 42.0 10.591 16 1 1 60 101 11 197.0 1057.486 14 2 23 11 20 23 10.988 Gy 5 Ã— 5 4 1 80 0 80 105 6 1 5 0 0 6 42.0 11.322 17 1 1 103 169 11 154.0 1670.887 11 2 25 6 20 26 11.197 Rob. Cross 3 Ã— 3 6 2 42.0 0.0 24.0 63.0 5 1 2 2 0 3 45.0 9.786 12 1 2 10 27 11 96.0 291.833 11 2 12 9 10 12 9.661 Rob. Cross 4 Ã— 4 6 2 76.0 0.0 44.0 112.0 5 1 2 2 0 3 44.0 10.363 12 1 2 24 51 9 125.0 543.704 11 2 12 9 10 12 10.133 Rob. Cross 5 Ã— 5 6 2 120.0 0.0 70.0 175.0 4 1 2 0 0 4 42.0 11.681 12 1 2 43 95 10 126.0 857.648 8 2 9 3 7 10 11.505 Mat. Mul. 3 Ã— 3 3 1 27 0 0 18 4 1 2 1 0 2 41.0 9.426 9 1 2 9 14 5 93.0 456.644 11 2 19 11 17 17 9.452 Mat. Mul. 4 Ã— 4 4 1 64 0 0 48 4 1 2 1 0 2 42.0 10.039 10 1 2 32 44 7 94.0 1085.128 13 2 30 16 28 26 9.952 Mat. Mul. 5 Ã— 5 5 1 125 0 0 100 4 1 5 0 0 4 42.0 11.601 14 1 1 69 82 13 145.0 2158.145 10 2 55 16 50 44 11.324 Max 3 6 2 6 0 0 6 9 2 3 3 0 4 76.0 9.481 14 2 3 3 10 9 75.0 132.890 9 2 3 3 0 4 9.481 Max 4 8 3 12 0 0 12 11 3 7 3 0 8 107.0 11.784 22 3 6 8 25 16 235.0 252.436 11 3 7 3 0 8 11.784 Max 5 10 4 20 0 0 20 15 4 12 5 0 12 140.0 149.936 29 4 9 27 55 21 321.0 509.189 15 4 12 5 0 12 149.936 Sort 3 8 3 10 0 0 8 11 3 5 3 0 6 107.0 10.552 12 3 4 5 6 9 188.0 184.944 11 3 5 3 0 6 10.552 Sort 4 14 6 58 0 0 35 21 6 26 5 0 35 206.0 522.043 42 6 10 66 114 31 369.0 959.704 21 6 26 5 0 35 522.043 Tree 50-50-5 4 2 2.0 0.0 0.0 4.0 8 2 2 3 0 3 73.0 9.271 4 2 2 0 0 4 73.0 4.306 8 2 2 3 0 3 9.271 Tree 50-50-10 10 5 16.0 0.0 0.0 16.0 15 5 15 2 0 18 172.0 18.17 27 7 7 7 19 21 243.0 147.033 15 5 15 2 0 18 18.17 Tree 100-50-5 5 3 15.0 0.0 0.0 16.0 13 5 8 3 0 13 169.0 12.428 18 3 4 7 22 14 212.0 176.904 13 5 8 3 0 13 12.428 Tree 100-50-10 10 8 519.0 0.0 0.0 504.0 16 8 509 2 0 511 334.0 148.398 50 8 148 490 873 243 369.0 6798.692 16 8 509 2 0 511 148.398 Tree 100-100-5 5 4 29.0 0.0 0.0 2.0 10 4 4 5 0 1 141.0 11.152 16 5 5 5 13 7 211.0 170.154 10 4 4 5 0 1 11.152 Tree 100-100-10 10 9 1022.0 0.0 0.0 1.0 12 9 256 2 0 1 307.0 91.627 36 10 10 334 373 16 369.0 5396.742 12 9 256 2 0 1 91.627 

## J More Detailed Related Work 

FHE Compilers for Circuit Optimization. EVA [ 26 ] is an example of such a compiler, it focuses on automatic pa-rameters selection and ciphertext maintenance to manage noise and scale of ciphertexts for the CKKS scheme, how-ever, it does not apply any optimization strategies in order to reduce the multiplicative depth or the number of opera-tions. In a later version of the same work [ 21 ], CSE (Common Subexpression Elimination) was added, which provides basic simplifications of the circuit (in CSE, redundant expressions are computed once and used multiple times). CHEHAB also applies CSE on the generated code, but in addition to that, it applies term rewriting to reduce the number of opera-tions and the multiplicative depth. Ramparts [ 5 ] uses Julia as input language and targets the BFV scheme. It provides automatic parameter selection based on noise growth estima-tion, it also simplifies circuits in order to reduce the number of operations by applying simple and classical optimization techniques such as CSE and constant folding, it also offers optimizations such as loop unrolling, and function inlining. It does insert ciphertext-maintenance operation, but in a naive way [ 73 ]. Unlike CHEHAB, Ramparts cannot optimize Bilel Sefsaf et al. 

vectorized code [73], which affects its ability to take advan-tage of SIMD parallelism and improve latency. HECATE [ 49 ]is a recent work that focuses on selecting the parameter 

ğ‘ for CKKS, and at the same time it performs ciphertext-maintenance operations scheduling by applying rewrite on the input circuit, HECATE outperforms EVA by 27 .38% , how-ever, it does not apply any optimization to reduce the number of operations and multiplicative depth of the circuit. 

RL-based methods for Code Optimization. Recent at-tempts explored the use of reinforcement learning to solve the problem of choosing the right sequence of code trans-formations. In PolyGym [ 17 ] and CompilerGym [ 25 ], the authors propose only RL environments without implement-ing RL agents to optimize code; their main contribution is to show that their action space has potentially good optimiza-tions to explore. They leave the implementation of an RL agent as future work. Other work such as HalideRL [ 59 ], AutoPhase [ 37 ] and Su-perSonic [ 40 ] propose RL agents to optimize code. HalideRL is not fully automatic. The user has to provide an initial set of code transformations. The HalideRL agent then discards transformations that are not useful and keeps only those that are useful. It then selects the best parameters for the useful transformations. In addition, HalideRL does not generalize to programs unseen during training. It is trained on a given program with multiple random data input sizes. Then, during deployment, it is used to optimize that same program. This is different from our approach. Our RL agent is designed to generalize to programs unseen during training. We train our RL agent on a large set of random LLM-generated programs. Once it learns how to optimize them, we then deploy it on new unseen programs and use it to optimize them. SuperSonic [ 40 ] is a meta-optimizer that targets the prob-lem of choosing the best RL algorithm and the best repre-sentation of states and actions, while AutoPhase [ 37 ] targets the problem of phase ordering, i.e., selecting the best order for compiler passes. While previous work addresses traditional code optimiza-tions, it does not consider the unique constraints of FHE. Our work is the first to formulate FHE optimization as an RL problem, where the agent must learn a policy that navigates the trade-offs between vectorization, cryptographic noise accumulation, and the cost of operations. 

Tokenization and Variable Renaming. Tokenization has been widely used in NLP. Classical NLP moved from word-level tokenization to learned subword units, with meth-ods such as Byte-Pair Encoding (BPE) [ 65 ]; more recently, tokenization-free methods process raw characters or bytes (e.g., CANINE [ 22 ]), which eliminates vocabulary design but lengthens sequences and shifts compute into the model. In coding tasks, BPE has been widely used as a tokenization method for models that take code as input in its textual for-mat (e.g. CodeBERT [ 33 ]). None of these methods applies variable renaming at the tokenization level, though. Variable renaming to obtain canonical representations of code was explored for classical clone detection, as in 

CCFinder [44 ]. Such variable renaming was not used as a tokenization method for deep learning models, though. Our approach differs from the previous approaches. We normalize the IR by replacing variable names and numeric constants with generic tokens, since their exact values do not affect our rewrite rules, which means that our tokenization method is more specific to our use case. This makes it faster to learn than BPE but still preserves the structural signals the model needs. 

Random Code Generation. Random code generation is a common strategy for constructing training corpora for learning-based compiler optimization. Systems such as the Tiramisu autoscheduler [ 9 ], Looper [ 55 ], and the Halide au-toscheduler [ 1 ] use stochastic code generators in which the probabilities of syntactic and semantic patterns are manu-ally specified to sample diverse code patterns. To eliminate this manual specification burden, Cummins et al. [ 24 ] learn a generative model from large-scale real-world code and then sample synthetic programs whose distribution better matches human-written code. More recently, PIE [ 66 ] and Ef-fiCoder [ 39 ] use large language models (LLMs) to synthesize code that is subsequently used to train or fine-tune down-stream models for performance-oriented code optimization. Our approach follows this latter line: we leverage an off-the-shelf, pretrained LLM, already exposed to the distribution of real-world code, to synthesize training programs, thereby avoiding task-specific generator design and hand-tuning of pattern priors. 

## K Frequently Asked Questions 

In this section, we provide a list of frequently asked ques-tions and answers to these questions. These provide more clarification about the paper. 

â€¢ Examples of end-user deployments for homo-morphic encryption End -user deployments for ho-momorphic encryption have already appeared: for ex-ample, Microsoft Edgeâ€™s Password Monitor uses homo-morphic encryption to check user credentials against breach corpora without revealing inputs [ 48 , 72 ]. Be-yond credentials checking, homomorphic encryption is being used in sensitive scientific/health settings (e.g., private genotype imputation and kinship detection in genomics), both reporting practical runtimes on real datasets [ 35 , 46 ]. The UK Information Commissionerâ€™s Office documents a cross -institution deployment in which banks and law -enforcement agencies use ho-momorphic encryption to run encrypted queries to detect financial crime [41]. CHEHAB RL: Learning to Optimize Fully Homomorphic Encryption Computations 

Figure 12. Semi-log plots comparing the execution times of the default CHEHAB and CHEHAB RL. 

Figure 13. Graph comparing Episode Mean Reward Over Timesteps of Flat vs. Hierarchical Action Spaces. 

â€¢ Why not use an LLM to directly optimize CHEHAB IR at inference time? It is an interesting direction. In this work, our goal is fast and deterministic com-pilation, which favors an RL policy evaluated locally inside the compiler. At inference time, the RL agent produces a rewrite sequence in a few seconds with stable runtime and fully reproducible behavior. In con-trast, LLM-based optimization at inference time typi-cally incurs substantially higher latency and cost, and can be less predictable due to sampling and the need for output validation/repair. For example, the Com-Pilot paper [ 56 ] reports an average of 8 minutes to optimize a single loop nest. 

## L Artifact Appendix 

L.1 Abstract 

CHEHAB is a fully homomorphic encryption (FHE) compiler that translates a domain-specific language into Microsoft SEAL (BFV) programs and applies optimization passes in-cluding a reinforcement-learning-guided rewrite selection, constant folding and common subexpression elimination. The artifact reproduces the key results of our paper (Table 6, Figure 5) by running the benchmark suite (e.g., Box Blur, Dot Product, Hamming Distance, L2 Distance, Linear/Poly-nomial Regression, Matrix Multiplication, Max, Sort, and polynomial-tree benchmarks) under the same optimization configurations used in the evaluation, and collecting compile-time and execution-time metrics as well as circuit-level prop-erties (depth, multiplicative depth, remaining noise budget, and operation counts). The workflow produces CSV result files in results/ and includes scripts to generate the cor-responding plots from these CSVs. The artifact is packaged with a ready-to-use Docker environment (Ubuntu + SEAL + Conda dependencies) for interactive use of the compiler, and an optional web interface for running individual benchmark configurations and inspecting logs and optimized expres-sions. 

L.2 Artifact check-list (meta-information) 

â€¢ Algorithm: RL-guided optimization for FHE compilation (learned rewrite selection) 

â€¢ Program: C++ compiler + benchmarks, Python benchmark driver, optional FastAPI web UI 

â€¢ Compilation: CMake, GCC/G++, Microsoft SEAL (BFV) 

â€¢ Transformations: RL-guided rewrite selection, constant folding, common subexpression elimination 

â€¢ Binary: benchmark executables in build/benchmarks/<bench> / HE runner main in generated he/ 

â€¢ Model: RL agent code under RL/fhe\_rl/ (trained models included) 

â€¢ Data set: LLM-generated dataset used for training (no ex-ternal dataset) 

â€¢ Run-time environment: Docker (Ubuntu 22.04) + Conda env chehabEnv ; optional host install per README 

â€¢ Hardware: x86_64 CPU, â‰¥32 GB RAM recommended, for our experiments we used 1 node, 32 cores, 128 GB RAM 

â€¢ Execution: pythonrun\_benchmarks.py (RL mode); op-tional dockercomposeupchehab-demo for web UI 

â€¢ Metrics: compile time, execution time, depth, multiplicative depth, remaining noise budget, operation counts 

â€¢ Output: CSV files in results/ ; optional plots (PNG) from 

results/generate_graphs.py 

â€¢ Experiments: benchmark suite runs across multiple slot counts and RL settings; per-benchmark runs via CLI or web UI 

â€¢ How much disk space required (approximately)?: 25-30 GB (Docker image + build + outputs) 

â€¢ How much time is needed to prepare workflow (ap-proximately)?: 45-60 minutes (first Docker build) 

â€¢ How much time is needed to complete experiments (approximately)?: 45-90 minutes (depends on iterations) 

â€¢ Publicly available?: Yes 

â€¢ Workflow automation framework used?: Python scripts, Docker Compose Bilel Sefsaf et al. 

L.3 Description L.3.1 How to access. The artifact is available as a pub-lic repository: https://github.com/Modern-Compilers-Lab/ CHEHAB . A Docker-based environment is provided for re-producible setup and execution. A host-native installation is also possible by following the repository README (including Microsoft SEAL and toolchain installation). 

L.3.2 Software dependencies. Recommended: Docker and Docker Compose. The Docker image includes Ubuntu 22.04, Microsoft SEAL, the required build toolchain, and a Conda environment ( chehabEnv ) with Python dependencies used by the RL optimization pipeline. 

L.4 Installation 

Build the interactive environment. From the repository root, build the interactive environment: 

$ docker compose build chehab - main 

Build the web UI service (optional). From the repository root, build the web UI service: 

$ docker compose build chehab - demo 

Host setup (optional). If you prefer running without Docker, follow the README for the complete host installa-tion procedure (including Microsoft SEAL and all required dependencies). 

L.5 Experiment workflow 

CLI workflow (recommended). Launch an interactive container shell: 

$ docker compose run -- rm -it \chehab - main / bin / bash 

The Docker image is configured to auto-activate chehabEnv 

for interactive bash shells. If it is not active, run: 

$ source / opt / conda / etc / profile .d/ conda . sh $ conda activate chehabEnv 

Run the benchmark suite: 

$ python run_benchmarks . py 

The script writes the results as CSV files in results/ , this directory is bind-mounted, so the files are mirrored to the local results/ folder on the host. 

Web workflow (optional). Start the web service: 

$ docker compose up chehab - demo 

Then open http://localhost:8000 to run individual benchmark configurations and inspect logs. 

L.6 Evaluation and expected results 

Successful execution produces CSV result files in results/ .Each row corresponds to a benchmark configuration and re-ports compile-time and execution-time measurements, along with circuit-level statistics (e.g., depth, multiplicative depth, remaining noise budget, and operation counts). Optional plots can be generated from the CSV outputs using generate_ graphs.py . a file such as results/results_RL.csv is pro-duced. To generate an execution-time plot: 

$ python results / generate_graphs . py \-- metric exec \-- csv results / results_RL . csv \-- label " CHEHAB RL " \-- output results / exec_time . png 

To plot remaining noise budget: 

$ python results / generate_graphs . py \-- metric noise \-- csv results / results_RL . csv \-- label " CHEHAB RL " \-- output results / noise_budget . png 

L.7 Experiment customization 

The benchmark sweep parameters (e.g., slot counts, num-ber of iterations, and timeouts) can be modified in run_ benchmarks.py . When using Docker Compose, run_benchmarks. py is bind-mounted into the container, so changes are mir-rored immediately and do not require rebuilding the image. The web UI exposes common parameters directly in its input form. RL-specific customization is done in RL/fhe_rl/config. py , which selects the RL model to use, for example, users can switch to the agent trained with the random dataset by changing the configured model path. This file is also bind-mounted in the Docker workflow, so edits take effect without rebuilding. 

L.8 Notes 

The Docker workflow is recommended to avoid dependency and toolchain mismatches. If running outside Docker, follow the README to install Microsoft SEAL and all dependencies. 

## References       

> [1] Andrew Adams, Karima Ma, Luke Anderson, Riyadh Baghdadi, Tzu-Mao Li, MichaÃ«l Gharbi, Benoit Steiner, Steven Johnson, Kayvon Fata-halian, FrÃ©do Durand, and Jonathan Ragan-Kelley. 2019. Learning to optimize halide with tree search and random programs. ACM Trans. Graph. 38, 4, Article 121 (July 2019), 12 pages. doi: 10.1145/3306346. 3322967
> [2] Alfred V. Aho, Monica S. Lam, Ravi Sethi, and Jeffrey D. Ullman. 2006.
> Compilers: Principles, Techniques, and Tools (2 ed.). Addison-Wesley, Boston, MA, USA. [3] Martin Albrecht, Melissa Chase, Hao Chen, Jintai Ding, Shafi Gold-wasser, Sergey Gorbunov, Shai Halevi, Jeffrey Hoffstein, Kim Laine, Kristin Lauter, Satya Lokam, Daniele Micciancio, Dustin Moody, Travis

CHEHAB RL: Learning to Optimize Fully Homomorphic Encryption Computations 

Morrison, Amit Sahai, and Vinod Vaikuntanathan. 2019. Homomor-phic Encryption Standard. Cryptology ePrint Archive, Paper 2019/939. 

https://eprint.iacr.org/2019/939 

[4] Asra Ali, Jaeho Choi, Bryant Gipson, Shruthi Gorantala, Jeremy Kun, Wouter Legiest, Lawrence Lim, Alexander Viand, Meron Zer-ihun Demissie, and Hongren Zheng. 2025. HEIR: A Universal Compiler for Homomorphic Encryption. arXiv:2508.11095 [cs.CR]. arXiv:2508.11095 [cs.CR] [5] David W. Archer, JosÃ© Manuel CalderÃ³n Trilla, Jason Dagit, Alex Mal-ozemoff, Yuriy Polyakov, Kurt Rohloff, and Gerard Ryan. 2019. RAM-PARTS: A Programmer-Friendly System for Building Homomorphic Encryption Applications. In Proceedings of the 7th ACM Workshop on Encrypted Computing & Applied Homomorphic Cryptography (London, United Kingdom) (WAHCâ€™19) . Association for Computing Machinery, New York, NY, USA, 57â€“68. doi: 10.1145/3338469.3358945 

[6] Frederik Armknecht, Colin Boyd, Christopher Carr, Kristian GjÃ¸steen, Angela JÃ¤schke, Christian A Reuter, and Martin Strand. 2015. A guide to fully homomorphic encryption. Cryptology ePrint Archive, Paper 2015/1192. https://eprint.iacr.org/2015/1192 .[7] Amir H. Ashouri, Mostafa Elhoushi, Yuzhe Hua, Xiang Wang, Muham-mad Asif Manzoor, Bryan Chan, and Yaoqing Gao. 2022. Work-in-Progress: MLGOPerf: An ML Guided Inliner to Optimize Performance. In 2022 International Conference on Compilers, Architecture, and Syn-thesis for Embedded Systems (CASES) . 3â€“4. doi: 10.1109/CASES55004. 2022.00008 

[8] Riyadh Baghdadi. 2015. Improving tiling, reducing compilation time, and extending the scope of polyhedral compilation . Ph. D. Dissertation. Paris 6. [9] Riyadh Baghdadi, Massinissa Merouani, Mohamed-Hicham Leghettas, Kamel Abdous, Taha Arbaoui, Karima Benatchba, and Saman Ama-rasinghe. 2021. A Deep Learning Based Cost Model for Automatic Code Optimization. arXiv:2104.04955 [cs.PL] https://arxiv.org/abs/ 2104.04955 

[10] Riyadh Baghdadi, Jessica Ray, Malek Ben Romdhane, Emanuele Del Sozzo, Abdurrahman Akkas, Yunming Zhang, Patricia Suriana, Shoaib Kamil, and Saman Amarasinghe. 2019. Tiramisu: a polyhedral compiler for expressing fast and portable code. In Proceedings of the 2019 IEEE/ACM International Symposium on Code Generation and Opti-mization (Washington, DC, USA) (CGO 2019) . IEEE Press, Piscataway, NJ, USA, 193â€“205. [11] Riyadh Baghdadi, Jessica Ray, Malek Ben Romdhane, Emanuele Del Sozzo, Patricia Suriana, Shoaib Kamil, and Saman P Amarasinghe. 2018. Tiramisu: A code optimization framework for high performance systems. arXiv preprint arXiv:1804.10694 (2018). [12] Uday Bondhugula, Albert Hartono, J. Ramanujam, and P. Sadayappan. 2008. A practical automatic polyhedral parallelizer and locality opti-mizer. SIGPLAN Not. 43, 6 (June 2008), 101â€“113. doi: 10.1145/1379022. 1375595 

[13] Uday Bondhugula, Albert Hartono, J. Ramanujam, and P. Sadayap-pan. 2008. A practical automatic polyhedral parallelizer and locality optimizer. In PLDI . 101â€“113. [14] Zvika Brakerski. 2012. Fully Homomorphic Encryption without Mod-ulus Switching from Classical GapSVP. In Advances in Cryptology â€“ CRYPTO 2012 , Reihaneh Safavi-Naini and Ran Canetti (Eds.). Springer Berlin Heidelberg, Berlin, Heidelberg, 868â€“886. [15] Zvika Brakerski, Craig Gentry, and Vinod Vaikuntanathan. 2012. (Lev-eled) fully homomorphic encryption without bootstrapping. In Pro-ceedings of the 3rd Innovations in Theoretical Computer Science Confer-ence (Cambridge, Massachusetts) (ITCS â€™12) . Association for Comput-ing Machinery, New York, NY, USA, 309â€“325. doi: 10.1145/2090236. 2090262 

[16] Alexander Brauckmann, AndrÃ©s Goens, and Jeronimo Castrillon. 2021. PolyGym: Polyhedral Optimizations as an Environment for Rein-forcement Learning. In Proceedings of the 30th International Con-ference on Parallel Architectures and Compilation Techniques (At-lanta, GA, USA) (PACT â€™21) . IEEE Press, Piscataway, NJ, USA, 17â€“29. doi: 10.1109/PACT52795.2021.00009 

[17] Alexander Brauckmann, AndrÃ©s Goens, and Jeronimo Castrillon. 2021. A reinforcement learning environment for polyhedral optimizations. arXiv preprint arXiv:2104.13732. [18] Tianqi Chen, Lianmin Zheng, Eddie Yan, Ziheng Jiang, Thierry Moreau, Luis Ceze, Carlos Guestrin, and Arvind Krishnamurthy. 2018. Learning to optimize tensor programs. In Advances in Neural Informa-tion Processing Systems . 3389â€“3400. [19] Yishen Chen, Charith Mendis, Michael Carbin, and Saman Amaras-inghe. 2021. VeGen: a vectorizer generator for SIMD and beyond. In 

Proceedings of the 26th ACM International Conference on Architectural Support for Programming Languages and Operating Systems (Virtual, USA) (ASPLOS â€™21) . Association for Computing Machinery, New York, NY, USA, 902â€“914. doi: 10.1145/3445814.3446692 

[20] Eduardo Chielle, Oleg Mazonka, Homer Gamil, Nektarios Georgios Tsoutsos, and Michail Maniatakos. 2018. E3: A Framework for Com-piling C++ Programs with Encrypted Operands. Cryptology ePrint Archive, Paper 2018/1013. https://eprint.iacr.org/2018/1013 

[21] Sangeeta Chowdhary, Wei Dai, Kim Laine, and Olli Saarikivi. 2021. EVA Improved: Compiler and Extension Library for CKKS. Cryptology ePrint Archive, Paper 2021/1505. doi: 10.1145/3474366.3486929 https: //eprint.iacr.org/2021/1505 .[22] Jonathan H. Clark, Dan Garrette, Iulia Turc, and John Wieting. 2022. Canine: Pre-training an Efficient Tokenization-Free Encoder for Lan-guage Representation. Transactions of the Association for Computa-tional Linguistics 10 (2022), 73â€“91. doi: 10.1162/tacl_a_00448 

[23] Meghan Cowan, Deeksha Dangwal, Armin Alaghi, Caroline Trippel, Vincent T. Lee, and Brandon Reagen. 2021. Porcupine: A Synthesizing Compiler for Vectorized Homomorphic Encryption. In Proceedings of the 42nd ACM SIGPLAN International Conference on Programming Language Design and Implementation (Virtual, Canada) (PLDI 2021) .Association for Computing Machinery, New York, NY, USA, 375â€“389. doi: 10.1145/3453483.3454050 

[24] Chris Cummins, Pavlos Petoumenos, Zheng Wang, and Hugh Leather. 2017. Synthesizing benchmarks for predictive modeling. In 2017 IEEE/ACM International Symposium on Code Generation and Optimiza-tion (CGO) . IEEE Press, Piscataway, NJ, USA, 86â€“99. doi: 10.1109/CGO. 2017.7863731 

[25] Chris Cummins, Bram Wasti, Jiadong Guo, Brandon Cui, Jason Ansel, Sahir Gomez, Somya Jain, Jia Liu, Olivier Teytaud, Benoit Steiner, Yuan-dong Tian, and Hugh Leather. 2022. CompilerGym: robust, performant compiler optimization environments for AI research. In Proceedings of the 20th IEEE/ACM International Symposium on Code Generation and Optimization (Virtual Event, Republic of Korea) (CGO â€™22) . IEEE Press, Piscataway, NJ, USA, 92â€“105. doi: 10.1109/CGO53902.2022.9741258 

[26] Roshan Dathathri, Blagovesta Kostova, Olli Saarikivi, Wei Dai, Kim Laine, and Madan Musuvathi. 2020. EVA: An Encrypted Vector Arith-metic Language and Compiler for Efficient Homomorphic Computa-tion. In Proceedings of the 41st ACM SIGPLAN Conference on Program-ming Language Design and Implementation (London, UK) (PLDI 2020) .Association for Computing Machinery, New York, NY, USA, 546â€“561. doi: 10.1145/3385412.3386023 

[27] Roshan Dathathri, Olli Saarikivi, Hao Chen, Kim Laine, Kristin Lauter, Saeed Maleki, Madanlal Musuvathi, and Todd Mytkowicz. 2019. CHET: An Optimizing Compiler for Fully-Homomorphic Neural-Network Inferencing. In Proceedings of the 40th ACM SIGPLAN Conference on Pro-gramming Language Design and Implementation (Phoenix, AZ, USA) 

(PLDI 2019) . Association for Computing Machinery, New York, NY, USA, 142â€“156. doi: 10.1145/3314221.3314628 

[28] Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2019. BERT: Pre-training of Deep Bidirectional Transformers for Lan-guage Understanding. In Proceedings of the 2019 Conference of the Bilel Sefsaf et al. 

North American Chapter of the Association for Computational Linguis-tics: Human Language Technologies, Volume 1 (Long and Short Papers) ,Jill Burstein, Christy Doran, and Thamar Solorio (Eds.). Association for Computational Linguistics, Minneapolis, Minnesota, 4171â€“4186. doi: 10.18653/v1/N19-1423 

[29] David Steven Dummit and Richard M Foote. 2004. Abstract Algebra .Vol. 3. John Wiley & Sons, Hoboken, NJ. [30] Austin Ebel, Karthik Garimella, and Brandon Reagen. 2025. Orion: A Fully Homomorphic Encryption Framework for Deep Learning. In Proceedings of the 30th ACM International Conference on Archi-tectural Support for Programming Languages and Operating Systems, Volume 2 (ASPLOS â€™25) . ACM, New York, NY, USA, Article 16, 16 pages. arXiv:arXiv:2311.03470v3 doi: 10.1145/3676641.3716008 

[31] Alexandre E. Eichenberger, Peng Wu, and Kevin Oâ€™Brien. 2004. Vector-ization for SIMD architectures with alignment constraints. SIGPLAN Not. 39, 6 (June 2004), 82â€“93. doi: 10.1145/996893.996853 

[32] Junfeng Fan and Frederik Vercauteren. 2012. Somewhat Practical Fully Homomorphic Encryption. Cryptology ePrint Archive, Paper 2012/144. https://eprint.iacr.org/2012/144 

[33] Zhangyin Feng, Daya Guo, Duyu Tang, Nan Duan, Xiaocheng Feng, Ming Gong, Linjun Shou, Bing Qin, Ting Liu, Daxin Jiang, and Ming Zhou. 2020. CodeBERT: A Pre-Trained Model for Programming and Natural Languages. In Findings of the Association for Computational Linguistics: EMNLP 2020 , Trevor Cohn, Yulan He, and Yang Liu (Eds.). Association for Computational Linguistics, Online, 1536â€“1547. doi: 10. 18653/v1/2020.findings-emnlp.139 

[34] Tobias Grosser, Armin Groslinger, and Christian Lengauer. 2012. Polly - Performing Polyhedral Optimizations on a Low-Level Intermediate Representation. Parallel Processing Letters 22, 4 (2012). http://dblp.uni-trier.de/db/journals/ppl/ppl22.html#GrosserGL12 

[35] Gamze GÃ¼rsoy, Eduardo Chielle, Charlotte M Brannon, Michail Ma-niatakos, and Mark Gerstein. 2022. Privacy-preserving genotype imputation with fully homomorphic encryption. Cell systems 13, 2 (2022), 173â€“182. [36] Ameer Haj-Ali, Nesreen K. Ahmed, Ted Willke, Yakun Sophia Shao, Krste Asanovic, and Ion Stoica. 2020. NeuroVectorizer: end-to-end vec-torization with deep reinforcement learning. In Proceedings of the 18th ACM/IEEE International Symposium on Code Generation and Optimiza-tion (San Diego, CA, USA) (CGO â€™20) . Association for Computing Ma-chinery, New York, NY, USA, 242â€“255. doi: 10.1145/3368826.3377928 

[37] Ameer Haj-Ali, Qijing Huang, John Xiang, William Moses, Ion Stoica, Krste Asanovic, and John Wawrzynek. 2020. AutoPhase: Juggling HLS Phase Orderings in Random Forests with Deep Reinforcement Learning. In Proceedings of the 3rd Conference on Machine Learning and Systems (MLSys â€™20) , Vol. 2. mlsys.org, Austin, TX, USA, 177â€“202. 

https://proceedings.mlsys.org/papers/2020/26 

[38] Yacine Hakimi, Riyadh Baghdadi, and Yacine Challal. 2023. A hybrid machine learning model for code optimization. International Journal of Parallel Programming 51, 6 (2023), 309â€“331. [39] Dong Huang, Guangtao Zeng, Jianbo Dai, Meng Luo, Han Weng, Yuhao Qing, Heming Cui, Zhijiang Guo, and Jie M. Zhang. 2025. EffiCoder: Enhancing Code Generation in Large Language Models through Efficiency-Aware Fine-tuning. arXiv:2410.10209 [cs.CL] 

https://arxiv.org/abs/2410.10209 

[40] Wang Huanting, Tang Zhanyong, Zhang Cheng, Zhao Jiaqi, Cum-mins Chris, Leather Hugh, and Wang Zheng. 2022. Automating Reinforcement Learning Architecture Design for Code Optimiza-tion. In Proceedings of the 31st ACM SIGPLAN International Confer-ence on Compiler Construction (Seoul, South Korea) (CC 2022) . As-sociation for Computing Machinery, New York, NY, USA, 129â€“143. doi: 10.1145/3497776.3517769 

[41] Information Commissionerâ€™s Office. 2023. Case study: homomorphic encryption for data sharing. https://ico.org.uk/for-organisations/uk-gdpr-guidance-and-resources/data-sharing/privacy-enhancing-technologies/case-studies/homomorphic-encryption-for-data-sharing/ Accessed: 2025-08-17. [42] F. Irigoin and R. Triolet. 1988. Supernode Partitioning. In POPLâ€™88 .San Diego, CA, 319â€“328. [43] Lei Jiang and Lei Ju. 2022. FHEBench: Benchmarking Fully Ho-momorphic Encryption Schemes. arXiv:2203.00728 [cs.CR] https: //arxiv.org/abs/2203.00728 

[44] T. Kamiya, S. Kusumoto, and K. Inoue. 2002. CCFinder: a multilin-guistic token-based code clone detection system for large scale source code. IEEE Transactions on Software Engineering 28, 7 (2002), 654â€“670. doi: 10.1109/TSE.2002.1019480 

[45] Ken Kennedy and John R. Allen. 2001. Optimizing compilers for mod-ern architectures: a dependence-based approach . Morgan Kaufmann Publishers Inc., San Francisco, CA, USA. [46] Miran Kim, Arif Ozgun Harmanci, Jean-Philippe Bossuat, Sergiu Car-pov, Jung Hee Cheon, Ilaria Chillotti, Wonhee Cho, David Froelicher, Nicolas Gama, Mariya Georgieva, Seungwan Hong, Jean-Pierre Hubaux, Duhyeong Kim, Kristin Lauter, Yiping Ma, Lucila Ohno-Machado, Heidi Sofia, Yongha Son, Yongsoo Song, Juan Troncoso-Pastoriza, and Xiaoqian Jiang. 2021. Ultrafast homomorphic encryp-tion models enable secure outsourcing of genotype imputation. Cell Systems 12, 11 (2021), 1108â€“1120.e4. doi: 10.1016/j.cels.2021.07.010 

[47] Samuel Larsen and Saman Amarasinghe. 2000. Exploiting superword level parallelism with multimedia instruction sets. In Proceedings of the ACM SIGPLAN 2000 Conference on Programming Language Design and Implementation (Vancouver, British Columbia, Canada) (PLDI â€™00) .Association for Computing Machinery, New York, NY, USA, 145â€“156. doi: 10.1145/349299.349320 

[48] Kristin Lauter, Sreekanth Kannepalli, Kim Laine, and Radames Cruz Moreno. 2021. Password Monitor: Safeguard-ing passwords in Microsoft Edge. Microsoft Research Blog. 

https://www.microsoft.com/en-us/research/blog/password-monitor-safeguarding-passwords-in-microsoft-edge/ Accessed: 2025-08-17. [49] Yongwoo Lee, Seonyeong Heo, Seonyoung Cheon, Shinnung Jeong, Changsu Kim, Eunkyung Kim, Dongyoon Lee, and Hanjun Kim. 2022. HECATE: Performance-Aware Scale Optimization for Homomorphic Encryption Compiler. In 2022 IEEE/ACM International Symposium on Code Generation and Optimization (CGO) . IEEE Press, Piscataway, NJ, USA, 193â€“204. doi: 10.1109/CGO53902.2022.9741265 

[50] Long Li, Jianxin Lai, Peng Yuan, Tianxiang Sui, Yan Liu, Qing Zhu, Xiaojing Zhang, Linjie Xiao, Wenguang Chen, and Jingling Xue. 2025. ANT-ACE: An FHE Compiler Framework for Automating Neural Net-work Inference. In Proceedings of the 23rd ACM/IEEE International Symposium on Code Generation and Optimization (CGO â€™25) (Las Ve-gas, NV, USA). Association for Computing Machinery, New York, NY, USA, 408â€“421. doi: 10.1145/3696443.3708924 

[51] Vadim Lyubashevsky, Chris Peikert, and Oded Regev. 2013. On Ideal Lattices and Learning with Errors over Rings. J. ACM 60, 6, Article 43 (2013), 35 pages. [52] Raghav Malik, Kabir Sheth, and Milind Kulkarni. 2023. Coyote: A Compiler for Vectorizing Encrypted Arithmetic Circuits. In Proceedings of the 28th ACM International Conference on Architectural Support for Programming Languages and Operating Systems, Volume 3 (Vancouver, BC, Canada) (ASPLOS 2023) . Association for Computing Machinery, New York, NY, USA, 118â€“133. doi: 10.1145/3582016.3582057 

[53] Charith Mendis and Saman Amarasinghe. 2018. goSLP: globally opti-mized superword level parallelism framework. Proc. ACM Program. Lang. 2, OOPSLA, Article 110 (Oct. 2018), 28 pages. doi: 10.1145/ 3276480 

[54] Massinissa Merouani, Khaled Afif Boudaoud, Iheb Nassim Aouadj, Nassim Tchoulak, Islem Kara Bernou, Hamza Benyamina, Fatima Benbouzid-Si Tayeb, Karima Benatchba, Hugh Leather, and Riyadh Baghdadi. 2024. LOOPer: A Learned Automatic Code Optimizer For Polyhedral Compilers. arXiv preprint arXiv:2403.11522 (2024). CHEHAB RL: Learning to Optimize Fully Homomorphic Encryption Computations 

[55] Massinissa Merouani, Khaled Afif Boudaoud, Iheb Nassim Aouadj, Nassim Tchoulak, Islem Kara Bernou, Hamza Benyamina, Fatima Benbouzid-Si Tayeb, Karima Benatchba, Hugh Leather, and Riyadh Baghdadi. 2025. LOOPer: A Learned Automatic Code Optimizer For Polyhedral Compilers. arXiv:2403.11522 [cs.PL] https://arxiv.org/abs/ 2403.11522 

[56] Massinissa Merouani, Islem Kara Bernou, and Riyadh Baghdadi. 2025. Agentic Auto-Scheduling: An Experimental Study of LLM-Guided Loop Optimization. In International Conference on Parallel Architectures and Compilation Techniques (PACT) . IEEE, Piscataway, NJ, USA, 186â€“ 200. arXiv:2511.00592 [cs.PL] doi: 10.1109/PACT65351.2025.00027 

[57] Microsoft Research. 2023. Microsoft SEAL (release 4.1). https://github. com/Microsoft/SEAL . Redmond, WA. [58] Julie L. Newcomb, Andrew Adams, Steven Johnson, Rastislav Bodik, and Shoaib Kamil. 2020. Verifying and Improving Halideâ€™s Term Rewriting System with Program Synthesis. Proc. ACM Program. Lang. 

4, OOPSLA, Article 166 (nov 2020), 28 pages. doi: 10.1145/3428234 

[59] Marcelo Pecenin, AndrÃ© Maidl, and Daniel Weingaertner. 2019. Opti-mization of Halide Image Processing Schedules with Reinforcement Learning. In Proceedings of the 20th Symposium on High Performance Computing Systems (Campo Grande). SBC, Porto Alegre, RS, Brasil, 37â€“48. doi: 10.5753/wscad.2019.8655 

[60] Phitchaya Mangpo Phothilimthana, Archibald Samuel Elliott, An Wang, Abhinav Jangda, Bastian Hagedorn, Henrik Barthels, Samuel J. Kaufman, Vinod Grover, Emina Torlak, and Rastislav Bodik. 2019. Swizzle Inventor: Data Movement Synthesis for GPU Kernels. In Pro-ceedings of the Twenty-Fourth International Conference on Architectural Support for Programming Languages and Operating Systems (Provi-dence, RI, USA) (ASPLOS â€™19) . Association for Computing Machinery, New York, NY, USA, 65â€“78. doi: 10.1145/3297858.3304059 

[61] Antonin Raffin, Ashley Hill, Adam Gleave, Anssi Kanervisto, Maximil-ian Ernestus, and Noah Dormann. 2021. Stable-Baselines3: Reliable Re-inforcement Learning Implementations. Journal of Machine Learning Research 22, 268 (2021), 1â€“8. http://jmlr.org/papers/v22/20-1364.html 

[62] Jonathan Ragan-Kelley, Andrew Adams, Dillon Sharlet, Connelly Barnes, Sylvain Paris, Marc Levoy, Saman Amarasinghe, and FrÃ©do Durand. 2017. Halide: decoupling algorithms from schedules for high-performance image processing. Commun. ACM 61, 1 (Dec. 2017), 106â€“115. doi: 10.1145/3150211 

[63] Gang Ren, Peng Wu, and David Padua. 2006. Optimizing data permu-tations for SIMD devices. SIGPLAN Not. 41, 6 (June 2006), 118â€“131. doi: 10.1145/1133255.1133996 

[64] John Schulman, Filip Wolski, Prafulla Dhariwal, Alec Radford, and Oleg Klimov. 2017. Proximal Policy Optimization Algorithms. arXiv preprint arXiv:1707.06347. https://arxiv.org/abs/1707.06347 

[65] Rico Sennrich, Barry Haddow, and Alexandra Birch. 2016. Neural Machine Translation of Rare Words with Subword Units. In Proceed-ings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers) , Katrin Erk and Noah A. Smith (Eds.). Association for Computational Linguistics, Berlin, Germany, 1715â€“1725. doi: 10.18653/v1/P16-1162 

[66] Alexander Shypula, Aman Madaan, Yimeng Zeng, Uri Alon, Ja-cob Gardner, Milad Hashemi, Graham Neubig, Parthasarathy Ran-ganathan, Osbert Bastani, and Amir Yazdanbakhsh. 2024. Learn-ing Performance-Improving Code Edits. arXiv:2302.07867 [cs.SE] 

https://arxiv.org/abs/2302.07867 

[67] William Thies, FrÃ©dÃ©ric Vivien, Jeffrey Sheldon, and Saman Amaras-inghe. 2001. A unified framework for schedule and storage optimiza-tion. In Proc. of the 2001 PLDI Conf. 

[68] Konrad Trifunovic, Dorit Nuzman, Albert Cohen, Ayal Zaks, and Ira Rosen. 2009. Polyhedral-Model Guided Loop-Nest Auto-Vectorization. In 18th International Conference on Parallel Architectures and Compi-lation Techniques . IEEE, Piscataway, NJ, USA, 327â€“337. doi: 10.1109/ PACT.2009.18 

[69] Mircea Trofin, Yundi Qian, Eugene Brevdo, Zinan Lin, Krzysztof Choro-manski, and David Li. 2021. MLGO: A Machine Learning Guided Compiler Optimizations Framework. arXiv preprint arXiv:2101.04808. 

https://arxiv.org/abs/2101.04808 

[70] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Åukasz Kaiser, and Illia Polosukhin. 2017. Attention Is All You Need. In Advances in Neural Information Processing Systems 30 (NIPS 2017) , I. Guyon, U. V. Luxburg, S. Bengio, H. Wallach, R. Fergus, S. Vishwanathan, and R. Garnett (Eds.). Curran Associates, Inc., Red Hook, NY, USA, 5998â€“6008. http://papers.nips.cc/paper/7181-attention-is-all-you-need.pdf 

[71] S. VenkataKeerthy, Siddharth Jain, Anilava Kundu, Rohit Aggarwal, Albert Cohen, and Ramakrishna Upadrasta. 2023. RL4ReAl: Reinforce-ment Learning for Register Allocation. In Proceedings of the 32nd ACM SIGPLAN International Conference on Compiler Construction (CC â€™23) .ACM, New York, NY, USA, 133â€“144. doi: 10.1145/3578360.3580273 

[72] Alexander Viand, Patrick Jattke, Miro Haller, and Anwar Hithnawi. 2022. HECO: Fully Homomorphic Encryption Compiler. In 31st USENIX Security Symposium (USENIX Security 22) . USENIX Asso-ciation, Berkeley, CA, USA, 4133â€“4150. https://www.usenix.org/ conference/usenixsecurity22/presentation/viand 

[73] Alexander Viand, Patrick Jattke, and Anwar Hithnawi. 2021. SoK: Fully Homomorphic Encryption Compilers. In 2021 IEEE Symposium on Security and Privacy (SP) . IEEE, Piscataway, NJ, USA, 1092â€“1108. doi: 10.1109/SP40001.2021.00068 

[74] Zheng Wang and Michael Oâ€™Boyle. 2018. Machine Learning in Com-piler Optimization. Proc. IEEE PP (05 2018), 1â€“23. doi: 10.1109/JPROC. 2018.2817118 

[75] Zhongcheng Zhang, Ying Liu, Yuyang Zhang, Zhenchuan Chen, Ji-acheng Zhao, Xiaobing Feng, Huimin Cui, and Jingling Xue. 2025. Qiwu: Exploiting Ciphertext-Level SIMD Parallelism in Homomorphic Encryption Programs. In Proceedings of the 2025 IEEE/ACM Interna-tional Symposium on Code Generation and Optimization (CGO) (Las Vegas, NV, USA). ACM, New York, NY, USA, 523â€“537. [76] Lianmin Zheng, Chengfan Jia, Minmin Sun, Zhao Wu, Cody Hao Yu, Ameer Haj-Ali, Yida Wang, Jun Yang, Danyang Zhuo, Koushik Sen, Joseph E. Gonzalez, and Ion Stoica. 2020. Ansor: generating high-performance tensor programs for deep learning. In Proceedings of the 14th USENIX Conference on Operating Systems Design and Implementa-tion (OSDIâ€™20) . USENIX Association, USA, Article 49, 17 pages.
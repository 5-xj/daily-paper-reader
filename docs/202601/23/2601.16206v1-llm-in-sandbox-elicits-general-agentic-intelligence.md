# LLM-in-Sandbox Elicits General Agentic Intelligence
# LLM-in-Sandbox 激发通用智能体智能

**Authors**: Daixuan Cheng, Shaohan Huang, Yuxian Gu, Huatong Song, Guoxin Chen, Li Dong, Wayne Xin Zhao, Ji-Rong Wen, Furu Wei
**Date**: 2026-01-22
**PDF**: https://arxiv.org/pdf/2601.16206v1
**Tags**: <span class="tag-label tag-blue">精读区</span> <span class="tag-label tag-pink">keyword:RL</span> <span class="tag-label tag-pink">query:大厂llm</span>
**Score**: 8.0
**Evidence**: combines LLM architectures with reinforcement learning for agentic intelligence

---

## Abstract
We introduce LLM-in-Sandbox, enabling LLMs to explore within a code sandbox (i.e., a virtual computer), to elicit general intelligence in non-code domains. We first demonstrate that strong LLMs, without additional training, exhibit generalization capabilities to leverage the code sandbox for non-code tasks. For example, LLMs spontaneously access external resources to acquire new knowledge, leverage the file system to handle long contexts, and execute scripts to satisfy formatting requirements. We further show that these agentic capabilities can be enhanced through LLM-in-Sandbox Reinforcement Learning (LLM-in-Sandbox-RL), which uses only non-agentic data to train models for sandbox exploration. Experiments demonstrate that LLM-in-Sandbox, in both training-free and post-trained settings, achieves robust generalization spanning mathematics, physics, chemistry, biomedicine, long-context understanding, and instruction following. Finally, we analyze LLM-in-Sandbox's efficiency from computational and system perspectives, and open-source it as a Python package to facilitate real-world deployment.

## 摘要
我们引入了 LLM-in-Sandbox，使大语言

---

## 论文详细总结（自动生成）

这篇论文由微软亚洲研究院、中国人民大学和清华大学的研究团队合作完成，提出了一种名为 **LLM-in-Sandbox** 的新范式。以下是对该论文的深度结构化总结：

### 1. 核心问题与整体含义（研究动机和背景）
*   **核心问题**：如何进一步释放大语言模型（LLM）的通用智能，使其超越单纯的文本生成，具备解决复杂、跨领域任务的能力？
*   **研究背景**：LLM 的演进经历了从上下文学习（ICL）到思维链（CoT），再到智能体（Agent）框架的过程。目前的智能体通常局限于特定工具或编程任务。
*   **核心动机**：作者认为“计算机”是人类发明的最通用平台。如果给 LLM 一个**代码沙盒（虚拟计算机）**，让其具备外部资源访问、文件管理和代码执行这三大“元能力”，LLM 就能像人类使用电脑一样，通过自主探索解决非编程领域的通用任务（如数学、科学、长文本处理等）。

### 2. 论文提出的方法论
#### 核心思想
将 LLM 置于一个轻量级的虚拟计算环境（Ubuntu Docker 容器）中，不预设复杂的任务特定工具，而是让模型通过基础的终端接口自主构建解决方案。

#### 关键技术细节
*   **三大元能力**：
    1.  **外部资源访问**：通过 `curl` 或 `pip install` 获取互联网信息或安装领域特定库（如化学库 RDKit）。
    2.  **文件管理**：利用文件系统处理超出上下文窗口的超长文档，进行持久化存储。
    3.  **代码执行**：编写并运行 Python/Bash 脚本进行精确计算、模拟或格式转换。
*   **LLM-in-Sandbox-RL（强化学习训练）**：
    *   **创新点**：使用**非智能体（Non-agentic）**的通用数据来训练模型的智能体能力。
    *   **训练策略**：将任务背景资料（Context）存放在沙盒的文件系统中，而非直接放入 Prompt。这迫使模型必须学会使用 `ls`、`grep`、`read` 等命令来探索环境并获取信息，从而完成任务。
    *   **奖励机制**：采用基于结果的奖励（Outcome-based Reward），通过 GRPO++ 算法进行大规模强化学习。

### 3. 实验设计
*   **数据集/场景**：涵盖了 6 个非编程领域和 1 个编程领域：
    *   **数学** (AIME25)、**物理** (UGPhysics)、**化学** (ChemBench)、**生物医学** (MedXpertQA)。
    *   **长文本理解** (AA-LCR)：处理平均 100K token 的文档。
    *   **指令遵循** (IFBench)：验证复杂约束下的执行力。
    *   **软件工程** (SWE-bench Verified)：验证编程基础能力。
*   **对比方法**：
    *   **Vanilla LLM**：直接生成答案，不使用沙盒。
    *   **LLM-RL**：仅在文本层面进行强化学习训练的基准。
*   **评估模型**：包括 Claude-Sonnet-4.5、GPT-5、DeepSeek-V3.2、Kimi-K2、MiniMax-M2 以及 Qwen3 系列（4B 到 30B）。

### 4. 资源与算力
*   **算力设备**：实验使用了单台 **NVIDIA DGX 节点**进行推理分析。
*   **训练细节**：
    *   Qwen3-4B-Instruct 训练了 150 个 Step。
    *   Qwen3-Coder-30B 训练了 50 个 Step。
    *   推理时设置了 64 的并发查询量。
*   **基础设施**：沙盒环境极其轻量，单个容器闲置仅需 50MB 内存，峰值约 200MB。在 2TB RAM 的服务器上支持 512 个并发沙盒仅占用 5% 的内存。

### 5. 实验数量与充分性
*   **实验规模**：论文在 7 个基准测试上进行了广泛实验，涵盖了从 4B 到顶级闭源模型的多种架构。
*   **消融实验**：
    *   对比了“上下文在 Prompt 中”与“上下文在沙盒中”的效果。
    *   测试了不同训练数据源（数学、编程、通用数据）对泛化能力的影响。
*   **充分性评价**：实验设计非常充分且具有前瞻性。不仅验证了性能提升，还深入分析了模型在沙盒中的行为模式（如调用外部资源的频率），并探讨了推理效率（Token 消耗和速度）。

### 6. 论文的主要结论与发现
1.  **涌现能力**：强模型（如 GPT-5, Claude 4.5）无需额外训练即可自发利用沙盒解决非编程任务，性能显著提升（如数学提升达 24.2%）。
2.  **RL 的奇效**：通过在沙盒中进行强化学习，弱模型（如 Qwen-4B）也能学会高效探索，且这种“智能体能力”能反哺回非沙盒模式，提升纯文本生成的逻辑性
# Structured Hints for Sample-Efficient Lean Theorem Proving
# 结构化提示助力样本高效的 Lean 定理证明

**Authors**: Zachary Burton
**Date**: 2026-01-22
**PDF**: https://arxiv.org/pdf/2601.16172v1
**Tags**: <span class="tag-label tag-blue">精读区</span> <span class="tag-label tag-pink">keyword:RL</span> <span class="tag-label tag-pink">query:大厂llm</span>
**Score**: 8.0
**Evidence**: evaluates DeepSeek-Prover which uses LLMs and reinforcement learning

---

## Abstract
State-of-the-art neural theorem provers like DeepSeek-Prover-V1.5 combine large language models with reinforcement learning, achieving impressive results through sophisticated training. We ask: do these highly-trained models still benefit from simple structural guidance at inference time? We evaluate a lightweight intervention -- a fixed prompt schedule over 15 common tactic skeletons -- on the miniF2F benchmark. This simple approach yields 21.7% pass@16 compared to 15.2% for standard sampling from the same model, a 43% relative improvement using the same number of samples (k=16) and same maximum generation length (1024 tokens). Our results suggest that even capable RL-trained provers underutilize structural priors available in the tactic language, and that simple inference-time guidance remains a cheap, complementary boost.

## 摘要
像 DeepSeek-Prover-V1.5 这样最先进的神经定理证明器结合了大语言模型与强化学习，通过复杂的训练取得了令人瞩目的成果。我们提出一个问题

---

## 论文详细总结（自动生成）

这篇论文《Structured Hints for Sample-Efficient Lean Theorem Proving》探讨了如何通过简单的推理时干预，提升强化学习（RL）训练后的神经定理证明器的效率。以下是对该论文的结构化总结：

### 1. 核心问题与整体含义（研究动机和背景）
*   **核心问题**：即使是经过大规模强化学习（RL）训练的最先进模型（如 DeepSeek-Prover-V1.5），在形式化证明中仍经常犯低级结构性错误（如语法错误、标识符幻觉）。作者质疑：**这些高度训练的模型是否仍能从推理时的简单结构引导中获益？**
*   **背景**：当前的神经定理证明通常依赖于大规模采样（如 $k=1024$）或复杂的树搜索，这在资源受限的环境下成本极高。论文旨在探索一种轻量级的、无需额外训练的干预手段，以提高样本效率。

### 2. 论文提出的方法论
*   **核心思想**：引入一种**结构化中间表示（IR）**，通过“固定提示调度”（Fixed Prompt Schedule）强制模型在生成证明前遵循特定的策略骨架。
*   **关键技术细节**：
    *   **结构化查询**：将查询定义为元组 $q = (x, s)$，其中 $x$ 是定理陈述，$s$ 是**策略骨架（Tactic Skeleton）**。
    *   **策略骨架**：预设了 15 种常见的 Lean 证明起始策略（如 `simp`, `intro`, `induction`, `constructor`, `linarith` 等）。
    *   **固定调度**：对于每个定理，不再进行纯随机采样，而是依次使用这 15 个骨架作为前缀引导模型生成（第 16 次尝试使用空骨架加自然语言提示）。
    *   **推理流程**：模型被“锁定”在特定的证明路径起点，从而缩小了搜索空间，减少了早期步入歧途的概率。

### 3. 实验设计
*   **数据集/场景**：使用 **miniF2F-test** 基准测试集（Lean 4 版本，共 244 个定理）。
*   **对比方法**：
    *   **Baseline**：标准采样（Unguided），直接对模型进行 $k=16$ 次采样。
    *   **Structured IR (Ours)**：使用固定调度的 16 次结构化引导采样。
*   **实验约束**：为了模拟资源受限场景，严格限制 $k=16$，最大生成长度为 1024 tokens，解码温度 0.6。

### 4. 资源与算力
*   **算力说明**：论文**未明确说明**具体的 GPU 型号、数量或总训练时长。
*   **环境配置**：使用了 HuggingFace 上的 `DeepSeek-Prover-V1.5-RL` 模型，验证环境为 Lean 4 (v4.27.0-rc1)，每个尝试的超时时间设为 60 秒。

### 5. 实验数量与充分性
*   **实验规模**：针对 244 个定理进行了对比实验，并进行了失败模式分析（Failure Mode Analysis）和配对显著性检验（McNemar Test）。
*   **充分性评价**：
    *   **优点**：通过配对分析（19 胜 vs 3 负）证明了改进的稳健性，而非随机波动。
    *   **不足**：实验仅限于一个模型（DeepSeek）和一个数据集（miniF2F），且采样次数 $k$ 较小，缺乏在更大规模采样（如 $k=1024$）下的表现对比。

### 6. 主要结论与发现
*   **性能提升**：在相同的推理预算下，结构化引导将 Pass@16 从 **15.16% 提升至 21.72%**，相对提升了 **43.2%**。
*   **结构优先级的价值**：即使是 RL 训练的模型也未能充分利用策略语言中的结构先验。
*   **失败模式一致性**：引导组和基准组的错误分布（如未解决目标、语法错误等）非常相似。这表明结构化引导的收益来自于**提高了正确路径的命中率**，而不是系统性地消除了某种特定类型的错误。

### 7. 优点
*   **轻量高效**：无需重新训练模型，仅通过推理时的 Prompt 调整即可获得显著增益。
*   **互补性强**：这种方法可以与现有的 RL 训练或搜索算法结合使用。
*   **资源友好**：在低算力预算（小 $k$ 值、短上下文）下表现优异，适合快速验证。

### 8. 不足与局限
*   **实验覆盖面有限**：未在更大的数据集（如 ProofNet 或 IMO-level 题目）上验证。
*   **截断风险**：1024 tokens 的限制可能导致一些需要长证明的题目被强制判定为失败。
*   **骨架固定**：目前的 15 个骨架是静态的，可能无法覆盖所有数学领域。
*   **缺乏消融实验**：未深入探讨 15 个骨架中哪些贡献最大，或者自然语言提示（第 16 次尝试）的具体影响。
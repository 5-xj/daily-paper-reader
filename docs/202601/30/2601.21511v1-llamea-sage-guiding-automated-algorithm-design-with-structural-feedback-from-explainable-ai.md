# LLaMEA-SAGE: Guiding Automated Algorithm Design with Structural Feedback from Explainable AI
# LLaMEA-SAGE：利用可解释人工智能的结构化反馈引导自动化算法设计

**Authors**: Niki van Stein, Anna V. Kononova, Lars Kotthoff, Thomas Bäck \\
**Date**: 2026-01-29 \\
**PDF**: https://arxiv.org/pdf/2601.21511v1 \\
**Tags**: <span class="tag-label tag-blue">精读区</span> <span class="tag-label tag-pink">keyword:EOH</span> <span class="tag-label tag-pink">keyword:EAA</span> \\
**Score**: 9.0 \\
**Evidence**: automated algorithm design using evolutionary frameworks and structural feedback \\

---

## Abstract
Large language models have enabled automated algorithm design (AAD) by generating optimization algorithms directly from natural-language prompts. While evolutionary frameworks such as LLaMEA demonstrate strong exploratory capabilities across the algorithm design space, their search dynamics are entirely driven by fitness feedback, leaving substantial information about the generated code unused. We propose a mechanism for guiding AAD using feedback constructed from graph-theoretic and complexity features extracted from the abstract syntax trees of the generated algorithms, based on a surrogate model learned over an archive of evaluated solutions. Using explainable AI techniques, we identify features that substantially affect performance and translate them into natural-language mutation instructions that steer subsequent LLM-based code generation without restricting expressivity.   We propose LLaMEA-SAGE, which integrates this feature-driven guidance into LLaMEA, and evaluate it across several benchmarks. We show that the proposed structured guidance achieves the same performance faster than vanilla LLaMEA in a small controlled experiment. In a larger-scale experiment using the MA-BBOB suite from the GECCO-MA-BBOB competition, our guided approach achieves superior performance compared to state-of-the-art AAD methods. These results demonstrate that signals derived from code can effectively bias LLM-driven algorithm evolution, bridging the gap between code structure and human-understandable performance feedback in automated algorithm design.

## 摘要
大语言模型通过直接从自然

---

## 论文详细总结（自动生成）

这篇论文提出了 **LLaMEA-SAGE**，这是一种利用可解释人工智能（XAI）提取代码结构化特征，并以此引导大语言模型（LLM）进行自动化算法设计（AAD）的新框架。

以下是对该论文的深度结构化总结：

### 1. 核心问题与整体含义（研究动机）
*   **核心问题**：目前的 LLM 驱动的自动化算法设计（如 LLaMEA, EoH）主要依赖“适应度反馈”（即算法运行的分数），而忽略了生成的**代码本身所蕴含的结构化信息**。
*   **研究动机**：
    *   现有的搜索策略在巨大的代码空间中往往效率低下，容易陷入局部最优。
    *   缺乏对“什么样的代码结构会导致高性能”的系统性理解。
    *   作者希望通过分析代码的抽象语法树（AST）和复杂度特征，将这些“结构化信号”转化为自然语言指令，从而更精准地引导 LLM 进行算法演化。

### 2. 方法论：LLaMEA-SAGE 核心思想
LLaMEA-SAGE 在传统的进化算法循环中引入了一个基于特征的反馈闭环：
1.  **代码特征提取**：将生成的 Python 代码解析为**抽象语法树（AST）**，提取图论特征（如节点数、边数、度分布、树深度、聚类系数等）和复杂度指标（如圈复杂度、参数数量、Token 总数）。
2.  **代理模型构建**：维护一个已评估算法的存档（Archive），利用 **XGBoost** 训练一个回归模型，学习代码特征与性能（AOCC 分数）之间的非线性映射关系。
3.  **可解释性分析（SHAP）**：利用 **SHAP 值** 分析代理模型，识别出对性能影响最大的代码特征。
4.  **结构化反馈生成**：将 SHAP 的分析结果转化为自然语言指令（例如：“根据分析，尝试增加代码的圈复杂度”），并将其加入到 LLM 的变异提示词（Mutation Prompt）中。
5.  **引导式变异**：LLM 根据性能反馈和结构化建议生成新的算法候选者，从而实现“结构感知”的进化。

### 3. 实验设计
*   **数据集/场景**：
    *   **实验 1 (受控实验)**：SBOX-COST 基准测试（包含 5 个可分离函数），用于验证特征引导的有效性。
    *   **实验 2 (大规模对比)**：MA-BBOB（多仿射黑盒优化基准），这是 GECCO 竞赛的官方测试集，包含大量复杂的仿射组合函数。
*   **Benchmark 与对比方法**：
    *   **Vanilla LLaMEA**：不带结构化反馈的基准版本。
    *   **MCTS-AHD**：基于蒙特卡洛树搜索的状态最先进（SOTA）方法。
    *   **LHNS**：基于大邻域搜索的 SOTA 方法。
    *   **NeighborhoodAdaptiveDE**：2025 年 MA-BBOB 竞赛的冠军算法（手动设计/调优）。

### 4. 资源与算力
*   **LLM 后端**：主要使用了 **GPT-5-mini**（注：文中提及，可能为该研究设定下的特定模型版本或代号）和 **Gemini-2.0-flash-lite**（用于消融实验）。
*   **算力细节**：文中**未明确说明**具体的 GPU 型号或训练时长，但详细记录了 **Token 消耗量**。MCTS-AHD 的 Token 成本最高（是 LLaMEA 的两倍以上），而 LLaMEA-SAGE 在增加少量计算开销的情况下，Token 成本与原版 LLaMEA 接近。
*   **评估预算**：每个 AAD 运行包含 200 次算法评估，每个生成的算法在测试集上有固定的运行时间限制（1 小时）。

### 5. 实验数量与充分性
*   **实验规模**：
    *   针对每个方法进行了 **5 次独立运行**（不同随机种子）。
    *   在 $d=10$ 维度上进行训练，并在 $d=5, 10, 20$ 维度上进行泛化性验证。
    *   包含针对不同 LLM 后端的消融实验。
*   **充分性评价**：实验设计较为严谨，包含了 SOTA 对比和跨维度验证。但由于 LLM API 调用成本极高，**5 次运行的样本量相对较小**，导致部分统计显著性测试（如 Wilcoxon 秩和检验）的 p 值不够理想，尽管平均性能提升明显。

### 6. 主要结论与发现
*   **加速收敛**：LLaMEA-SAGE 在进化初期能更快地找到高性能算法，相比原版 LLaMEA 具有显著的加速比。
*   **性能优越**：在 MA-BBOB 竞赛套件上，LLaMEA-SAGE 显著优于 MCTS-AHD 和 LHNS。
*   **泛化能力**：生成的算法在未见过的维度（$d=5, 20$）上表现稳健，甚至在某些维度上击败了专门调优的竞赛冠军算法。
*   **LLM 遵循性**：分析发现，当提示词要求“改进（Refine）”现有算法时，LLM 能很好地遵循结构化反馈；但当要求“生成全新算法”时，LLM 倾向于忽略反馈。

### 7. 优点与亮点
*   **白盒化引导**：将原本黑盒的 LLM 搜索过程变得更具解释性，利用 X
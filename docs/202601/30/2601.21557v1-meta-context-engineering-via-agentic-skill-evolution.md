# Meta Context Engineering via Agentic Skill Evolution
# 通过智能体技能演化的元上下文工程

**Authors**: Haoran Ye, Xuning He, Vincent Arak, Haonan Dong, Guojie Song \\
**Date**: 2026-01-29 \\
**PDF**: https://arxiv.org/pdf/2601.21557v1 \\
**Tags**: <span class="tag-label tag-blue">精读区</span> <span class="tag-label tag-pink">keyword:EOH</span> <span class="tag-label tag-pink">keyword:EAA</span> \\
**Score**: 9.0 \\
**Evidence**: Co-evolving skills via agentic crossover is a direct application of Evolution of Heuristics \\

---

## Abstract
The operational efficacy of large language models relies heavily on their inference-time context. This has established Context Engineering (CE) as a formal discipline for optimizing these inputs. Current CE methods rely on manually crafted harnesses, such as rigid generation-reflection workflows and predefined context schemas. They impose structural biases and restrict context optimization to a narrow, intuition-bound design space. To address this, we introduce Meta Context Engineering (MCE), a bi-level framework that supersedes static CE heuristics by co-evolving CE skills and context artifacts. In MCE iterations, a meta-level agent refines engineering skills via agentic crossover, a deliberative search over the history of skills, their executions, and evaluations. A base-level agent executes these skills, learns from training rollouts, and optimizes context as flexible files and code. We evaluate MCE across five disparate domains under offline and online settings. MCE demonstrates consistent performance gains, achieving 5.6--53.8% relative improvement over state-of-the-art agentic CE methods (mean of 16.9%), while maintaining superior context adaptability, transferability, and efficiency in both context usage and training.

## 摘要
大语言模型的运行效能高度依赖于其推理时上下文。这使得上下文工程（Context Engineering, CE）成为优化这些输入的一门正式学科。目前的 CE 方法依赖于人工构建的框架，例如僵化的生成-反思工作流和预定义的上下文模式。这些方法引入了结构性偏差，并将上下文优化限制在狭

---

## 论文详细总结（自动生成）

这是一份关于论文《Meta Context Engineering via Agentic Skill Evolution》的结构化深入总结：

### 1. 核心问题与整体含义（研究动机和背景）
*   **核心问题**：大型语言模型（LLM）的性能高度依赖于推理时的上下文质量。现有的“上下文工程”（Context Engineering, CE）方法（如 ACE, GEPA 等）主要依赖人工设计的固定框架（Harness），例如预定义的“生成-反思-更新”工作流或固定的上下文结构（如简单的列表或图）。
*   **研究动机**：人工设计的框架存在结构性偏差，限制了优化空间，难以发现超越人类直觉的最优策略。
*   **整体含义**：论文提出了**元上下文工程（Meta Context Engineering, MCE）**，将 CE 视为一个双层优化问题，通过智能体自主演化“工程技能”和“上下文人工制品”，实现了从“手动设计工作流”到“自动演化学习算法”的范式转变。

### 2. 方法论：核心思想与关键技术
MCE 采用**双层优化框架（Bi-level Optimization）**，核心思想是解耦“如何学习上下文（技能）”与“学习到了什么（上下文）”：
*   **元层（Meta-level）：智能体技能演化**
    *   **核心技术**：**智能体交叉（Agentic Crossover）**。元智能体（Meta-agent）通过分析历史技能、执行轨迹和评估指标，自主推理并合成更优的技能。
    *   **技能定义**：技能（Skill）被定义为包含自然语言指令、可执行脚本（Python）、上下文模板和验证协议的文件夹。
*   **基础层（Base-level）：全智能体上下文优化**
    *   **核心技术**：基础智能体（Base-agent）执行元层生成的技能，通过对训练数据的运行（Rollouts）进行学习。
    *   **上下文表示**：上下文不再是静态文本，而是由文件和代码构成的**程序化人工制品**。智能体可以利用代码工具（如检索、过滤逻辑）动态构建推理时的上下文。
*   **算法流程**：采用 (1+1)-演化策略（ES）。每一轮迭代中，元智能体生成新技能，基础智能体执行并产生新上下文，根据验证集表现保留最优解。

### 3. 实验设计
*   **数据集/场景**：覆盖五个迥异的领域：
    1.  **金融 (FiNER)**：财务报表实体标注。
    2.  **化学 (USPTO-50k)**：逆合成反应预测。
    3.  **医学 (Symptom2Disease)**：疾病诊断预测。
    4.  **法律 (LawBench)**：中国法律罪名预测。
    5.  **AI 安全 (AEGIS2)**：安全护栏分类。
*   **对比方法（Baselines）**：
    *   基础模型（Zero-shot）、ICL（少样本学习）。
    *   SOTA 优化方法：MIPROv2、GEPA、Dynamic Cheatsheet (DC)、ACE。
*   **实验设置**：分为**离线（Offline）**训练和**在线（Online）**连续学习两种模式。

### 4. 资源与算力
*   **模型使用**：主要使用 DeepSeek-V3.1 作为生成器和反思器，MiniMax M2.1 作为智能体模型（Agentic Model），Qwen3-8B 用于安全任务。
*   **算力消耗**：论文未明确提及具体的 GPU 型号和数量，因为实验主要通过 API 调用完成。
*   **训练效率**：在 FiNER 任务上，MCE 的训练时长为 **1.9 小时**，而对比方法 ACE 需要 **25.8 小时**（提速 **13.6 倍**）。

### 5. 实验数量与充分性
*   **实验规模**：在 5 个领域、4 种不同规模的 LLM 上进行了全面测试。
*   **消融实验**：对比了“无技能引导”、“固定技能”与“演化技能”的效果，验证了双层设计的必要性。
*   **公平性**：所有方法使用相同的初始上下文/提示词模板，且 MCE 的训练预算（Rollouts 数量）通常低于对比方法。
*   **鲁棒性测试**：进行了“强模型到弱模型”的上下文迁移实验，以及更换不同智能体模型的对比实验，证明了结论的客观性。

### 6. 主要结论与发现
*   **性能卓越**：MCE 在所有基准测试中均排名第一，较 SOTA 方法平均提升 **16.9%**（最高提升 53.8%）。
*   **自适应性强**：MCE 能根据任务自动调整上下文长度（从 1.5K 到 86K token），克服了以往方法过短（信息不足）或过长（上下文膨胀）的偏差。
*   **迁移性好**：由强模型（DeepSeek-V3.1）训练的上下文迁移到弱模型（G
Title: Task-free Adaptive Meta Black-box Optimization

URL Source: https://arxiv.org/pdf/2601.21475v1

Published Time: Fri, 30 Jan 2026 01:44:48 GMT

Number of Pages: 31

Markdown Content:
Published as a conference paper at ICLR 2026 

# TASK -FREE ADAPTIVE META BLACK -BOX OPTIMIZA -

## TION 

Chao Wang 1, Licheng Jiao 1, Lingling Li 1,∗, Jiaxuan Zhao 2, Guanchun Wang 1, Fang Liu 1

Shuyuan Yang 11Xidian University 2Tianjin Research Institute for Water Transport Engineering, M.O.T. 

xiaofengxd@126.com, lchjiao@mail.xidian.edu.cn, 

{llli,wangguanchun,syyang }@xidian.edu.cn, jiaxuanzhao@stu.xidian.edu.cn, f63liu@163.com 

ABSTRACT 

Handcrafted optimizers become prohibitively inefficient for complex black-box optimization (BBO) tasks. MetaBBO addresses this challenge by meta-learning to automatically configure optimizers for low-level BBO tasks, thereby eliminat-ing heuristic dependencies. However, existing methods typically require exten-sive handcrafted training tasks to learn meta-strategies that generalize to target tasks, which poses a critical limitation for realistic applications with unknown task distributions. To overcome the issue, we propose the Adaptive meta Black-box Optimization Model (ABOM), which performs online parameter adaptation using solely optimization data from the target task, obviating the need for prede-fined task distributions. Unlike conventional metaBBO frameworks that decouple meta-training and optimization phases, ABOM introduces a closed-loop adaptive parameter learning mechanism, where parameterized evolutionary operators con-tinuously self-update by leveraging generated populations during optimization. This paradigm shift enables zero-shot optimization: ABOM achieves competitive performance on synthetic BBO benchmarks and realistic unmanned aerial vehi-cle path planning problems without any handcrafted training tasks. Visualization studies reveal that parameterized evolutionary operators exhibit statistically sig-nificant search patterns, including natural selection and genetic recombination. 

1 INTRODUCTION 

Black-box optimization (BBO) problems arise in diverse machine learning applications such as neu-roevolution Stanley et al. (2019); Miikkulainen (2025), hyperparameter tuning Bai & Cheng (2024), neural architecture search Wang et al. (2023); Salmani Pour Avval et al. (2025), and prompt engi-neering Romera-Paredes et al. (2024); Wang et al. (2025a). In these scenarios, the objective function is accessible solely through expensive evaluations f (x), with derivative information like gradients or Hessians inherently unavailable. Evolutionary algorithms (EAs) Eiben & Smith (2015); De Jong (2017) address this challenge by iteratively updating populations through derivative-free heuristic operators, including selection, crossover, and mutation, to explore complex fitness landscapes. Re-cent advances in computational infrastructure have enabled EAs to generate robust solutions for increasingly complex BBO problems Miikkulainen & Forrest (2021). The ”No Free Lunch” (NFL) theorem Wolpert & Macready (2002) establishes that no optimization algorithm universally outperforms others across all problem domains. To enhance cross-domain ap-plicability, numerous adaptive mechanisms have been designed B¨ ack & Schwefel (1993); Brest et al. (2021); Li et al. (2013); Hansen (2016); Tao et al. (2021) that leverage optimization data generated during the search process to dynamically select operators or adjust parameters. Although these adap-tive methods achieve strong performance on standard benchmarks, they require specialized expertise in optimization theory and problem characteristics Ma et al. (2024). Meta Black-Box Optimization (MetaBBO) addresses this limitation by automating meta-level strategies Ma et al. (2025b), such as algorithm selection Tian et al. (2020); Guo et al. (2024), algorithm configuration Lange et al. (2023b;a); Guo et al. (2025), solution manipulation Li et al. (2024; 2025), and generative design Chen et al. (2024); Yang et al. (2024), through meta-learning (Fig. 1, Left). Yet existing MetaBBO 1

> arXiv:2601.21475v1 [cs.NE] 29 Jan 2026

Published as a conference paper at ICLR 2026 methods require training on handcrafted task distributions F or prior knowledge for generalization to new domains. Since such distributions are often inaccessible in practical scenarios (e.g., when the target task is unique or data-scarce), this dependency severely limits real-world deployment. Selection/    

> Configur ation/
> Manipulation/
> Gener ation
> Meta-Lear ning
> Machine
> Lear ning
> Task Distr ibution
> Sample
> Machine
> Lear ning
> Evolutionar y
> Algor ithm
> Model
> Adaptive Par ameter Lear ning
> Meta Black-Box Optimization Our Fr amewor k
> Solve
> Optimization
> Task
> Evolutionar y
> Algor ithm
> Population
> Fitness
> Optimization
> Data
> Gener ate
> Solve
> Optimization
> Task

Figure 1: Conceptual comparison: (Left) MetaBBO methods learn meta-strategies from task distri-butions but depend on handcrafted training tasks; (Right) Our framework performs adaptive param-eter learning using self-generated optimization data, eliminating task distribution dependency. To address this limitation, we propose the Adaptive meta Black-box Optimization Model (ABOM), a task-free meta-optimizer that adaptively learns parameters using only self-generated data (Fig. 1, Right). ABOM’s distinguishing feature is an end-to-end differentiable framework that parameter-izes evolutionary operators as learnable functions (Fig. 2). Inspired by EA dynamics, it employs attention mechanisms to separately model relationships among individuals, fitness landscapes, and genetic components, thereby replicating selection, crossover, and mutation as differentiable oper-ations. Crucially, ABOM updates its parameters during optimization by aligning the generated offspring population with an elite archive of high-quality solutions, bypassing the need for meta-training on task distributions. This design yields two key contributions: • Task-free adaptation : The parameters of ABOM are updated via adaptive learning using optimization data from the target task, eliminating the reliance on handcrafted training tasks or heuristic rules. Theoretically, ABOM guarantees convergence to the global optimum. • Intrinsic interpretability : Attention matrices provide quantifiable insights into search pat-terns, such as selection bias toward high-fitness individuals and consistent genetic interac-tion patterns during mutation. Moreover, ABOM supports GPU acceleration out of the box, without requiring changes to standard EA infrastructure. 

2 RELATED WORKS 

Evolutionary Algorithms . EAs, such as genetic algorithms (GA) Holland (1962), evolution strate-gies (ES)Rechenberg (1984), particle swarm optimization (PSO) Kennedy & Eberhart (1995), and differential evolution (DE) Storn & Price (1997), are widely adopted for BBO tasks due to their derivative-free nature. These methods manipulate populations via heuristic operators but often suf-fer from inefficiency and fragility when applied to new tasks, as they require labor-intensive manual parameter tuning. While ABOM draws inspiration from EA dynamics, it eliminates manual tuning by enabling adaptive parameter learning directly from optimization data. 

Adaptive Optimization . To improve cross-domain generalization, adaptive EA variants employ dynamic operator selection or parameter adjustment such as CMAES Hansen (2016); Ollivier et al. (2017), SAHLPSO Tao et al. (2021), JDE21 Brest et al. (2021)). These methods achieve state-of-the-art results on standard BBO benchmarks but demand deep expertise in optimization theory and often require problem-specific GPU acceleration for scalability. In contrast, ABOM adheres to a unified deep learning architecture, replacing heuristic rules with adaptive parameter learning and reducing deployment barriers. 

Meta Black-Box Optimization . MetaBBO techniques leverage meta-learning to automate meta-level strategies for solving lower-level BBO tasks Ma et al. (2025b); Wang et al. (2025b); Yun et al. (2025), thereby reducing the need for expert intervention. Common paradigms include algorithm selection Tian et al. (2020); Guo et al. (2024), which chooses from a predefined pool of operators; algorithm configuration Lange et al. (2023b;a); Guo et al. (2025), which tunes hyperparameters via 2Published as a conference paper at ICLR 2026 meta-strategies; solution manipulation Li et al. (2024; 2025), which integrates meta-strategies di-rectly into the optimization process; and algorithm generation Chen et al. (2024); Yang et al. (2024), which synthesizes entire optimization workflows. Despite their promise, these methods critically depend on manually designed components, such as discrete algorithm search spaces A, state fea-ture spaces, meta-objectives, and training task distributions F. The dependency on handcrafted F

hinders real-world applicability when task distributions are unavailable. ABOM addresses this limi-tation by unifying evolutionary operators into a continuous, differentiable parameter space, enabling adaptive parameter learning without requiring F or discrete algorithm search spaces. 

3 ADAPTIVE META BLACK -B OX OPTIMIZATION MODEL 

3.1 PROBLEM DEFINITION 

A target BBO task is defined as: 

min 

> x∈Rd

fT (x), (1) where x is the solution vector in a d-dimensional search space. MetaBBO methods formalize the automated design of optimizers as a triplet T := ( A, R, F), with the discrete algorithm search space 

A , the performance metric R, and the training task distribution F. The meta-optimization objective maximizes expected performance Ma et al. (2025b): 

J(θ) = max  

> θ∈Θ

Ef ∼F 

R A, π θ , f  , (2) where the meta-strategy πθ selects the algorithm (or configuration) a ∈ A for each task f . The Eq. (2) needs to be designed manually F. To mitigate the need for F, we define adaptive MetaBBO as Tadaptive := ( A, R, f T ), operating directly on the target task fT . Using cumula-tive optimization knowledge M(t) = ( X (t), Y(t)), where X (t) = {x(1) , . . . , x(t)} (solutions) and 

Y(t) = {f (x(1) ), . . . , f (x(t))} (evaluations) during optimization, the Eq. (2) becomes the follow-ing: 

J(θ) = max 

> θ∈Θ

h

R A, π θ , M(t)i

, (3) with θ updated online using M(t). However, A and πθ still require expert-crafted components. To address this limitation, ABOM replaces the discrete meta-optimization framework (A, π θ ) with a single, differentiable optimizer πθ parameterized by θ. The final objective is: 

J(θ) = max 

> θ∈Θ

h

R πθ , M(t)i

, (4) where θ is updated only using M(t) from fT , thereby eliminating the need for manual design of 

F, discrete search spaces A, and expert-dependent feature engineering. The Eq. (4) establishes an end-to-end differentiable framework where adaptive parameter learning occurs through continuous feedback from M(t).3.2 META -S TRATEGY ARCHITECTURE 

ABOM implements a differentiable meta-strategy ˆP(t) = πθ (P(t), F(t)) (Fig. 2, Bottom) that learns evolutionary operators via attention mechanisms Vaswani et al. (2017). At generation t,the population P(t) =

h

p(t)⊤ 

> 1

; . . . ; p(t)⊤

> N

i

∈ RN ×d represents N candidate solutions in the search space, where the individual p(t) 

> i

∈ Rd is a solution vector. The fitness values F(t) =h

fT (p(t)1 ); ... ; fT (p(t) 

> N

)

i

∈ RN are scalar evaluations fT (p(t) 

> i

) obtained via black-box queries to the target objective fT (·), with lower values indicating better solutions. Given the population-fitness pair, ABOM generates offspring through three unified modules: 

Selection. The selection matrix A(t) ∈ RN ×N is computed to jointly model relationships in the solution space and among fitness values via attention: 

A(t) = softmax 

 (P(t)WQP )( P(t)WKP )⊤ + ( F(t)WQF )( F(t)WKF )⊤

√dA



, (5) 3Published as a conference paper at ICLR 2026 MatMul&Scale            

> Softmax
> MatMul&Scale
> Add
> Crossover Selection
> Fiteness Population
> Population
> Selection
> Matrix
> Linear Linear Linear Linear
> Linear Linear
> Softmax
> MatMul
> MatMul&Scale
> MLP& Dropout
> Individual 1
> Offspring Population
> Mutation
> MatMul
> MLP&Dropout
> Population
> Linear Linear
> Softmax
> MatMul
> MatMul&Scale
> MLP&Dropout
> Individual N
> Concat
> Solution relations
> and fitness relations
> Mutation
> Matrix
> Mutation
> Matrix
> Gene
> relations
> Add Add
> Tar get
> Optimization
> Task
> No
> Yes
> Evaluation
> Best Individual
> Stop?
> Elite
> Individual s
> 0,0
> Meta-Str ategy Ar chitectur e
> 0.3,0.1
> 0.4,0.2
> ⋮
> 0.1,0.5
> 15.10
> 20.17
> ⋮
> 27.20
> Poputation Fitness Initialization Example:
> 2D Rastrigin
> Offspring 1 Offspring N
> Parameter
> Adaptation Reproduction
> Add

Figure 2: Workflow of ABOM: (Top) Adaptive optimization loop: Initialization, reproduction, eval-uation, elitism, and parameter adaptation; (Bottom) Meta-strategies for reproduction: Attention-based evolutionary operators, including selection, crossover, and mutation. where WQP , WKP ∈ Rd×dA project solution features, and WQF , WKF ∈ R1×dA process fitness values. The first term captures spatial relationships in the solution space, while the second term en-codes fitness-driven selection pressure. This dual-path design ensures that recombination prioritizes solutions based on both their search-space positioning and fitness ranking, rather than fitness alone. 

Crossover. The intermediate population P′(t) is generated by: 

P′(t) = P(t) + MLP θc



A(t)P(t)

, (6) where MLP θc (z) = W2 tanh( W1z + b1) + b2 with W1 ∈ Rd×dM , b1 ∈ RdM , W2 ∈ RdM ×d,

b2 ∈ Rd. Dropout with rate pC is applied to the hidden layer during both adaptive parameter learn-ing and inference. The mechanism ensures persistent exploration through controlled randomness and is consistently maintained across all stochastic operations in ABOM. The term A(t)P(t) com-putes an adaptive recombination pool: each row PNj=1 A(t)

i,j p(t)

j represents a context-aware blend of parent solutions, where weights A(t)

i,j dynamically balance proximity in solution space and fitness-driven selection pressure. 

Mutation. For each individual p′(t)

i ∈ Rd in P′(t), offspring ˆp(t)

i is generated via: 

ˆp(t)

i = p′(t)

i + MLP θm



M(t)

i p′(t)

i



, M(t)

i = softmax (p′(t)

i WQM )( p′(t)

i WKM )⊤

√dA

!

, (7) where WQM , WKM ∈ R1×dA , and MLP θm (z) = W4 tanh( W3z + b3) + b4 with W3 ∈ Rd×dM ,

b3 ∈ RdM , W4 ∈ RdM ×d, b4 ∈ Rd. Following the same exploration principle as crossover, dropout with rate pM is applied during inference to maintain persistent exploration. The mutation matrix M(t) ∈ Rd×d dynamically models gene-wise dependencies: each entry M(t)

j,k quantifies the interaction strength between the j-th and k-th dimensions, enabling context-aware perturbations. Finally, offspring are concatenated as: 

ˆP(t) =

h

ˆp(t)⊤

1 ; . . . ; ˆ p(t)⊤

N

i

∈ RN ×d. (8) The set θ containing all parameters is: 

θ = WQP , WKP , WQF , WKF , WQM , WKM ∪ θc ∪ θm, (9) with θc = {W1, b1, W2, b2}, θm = {W3, b3, W4, b4}. Note that pC and pM are hyperparam-eters that govern the intensity of exploration. All modules share attention dimension dA and MLP 4Published as a conference paper at ICLR 2026 hidden dimension dM . The parameterization transforms evolutionary operators into stochastic yet differentiable functions, where structured randomness maintains exploration without compromising gradient-based adaptation. 3.3 ADAPTIVE PARAMETER LEARNING 

As shown in Fig. 2 (Top), ABOM’s optimization loop comprises: 1) Initialization : The initial population P(0) is randomly generated by Latin hypercube sampling; 2) Reproduction : Offspring 

ˆP(t) are generated via ˆP(t) = πθ (P(t), F(t)); 3) Evaluation : Fitness values ˆF(t) are computed for 

ˆP(t); 4) Elitism Deb et al. (2002): The elite archive E(t) ∈ RN ×d, formed by the top N individuals from P(t) ∪ ˆP(t), and their fitness values F(t) 

> E

∈ RN , are carried over to the next generation; 5) 

Parameter adaptation : θ is updated via adaptive parameter learning. The pseudocode of ABOM can be found in the Appendix C (Alg. 1). Crucially, ABOM performs adaptive parameter learning by minimizing the distance between offspring and the elite archive: 

min  

> θ

L(t) = ∥ ˆP(t) − E(t)∥2, (10) where, E(t) denotes the elite archive. The objective refines evolutionary operators using task-specific knowledge from M(t). From a learning perspective, adaptive parameter learning operates in a supervised paradigm. Gradients of L with respect to θ are computed, and θ ← θ − η∇θ L(t) is updated via a gradient-based optimizer (e.g., AdamW Loshchilov & Hutter (2019)). The process ensures continuous adaptation to the target task without handcrafted training tasks. 

Discussion. ABOM introduces three algorithmic properties that enhance its suitability for BBO: (1) 

Learnable operators : evolutionary mechanisms are parameterized and adapted online via gradient-based learning, reducing reliance on hand-designed heuristics; (2) GPU-parallelizable design : neu-ral computation enables efficient batched execution on GPU, reducing wall-clock time per iteration; and (3) Interpretable dynamics : learned selection and mutation matrices reveal structured patterns in solution-fitness interactions and dimensional dependencies. 3.4 COMPUTATIONAL COMPLEXITY AND CONVERGENCE ANALYSIS 

The computational cost of ABOM is primarily dominated by the selection, crossover, and mutation. The selection matrix (Eq. 5) incurs complexity O(N dd A + N 2dA), where N is the population size, 

d the search space dimension, and dA the attention dimension. The MLP of the crossover (Eq. 6) contributes O(N d AdM + N d M d), with dM the hidden dimension of the MLP. The mutation (Eq. 7) contributes O(d2dA + dd AdM ). Summing these, the total complexity is: 

O(N dd A + N 2dA + N d AdM + N d M d + d2dA + dd AdM ). (11) Assuming dA = dM = d for simplicity, the formulation (11) reduces to O(N d 2 + N 2d + d3). In typical high-dimensional optimization ( N ≪ d), the leading term is O(d3), indicating that compu-tational cost is primarily governed by the problem dimension. Note that dA and dM can be adjusted in practice to balance expressivity and efficiency. Next, we establish that ABOM achieves global convergence under the following assumption: 

Assumption 1 The search space X ⊆ Rd is compact, the objective fT is continuous with global minimizer x∗ in the interior of X , and ABOM uses tanh -activated MLPs ( dM ≥ 1) with dropout rates ( 0 < p C , p M < 1) during inference (operator execution). 

Let f ∗ 

> t

= min x∈E(t) fT (x) denote the best objective value in the elite archive. The filtration 

Ft = σ(P(0) , . . . , P(t), θ (0) , . . . , θ (t)) captures all algorithmic history up to generation t. ABOM preserves a non-vanishing probability of generating offspring ˆp(t) 

> i

near the global optimum: 

Corollary 1 (Exploration Guarantee) For any δ > 0, ∃ γ > 0 such that ∀t ≥ 0,

P ∃ i : ∥ˆp(t) 

> i

− x∗∥ < δ | F t

 ≥ 1 − (1 − γ)N > 0. (12) 5Published as a conference paper at ICLR 2026 Let f ∗ = fT (x∗) be the global optimum value. Corollary 2 establishes a positive drift condition: when f ∗ 

> t

> f ∗ + ϵ, the expected improvement is strictly positive. 

Corollary 2 (Progress Guarantee) For any ϵ > 0, ∃ η(ϵ) > 0 such that ∀t ≥ 0,

Ef ∗ 

> t

− f ∗ 

> t+1

| F t, f ∗ 

> t

> f ∗ + ϵ ≥ η(ϵ). (13) Combining these properties, we have: 

Theorem 3.1 (Global Convergence) Under Assumption 1, ABOM converges to the global optimum almost surely: 

f ∗

> t
> a.s.

−−→ f ∗ as t → ∞ . (14) 

All proofs are provided in Appendix D. 

4 EXPERIMENTS 

In this section, we address the following research questions: RQ1 (Performance Comparison): How does ABOM compare against classical and state-of-the-art BBO baselines on both synthetic and real-world benchmarks? RQ2 (Visualization Study): What statistical patterns emerge in ABOM’s selection and mutation matrices? RQ3 (Ablation Study): Are all components of ABOM neces-sary for achieving competitive performance? RQ4 (Parameter Analysis): How sensitive is ABOM’s performance to its key hyperparameters? We first describe the experimental setup and then system-atically address RQ1–RQ4. 4.1 EXPERIMENTAL SETUP 

BBO Tasks . We evaluate ABOM on the advanced MetaBox Benchmark Ma et al. (2023; 2025a), comprising both the synthetic black-box optimization benchmark (BBOB) Hansen et al. (2021) and the realistic unmanned aerial vehicle (UAV) path planning benchmark Shehadeh & K¨ udela (2025). The BBOB benchmark suite, widely adopted for evaluating black-box optimizers, comprises 24 con-tinuous functions that exhibit diverse global optimization characteristics, including unimodal, mul-timodal, rotated, and shifted structures, with varying properties of Lipschitz continuity and second-order differentiability. We set the search space to [−100 , 100] d with d = 30 /100 /500 . The UAV benchmark provides 56 terrain-based problem instances for path planning in realistic landscapes with cylindrical threats. The objective is to select a specified number of path nodes in 3D space to minimize the total flight path length while ensuring collision-free navigation. The maximum func-tion evaluations for BBOB and UAV are set to 20,000 and 2,500, respectively. All experiments are conducted on a Linux platform with an NVIDIA RTX 2080 Ti GPU (12 GB memory, CUDA 11.3). Detailed task configurations and other experimental results are provided in Appendices F, H, and J. 

Baselines . We compare ABOM against three categories of baselines: (1) Traditional BBO meth-ods : Random Search (RS) Bergstra & Bengio (2012), PSO Kennedy & Eberhart (1995), and DE Storn & Price (1997); (2) Adaptive optimization variants : SAHLPSO (advanced adaptive PSO variant) Tao et al. (2021), JDE21 (advanced adaptive DE variant) Brest et al. (2021), and CMAES (state-of-the-art adaptive ES variant) Hansen (2016); Ollivier et al. (2017); (3) MetaBBO meth-ods : GLEET (advanced MetaBBO for PSO) Ma et al. (2024), RLDEAFL (advanced MetaBBO for DE) Guo et al. (2025), LES (advanced MetaBBO for ES) Lange et al. (2023b), and GLHF (advanced MetaBBO for solution manipulation) Li et al. (2024). All baselines follow the config-urations outlined in the original papers. For all MetaBBO methods, we train them in the same problem distribution as RLDEAFL Guo et al. (2025) using the recommended settings. For BBOB, 8 out of the 24 problem instances are used as the training set, and the remaining 16 instances (f4, f 6 ∼ f14 , f 18 ∼ f20 , f 22 ∼ f24 ) serve as the test set. For UAV, the 56 problem instances are evenly divided into training and test sets, with a partition of 50% / 50%. All parameter configu-rations are provided in the Appendix G. 4.2 PERFORMANCE COMPARISON (RQ1) 

Results on BBOB . We evaluate ABOM against the baselines on the BBOB suite with d =30 /100 /500 . Tabless 1, 7, and 8 (See Appendix K) show the mean and standard deviation over 6Published as a conference paper at ICLR 2026 Table 1: The comparison results of the baselines on the BBOB suite with d = 500 . All results are reported as the mean and standard deviation (mean ± std) over 30 independent runs. Symbols “ −”, “≈”, and “ +” imply that the corresponding baseline is significantly worse, similar, and better than ABOM on the Wilcoxon rank-sum test with 95% confidence level, respectively. The best results are indicated in bold , and the suboptimal results are underlined. 

Traditional BBO Adaptive Variants MetaBBO Ours 

ID RS PSO DE SAHLPSO JDE21 CMAES GLEET RLDEAFL LES GLHF ABOM 

f4 3.700e+5 

±1.192e+4 8.863e+4 

±1.525e+4 3.166e+5 

±3.506e+4 2.947e+5 

±2.418e+4 7.876e+4 

±2.086e+4 1.447e+4 

±7.83e+2 2.605e+5 

±2.173e+4 4.573e+4 

±1.079e+4 2.363e+5 

±4.075e+3 2.324e+5 

±7.512e+3 

1.215e+4 

±5.389e+2 

f6 1.529e+7 

±6.327e+5 5.266e+6 

±5.262e+5 1.206e+7 

±1.390e+6 1.026e+7 

±3.e+5 4.399e+6 

±9.051e+5 2.164e+4 

±6.814e+3 9.870e+6 

±2.409e+5 1.875e+6 

±2.855e+5 9.253e+6 

±9.110e+4 9.194e+6 

±2.104e+5 

6.201e+3 

±6.326e+2 

f7 3.92e+4 

±1.094e+3 2.811e+4 

±2.309e+3 3.366e+4 

±2.93e+3 2.774e+4 

±2.246e+3 1.856e+4 

±2.522e+3 1.289e+5 

±5.883e+2 2.525e+4 

±1.623e+3 1.481e+4 

±1.657e+3 2.285e+4 

±2.143e+2 2.073e+4 

±3.669e+2 

2.432e+3 

±2.250e+2 

f8 6.052e+8 

±2.354e+7 4.083e+8 

±3.847e+7 4.153e+8 

±4.952e+7 2.194e+8 

±2.342e+7 1.332e+8 

±2.237e+7 2.827e+5 

±6.292e+4 1.183e+8 

±1.271e+7 5.807e+7 

±1.28e+7 5.068e+7 

±2.664e+5 5.055e+7 

±5.094e+5 

8.886e+4 

±1.267e+5 

f9 4.159e+8 

±1.368e+7 1.719e+8 

±2.766e+7 2.002e+8 

±3.504e+7 5.151e+7 

±1.06e+7 3.326e+7 

±1.238e+7 2.533e+5 

±5.445e+4 1.473e+7 

±3.238e+6 1.145e+7 

±3.538e+6 4.548e+3 

±3.713e+0 

3.243e+3 

±5.560e-2 

1.792e+5 

±5.876e+4 

f10 2.832e+8 

±1.366e+7 8.026e+7 

±9.438e+6 2.440e+8 

±3.217e+7 2.229e+8 

±2.573e+7 5.459e+7 

±1.667e+7 1.580e+7 

±2.835e+6 2.097e+8 

±2.18e+7 2.232e+7 

±3.291e+6 2.085e+8 

±4.324e+6 2.002e+8 

±9.454e+6 

5.958e+6 

±5.916e+5 

f11 5.881e+3 

±1.591e+2 6.187e+3 

±7.026e+2 4.999e+3 

±5.091e+2 4.835e+3 

±8.117e+2 4.371e+3 

±5.691e+2 1.248e+4 

±2.251e+2 3.722e+3 

±3.575e+2 3.259e+3 

±2.521e+2 5.107e+3 

±8.481e+1 

2.529e+3 

±3.248e+1 

5.392e+3 

±3.159e+2 

f12 3.015e+10 

±2.064e+9 1.414e+10 

±1.401e+9 2.055e+10 

±4.629e+9 1.675e+10 

±3.634e+9 4.800e+9 

±9.841e+8 1.32e+8 

±2.254e+7 1.235e+10 

±2.046e+9 2.819e+9 

±3.899e+8 1.084e+10 

±5.738e+8 9.757e+9 

±6.844e+8 

2.733e+7 

±4.903e+7 

f13 1.444e+4 

±1.618e+2 1.319e+4 

±2.75e+2 1.324e+4 

±4.159e+2 1.197e+4 

±2.857e+2 8.994e+3 

±6.370e+2 2.363e+3 

±1.43e+2 1.116e+4 

±3.338e+2 7.073e+3 

±3.424e+2 1.255e+4 

±5.007e+1 1.024e+4 

±5.299e+1 

1.221e+3 

±3.010e+2 

f14 6.634e+2 

±2.241e+1 4.824e+2 

±4.296e+1 5.081e+2 

±7.419e+1 4.208e+2 

±4.277e+1 1.842e+2 

±2.998e+1 2.494e+1 

±3.554e+0 3.231e+2 

±2.764e+1 1.157e+2 

±1.216e+1 1.458e+3 

±6.108e+0 2.542e+2 

±8.222e+0 

1.487e+1 

±2.291e+0 

f18 1.428e+2 

±5.025e+0 1.017e+2 

±9.614e+0 1.093e+2 

±8.297e+0 9.814e+1 

±7.383e+0 7.074e+1 

±8.102e+0 1.100e+3 

±1.069e+1 8.539e+1 

±8.386e+0 5.495e+1 

±4.191e+0 3.704e+2 

±6.062e-1 6.875e+1 

±1.422e+0 

3.792e+1 

±4.075e+0 

f19 2.09e+3 

±6.041e+1 9.012e+2 

±1.148e+2 9.606e+2 

±1.704e+2 2.764e+2 

±4.896e+1 1.772e+2 

±5.848e+1 1.374e+1 

±5.336e-1 8.479e+1 

±1.668e+1 8.767e+1 

±2.029e+1 2.502e+3 

±8.225e-1 

2.504e-1 

±3.113e-6 

1.813e+1 

±1.603e+0 

f20 3.233e+6 

±1.022e+5 2.374e+6 

±2.320e+5 2.432e+6 

±2.800e+5 1.471e+6 

±1.945e+5 5.884e+5 

±1.564e+5 3.802e+3 

±1.702e+3 9.466e+5 

±1.069e+5 2.136e+5 

±6.086e+4 3.772e+5 

±6.088e+3 3.753e+5 

±6.417e+3 

2.565e+2 

±1.351e+3 

f22 8.636e+1 

±1.942e-2 8.609e+1 

±9.432e-2 8.61e+1 

±1.371e-1 8.542e+1 

±2.480e-1 8.003e+1 

±1.838e+0 2.851e+1 

±3.852e-1 8.478e+1 

±2.648e-1 7.159e+1 

±2.18e+0 1.184e+3 

±4.394e-2 8.356e+1 

±7.540e-2 

4.971e+0 

±6.520e+0 

f23 1.652e+0 

±3.551e-2 1.641e+0 

±4.291e-2 1.659e+0 

±2.456e-2 1.658e+0 

±5.790e-2 1.586e+0 

±6.784e-2 

3.959e-1 

±3.54e-2 

1.659e+0 

±4.429e-2 1.559e+0 

±1.525e-1 1.202e+3 

±3.532e-2 1.663e+0 

±3.539e-2 1.656e+0 

±3.434e-2 

f24 2.089e+4 

±2.555e+2 1.604e+4 

±5.679e+2 1.610e+4 

±9.073e+2 1.222e+4 

±4.744e+2 1.198e+4 

±9.584e+2 4.986e+4 

±3.337e+1 1.010e+4 

±4.16e+2 9.9e+3 

±6.456e+2 8.822e+3 

±5.392e+1 

7.437e+3 

±7.572e+1 

8.09e+3 

±3.268e+2 

−/≈/+ 15/1/0 15/1/0 14/1/1 14/1/1 14/1/1 15/0/1 14/1/1 14/1/1 14/0/2 11/1/4 -

30 runs for each baseline. Convergence curves of average normalized cost across all cases are pro-vided in the Appendix K. ABOM matches or outperforms all baselines, achieving state-of-the-art performance, which validates the effectiveness of the proposed method. Both ABOM and adaptive optimization methods adjust the parameters online using optimization data. ABOM’s parameterized operators offer greater flexibility than the fixed adaptation rules in the variant, leading to stronger performance. Compared to existing metaBBO algorithms, ABOM’s improvements highlight the importance of parameter adaptation in enabling effective meta-optimization across diverse prob-lem instances. The results suggest that adaptive mechanisms can support competitive performance without relying on handcrafted training tasks. 

Results on UAV . We evaluate ABOM on 28 UAV benchmarks to validate its practical effectiveness. Fig. 3 shows the convergence of the normalized cost and runtime. ABOM converges fastest under limited evaluations and achieves the lowest normalized cost. Unlike metaBBO-based methods (e.g., GLHF, GLEET, RLDEAFL, LES), ABOM and adaptive optimization methods eliminate the need for training on hand-crafted tasks and associated overhead. Through GPU-accelerated evolution and adaptive parameter learning, ABOM achieves significantly faster runtime than most baselines. 4.3 VISUALIZATION STUDY (RQ2) AND ABLATION STUDY (RQ3) We visualize the learned selection and mutation matrices of ABOM on three BBOB functions ( f4,

f11 , f24 , d = 30 ) in Fig. 4. In all cases, the matrices develop structured statistical patterns as optimization proceeds. The selection matrix shows row similarity, indicating that ABOM learns to generate offspring from a small subset of individuals. This behavior resembles the difference vector mechanism in DE Storn & Price (1997), which reflects the strong expressive capacity of the learnable operator. Individuals with higher fitness are preferentially selected, in line with the 7Published as a conference paper at ICLR 2026 0 500 1000 1500 2000 2500 

> Function Evaluations (FEs)
> 0.2
> 0.4
> 0.6
> 0.8
> 1.0
> Normalized Costs
> GLHF
> GLEET
> RLDEAFL
> LES
> ABOM
> CMAES
> SAHLPSO
> PSO
> DE
> JDE21
> Random_search

(a) Convergence curve RS  

> PSO
> DE
> SAHLPSO
> JDE21
> CMAES
> GLEET
> RLDEAFL
> LES
> GLHF
> ABOM
> 0
> 20000
> 40000
> 60000
> 80000
> Optimization Runtime
> Optimization Time
> Training Time
> 0
> 2
> 4
> 6
> 8
> 10
> 12
> 14
> log(Training Runtime)

(b) Runtime comparison 

Figure 3: Performance on 28 UAV problems: (Left) Convergence curve of average normalized cost across all problems. Costs (lower is better) are min-max normalized for each case. Detailed results are shown in the Appendix K; (Right) Average runtime (GPU seconds) over 30 independent runs. Selection Matrix Mutation Matrix 

Figure 4: Learned selection and mutation matrices of ABOM on BBOB functions f4, f11 , and f24 

(d = 30 ) at Generation 1, 500, and 1000. For the selection matrix, axes represent individuals ranked by their fitness values (0 is the best). For the mutation matrix, axes represent gene (variable) indices. principle of survival of the fittest. The best individual is not always selected, which may help preserve population diversity. The mutation matrix evolves from random initialization to an ordered structure, suggesting that mutation follows consistent patterns adapted to the problem. These results demonstrate that ABOM provides greater interpretability than the metaBBO methods, which directly map neural networks to solution manipulation Li et al. (2024; 2025). Table 2: Ablation study of ABOM’s key components on the BBOB suite with d = 30 .

ID No Crossover No Mutation No Parameter Adaptation ABOM 

(mean ± std) (mean ± std) (mean ± std) (mean ± std) 

f4 4.23e+03 ± 3.02e+03 1.01e+03 ± 5.44e+02 2.58e+04 ± 1.67e+04 5.45e+02 ± 2.95e+02 

f6 1.62e+04 ± 1.55e+04 1.10e+04 ± 1.95e+04 4.54e+04 ± 3.61e+04 2.60e+02 ± 2.64e+02 

f7 6.39e+03 ± 6.91e+03 1.18e+03 ± 6.86e+02 1.67e+04 ± 1.11e+04 5.58e+02 ± 2.77e+02 

f8 1.52e+03 ± 2.91e+03 1.94e+03 ± 3.62e+03 1.03e+08 ± 2.68e+08 1.15e+02 ± 1.56e+02 

f9 1.96e+04 ± 7.02e+04 1.13e+03 ± 3.15e+03 2.49e+06 ± 5.94e+06 2.35e+03 ± 5.30e+03 

f10 1.16e+07 ± 7.11e+06 1.07e+07 ± 3.48e+06 3.65e+07 ± 1.64e+07 9.72e+05 ± 7.38e+05 

f11 1.05e+05 ± 3.19e+04 1.00e+05 ± 2.68e+04 8.00e+04 ± 2.20e+04 2.61e+04 ± 1.01e+04 

f12 1.12e+09 ± 3.12e+09 2.30e+07 ± 5.74e+07 1.63e+10 ± 1.61e+10 5.28e+07 ± 1.45e+08 

f13 7.54e+01 ± 4.06e+01 7.71e+01 ± 3.93e+01 8.71e+03 ± 3.16e+03 7.28e+01 ± 3.07e+01 

f14 8.43e+01 ± 7.23e+01 9.29e+00 ± 2.49e+01 9.28e+02 ± 5.96e+02 3.46e-02 ± 3.39e-02 

f18 1.18e+03 ± 2.21e+03 7.02e+02 ± 2.46e+02 4.94e+02 ± 1.66e+02 5.12e+02 ± 1.37e+02 

f19 2.35e+01 ± 3.45e+01 1.23e+01 ± 1.23e+01 1.64e+02 ± 3.27e+02 2.48e-01 ± 1.11e-03 

f20 -6.54e+01 ± 4.95e+00 -6.58e+01 ± 3.53e+00 -5.82e+01 ± 4.19e+00 -6.57e+01 ± 3.80e+00 

f22 8.66e+01 ± 0.00e+00 8.66e+01 ± 0.00e+00 8.66e+01 ± 0.00e+00 8.66e+01 ± 0.00e+00 

f23 3.03e+00 ± 5.33e-01 3.12e+00 ± 4.54e-01 3.20e+00 ± 4.25e-01 3.01e-01 ± 2.19e-01 

f24 2.92e+02 ± 2.46e+02 2.30e+02 ± 5.31e+01 4.94e+03 ± 3.41e+03 2.44e+02 ± 2.37e+01 

−/ ≈/+ 13/3/0 10/3/3 14/1/1 –

8Published as a conference paper at ICLR 2026 We conduct an ablation study comparing the proposed ABOM with variants that disable specific mechanisms, including no crossover, no mutation, and no parameter adaptation. Table 2 presents the mean and standard deviation over 30 runs on the BBOB suite with d = 30 . Table 2 illustrates that both crossover and mutation are crucial components, as their removal individually causes sig-nificant performance deterioration. Furthermore, the variant without parameter adaptation performs significantly worse than ABOM, underscoring the critical importance of the adaptive mechanism for achieving robust and high-quality optimization. 4.4 PARAMETER ANALYSIS (RQ4) Fig. 5 illustrates ABOM’s hyperparameter sensitivity on the BBOB suite ( d = 30 ). A population size of 20 proves sufficient for robust performance across most functions within 20,000 evaluations. Similarly, a hidden dimension dM smaller than d (e.g., dM = 16 ) often achieves competitive results. In practice, dM should be carefully configured to balance computational efficiency and optimization quality effectively. The parameters pC and pM exhibit optimal performance at 0.95, indicating that higher values increase stochasticity and exploration. Nevertheless, setting either parameter to 1 eliminates beneficial randomness, degrading performance. Thus, controlled stochasticity is crucial for maintaining the balance between exploitation and diversity. 10 20 30 40 50  

> Population Size N
> f4
> f6
> f7
> f8
> f9
> f10
> f11
> f12
> f13
> f14
> f18
> f19
> f20
> f22
> f23
> f24
> Function ID
> 0.0
> 0.2
> 0.4
> 0.6
> 0.8
> 1.0
> Normalized Average Objective Value

(a) N8 16 32 64 128   

> Hidden Dimension dM
> f4
> f6
> f7
> f8
> f9
> f10
> f11
> f12
> f13
> f14
> f18
> f19
> f20
> f22
> f23
> f24
> Function ID
> 0.0
> 0.2
> 0.4
> 0.6
> 0.8
> 1.0
> Normalized Average Objective Value

(b) dM0.05  

> 0.20
> 0.35
> 0.50
> 0.65
> 0.80
> 0.95
> 1.00
> Crossover dropout rate pC
> 0.0
> 0.2
> 0.4
> 0.6
> 0.8
> 1.0
> Normalized Average Objective Value  f4
> f6
> f7
> f8
> f9
> f10
> f11
> f12
> f13
> f14
> f18
> f19
> f20
> f22
> f23
> f24

(c) pC0.05   

> 0.20
> 0.35
> 0.50
> 0.65
> 0.80
> 0.95
> 1.00
> Mutation dropout rate pM
> 0.0
> 0.2
> 0.4
> 0.6
> 0.8
> 1.0
> Normalized Average Objective Value  f4
> f6
> f7
> f8
> f9
> f10
> f11
> f12
> f13
> f14
> f18
> f19
> f20
> f22
> f23
> f24

(d) pM

Figure 5: Sensitivity analysis of key hyperparameters on the BBOB suite with d = 30 : Algorithm performance across different settings for population size ( N ), hidden dimension ( dM ), crossover dropout rate ( pC ), and mutation dropout rate ( pM ). The learning rate analysis is in Appendix I. 

5 CONCLUSION AND DISCUSSION 

Summary . We present a task-free adaptive metaBBO method, ABOM, which eliminates depen-dency on handcrafted training tasks by performing online parameter adaptation using only opti-mization data from the target task. Unlike conventional MetaBBO methods that require offline meta-training, ABOM integrates parameter learning directly into the evolutionary loop, enabling zero-shot generalization. Our framework parameterizes evolutionary operators as differentiable modules, up-dated via gradient descent to align offspring with elites, thereby eliminating the need for pretraining or heuristic design. Empirical results in synthetic and realistic benchmarks demonstrate that ABOM matches or outperforms advanced baselines without prior task knowledge. Attention visualization reveals interpretable search behaviors with consistent structural patterns. Thus, ABOM establishes a task-free paradigm for metaBBO, where learning and search co-evolve in real time. 9Published as a conference paper at ICLR 2026 

Limitations and Future Work . Current limitations motivate several promising directions: (1) Ad-dressing the cubic computational bottleneck ( O(d3)) through sparse or low-rank attention mecha-nisms to reduce ABOM’s complexity; (2) Dynamically adapting population size and model capacity during optimization; (3) Conducting a convergence rate analysis grounded in the theoretical exam-ination of adaptive parameter learning in ABOM; and (4) Exploring hybrid training paradigms that integrate pretraining on prior knowledge with online adaptation, thereby enhancing optimization efficiency and bridging the gap between task-agnostic adaptation and cross-task generalization. ACKNOWLEDGMENTS 

This work was supported in part by the National Natural Science Foundation of China(No.62576264), Project supported by the National Science and Technology Major Project of the Ministry of Science and Technology of China (No.2025ZD0551500, No.2025ZD0551502) , the Key Project of National Natural Science Foundation of China (62431020,62231027), the Joint Fund Project of National Natural Science Foundation of China (No.U22B2054), the Fund for Foreign Scholars in University Research and Teaching Programs (the 111 Project) (No.B07048), the Postdoctoral Fellowship Program of China Postdoctoral Science Foundation (CPSF) (No.GZC20232033), the Natural Science Basic Research Program of Shaanxi (Program No. 2025JC-YBQN-795), the China Postdoctoral Science Foundation (Certificate Number: 2025T180431 and 2025M771550), the Program for Cheung Kong Scholars and Innovative Re-search Team in University (No.IRT 15R53), the Key Scientific Technological Innovation Research Project by Ministry of Education and the National Key Laboratory of Human-Machine Hybrid Augmented Intelligence, Xi’an Jiaotong University (No.HMHAI-202404, No. HMHAI-202405). 

REFERENCES 

Thomas B¨ ack and Hans-Paul Schwefel. An overview of evolutionary algorithms for parameter optimization. Evolutionary computation , 1(1):1–23, 1993. Hui Bai and Ran Cheng. Generalized population-based training for hyperparameter optimization in reinforcement learning. IEEE Transactions on Emerging Topics in Computational Intelligence , 8 (5):3450–3462, 2024. James Bergstra and Yoshua Bengio. Random search for hyper-parameter optimization. Journal of Machine Learning Research , 13(10):281–305, 2012. Janez Brest, Mirjam Sepesy Mauˇ cec, and Borko Boˇ skovi´ c. Self-adaptive differential evolution al-gorithm with population size reduction for single objective bound-constrained optimization: Al-gorithm j21. In 2021 IEEE Congress on Evolutionary Computation , pp. 817–824, 2021. Jiacheng Chen, Zeyuan Ma, Hongshu Guo, Yining Ma, Jie Zhang, and Yue-Jiao Gong. SYMBOL: Generating flexible black-box optimizers through symbolic equation learning. In The Twelfth International Conference on Learning Representations , 2024. Kenneth De Jong. Evolutionary computation: a unified approach. In Proceedings of the Genetic and Evolutionary Computation Conference Companion , GECCO ’17, pp. 373–388, New York, NY, USA, 2017. Association for Computing Machinery. K. Deb, A. Pratap, S. Agarwal, and T. Meyarivan. A fast and elitist multiobjective genetic algorithm: Nsga-ii. IEEE Transactions on Evolutionary Computation , 6(2):182–197, 2002. Agoston E Eiben and Jim Smith. From evolutionary computation to the evolution of things. Nature ,521(7553):476–482, 2015. Hongshu Guo, Yining Ma, Zeyuan Ma, Jiacheng Chen, Xinglin Zhang, Zhiguang Cao, Jun Zhang, and Yue-Jiao Gong. Deep reinforcement learning for dynamic algorithm selection: A proof-of-principle study on differential evolution. IEEE Transactions on Systems, Man, and Cybernetics: Systems , 54(7):4247–4259, 2024. Hongshu Guo, Sijie Ma, Zechuan Huang, Yuzhi Hu, Zeyuan Ma, Xinglin Zhang, and Yue-Jiao Gong. Reinforcement learning-based self-adaptive differential evolution through automated land-scape feature learning. In Proceedings of the Genetic and Evolutionary Computation Conference ,GECCO ’25, pp. 1117–1126, New York, NY, USA, 2025. Association for Computing Machinery. 10 Published as a conference paper at ICLR 2026 Peter Hall and Christopher C Heyde. Martingale limit theory and its application . Academic press, 2014. Muqi Han, Xiaobin Li, Kai Wu, Xiaoyu Zhang, and Handing Wang. Enhancing zero-shot black-box optimization via pretrained models with efficient population modeling, interaction, and stable gra-dient approximation. In The Thirty-ninth Annual Conference on Neural Information Processing Systems , 2025. Nikolaus Hansen. The cma evolution strategy: A tutorial. arXiv preprint arXiv:1604.00772 , 2016. Nikolaus Hansen, Anne Auger, Raymond Ros, Olaf Mersmann, Tea Tuˇ sar, and Dimo Brockhoff. Coco: A platform for comparing continuous optimizers in a black-box setting. Optimization Methods and Software , 36(1):114–144, 2021. Jun He and Xin Yao. Drift analysis and average time complexity of evolutionary algorithms. Artifi-cial intelligence , 127(1):57–85, 2001. John H. Holland. Outline for a logical theory of adaptive systems. J. ACM , 9(3):297–314, July 1962. J. Kennedy and R. Eberhart. Particle swarm optimization. In Proceedings of ICNN’95 - International Conference on Neural Networks , volume 4, pp. 1942–1948 vol.4, 1995. Robert Lange, Tom Schaul, Yutian Chen, Chris Lu, Tom Zahavy, Valentin Dalibard, and Sebas-tian Flennerhag. Discovering attention-based genetic algorithms via meta-black-box optimiza-tion. In Proceedings of the Genetic and Evolutionary Computation Conference , GECCO ’23, pp. 929–937, New York, NY, USA, 2023a. Association for Computing Machinery. Robert Tjarko Lange, Tom Schaul, Yutian Chen, Tom Zahavy, Valentin Dalibard, Chris Lu, Satinder Singh, and Sebastian Flennerhag. Discovering evolution strategies via meta-black-box optimiza-tion. In The Eleventh International Conference on Learning Representations , 2023b. Ke Li, Alvaro Fialho, Sam Kwong, and Qingfu Zhang. Adaptive operator selection with bandits for a multiobjective evolutionary algorithm based on decomposition. IEEE Transactions on Evolu-tionary Computation , 18(1):114–130, 2013. Xiaobin Li, Kai Wu, Yujian Betterest Li, Xiaoyu Zhang, Handing Wang, and Jing Liu. Pretrained optimization model for zero-shot black box optimization. In The Thirty-eighth Annual Conference on Neural Information Processing Systems , 2024. Xiaobin Li, Kai Wu, Xiaoyu Zhang, and Handing Wang. B2opt: Learning to optimize black-box optimization with little budget. Proceedings of the AAAI Conference on Artificial Intelligence , 39 (17):18502–18510, Apr. 2025. Fei Liu, Xi Lin, Shunyu Yao, Zhenkun Wang, Xialiang Tong, Mingxuan Yuan, and Qingfu Zhang. Large language model for multiobjective evolutionary optimization. In Hemant Singh, Tapabrata Ray, Joshua Knowles, Xiaodong Li, Juergen Branke, Bing Wang, and Akira Oyama (eds.), Evolu-tionary Multi-Criterion Optimization , pp. 178–191, Singapore, 2025. Springer Nature Singapore. Ilya Loshchilov and Frank Hutter. Decoupled weight decay regularization. In International Confer-ence on Learning Representations , 2019. Zeyuan Ma, Hongshu Guo, Jiacheng Chen, Zhenrui Li, Guojun Peng, Yue-Jiao Gong, Yining Ma, and Zhiguang Cao. Metabox: A benchmark platform for meta-black-box optimization with re-inforcement learning. In Thirty-seventh Conference on Neural Information Processing Systems Datasets and Benchmarks Track , 2023. Zeyuan Ma, Jiacheng Chen, Hongshu Guo, Yining Ma, and Yue-Jiao Gong. Auto-configuring exploration-exploitation tradeoff in evolutionary computation via deep reinforcement learning. In Proceedings of the Genetic and Evolutionary Computation Conference , GECCO ’24, pp. 1497–1505, New York, NY, USA, 2024. Association for Computing Machinery. 11 Published as a conference paper at ICLR 2026 Zeyuan Ma, Yue-Jiao Gong, Hongshu Guo, Wenjie Qiu, Sijie Ma, Hongqiao Lian, Jiajun Zhan, Kaixu Chen, Chen Wang, Zhiyang Huang, Zechuan Huang, Guojun Peng, Ran Cheng, and Yining Ma. Metabox-v2: A unified benchmark platform for meta-black-box optimization. In The Thirty-ninth Annual Conference on Neural Information Processing Systems Datasets and Benchmarks Track , 2025a. Zeyuan Ma, Hongshu Guo, Yue-Jiao Gong, Jun Zhang, and Kay Chen Tan. Toward automated algo-rithm design: A survey and practical guide to meta-black-box-optimization. IEEE Transactions on Evolutionary Computation , pp. 1–1, 2025b. Risto Miikkulainen. Neuroevolution insights into biological neural computation. Science , 387 (6735):eadp7478, 2025. Risto Miikkulainen and Stephanie Forrest. A biological perspective on evolutionary computation. 

Nature Machine Intelligence , 3(1):9–15, 2021. Yann Ollivier, Ludovic Arnold, Anne Auger, and Nikolaus Hansen. Information-geometric opti-mization algorithms: A unifying picture via invariance principles. Journal of Machine Learning Research , 18(18):1–65, 2017. Ingo Rechenberg. The evolution strategy. a mathematical model of darwinian evolution. In Syner-getics—From Microscopic to Macroscopic Order: Proceedings of the International Symposium on Synergetics at Berlin, July 4–8, 1983 , pp. 122–132. Springer, 1984. Bernardino Romera-Paredes, Mohammadamin Barekatain, Alexander Novikov, Matej Balog, M Pawan Kumar, Emilien Dupont, Francisco JR Ruiz, Jordan S Ellenberg, Pengming Wang, Omar Fawzi, et al. Mathematical discoveries from program search with large language models. 

Nature , 625(7995):468–475, 2024. Sasan Salmani Pour Avval, Nathan D Eskue, Roger M Groves, and Vahid Yaghoubi. Systematic review on neural architecture search. Artificial Intelligence Review , 58(3):73, 2025. Mhd Ali Shehadeh and Jakub K¨ udela. Benchmarking global optimization techniques for unmanned aerial vehicle path planning. Expert Systems with Applications , pp. 128645, 2025. Kenneth O Stanley, Jeff Clune, Joel Lehman, and Risto Miikkulainen. Designing neural networks through neuroevolution. Nature Machine Intelligence , 1(1):24–35, 2019. Rainer Storn and Kenneth Price. Differential evolution – a simple and efficient heuristic for global optimization over continuous spaces. J. of Global Optimization , 11(4):341–359, December 1997. Xinmin Tao, Xiangke Li, Wei Chen, Tian Liang, Yetong Li, Jie Guo, and Lin Qi. Self-adaptive two roles hybrid learning strategies-based particle swarm optimization. Information Sciences , 578: 457–481, 2021. Ye Tian, Shichen Peng, Xingyi Zhang, Tobias Rodemann, Kay Chen Tan, and Yaochu Jin. A recom-mender system for metaheuristic algorithms for continuous optimization based on deep recurrent neural networks. IEEE Transactions on Artificial Intelligence , 1(1):5–18, 2020. Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Ł ukasz Kaiser, and Illia Polosukhin. Attention is all you need. In I. Guyon, U. Von Luxburg, S. Bengio, H. Wallach, R. Fergus, S. Vishwanathan, and R. Garnett (eds.), Advances in Neural Information Processing Systems , volume 30. Curran Associates, Inc., 2017. Chao Wang, Licheng Jiao, Jiaxuan Zhao, Lingling Li, Xu Liu, Fang Liu, and Shuyuan Yang. Bi-level multiobjective evolutionary learning: A case study on multitask graph neural topology search. 

IEEE Transactions on Evolutionary Computation , 28(1):208–222, 2023. Chao Wang, Jiaxuan Zhao, Licheng Jiao, Lingling Li, Fang Liu, and Shuyuan Yang. When large lan-guage models meet evolutionary algorithms: Potential enhancements and challenges. Research ,8:0646, 2025a. 12 Published as a conference paper at ICLR 2026 Chen Wang, Zeyuan Ma, Zhiguang Cao, and Yue-Jiao Gong. Instance generation for meta-black-box optimization through latent space reverse engineering. arXiv preprint arXiv:2509.15810 ,2025b. David H Wolpert and William G Macready. No free lunch theorems for optimization. IEEE trans-actions on evolutionary computation , 1(1):67–82, 2002. Xiaoming Xue, Cuie Yang, Liang Feng, Kai Zhang, Linqi Song, and Kay Chen Tan. A scalable test problem generator for sequential transfer optimization. IEEE Transactions on Cybernetics , 55(5): 2110–2123, 2025. Chengrun Yang, Xuezhi Wang, Yifeng Lu, Hanxiao Liu, Quoc V Le, Denny Zhou, and Xinyun Chen. Large language models as optimizers. In B. Kim, Y. Yue, S. Chaudhuri, K. Fragkiadaki, M. Khan, and Y. Sun (eds.), International Conference on Representation Learning , volume 2024, pp. 12028–12068, 2024. Taeyoung Yun, Kiyoung Om, Jaewoo Lee, Sujin Yun, and Jinkyoo Park. Posterior inference with diffusion models for high-dimensional black-box optimization. In Forty-second International Conference on Machine Learning , 2025. Zhi-Hua Zhou, Yang Yu, and Chao Qian. Evolutionary learning: Advances in theories and algo-rithms . Springer, 2019. 13 Published as a conference paper at ICLR 2026 

A REPRODUCIBILITY STATEMENT 

To ensure the reproducibility, we have taken the following measures: • Source Code : We provide a complete implementation of the Adaptive meta Black-box Optimization Model (ABOM) at the following repository: https://github.com/ xiaofangxd/ABOM .• Algorithm Specification : ABOM is fully detailed in Section 3, including the mathemati-cal formulations for the selection, crossover, and mutation operators. The complete pseu-docode for the optimization loop is provided in Algorithm 1 (Appendix C). • Experimental Setup : All baselines are implemented and evaluated using the state-of-the-art MetaBox benchmark platform Ma et al. (2023; 2025a). This ensures a standardized, fair, and reproducible comparison. Appendix F describes the BBOB and UAV benchmarks, including their characteristics, search space dimensions, and evaluation budgets. Appendix G details the hyperparameter settings for all baselines as specified in the original papers and implemented in MetaBox. By providing the code, algorithmic descriptions, and experimental configurations on the unified MetaBox platform, we aim to enable other researchers to fully reproduce and build upon our results. 

B USE OF LARGE LANGUAGE MODELS 

Large Language Models (LLMs) were used solely as a general-purpose writing assistance tool. Their role was limited to language polishing, grammatical refinement, and improving the clarity and flu-ency of the paper. LLMs did not contribute to the conception of research ideas, experimental design, data analysis, or interpretation of results. All intellectual contributions, including the formulation of the problem, methodology, and conclusions, were made entirely by the human authors. 

C PSEUDOCODE OF ABOM 

Algorithm 1 Adaptive meta Black-box Optimization Model (ABOM) 

Input: Target black-box optimization task fT , population size N , max generations T , crossover dropout rate pC , mutation dropout rate pM , learning rate η, attention dimension dA, and MLP hidden dimension dM . 

> 1:

Initialize P(0) via Latin hypercube sampling;  

> 2:

Evaluate: F(0) ← fT (P(0) ); 

> 3:

for t = 0 to T − 1 do  

> 4:

Generate offspring: ˆP(t) ← πθ (P(t), F(t); dA, d M , p C , p M ) ; 

> 5:

Evaluate: ˆF(t) ← fT ( ˆP(t)); 

> 6:

Form elite archive: E(t), F(t) 

> E

← top N



P(t) ∪ ˆP(t)



, top N



F(t) ∪ ˆF(t)



; 

> 7:

Update parameters by AdamW: θ ← θ − η∇θ ˆP(t) − E(t) 2

; 

> 8:

Elitism: P(t+1) ← E(t), F(t+1) ← F(t) 

> E

; 

> 9:

end for Output: Optimal individual (solution) p∗ = arg min p∈P(t) fT (p).

D CONVERGENCE ANALYSIS OF ABOM 

This section presents a convergence analysis of ABOM under some assumptions. We rigorously prove that ABOM converges with probability 1 to the global optimum of the objective function. Let X ⊆ Rd be a compact search space and fT : X → R be a continuous objective function with global minimum f ∗ = fT (x∗). ABOM maintains a population P(t) ∈ RN ×d at generation 14 Published as a conference paper at ICLR 2026 

t, with corresponding fitness values F(t). For the convergence analysis, we make the following assumptions: 

Assumption 2 The following conditions hold: (i) The global optimum x∗ lies in the interior of X .(ii) Dropout rates satisfy 0 < p C , p M < 1.(iii) MLP hidden dimension dM ≥ 1 with tanh activation. 

Define f ∗ 

> t

= min x∈E(t) fT (x), where E(t) is the elite archive containing the top N individuals from 

P(t) ∪ ˆP(t). Let Ft = σ(P(0) , . . . , P(t), θ (0) , . . . , θ (t)) be the filtration representing all information up to generation t. The elitism mechanism ensures f ∗ 

> t+1

≤ f ∗ 

> t

almost surely, implying E[f ∗ 

> t+1

|Ft] ≤ f ∗ 

> t

. Since fT is bounded on the compact set X , the sequence {f ∗ 

> t

, Ft} forms a lower-bounded supermartingale. By the martingale convergence theorem Hall & Heyde (2014), f ∗ 

> t

converges with probability 1 to the random variable f ∗∞ ≥ f ∗. To establish global convergence, we need to prove 

f ∗∞ = f ∗ with probability 1. 

Lemma 1 Under Assumption 2, for any δ > 0, there exists γ > 0 such that: 

P(∃i : ∥ˆp(t) 

> i

− x∗∥ < δ | F t) ≥ 1 − (1 − γ)N > 0. (15) 

Proof 1 For the crossover operation, consider any parent p(t) 

> i

∈ X and let v = x∗ − p(t) 

> i

. Define the MLP configuration with W1 = 0, b1 = 0, W2 = 0, and b2 = v. Then: 

MLP θ∗ 

> c

(A(t)p(t) 

> i

) = W2 tanh( W1A(t)p(t) 

> i

+ b1) + b2 = v. (16) 

Consequently: 

p(t) 

> i

+ MLP θ∗ 

> c

(A(t)p(t) 

> i

) = x∗. (17) 

By continuity of the MLP (as a composition of continuous functions), there exists ϵ > 0 such that for all θc ∈ N ϵ(θ∗ 

> c

):

∥p(t) 

> i

+ MLP θc (A(t)p(t) 

> i

) − x∗∥ < δ/ 2. (18) 

Define μc = P(θ(t) 

> c

∈ N ϵ(θ∗ 

> c

) | F t). Given the parameter update θ(t+1)  

> c

= θ(t) 

> c

− η∇L (θ(t) 

> c

) + ξ(t)

with stochastic perturbations ξ(t) from dropout patterns D(t) ∼ Bernoulli(1 − pC )dM , which have minimum probability mass: 

min  

> D

P(D(t) = D) = (min {pC , 1 − pC })dM > 0, (19) 

and since the conditional distribution of θ(t) 

> c

has positive density, there exists ct > 0 such that: 

μc ≥ (min {pC , 1 − pC })dM · ct > 0. (20) 

For the mutation operation, consider any intermediate solution p′(t) 

> i

and let w = x∗ − p′(t) 

> i

. Define the MLP configuration with W3 = 0, b3 = 0, W4 = 0, and b4 = w. Then: 

MLP θ∗ 

> m

(M(t) 

> i

p′(t) 

> i

) = W4 tanh( W3M(t) 

> i

p′(t) 

> i

+ b3) + b4 = w. (21) 

Consequently: 

p′(t) 

> i

+ MLP θ∗ 

> m

(M(t) 

> i

p′(t) 

> i

) = x∗. (22) 

By identical continuity properties, there exists ϵ > 0 such that for all θm ∈ N ϵ(θ∗

> m

):

∥p′(t) 

> i

+ MLP θm (M(t) 

> i

p′(t) 

> i

) − x∗∥ < δ/ 2. (23) 

Define μm = P(θ(t) 

> m

∈ N ϵ(θ∗

> m

) | F t). By analogous reasoning to the crossover operation: 

μm ≥ (min {pM , 1 − pM })dM · c′ 

> t

> 0, (24) 15 Published as a conference paper at ICLR 2026 

where c′ 

> t

> 0 is determined by mutation parameters. The probability that a single offspring ˆp(t) 

> i

falls within δ of x∗ satisfies: 

P(∥ˆp(t) 

> i

− x∗∥ < δ | F t) ≥ μcμm. (25) 

Let γ = μcμm > 0, which is a positive constant independent of t and depends only on hyperparam-eters pC , pM , dM , and the adaptive parameter learning. Finally, for N independent offspring: 

P(∃i : ∥ˆp(t) 

> i

− x∗∥ < δ | F t) = 1 −

> N

Y

> i=1

(1 − P(∥ˆp(t) 

> i

− x∗∥ < δ | F t)) ≥ 1 − (1 − γ)N > 0. (26) Define the distance function Vt = f ∗ 

> t

− f ∗ ≥ 0. Using Lemma 1, we establish the following drift condition He & Yao (2001); Zhou et al. (2019): 

Lemma 2 Under Assumption 2, for any ϵ > 0, there exists η(ϵ) > 0 such that: 

E[Vt − Vt+1 | F t, V t > ϵ ] ≥ η(ϵ) > 0. (27) 

Proof 2 Define the event At = {∃ i : ∥ˆp(t) 

> i

− x∗∥ < δ }, where δ > 0 is chosen such that for all 

x ∈ X with ∥x − x∗∥ < δ , we have fT (x) < f ∗ + ϵ/ 2 (which exists by the continuity of fT and Assumption 2(i)). By Lemma 1, there exists γ > 0 such that: 

P(At | F t, V t > ϵ ) ≥ 1 − (1 − γ)N > 0. (28) 

When At occurs, the elite archive at generation t + 1 contains at least one solution with fitness value less than f ∗ + ϵ/ 2, so: 

Vt+1 = f ∗ 

> t+1

− f ∗ < ϵ/ 2. (29) 

When At does not occur, the elitism mechanism ensures Vt+1 ≤ Vt (since the elite archive preserves the best solutions). Therefore, the expected drift can be decomposed as: 

E[Vt − Vt+1 | F t, V t > ϵ ] = E[Vt − Vt+1 | F t, V t > ϵ, A t] · P(At | F t, V t > ϵ ) (30) 

+ E[Vt − Vt+1 | F t, V t > ϵ, A ct ] · P(Act | F t, V t > ϵ ). (31) 

For the first term, using Eq. (29) and the condition Vt > ϵ :

E[Vt − Vt+1 | F t, V t > ϵ, A t] ≥ Vt − ϵ/ 2 (32) 

> ϵ − ϵ/ 2 = ϵ/ 2. (33) 

For the second term, since Vt+1 ≤ Vt by the elitism mechanism: 

E[Vt − Vt+1 | F t, V t > ϵ, A ct ] ≥ 0. (34) 

Combining these results with Eq. (28): 

E[Vt − Vt+1 | F t, V t > ϵ ] ≥ (ϵ/ 2) · (1 − (1 − γ)N ) + 0 · P(Act | F t, V t > ϵ ) (35) 

≥ (ϵ/ 2) · (1 − (1 − γ)N ). (36) 

Setting η(ϵ) = ( ϵ/ 2) · (1 − (1 − γ)N ) > 0 completes the proof. 

With the positive drift condition established, we can prove global convergence. 

Theorem D.1 Under Assumption 2, ABOM converges with probability 1 to the global optimum: 

f ∗

> t
> a.s.

−−→ f ∗ as t → ∞ . (37) 

Proof 3 By the martingale convergence theorem Hall & Heyde (2014), f ∗ 

> t

converges with proba-bility 1 to some random variable f ∗∞ ≥ f ∗. Assume for contradiction that f ∗∞ > f ∗ with positive 

16 Published as a conference paper at ICLR 2026 

probability. Then there exists ϵ > 0 such that Vt > ϵ for all sufficiently large t. Define the stopping time τk = inf {t ≥ k : Vt ≤ ϵ}.Consider the value function change from time k to τk:

Vk − Vτk = 

> τk−1

X

> t=k

(Vt − Vt+1 ). (38) 

Taking expectations and applying the law of iterated expectations: 

E[Vk − Vτk ] = E

"τk −1X

> t=k

E[Vt − Vt+1 | F t]

#

. (39) 

For t < τ k, we have Vt > ϵ , so by Lemma 2: 

E

"τk −1X

> t=k

E[Vt − Vt+1 | F t]

#

≥ η(ϵ) · E[τk − k]. (40) 

Thus: 

E[Vk] − E[Vτk ] ≥ η(ϵ) · E[τk − k]. (41) 

Since Vτk ≤ ϵ, we have: 

E[τk − k] ≤ E[Vk]

η(ϵ) < ∞. (42) 

This implies P(τk < ∞) = 1 , contradicting the assumption that Vt > ϵ for all sufficiently large t.Therefore, f ∗∞ = f ∗ with probability 1. 

Theorem D.1 establishes that ABOM converges with probability 1 to the global optimum under Assumption 2. The persistent application of dropout during inference, coupled with the adaptive pa-rameter learning mechanism, ensures that there exists a positive probability of generating offspring within an arbitrarily small neighborhood of the optimum at each iteration. 

Theoretical Limitation. Theorem D.1 establishes asymptotic convergence but not polynomial-time convergence. Convergence rate analysis (expected hitting time) for specific problems is one of the important research directions for the future. It is worth noting that our convergence analysis does not directly apply in cases where the global optimum lies on the boundary or where constraint handling results in a discontinuous feasible region. 

Theoretical Contributions. Our work establishes two theoretical contributions for meta black-box optimization: 1) We prove a novel exploration guarantee (Lemma 1) showing that attention-based MLP parameterization with dropout maintains persistent exploration capability. 2) We prove global convergence of ABOM with adaptive parameter learning (Theorem D.1). Crucially, this demon-strates that self-supervised parameter adaptation does not compromise convergence guarantees. This stands in contrast to existing neural network-parameterized methods such as GLHF Li et al. (2024) and B2Opt Li et al. (2025), which lack rigorous convergence analysis despite empirical success. These theoretical foundations provide ABOM’s reliability while preserving the flexibility of adap-tive optimization. 

E CONVERGENCE ANALYSIS OF PARAMETER ADAPTATION 

Fig. 6 shows the loss curves of parameter adaptation on the BBOB suite with [−100 , 100] 500 . De-spite the large search space and high dimensionality, the loss of parameter adaptation consistently decreases and converges across all test functions, with minimal variance across 30 independent runs. This empirical evidence validates our theoretical assumption of local convergence for parameter adaptation (Eq. 18), demonstrating that the self-supervised learning paradigm with AdamW opti-mizer remains stable even in challenging high-dimensional optimization scenarios. The consistent convergence behavior aligns with standard machine learning practices for training attention-based MLP architectures using gradient-based optimization, confirming the practical viability of our adap-tive parameter learning framework. 17 Published as a conference paper at ICLR 2026 0 5000 10000 15000 20000 

Function Evaluations (FEs) 

> 0
> 100000
> 200000
> 300000
> 400000
> Loss

Buche_Rastrigin     

> 05000 10000 15000 20000

Function Evaluations (FEs) 

> 0
> 100000
> 200000
> 300000
> 400000
> Loss

Attractive_Sector     

> 05000 10000 15000 20000

Function Evaluations (FEs) 

> 0
> 50000
> 100000
> 150000
> 200000
> 250000
> 300000
> 350000
> 400000
> Loss

Step_Ellipsoidal     

> 05000 10000 15000 20000

Function Evaluations (FEs) 

> 0
> 50000
> 100000
> 150000
> 200000
> 250000
> 300000
> 350000
> 400000
> Loss

Rosenbrock_original     

> 05000 10000 15000 20000

Function Evaluations (FEs) 

> 50000
> 100000
> 150000
> 200000
> 250000
> 300000
> 350000
> 400000
> Loss

Rosenbrock_rotated     

> 05000 10000 15000 20000

Function Evaluations (FEs) 

> 0
> 100000
> 200000
> 300000
> 400000
> Loss

Ellipsoidal_high_cond     

> 05000 10000 15000 20000

Function Evaluations (FEs) 

> 100000
> 200000
> 300000
> 400000
> Loss

Discus     

> 05000 10000 15000 20000

Function Evaluations (FEs) 

> 0
> 100000
> 200000
> 300000
> 400000
> Loss

Bent_Cigar     

> 05000 10000 15000 20000

Function Evaluations (FEs) 

> 0
> 100000
> 200000
> 300000
> 400000
> Loss

Sharp_Ridge     

> 05000 10000 15000 20000

Function Evaluations (FEs) 

> 0
> 100000
> 200000
> 300000
> 400000
> Loss

Different_Powers     

> 05000 10000 15000 20000

Function Evaluations (FEs) 

> 0
> 100000
> 200000
> 300000
> 400000
> Loss

Schaffers_high_cond     

> 05000 10000 15000 20000

Function Evaluations (FEs) 

> 50000
> 100000
> 150000
> 200000
> 250000
> 300000
> 350000
> 400000
> Loss

Composite_Grie_rosen     

> 05000 10000 15000 20000

Function Evaluations (FEs) 

> 0
> 50000
> 100000
> 150000
> 200000
> 250000
> 300000
> 350000
> 400000
> Loss

Schwefel     

> 05000 10000 15000 20000

Function Evaluations (FEs) 

> 250000
> 300000
> 350000
> 400000
> Loss

Gallagher_21Peaks     

> 05000 10000 15000 20000

Function Evaluations (FEs) 

> 250000
> 300000
> 350000
> 400000
> 450000
> Loss

Katsuura     

> 05000 10000 15000 20000

Function Evaluations (FEs) 

> 0
> 50000
> 100000
> 150000
> 200000
> 250000
> 300000
> 350000
> 400000
> Loss

Lunacek_bi_Rastrigin 

Figure 6: Loss curves of parameter adaptation on the BBOB suite with d = 500 . Each subplot de-picts the mean loss across 30 independent runs, with shaded regions representing standard deviation. 0 5000 10000 15000 20000 

Function Evaluations (FEs) 

0.0 

0.2 

0.4 

0.6 

0.8 

1.0 

> Normalized Costs

ABOM 

ABOM-NPA 

Figure 7: Convergence comparison be-tween ABOM and ABOM-NPA on BBOB suite with d = 500 , which shows normalized costs against function eval-uations over 30 independent runs. Fig. 7 presents the convergence behavior of ABOM and ABOM-NPA (no parameter adaptation). Both meth-ods demonstrate convergence in practice, which empiri-cally confirms that the convergence guarantee stems from the core mechanisms of elite preservation and dropout-enabled exploration rather than solely depending on pa-rameter adaptation. While our theoretical analysis (The-orem D.1) formally establishes global convergence for ABOM with parameter adaptation, the experimental com-parison reveals that the fundamental convergence proper-ties are maintained even without this component, suggest-ing that the theoretical framework could be extended to cover variants without parameter adaptation. This empir-ical observation aligns with the martingale convergence argument in Theorem D.1, where the supermartingale property E[f ∗

t+1 |F t] ≤ f ∗

t is primarily ensured by the elitism mechanism rather than parameter adaptation. 

F TASK CONFIGURATION 

Table 3 presents 24 instances of synthetic black-box optimization benchmarks (BBOB) with diverse characteristics and landscapes. Following the standard protocol of the benchmark platform Ma et al. (2023; 2025a), functions f1, f2, f3, f5, f15 , f16 , f17 , and f21 are designated as training 18 Published as a conference paper at ICLR 2026 Table 3: Overview of the BBOB suites.                                                  

> ID Function Characteristic Usage
> f1Sphere Separable
> Train
> f2Ellipsoidal Train
> f3Rastrigin Train
> f5Linear Slope Train
> f15 Rastrigin (non-separable) Multi-modal with adequate global structure
> Train
> f16 Weierstrass Train
> f17 Schaffers F7 Train
> f21 Gallagher’s Gaussian 101-me Peaks Multi-modal with weak global structure Train
> f4Buche-Rastrigin Separable Test
> f6Attractive Sector Low/moderate conditioning Test
> f7Step Ellipsoidal Test
> f8Rosenbrock, original Test
> f9Rosenbrock, rotated Test
> f10 Ellipsoidal High conditioning, unimodal Test
> f11 Discus Test
> f12 Bent Cigar Test
> f13 Sharp Ridge Test
> f14 Different Powers Test
> f18 Schaffers F7, ill-conditioned Multi-modal with adequate global structure Test
> f19 Composite Griewank-Rosenbrock F8F2 Test
> f20 Schwefel Multi-modal with weak global structure Test
> f22 Gallagher’s Gaussian 21-hi Peaks Test
> f23 Katsuura Test
> f24 Lunacek bi-Rastrigin Test

functions, while the remaining functions serve as test instances, ensuring a balanced distribution of optimization difficulty between the training and test sets. The maximum number of function evaluations is set to 20,000. All functions are defined over [−100 , 100] d, d = 30 /100 /500 .The UAV benchmarks comprise 56 terrain-based scenarios that represent realistic unmanned aerial vehicle path planning problems, each with 30 dimensions. The scenarios are divided into training and test sets of equal size (28 instances each), with test instances corresponding to even-numbered indices (0, 2, 4, . . . , 54). Following the standard protocol of the benchmark platform Ma et al. (2023; 2025a), the maximum number of function evaluations is set to 2,500. 

G BASELINES 

Since our ABOM is an evolution-based meta-black-box optimization (metaBBO) algorithm, we re-strict comparisons exclusively to evolution-based methods, excluding non-evolution-based methods such as Bayesian optimization. Furthermore, we omit LLM-based metaBBO methods Liu et al. (2025); Romera-Paredes et al. (2024); Yang et al. (2024) from our baselines, as they are tailored for specific task types and are not directly comparable to evolution-based general-purpose frameworks. To ensure a fair and reproducible comparison, all baselines are implemented using the source code provided by the official MetaBox platform Ma et al. (2023; 2025a). Detailed hyperparameter con-figurations for baselines are provided in Table 4, while the configuration of our proposed ABOM is summarized in Table 5. All results are reported as the mean and standard deviation over 30 indepen-dent runs, with a fixed population size of 20 across all trials. For traditional BBO methods, we adopt the hyperparameter settings recommended in the original pa-per, rather than performing a grid search or manual tuning. The design choice aligns with a core mo-tivation of adaptive optimization and metaBBO methods: to reduce the reliance on labor-intensive hyperparameter tuning. By using default settings, we ensure a fair and meaningful comparison that highlights the intrinsic advantages of adaptive strategies. 19 Published as a conference paper at ICLR 2026 Table 4: Detailed hyperparameter configurations of baselines. ub and lb denote the upper and lower bounds of the search space, respectively. randn (d) denotes sampling a d-dimensional vector from a standard normal distribution. All MetaBBO methods are trained on the same synthetic problem distribution as RLDEAFL Guo et al. (2025). 

Baseline Parameter Setting Traditional BBO methods 

RS — Uniform sampling within [lb, ub ]d Bergstra & Bengio (2012). PSO Inertia weight w Linearly decreased from 0.9 to 0.4 over itera-tions Kennedy & Eberhart (1995). Coefficients c1/c 2 2.0/2.0 Kennedy & Eberhart (1995) DE Mutation factor F 0.5 Storn & Price (1997) Crossover probability CR 0.5 Storn & Price (1997) Strategy DE/rand/1/bin Storn & Price (1997) 

Adaptive optimization variants 

SAHLPSO Adaptive parameters Parameter ranges follow those specified in the original paper Tao et al. (2021). JDE21 Adaptive parameters Parameter ranges follow those specified in the original paper Brest et al. (2021). CMAES Initial step size σ 0.3 × (ub − lb ) Hansen (2016) Initial mean μ μ = lb + randn (d) × (ub − lb ) Hansen (2016) 

MetaBBO methods (Training on BBOB or UAV training set) GLEET Training parameters Parameter configurations are consistent with the original paper Ma et al. (2024). RLDEAFL Training parameters Parameter configurations are consistent with the original paper Guo et al. (2025). LES Training parameters Parameter configurations are consistent with the original paper Lange et al. (2023b). GLHF Training parameters Parameter configurations are consistent with the original paper Li et al. (2024). 

Table 5: Hyperparameter configuration of ABOM. 

Parameter Setting 

Crossover dropout rate pC 0.95 Mutation dropout rate pM 0.95 Learning rate η of AdamW 1 × 10 −3

Attention dimension dA d

MLP hidden dimension dM 2⌊log 2(d)⌋

20 Published as a conference paper at ICLR 2026 

H COMPARISON WITH EPOM 0 200 400 600 800 1000 

Function Evaluations (FEs) 

> 0.0
> 0.2
> 0.4
> 0.6
> 0.8
> 1.0
> 1.2
> Normalized Reward R
> EPOM
> ABOM

Figure 8: Convergence comparison between ABOM and EPOM on Bipedal Walker task. This section conducts a performance comparison be-tween our method ABOM and EPOM, a recently proposed meta black-box optimization method that represents the current state of the art in zero-shot optimization Han et al. (2025). EPOM operates as a pre-trained optimization model that learns a gener-alizable mapping from task-specific features to op-timization strategies, thereby enabling zero-shot op-timization capabilities on previously unseen black-box problems. We evaluate ABOM and EPOM on the Bipedal Walker task, which requires optimizing a fully-connected neural network policy with d =874 parameters over k = 800 timesteps to enhance robotic locomotion control performance. To ensure a fair and reproducible comparison, we strictly adhere to the experimental protocol and parameter settings established in the original paper Han et al. (2025). ABOM utilizes the identical hyperparameters as those employed in our prior experiments (refer to Table 5 for details), maintaining consistency across evaluations. As demonstrated in Fig. 8, ABOM achieves significantly faster convergence to high-quality solutions, while EPOM exhibits premature convergence, underscoring the robustness and effectiveness of our method in challenging optimization scenarios. 

I SENSITIVITY ANALYSIS OF LEARNING RATE f4             

> f6
> f7
> f8
> f9
> f10
> f11
> f12
> f13
> f14
> f18
> f19
> f20
> f22
> f23
> f24
> Function ID
> 1 × 10 5
> 1 × 10 4
> 1 × 10 3
> 1 × 10 2
> Learning Rate
> 0.0
> 0.2
> 0.4
> 0.6
> 0.8
> 1.0
> Normalized Average Objective Value
> (a) Normalized Average Objective Value 05000 10000 15000 20000
> Function Evaluations (FEs)
> 0.0
> 0.2
> 0.4
> 0.6
> 0.8
> Normalized Loss  = 1 × 10 5
> = 1 × 10 4
> = 1 × 10 3
> = 1 × 10 2(b) Normalized loss convergence curves

Figure 9: Sensitivity analysis of learning rate η on the BBOB suite with d = 30 .Fig. 9 presents the sensitivity analysis of the learning rate of AdamW for ABOM’s parameter adapta-tion. The heatmap (Fig. 9(a)) shows optimization performance across different learning rates, while the loss curves (Fig. 9(b)) demonstrate the convergence behavior of the parameter adaptation. The loss exhibits stable convergence across the evaluated learning rate spectrum (Fig. 9(b)), em-pirically validating our theoretical assumption of local convergence for parameter adaptation (Eq. 18). However, as shown in Fig. 9(a), optimization performance varies significantly across learning rates. η = 1 × 10 −3 achieves the best balance between convergence speed and solution quality. This demonstrates that while convergent behavior of the loss is necessary for stable parameter adaptation, it does not guarantee optimal optimization performance. The choice of learning rate remains crucial for effective parameter adaptation. 

J PRELIMINARY GENERALIZATION ANALYSIS OF ABOM 

This section preliminarily explores the generalization capability of ABOM through pre-training on the STOP benchmark suite Xue et al. (2025). The STOP suite comprises 12 sequence transfer optimization problems, where each problem contains a series of source optimization tasks and one 21 Published as a conference paper at ICLR 2026 target optimization task. Based on the similarity between source and target tasks (measured by fitness landscape overlap and optimal solution alignment), the 12 problems are categorized into three groups: high similarity (STOP1–4), mixed similarity (STOP5–8), and low similarity (STOP9– 12). Detailed properties of the optimization tasks are provided in Xue et al. (2025). For experimental evaluation, each problem is instantiated with 10 source tasks under a maximum evaluation budget of 5,000 per task. We treat these source tasks as the training set and the target task as the test set. This setup spans diverse similarity scenarios between training and test sets, enabling a more comprehensive evaluation of ABOM’s generalization performance. We introduce ABOM-PT, a pre-trained variant of ABOM, where meta-optimization knowledge is distilled from the training set. Specifically, ABOM is executed on 10 source tasks for T = 250 iter-ations per task, generating 2500 prior training samples M = {(P (t) 

> k

, F (t) 

> k

) | P (t) 

> k

∈ RN ×d, F (t) 

> k

∈

RN , k = 1 , ..., K, t = 1 , ..., T }. The pre-training objective minimizes the prediction error of popu-lation evolution: 

min  

> W

Lpt =

> K

X 

> k=1
> T−1

X

> t=1

P (t+1)  

> k

− ABOM W (P (t) 

> k

, F (t) 

> k

) 2

, (43) where ABOM W predicts the next-generation population P (t+1)  

> k

from current population-fitness pairs. We optimized the Eq. (43) using AdamW with a learning rate of 1 × 10 −3 and a batch size of 256. The hyperparameters for parameter adaptation are consistent with those in Table 5. Table 6 presents the experimental results of ABOM and ABOM-PT on the STOP benchmark suite, revealing four key insights: 1) ABOM-PT outperforms ABOM in 9 of 12 problems, confirming the generalization capability of our method; 2) Under high-similarity conditions (STOP1-4), ABOM-PT achieves substantially better performance by effectively leveraging optimization knowledge from training tasks to the test task; 3) ABOM-PT underperforms on some mixed-similarity problems (such as STOP8), revealing limitations in handling complex task relationships; 4) Surprisingly, pre-training on low-similarity tasks (STOP9-12) consistently improves performance on the test task, demonstrating that even dissimilar training tasks contain valuable optimization knowledge that en-hances generalization capability. Table 6: Performance comparison of ABOM vs. ABOM-PT on the STOP suite over 30 independent runs, reported as the mean and standard deviation of objective values (lower is better).                                                                                               

> Problem Similarity ABOM ABOM-PT (mean ±std) (mean ±std) STOP1 High 1.08e+0 ±4.42e-1 4.73e-1 ±1.97e-1
> STOP2 High 1.92e-1 ±7.26e-2 2.61e-2 ±7.45e-4
> STOP3 High 1.20e+0 ±4.87e+0 1.71e-1 ±8.04e-3
> STOP4 High 2.52e-1 ±6.50e-3 2.08e-1 ±2.72e-3
> STOP5 Medium 2.79e+0 ±1.21e+1 1.28e-2 ±9.88e-6
> STOP6 Medium 1.06e+2 ±9.62e+2 1.01e+2 ±3.74e+2
> STOP7 Medium 5.27e-2 ±1.28e-2 6.84e-3 ±7.83e-5
> STOP8 Medium 3.60e+0 ±1.22e+1 5.39e+0 ±2.90e+1 STOP9 Low 1.75e-2 ±1.50e-4 3.84e-3 ±4.32e-6
> STOP10 Low 3.87e+1 ±5.49e+1 2.69e+1 ±4.61e+1
> STOP11 Low 5.02e+0 ±3.97e+1 6.20e-1 ±1.20e-1
> STOP12 Low 9.52e+2 ±1.38e+6 8.55e+1 ±1.20e+4
> −/≈/+9/3/0 -

K EXPERIMENTAL RESULTS 

Tables 7 and 8 show the mean and standard deviation over 30 runs for each baseline on the BBOB suite with d = 30 /100 . The convergence curves of the average normalized cost across all test functions for the BBOB suite, with dimensions d = 30 /100 /500 , are presented in Fig. 10, based on 30 independent runs. 22 Published as a conference paper at ICLR 2026 The convergence curves of cost (log scale) for the 28 UAV problems over 30 independent runs are shown in Fig. 11, Fig. 12, and Fig. 13. The boxplots of cost (log scale) over 30 independent runs for the 28 UAV problems are shown in Fig. 14, Fig. 15, and Fig. 16. Table 7: The comparison results of the baselines on the BBOB suite with d = 30 . All results are reported as the mean and standard deviation (mean ± std) over 30 independent runs. Symbols “ −”, “≈”, and “ +” imply that the corresponding baseline is significantly worse, similar, and better than ABOM on the Wilcoxon rank-sum test with 95% confidence level, respectively. The best results are indicated in bold , and the suboptimal results are underlined. 

Traditional BBO Adaptive Variants MetaBBO Ours 

ID RS PSO DE SAHLPSO JDE21 CMAES GLEET RLDEAFL LES GLHF ABOM 

f4 5.17e+5 

±1.25e+5 1.28e+5 

±3.87e+4 9.84e+3 

±1.80e+3 2.04e+5 

±2.43e+5 5.58e+3 

±4.39e+3 

3.25e+1 

±6.05e+0 

3.68e+4 

±3.44e+4 6.18e+3 

±3.89e+3 1.81e+6 

±3.30e+5 6.96e+5 

±4.08e+5 5.45e+2 

±2.95e+2 

f6 5.42e+7 

±7.85e+6 2.49e+5 

±2.45e+5 6.12e+4 

±7.08e+3 5.11e+6 

±1.05e+7 2.80e+4 

±1.19e+4 

5.33e+0 

±4.28e+0 

3.76e+4 

±2.82e+4 2.09e+4 

±1.24e+4 8.01e+7 

±8.30e+6 6.61e+7 

±1.58e+7 2.60e+2 

±2.64e+2 

f7 2.68e+5 

±4.35e+4 6.70e+4 

±1.85e+4 2.45e+4 

±4.99e+3 5.67e+4 

±5.23e+4 3.86e+3 

±1.59e+3 3.26e+5 

±7.09e+5 8.11e+3 

±5.56e+3 6.28e+3 

±4.18e+3 3.54e+5 

±3.62e+4 2.59e+5 

±4.79e+4 

5.58e+2 

±2.77e+2 

f8 1.45e+10 

±2.94e+9 1.23e+9 

±5.32e+8 1.27e+3 

±2.86e+3 2.46e+8 

±2.53e+8 7.85e+3 

±3.26e+4 5.63e+2 

±1.57e+2 1.29e+7 

±6.97e+7 1.04e+3 

±1.98e+3 3.82e+9 

±4.23e+8 4.02e+9 

±5.45e+8 

1.15e+2 

±1.56e+2 

f9 1.19e+10 

±2.13e+9 8.86e+8 

±2.27e+8 1.56e+4 

±1.53e+4 3.82e+7 

±3.65e+7 2.34e+4 

±5.40e+4 

2.48e+1 

±1.05e+0 

2.03e+4 

±5.28e+4 4.36e+4 

±1.42e+5 1.49e+3 

±2.12e+0 1.85e+2 

±1.69e+0 2.35e+3 

±5.30e+3 

f10 7.47e+8 

±1.56e+8 1.43e+8 

±6.28e+7 1.11e+8 

±2.29e+7 2.51e+8 

±3.13e+8 1.73e+7 

±1.32e+7 8.99e+6 

±4.14e+6 1.54e+7 

±2.64e+7 7.42e+6 

±3.12e+6 1.81e+9 

±4.37e+8 6.69e+8 

±3.01e+8 

9.72e+5 

±7.38e+5 

f11 1.12e+5 

±1.23e+4 8.82e+4 

±2.84e+4 1.04e+5 

±1.57e+4 9.90e+4 

±2.55e+4 7.32e+4 

±2.54e+4 3.55e+4 

±2.96e+4 3.23e+4 

±1.04e+4 8.57e+4 

±2.88e+4 8.99e+5 

±1.71e+6 6.72e+4 

±7.71e+3 

2.61e+4 

±1.01e+4 

f12 1.68e+15 

±3.30e+15 1.38e+11 

±2.12e+11 1.05e+9 

±4.85e+8 3.46e+18 

±1.40e+19 1.52e+9 

±2.24e+9 

1.03e+0 

±2.14e+0 

3.96e+10 

±3.27e+10 6.45e+8 

±1.79e+9 8.23e+19 

±7.42e+19 2.56e+17 

±5.16e+17 5.28e+7 

±1.45e+8 

f13 4.34e+4 

±2.36e+3 2.17e+4 

±2.49e+3 6.96e+2 

±1.15e+2 1.51e+4 

±5.51e+3 5.18e+2 

±4.89e+2 

1.09e+0 

±1.45e+0 

3.57e+3 

±3.05e+3 7.71e+2 

±1.81e+3 3.97e+4 

±1.40e+3 3.78e+4 

±2.41e+3 7.28e+1 

±3.07e+1 

f14 3.52e+4 

±5.49e+3 5.77e+3 

±1.86e+3 3.76e+3 

±7.40e+2 5.07e+3 

±6.19e+3 3.72e+2 

±1.91e+2 3.99e+0 

±6.73e+0 5.69e+2 

±4.04e+2 1.94e+2 

±8.73e+1 9.99e+4 

±2.17e+4 3.30e+4 

±1.75e+4 

3.46e-2 

±3.39e-2 

f18 1.42e+5 

±1.06e+5 9.43e+2 

±2.09e+2 6.03e+2 

±6.10e+1 8.89e+5 

±1.19e+6 5.61e+2 

±1.26e+2 3.36e+12 

±2.84e+11 5.79e+2 

±1.62e+2 5.21e+2 

±1.28e+2 2.48e+6 

±1.74e+6 5.18e+5 

±4.19e+5 

5.12e+2 

±1.37e+2 

f19 1.01e+6 

±1.89e+5 7.82e+4 

±1.98e+4 1.22e+1 

±3.78e+0 2.92e+3 

±2.84e+3 2.01e+1 

±1.97e+1 6.76e+0 

±7.40e-1 1.37e+1 

±8.35e+0 2.87e+1 

±3.03e+1 1.30e+3 

±1.27e+0 9.19e+0 

±5.91e+0 

2.48e-1 

±1.11e-3 

f20 1.24e+7 

±2.78e+6 9.79e+5 

±6.89e+5 -3.88e+1 

±2.75e+0 4.04e+3 

±1.62e+4 -6.29e+1 

±2.67e+0 -1.53e+1 

±9.73e+0 -3.97e+1 

±4.98e+0 -5.20e+1 

±5.06e+0 1.49e+3 

±2.37e+0 -4.10e+0 

±1.77e+0 

-6.57e+1 

±3.80e+0 

f22 8.66e+1 

±0.00e+0 8.66e+1 

±0.00e+0 8.66e+1 

±0.00e+0 8.66e+1 

±0.00e+0 8.66e+1 

±0.00e+0 8.66e+1 

±0.00e+0 8.66e+1 

±0.00e+0 8.66e+1 

±0.00e+0 1.19e+3 

±4.55e-13 8.66e+1 

±0.00e+0 

8.66e+1 

±0.00e+0 

f23 3.29e+0 

±3.96e-1 3.23e+0 

±3.82e-1 3.18e+0 

±4.56e-1 3.41e+0 

±4.94e-1 3.32e+0 

±3.92e-1 3.30e+0 

±3.68e-1 2.98e+0 

±3.34e-1 3.31e+0 

±5.37e-1 1.30e+3 

±3.11e-1 3.34e+0 

±3.70e-1 

3.01e-1 

±2.19e-1 

f24 1.46e+5 

±1.37e+4 3.84e+4 

±7.79e+3 3.23e+2 

±5.65e+1 1.22e+4 

±5.97e+3 5.70e+2 

±8.02e+2 2.58e+2 

±1.64e+1 3.98e+2 

±7.61e+1 7.08e+2 

±5.00e+2 5.35e+4 

±2.34e+3 6.11e+4 

±2.70e+3 

2.44e+2 

±2.37e+1 

−/≈/+ 15/1/0 15/1/0 15/1/0 15/1/0 15/1/0 10/1/5 15/1/0 15/1/0 15/0/1 14/1/1 -

23 Published as a conference paper at ICLR 2026 Table 8: The comparison results of the baselines on the BBOB suite with d = 100 . All results are reported as the mean and standard deviation (mean ± std) over 30 independent runs. Symbols “ −”, “≈”, and “ +” imply that the corresponding baseline is significantly worse, similar, and better than ABOM on the Wilcoxon rank-sum test with 95% confidence level, respectively. The best results are indicated in bold , and the suboptimal results are underlined. 

Traditional BBO Adaptive Variants MetaBBO Ours 

ID RS PSO DE SAHLPSO JDE21 CMAES GLEET RLDEAFL LES GLHF ABOM 

f4 9.64e+6 

±1.21e+6 1.83e+6 

±4.72e+5 7.23e+5 

±7.94e+4 2.49e+6 

±2.14e+6 2.82e+5 

±5.83e+4 

3.72e+3 

±9.84e+2 

3.77e+5 

±1.74e+5 2.89e+5 

±8.20e+4 1.14e+7 

±8.00e+5 9.66e+6 

±1.47e+6 9.72e+3 

±5.28e+3 

f6 6.11e+8 

±3.81e+7 4.76e+7 

±2.94e+7 1.03e+6 

±4.92e+5 4.50e+7 

±3.58e+7 7.16e+5 

±1.07e+6 

2.15e+4 

±4.87e+3 

4.27e+5 

±9.26e+5 1.96e+5 

±9.09e+4 5.71e+8 

±1.63e+7 5.45e+8 

±2.78e+7 7.92e+4 

±3.49e+4 

f7 1.75e+6 

±9.77e+4 6.23e+5 

±6.59e+4 4.94e+5 

±3.66e+4 4.76e+5 

±2.10e+5 9.32e+4 

±2.85e+4 8.81e+3 

±2.97e+3 7.92e+4 

±2.07e+4 1.17e+5 

±2.87e+4 1.13e+6 

±6.30e+4 1.08e+6 

±8.55e+4 

6.23e+3 

±1.50e+3 

f8 4.33e+11 

±3.31e+10 8.71e+10 

±1.59e+10 2.67e+8 

±5.05e+7 2.65e+10 

±1.53e+10 4.60e+9 

±4.18e+9 5.16e+3 

±5.73e+3 1.41e+8 

±1.39e+8 3.79e+9 

±3.66e+9 5.24e+10 

±2.10e+9 5.30e+10 

±2.68e+9 

3.84e+3 

±5.03e+3 

f9 2.87e+11 

±2.82e+10 7.21e+10 

±1.21e+10 1.53e+9 

±4.45e+8 1.34e+9 

±5.55e+8 4.97e+8 

±4.42e+8 5.83e+4 

±1.89e+4 6.37e+7 

±2.21e+7 3.41e+8 

±2.71e+8 2.96e+3 

±2.16e+1 

6.43e+2 

±4.10e-1 

1.13e+5 

±2.79e+5 

f10 7.88e+9 

±7.69e+8 1.97e+9 

±3.14e+8 2.30e+9 

±2.58e+8 1.88e+9 

±9.32e+8 4.37e+8 

±1.37e+8 1.20e+8 

±3.66e+7 2.55e+8 

±8.80e+7 2.07e+8 

±8.93e+7 6.53e+9 

±5.19e+8 5.63e+9 

±8.08e+8 

6.65e+7 

±1.48e+7 

f11 4.30e+5 

±2.62e+4 4.12e+5 

±5.51e+4 4.35e+5 

±3.31e+4 2.99e+5 

±5.28e+4 3.78e+5 

±4.03e+4 9.10e+5 

±6.26e+5 

1.97e+5 

±3.31e+4 

2.02e+5 

±4.91e+4 1.15e+6 

±1.40e+6 2.07e+5 

±8.84e+3 3.48e+5 

±6.24e+4 

f12 1.84e+22 

±2.12e+22 7.09e+15 

±3.37e+16 6.78e+13 

±6.93e+13 2.77e+22 

±9.39e+22 5.29e+12 

±8.04e+12 

8.76e+8 

±5.66e+8 

2.84e+11 

±1.10e+11 4.77e+11 

±6.81e+11 6.99e+22 

±5.86e+22 3.75e+21 

±9.78e+21 3.97e+9 

±1.31e+10 

f13 1.08e+5 

±2.50e+3 6.70e+4 

±4.61e+3 2.86e+4 

±1.90e+3 5.28e+4 

±1.10e+4 2.32e+4 

±6.09e+3 

1.09e+2 

±2.35e+1 

1.69e+4 

±3.85e+3 2.31e+4 

±4.78e+3 8.37e+4 

±1.15e+3 8.14e+4 

±1.57e+3 3.65e+2 

±1.14e+2 

f14 3.10e+5 

±3.56e+4 4.73e+4 

±9.85e+3 6.79e+4 

±6.41e+3 5.84e+4 

±5.22e+4 8.14e+3 

±2.57e+3 1.53e+3 

±3.75e+2 4.62e+3 

±1.97e+3 4.89e+3 

±1.58e+3 2.60e+5 

±2.62e+4 2.16e+5 

±3.70e+4 

3.33e+2 

±1.35e+2 

f18 5.81e+7 

±2.84e+7 6.42e+3 

±8.93e+3 1.59e+4 

±8.45e+3 7.27e+7 

±3.12e+8 1.04e+4 

±6.34e+3 2.82e+3 

±3.60e+3 4.63e+3 

±6.79e+3 2.68e+4 

±4.78e+4 2.49e+7 

±1.01e+7 1.12e+7 

±6.30e+6 

2.46e+2 

±4.41e+1 

f19 7.48e+6 

±5.96e+5 1.77e+6 

±2.80e+5 3.42e+4 

±7.96e+3 2.87e+4 

±1.42e+4 1.06e+4 

±8.60e+3 2.93e+1 

±2.54e+0 1.69e+3 

±7.41e+2 6.34e+3 

±6.13e+3 5.06e+2 

±1.65e+0 1.54e+1 

±1.16e+1 

2.50e-1 

±7.63e-5 

f20 1.16e+8 

±5.88e+6 3.44e+7 

±6.40e+6 3.05e+4 

±3.04e+4 2.33e+5 

±2.88e+5 7.12e+4 

±1.44e+5 -3.04e+0 

±1.72e+0 -1.92e+1 

±5.28e+0 7.93e+4 

±1.51e+5 2.10e+3 

±8.78e-1 9.08e-1 

±5.31e-1 

-5.60e+1 

±3.36e+0 

f22 8.66e+1 

±0.00e+0 8.66e+1 

±0.00e+0 8.66e+1 

±0.00e+0 8.66e+1 

±0.00e+0 8.66e+1 

±0.00e+0 8.66e+1 

±0.00e+0 8.66e+1 

±0.00e+0 8.66e+1 

±0.00e+0 1.29e+3 

±4.55e-13 8.66e+1 

±0.00e+0 

8.66e+1 

±0.00e+0 

f23 4.85e+0 

±3.86e-1 4.87e+0 

±2.39e-1 4.90e+0 

±3.87e-1 4.80e+0 

±4.32e-1 4.85e+0 

±2.27e-1 7.11e+0 

±6.07e-1 4.84e+0 

±3.44e-1 4.66e+0 

±6.00e-1 2.11e+3 

±2.98e-1 4.88e+0 

±3.51e-1 

4.61e+0 

±4.11e-1 

f24 9.01e+5 

±3.01e+4 4.31e+5 

±3.66e+4 2.03e+4 

±1.26e+4 1.58e+5 

±5.12e+4 3.36e+4 

±1.53e+4 1.21e+3 

±7.02e+1 9.89e+3 

±1.84e+3 3.66e+4 

±1.64e+4 2.26e+5 

±3.33e+3 2.35e+5 

±3.69e+3 

1.05e+3 

±3.56e+1 

−/≈/+ 14/2/0 14/2/0 14/2/0 13/2/1 14/2/0 9/2/5 13/2/1 13/2/1 15/0/1 12/2/2 -

24 Published as a conference paper at ICLR 2026 0 2500 5000 7500 10000 12500 15000 17500 20000 

Function Evaluations (FEs) 

0.2 

0.4 

0.6 

0.8 

1.0 

> Normalized Costs

GLHF 

GLEET 

RLDEAFL 

LES 

ABOM 

CMAES 

SAHLPSO 

PSO 

DE 

JDE21 

Random_search 

(a) d = 30 0 2500 5000 7500 10000 12500 15000 17500 20000 

Function Evaluations (FEs) 

0.2 

0.4 

0.6 

0.8 

1.0 

> Normalized Costs

GLHF 

GLEET 

RLDEAFL 

LES 

ABOM 

CMAES 

SAHLPSO 

PSO 

DE 

JDE21 

Random_search 

(b) d = 100 0 2500 5000 7500 10000 12500 15000 17500 20000 

Function Evaluations (FEs) 

0.2 

0.4 

0.6 

0.8 

1.0 

> Normalized Costs

GLHF 

GLEET 

RLDEAFL 

LES 

ABOM 

CMAES 

SAHLPSO 

PSO 

DE 

JDE21 

Random_search 

(c) d = 500 

Figure 10: Convergence curves of the average normalized cost across all test functions in the BBOB suite, with d = 30 /100 /500 , over 30 independent runs. The cost values are min-max normalized per function to ensure comparability. Each subplot displays the performance trend, highlighting the algorithm’s scalability as the dimensionality increases. 25 Published as a conference paper at ICLR 2026 0 500 1000 1500 2000 2500 

FEs 

10.2 

10.4 

10.6 

10.8 

11.0 

11.2 

11.4 

11.6 

11.8 

> log cost

GLHF 

GLEET 

RLDEAFL 

LES 

ABOM 

CMAES 

SAHLPSO 

PSO 

DE 

JDE21 

Random_search 

(a) Terrain 2 0 500 1000 1500 2000 2500 

FEs 

10.25 

10.50 

10.75 

11.00 

11.25 

11.50 

11.75 

> log cost

GLHF 

GLEET 

RLDEAFL 

LES 

ABOM 

CMAES 

SAHLPSO 

PSO 

DE 

JDE21 

Random_search (b) Terrain 4 0 500 1000 1500 2000 2500 

FEs 

10.0 

10.2 

10.4 

10.6 

10.8 

11.0 

11.2 

11.4 

> log cost

GLHF 

GLEET 

RLDEAFL 

LES 

ABOM 

CMAES 

SAHLPSO 

PSO 

DE 

JDE21 

Random_search 

(c) Terrain 6 0 500 1000 1500 2000 2500 

FEs 

10.0 

10.2 

10.4 

10.6 

10.8 

11.0 

11.2 

11.4 

> log cost

GLHF 

GLEET 

RLDEAFL 

LES 

ABOM 

CMAES 

SAHLPSO 

PSO 

DE 

JDE21 

Random_search (d) Terrain 8 0 500 1000 1500 2000 2500 

FEs 

8.5 

9.0 

9.5 

10.0 

10.5 

11.0 

11.5 

> log cost

GLHF 

GLEET 

RLDEAFL 

LES 

ABOM 

CMAES 

SAHLPSO 

PSO 

DE 

JDE21 

Random_search 

(e) Terrain 10 0 500 1000 1500 2000 2500 

FEs 

8.5 

9.0 

9.5 

10.0 

10.5 

11.0 

11.5 

> log cost

GLHF 

GLEET 

RLDEAFL 

LES 

ABOM 

CMAES 

SAHLPSO 

PSO 

DE 

JDE21 

Random_search (f) Terrain 12 0 500 1000 1500 2000 2500 

FEs 

10.25 

10.50 

10.75 

11.00 

11.25 

11.50 

11.75 

> log cost

GLHF 

GLEET 

RLDEAFL 

LES 

ABOM 

CMAES 

SAHLPSO 

PSO 

DE 

JDE21 

Random_search 

(g) Terrain 14 0 500 1000 1500 2000 2500 

FEs 

9.5 

10.0 

10.5 

11.0 

11.5 

> log cost

GLHF 

GLEET 

RLDEAFL 

LES 

ABOM 

CMAES 

SAHLPSO 

PSO 

DE 

JDE21 

Random_search (h) Terrain 16 

Figure 11: Convergence curves of cost (log scale) for UAV problems (Terrain 2 to 16). 26 Published as a conference paper at ICLR 2026 0 500 1000 1500 2000 2500 

FEs 

10.0 

10.2 

10.4 

10.6 

10.8 

11.0 

11.2 

11.4 

> log cost

GLHF 

GLEET 

RLDEAFL 

LES 

ABOM 

CMAES 

SAHLPSO 

PSO 

DE 

JDE21 

Random_search 

(a) Terrain 18 0 500 1000 1500 2000 2500 

FEs 

8.5 

9.0 

9.5 

10.0 

10.5 

11.0 

11.5 

> log cost

GLHF 

GLEET 

RLDEAFL 

LES 

ABOM 

CMAES 

SAHLPSO 

PSO 

DE 

JDE21 

Random_search (b) Terrain 20 0 500 1000 1500 2000 2500 

FEs 

10.00 

10.25 

10.50 

10.75 

11.00 

11.25 

11.50 

11.75 

> log cost

GLHF 

GLEET 

RLDEAFL 

LES 

ABOM 

CMAES 

SAHLPSO 

PSO 

DE 

JDE21 

Random_search 

(c) Terrain 22 0 500 1000 1500 2000 2500 

FEs 

10.4 

10.6 

10.8 

11.0 

11.2 

11.4 

11.6 

> log cost

GLHF 

GLEET 

RLDEAFL 

LES 

ABOM 

CMAES 

SAHLPSO 

PSO 

DE 

JDE21 

Random_search (d) Terrain 24 0 500 1000 1500 2000 2500 

FEs 

10.25 

10.50 

10.75 

11.00 

11.25 

11.50 

11.75 

> log cost

GLHF 

GLEET 

RLDEAFL 

LES 

ABOM 

CMAES 

SAHLPSO 

PSO 

DE 

JDE21 

Random_search 

(e) Terrain 26 0 500 1000 1500 2000 2500 

FEs 

10.00 

10.25 

10.50 

10.75 

11.00 

11.25 

11.50 

11.75 

> log cost

GLHF 

GLEET 

RLDEAFL 

LES 

ABOM 

CMAES 

SAHLPSO 

PSO 

DE 

JDE21 

Random_search (f) Terrain 28 0 500 1000 1500 2000 2500 

FEs 

10.0 

10.5 

11.0 

11.5 

12.0 

> log cost

GLHF 

GLEET 

RLDEAFL 

LES 

ABOM 

CMAES 

SAHLPSO 

PSO 

DE 

JDE21 

Random_search 

(g) Terrain 30 0 500 1000 1500 2000 2500 

FEs 

10.0 

10.2 

10.4 

10.6 

10.8 

11.0 

11.2 

11.4 

> log cost

GLHF 

GLEET 

RLDEAFL 

LES 

ABOM 

CMAES 

SAHLPSO 

PSO 

DE 

JDE21 

Random_search (h) Terrain 32 0 500 1000 1500 2000 2500 

FEs 

10.2 

10.4 

10.6 

10.8 

11.0 

11.2 

11.4 

11.6 

11.8 

> log cost

GLHF 

GLEET 

RLDEAFL 

LES 

ABOM 

CMAES 

SAHLPSO 

PSO 

DE 

JDE21 

Random_search 

(i) Terrain 34 0 500 1000 1500 2000 2500 

FEs 

10.25 

10.50 

10.75 

11.00 

11.25 

11.50 

11.75 

12.00 

> log cost

GLHF 

GLEET 

RLDEAFL 

LES 

ABOM 

CMAES 

SAHLPSO 

PSO 

DE 

JDE21 

Random_search (j) Terrain 36 

Figure 12: Convergence curves of cost (log scale) for UAV problems (Terrain 18 to 36). 27 Published as a conference paper at ICLR 2026 0 500 1000 1500 2000 2500 

FEs 

10.25 

10.50 

10.75 

11.00 

11.25 

11.50 

11.75 

> log cost

GLHF 

GLEET 

RLDEAFL 

LES 

ABOM 

CMAES 

SAHLPSO 

PSO 

DE 

JDE21 

Random_search 

(a) Terrain 38 0 500 1000 1500 2000 2500 

FEs 

10.00 

10.25 

10.50 

10.75 

11.00 

11.25 

11.50 

11.75 

> log cost

GLHF 

GLEET 

RLDEAFL 

LES 

ABOM 

CMAES 

SAHLPSO 

PSO 

DE 

JDE21 

Random_search (b) Terrain 40 0 500 1000 1500 2000 2500 

FEs 

9.0 

9.5 

10.0 

10.5 

11.0 

11.5 

> log cost

GLHF 

GLEET 

RLDEAFL 

LES 

ABOM 

CMAES 

SAHLPSO 

PSO 

DE 

JDE21 

Random_search 

(c) Terrain 42 0 500 1000 1500 2000 2500 

FEs 

10.0 

10.5 

11.0 

11.5 

> log cost

GLHF 

GLEET 

RLDEAFL 

LES 

ABOM 

CMAES 

SAHLPSO 

PSO 

DE 

JDE21 

Random_search (d) Terrain 44 0 500 1000 1500 2000 2500 

FEs 

10.4 

10.6 

10.8 

11.0 

11.2 

11.4 

11.6 

> log cost

GLHF 

GLEET 

RLDEAFL 

LES 

ABOM 

CMAES 

SAHLPSO 

PSO 

DE 

JDE21 

Random_search 

(e) Terrain 46 0 500 1000 1500 2000 2500 

FEs 

9.0 

9.5 

10.0 

10.5 

11.0 

11.5 

> log cost

GLHF 

GLEET 

RLDEAFL 

LES 

ABOM 

CMAES 

SAHLPSO 

PSO 

DE 

JDE21 

Random_search (f) Terrain 48 0 500 1000 1500 2000 2500 

FEs 

9.0 

9.5 

10.0 

10.5 

11.0 

11.5 

12.0 

> log cost

GLHF 

GLEET 

RLDEAFL 

LES 

ABOM 

CMAES 

SAHLPSO 

PSO 

DE 

JDE21 

Random_search 

(g) Terrain 50 0 500 1000 1500 2000 2500 

FEs 

9.0 

9.5 

10.0 

10.5 

11.0 

11.5 

> log cost

GLHF 

GLEET 

RLDEAFL 

LES 

ABOM 

CMAES 

SAHLPSO 

PSO 

DE 

JDE21 

Random_search (h) Terrain 52 0 500 1000 1500 2000 2500 

FEs 

9.0 

9.5 

10.0 

10.5 

11.0 

11.5 

> log cost

GLHF 

GLEET 

RLDEAFL 

LES 

ABOM 

CMAES 

SAHLPSO 

PSO 

DE 

JDE21 

Random_search 

(i) Terrain 54 0 500 1000 1500 2000 2500 

FEs 

10.0 

10.5 

11.0 

11.5 

> log cost

GLHF 

GLEET 

RLDEAFL 

LES 

ABOM 

CMAES 

SAHLPSO 

PSO 

DE 

JDE21 

Random_search (j) Terrain 56 

Figure 13: Convergence curves of cost (log scale) for UAV problems (Terrain 38 to 56). 28 Published as a conference paper at ICLR 2026 GLHF 

GLEET 

RLDEAFL 

LES 

ABOM 

CMAES 

SAHLPSO 

PSO 

DE 

JDE21 

Random_search 

Agents 

20000 

30000 

40000 

50000 

60000 

70000 

80000 

90000 

100000 

> Terrain 2 Cost Boxplots

(a) Terrain 2 GLHF 

GLEET 

RLDEAFL 

LES 

ABOM 

CMAES 

SAHLPSO 

PSO 

DE 

JDE21 

Random_search 

Agents 

20000 

30000 

40000 

50000 

60000 

70000 

80000  

> Terrain 4 Cost Boxplots

(b) Terrain 4 GLHF 

GLEET 

RLDEAFL 

LES 

ABOM 

CMAES 

SAHLPSO 

PSO 

DE 

JDE21 

Random_search 

Agents 

20000 

30000 

40000 

50000 

60000 

70000 

> Terrain 6 Cost Boxplots

(c) Terrain 6 GLHF 

GLEET 

RLDEAFL 

LES 

ABOM 

CMAES 

SAHLPSO 

PSO 

DE 

JDE21 

Random_search 

Agents 

20000 

30000 

40000 

50000 

60000 

70000  

> Terrain 8 Cost Boxplots

(d) Terrain 8 GLHF 

GLEET 

RLDEAFL 

LES 

ABOM 

CMAES 

SAHLPSO 

PSO 

DE 

JDE21 

Random_search 

Agents 

10000 

20000 

30000 

40000 

50000 

60000 

70000 

> Terrain 10 Cost Boxplots

(e) Terrain 10 GLHF 

GLEET 

RLDEAFL 

LES 

ABOM 

CMAES 

SAHLPSO 

PSO 

DE 

JDE21 

Random_search 

Agents 

10000 

20000 

30000 

40000 

50000  

> Terrain 12 Cost Boxplots

(f) Terrain 12 GLHF 

GLEET 

RLDEAFL 

LES 

ABOM 

CMAES 

SAHLPSO 

PSO 

DE 

JDE21 

Random_search 

Agents 

20000 

30000 

40000 

50000 

60000 

70000 

80000 

90000 

> Terrain 14 Cost Boxplots

(g) Terrain 14 GLHF 

GLEET 

RLDEAFL 

LES 

ABOM 

CMAES 

SAHLPSO 

PSO 

DE 

JDE21 

Random_search 

Agents 

10000 

20000 

30000 

40000 

50000  

> Terrain 16 Cost Boxplots

(h) Terrain 16 GLHF 

GLEET 

RLDEAFL 

LES 

ABOM 

CMAES 

SAHLPSO 

PSO 

DE 

JDE21 

Random_search 

Agents 

20000 

30000 

40000 

50000 

60000 

> Terrain 18 Cost Boxplots

(i) Terrain 18 GLHF 

GLEET 

RLDEAFL 

LES 

ABOM 

CMAES 

SAHLPSO 

PSO 

DE 

JDE21 

Random_search 

Agents 

10000 

20000 

30000 

40000 

50000 

60000 

70000  

> Terrain 20 Cost Boxplots

(j) Terrain 20 

Figure 14: Boxplots of cost (log scale) over 30 runs for UAV problems (Terrain 2 to 20). 29 Published as a conference paper at ICLR 2026 GLHF 

GLEET 

RLDEAFL 

LES 

ABOM 

CMAES 

SAHLPSO 

PSO 

DE 

JDE21 

Random_search 

Agents 

20000 

30000 

40000 

50000 

60000 

70000 

80000 

90000 

100000 

> Terrain 22 Cost Boxplots

(a) Terrain 22 GLHF 

GLEET 

RLDEAFL 

LES 

ABOM 

CMAES 

SAHLPSO 

PSO 

DE 

JDE21 

Random_search 

Agents 

30000 

40000 

50000 

60000 

70000 

80000  

> Terrain 24 Cost Boxplots

(b) Terrain 24 GLHF 

GLEET 

RLDEAFL 

LES 

ABOM 

CMAES 

SAHLPSO 

PSO 

DE 

JDE21 

Random_search 

Agents 

20000 

30000 

40000 

50000 

60000 

70000 

80000 

> Terrain 26 Cost Boxplots

(c) Terrain 26 GLHF 

GLEET 

RLDEAFL 

LES 

ABOM 

CMAES 

SAHLPSO 

PSO 

DE 

JDE21 

Random_search 

Agents 

20000 

40000 

60000 

80000 

100000  

> Terrain 28 Cost Boxplots

(d) Terrain 28 GLHF 

GLEET 

RLDEAFL 

LES 

ABOM 

CMAES 

SAHLPSO 

PSO 

DE 

JDE21 

Random_search 

Agents 

20000 

30000 

40000 

50000 

60000 

70000 

80000 

> Terrain 30 Cost Boxplots

(e) Terrain 30 GLHF 

GLEET 

RLDEAFL 

LES 

ABOM 

CMAES 

SAHLPSO 

PSO 

DE 

JDE21 

Random_search 

Agents 

20000 

30000 

40000 

50000 

60000  

> Terrain 32 Cost Boxplots

(f) Terrain 32 GLHF 

GLEET 

RLDEAFL 

LES 

ABOM 

CMAES 

SAHLPSO 

PSO 

DE 

JDE21 

Random_search 

Agents 

30000 

40000 

50000 

60000 

70000 

80000 

90000 

> Terrain 34 Cost Boxplots

(g) Terrain 34 GLHF 

GLEET 

RLDEAFL 

LES 

ABOM 

CMAES 

SAHLPSO 

PSO 

DE 

JDE21 

Random_search 

Agents 

40000 

60000 

80000 

100000  

> Terrain 36 Cost Boxplots

(h) Terrain 36 GLHF 

GLEET 

RLDEAFL 

LES 

ABOM 

CMAES 

SAHLPSO 

PSO 

DE 

JDE21 

Random_search 

Agents 

30000 

40000 

50000 

60000 

70000 

80000 

> Terrain 38 Cost Boxplots

(i) Terrain 38 GLHF 

GLEET 

RLDEAFL 

LES 

ABOM 

CMAES 

SAHLPSO 

PSO 

DE 

JDE21 

Random_search 

Agents 

30000 

40000 

50000 

60000 

70000 

80000  

> Terrain 40 Cost Boxplots

(j) Terrain 40 

Figure 15: Boxplots of cost (log scale) over 30 runs for UAV problems (Terrain 22 to 40). 30 Published as a conference paper at ICLR 2026 GLHF 

GLEET 

RLDEAFL 

LES 

ABOM 

CMAES 

SAHLPSO 

PSO 

DE 

JDE21 

Random_search 

Agents 

10000 

20000 

30000 

40000 

50000 

60000 

70000 

80000 

90000 

> Terrain 42 Cost Boxplots

(a) Terrain 42 GLHF 

GLEET 

RLDEAFL 

LES 

ABOM 

CMAES 

SAHLPSO 

PSO 

DE 

JDE21 

Random_search 

Agents 

15000 

20000 

25000 

30000 

35000 

40000  

> Terrain 44 Cost Boxplots

(b) Terrain 44 GLHF 

GLEET 

RLDEAFL 

LES 

ABOM 

CMAES 

SAHLPSO 

PSO 

DE 

JDE21 

Random_search 

Agents 

30000 

40000 

50000 

60000 

70000 

80000 

> Terrain 46 Cost Boxplots

(c) Terrain 46 GLHF 

GLEET 

RLDEAFL 

LES 

ABOM 

CMAES 

SAHLPSO 

PSO 

DE 

JDE21 

Random_search 

Agents 

10000 

20000 

30000 

40000 

50000 

60000 

70000 

80000  

> Terrain 48 Cost Boxplots

(d) Terrain 48 GLHF 

GLEET 

RLDEAFL 

LES 

ABOM 

CMAES 

SAHLPSO 

PSO 

DE 

JDE21 

Random_search 

Agents 

10000 

20000 

30000 

40000 

50000 

60000 

70000 

> Terrain 50 Cost Boxplots

(e) Terrain 50 GLHF 

GLEET 

RLDEAFL 

LES 

ABOM 

CMAES 

SAHLPSO 

PSO 

DE 

JDE21 

Random_search 

Agents 

20000 

40000 

60000 

80000  

> Terrain 52 Cost Boxplots

(f) Terrain 52 GLHF 

GLEET 

RLDEAFL 

LES 

ABOM 

CMAES 

SAHLPSO 

PSO 

DE 

JDE21 

Random_search 

Agents 

20000 

40000 

60000 

80000 

> Terrain 54 Cost Boxplots

(g) Terrain 54 GLHF 

GLEET 

RLDEAFL 

LES 

ABOM 

CMAES 

SAHLPSO 

PSO 

DE 

JDE21 

Random_search 

Agents 

20000 

25000 

30000 

35000 

40000 

45000 

50000  

> Terrain 56 Cost Boxplots

(h) Terrain 56 

Figure 16: Boxplots of cost (log scale) over 30 runs for UAV problems (Terrain 42 to 56). 31
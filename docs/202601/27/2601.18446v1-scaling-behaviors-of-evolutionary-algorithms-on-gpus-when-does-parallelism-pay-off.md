# Scaling Behaviors of Evolutionary Algorithms on GPUs: When Does Parallelism Pay Off?
# 进化算法在 GPU 上的扩展行为：并行化何时产生效益？

**Authors**: Xinmeng Yu, Tao Jiang, Ran Cheng, Yaochu Jin, Kay Chen Tan \\
**Date**: 2026-01-26 \\
**PDF**: https://arxiv.org/pdf/2601.18446v1 \\
**Tags**: <span class="tag-label tag-blue">精读区</span> <span class="tag-label tag-pink">keyword:EOH</span> \\
**Score**: 8.0 \\
**Evidence**: empirical study of evolutionary algorithms and their scaling behaviors \\

---

## Abstract
Evolutionary algorithms (EAs) are increasingly implemented on graphics processing units (GPUs) to leverage parallel processing capabilities for enhanced efficiency. However, existing studies largely emphasize the raw speedup obtained by porting individual algorithms from CPUs to GPUs. Consequently, these studies offer limited insight into when and why GPU parallelism fundamentally benefits EAs. To address this gap, we investigate how GPU parallelism alters the behavior of EAs beyond simple acceleration metrics. We conduct a systematic empirical study of 16 representative EAs on 30 benchmark problems. Specifically, we compare CPU and GPU executions across a wide range of problem dimensionalities and population sizes. Our results reveal that the impact of GPU acceleration is highly heterogeneous and depends strongly on algorithmic structure. We further demonstrate that conventional fixed-budget evaluation based on the number of function evaluations (FEs) is inadequate for GPU execution. In contrast, fixed-time evaluation uncovers performance characteristics that are unobservable under small or practically constrained FE budgets, particularly for adaptive and exploration-oriented algorithms. Moreover, we identify distinct scaling regimes in which GPU parallelism is beneficial, saturates, or degrades as problem dimensionality and population size increase. Crucially, we show that large populations enabled by GPUs not only improve hardware utilization but also reveal algorithm-specific convergence and diversity dynamics that are difficult to observe under CPU-constrained settings. Consequently, our findings indicate that GPU parallelism is not strictly an implementation detail, but a pivotal factor that influences how EAs should be evaluated, compared, and designed for modern computing platforms.

## 摘要
进化算法（EAs）越来越多地在

---

## 论文详细总结（自动生成）

这篇论文对进化算法（EAs）在 GPU 上的并行化行为进行了系统性的深入研究，探讨了并行化不仅仅是“加速工具”，更是改变算法行为和评估标准的关键因素。以下是详细的结构化总结：

### 1. 核心问题与整体含义（研究动机）
*   **核心问题**：现有的 GPU 加速进化算法研究大多只关注从 CPU 迁移到 GPU 后的“原始加速比”（Speedup），而忽略了并行化如何从根本上改变算法的搜索行为、可扩展性以及评估逻辑。
*   **研究动机**：
    *   **异质性**：不同算法结构（数据依赖、同步需求）对 GPU 的利用率差异巨大。
    *   **评估标准过时**：传统的“固定函数评价次数（Fixed-FE）”在 GPU 环境下可能无法反映真实性能，因为 GPU 可以在相同时间内完成更多评价。
    *   **种群规模限制**：GPU 极大地放宽了种群规模限制，但这是否仅仅提高了硬件利用率，还是诱发了新的演化动力学？

### 2. 论文提出的方法论
*   **核心思想**：通过大规模实证研究，将 GPU 并行化视为影响算法设计和评估的枢纽因素，而非单纯的实现细节。
*   **关键技术细节**：
    *   **算法分类研究**：将 16 种算法分为单目标（SOEAs，如 PSO, DE, CMA-ES）和多目标（MOEAs，如 NSGA-II, MOEA/D, HypE）。
    *   **评估框架**：提出从“解的质量”和“计算效率”两个维度构建帕累托前沿（Performance Pareto Front），对比 CPU 与 GPU 在不同配置下的表现。
    *   **固定时间评估（Fixed-time Evaluation）**：提倡在相同墙钟时间内比较算法，以揭示在有限 FE 预算下被掩盖的算法潜力。
    *   **扩展性分析**：系统性地改变问题维度（$D$）和种群规模（$N$），识别并行化的受益区、饱和区和退化区。

### 3. 实验设计
*   **算法对象**：共 16 种。包括 PSO, CSO, DE, SaDE, GA, CMA-ES, IPOP-CMA-ES（单目标）；NSGA-II, NSGA-III, SPEA2, IBEA, HypE, MOEA/D, RVEA, LMOCSO（多目标）。
*   **数据集/场景**：共 30 个测试问题。
    *   **数值优化 ($f_a$)**：CEC2022 (F1-F5), Ackley, Sphere 等经典函数；DTLZ (1-7) 和 ZDT (1-3) 多目标套件。
    *   **神经演化 ($f_b$)**：基于 Brax 物理引擎的机器人控制任务（如 Halfcheetah, Hopper），并扩展为多目标版本。
*   **Benchmark 逻辑**：对比 Intel Xeon CPU 与 NVIDIA RTX 2080 Ti / 3090 GPU 的表现。

### 4. 资源与算力
*   **GPU 型号**：NVIDIA GeForce RTX 3090 (24GB) 和 RTX 2080 Ti (11GB)。
*   **CPU 型号**：Intel Xeon Gold 6226R (16核, 2.90GHz)。
*   **软件框架**：所有实验均基于 **EvoX** 分布式 GPU 加速框架实现，确保了算法逻辑在不同硬件上的一致性。
*   **训练时长**：实验包含固定 1,000,000 次 FE 的运行，以及固定 30 秒或 600 秒的运行。

### 5. 实验数量与充分性
*   **实验规模**：
    *   对 16 种算法在 30 个问题上进行了详尽测试。
    *   **扩展性实验**：种群规模和问题维度均从 16 指数级增加到 8192。
    *   **重复性**：每组实验独立运行 15 次（数值问题）或 10 次（神经演化），并提供标准差分析。
*   **充分性评价**：实验设计非常充分且客观。它不仅覆盖了不同类型的算法，还考虑了硬件架构（两代 GPU）的影响，并通过 EvoX 框架消除了实现偏差。

### 6. 主要结论与发现
*   **加速效果的异质性**：计算密集型且数据依赖低的算法（如 CMA-ES, HypE）在 GPU 上加速显著（最高达百倍）；而同步需求高或计算简单的算法（如 NSGA-III, PSO）加速有限甚至在小规模时不如 CPU。
*   **评估范式转移**：在 GPU 上，固定 FE 预算往往会过早终止搜索。固定时间评估显示，自适应算法（如 SaDE）和重采样算法在 GPU 提供的海量评价机会下能获得质的飞跃。
*   **扩展性规律**：GPU 在处理高维度（$D > 512$）和大种群（$N > 256$）时表现出近乎恒定的运行时间，而 CPU 呈线性增长。
*   **大种群的红利**：大种群不仅是为了填满 GPU 核心，它还能显著改善 CMA-ES 的协方差估计准确性，并帮助 GA 等算法维持多样性，延迟过早收敛。

### 7. 优点
*   **视角独特**：跳出了单纯“跑得快”的范畴，深入探讨了并行化对进化动力学（多样性、收敛性）的影响。
*   **实证严谨**：使用了统一的 EvoX 框架，避免了因代码优化程度不同导致的“不公平加速比”。
*   **实用性强**：为研究人员提供了何时该用 GPU、如何设置种群规模的实际指导。

### 8. 不足与局限
*   **硬件局限**：实验主要集中在 NVIDIA GPU 上，未涉及 AMD GPU 或 TPU 等其他加速器。
*   **问题复杂度**：虽然包含了神经演化，但模型（MLP）相对较小。在
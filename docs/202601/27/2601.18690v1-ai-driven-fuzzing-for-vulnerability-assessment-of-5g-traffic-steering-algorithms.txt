Title: AI-Driven Fuzzing for Vulnerability Assessment of 5G Traffic Steering Algorithms

URL Source: https://arxiv.org/pdf/2601.18690v1

Published Time: Tue, 27 Jan 2026 03:02:40 GMT

Number of Pages: 6

Markdown Content:
# AI-Driven Fuzzing for Vulnerability Assessment of 5G Traffic Steering Algorithms 

Seyed Bagher Hashemi Natanzi ∗, Hossein Mohammadi †, Bo Tang ∗, Vuk Marojevic †∗Electrical and Computer Engineering Department, Worcester Polytechnic Institute, USA 

> †

Electrical and Computer Engineering Department, Mississippi State University, USA Email: {snatanzi, btang1 }@wpi.edu , {hm1125, vm602 }@msstate.edu 

Abstract —Traffic Steering (TS) dynamically allocates user traffic across cells to enhance Quality of Experience (QoE), load balance, and spectrum efficiency in 5G networks. However, TS algorithms remain vulnerable to adversarial conditions such as interference spikes, handover storms, and localized outages. To address this, an AI-driven fuzz testing framework based on the Non-Dominated Sorting Genetic Algorithm II (NSGA-II) is proposed to systematically expose hidden vulnerabilities. Using NVIDIA Sionna, five TS algorithms are evaluated across six scenarios. Results show that AI-driven fuzzing detects 34.3% more total vulnerabilities and 5.8% more critical failures than traditional testing, achieving superior diversity and edge-case discovery. The observed variance in critical failure detection underscores the stochastic nature of rare vulnerabilities. These findings demonstrate that AI-driven fuzzing offers an effective and scalable validation approach for improving TS algorithm robustness and ensuring resilient 6G-ready networks. 

Index Terms —Traffic steering, AI-driven fuzzing, vulnerability assessment, NSGA-II, network resilience. 

I. I NTRODUCTION 

The dynamic nature of 5G networks demands advanced algorithms to manage user equipment (UE) assignments across base stations (BSs), ensuring efficient spectrum utilization and consistent Quality of Experience (QoE) [1]. Central to this functionality is traffic steering (TS), which dynamically optimizes UE–gNodeB associations to maintain load balance and network efficiency. Despite their sophistication, TS al-gorithms remain susceptible to adversarial conditions, severe interference, localized outages, and operational failures such as Evolved Packet System (EPS) fallback failure. These failures often stem from rapid radio fluctuations, inaccurate network-state estimation, or delayed control signaling under heavy load [2], [3], and are difficult to prevent due to the stochas-tic nature of wireless environments. Handover failures and suboptimal load-balancing decisions are frequent triggers with cascading impacts on QoE, spectrum efficiency, and operator profitability potentially leading to measurable revenue losses in dense urban deployments. Traditional Testing approaches, typically limited to static or traditional scenarios, fail to reveal the full breadth and depth of such flaws. This limitation underscores the need for advanced automated methodologies to rigorously assess algorithmic resilience in realistic and adversarial network conditions [4]. To address this gap, this study proposes an artificial in-telligence (AI)-driven fuzzing framework based on NSGA-II to generate adversarial network states that expose rare TS failures affecting QoE, fairness, and stability. The approach outperforms traditional testing by 34.3% in overall vulnera-bility detection, with p < 0.00001 indicating a highly signifi-cant improvement unlikely due to chance. It further provides architecture-level insights, showing that rule-based TS policies are more prone to failures under adversarial conditions than adaptive learning-based agents. These results establish AI-driven fuzzing as a statistically validated and architecture-aware method for enhancing the robustness of 5G TS systems. The remainder of this paper is structured as follows: Section II surveys related work, Section III elaborates on the system model and methodology, Section V presents the evaluation results, and Section VI provides conclusions and future research directions. II. B ACKGROUND AND RELATED WORK 

Traffic Steering in 5G networks encompasses three pri-mary categories: mobility-based steering for optimizing han-dovers, load-based steering for balancing network resources, and QoS-based steering for differentiating services. Classic approaches include 3GPP-standardized mechanisms such as Event A3-based handover and Cell Individual Offset (CIO) adjustments, which rely on predefined Reference Signal Re-ceived Power (RSRP) thresholds. Modern implementations increasingly adopt machine learning (ML) techniques, from supervised learning for pattern prediction to reinforcement learning for adaptive decision-making [5], [6]. Despite exten-sive research on TS optimization [2], vulnerability assessment remains largely unexplored. Existing studies focus on maxi-mizing throughput or minimizing handover rates under nor-mal conditions, overlooking failure modes that emerge under stress. For instance, reinforcement learning shows promise for adaptive control, but often fails catastrophically when encoun-tering out-of-distribution scenarios not seen during training. A vulnerability denotes network states where performance degrades beyond acceptable limits (per 3GPP TS 22.261), affecting stability, QoE, or fairness. Current testing methodolo-gies for TS algorithms fall into three categories: Conventional testing , which uses predefined scenarios but misses edge cases, formal verification , which provides theoretical guar-antees but becomes computationally intractable for realistic 5G models with hundreds of state variables [7], and fuzzing techniques , which have shown success for protocol testing [8], 

> arXiv:2601.18690v1 [eess.SP] 26 Jan 2026

[9], [10] and which focus on implementation errors rather than on algorithmic vulnerabilities specific to TS logic. The gap between optimization-focused TS research and security-oriented fuzzing presents an opportunity. Multi-objective ge-netic algorithms have explored network tradeoffs [11], but have not be applied for vulnerability discovery. This study bridges this gap by adapting NSGA-II for TS vulnerability assessment, introducing domain-specific fitness functions that simultaneously capture QoE degradation, fairness violations, and stability issues. Beyond academic relevance, the proposed framework also provides practical utility for telecom vendors’ back-office teams by enabling systematic identification of TS vulnerabilities during testing and validation. III. S YSTEM MODEL , P ROBLEM FORMULATION , AND 

METHODOLOGY 

This section defines the analytical system model for the 5G Traffic Steering (TS) environment and formulates the vul-nerability discovery problem as a multi-objective optimization task. The formulation establishes the basis for the proposed NSGA-II–based AI-driven fuzzing framework. 

A. System Model 

We consider a 5G network composed of a set of M

gNodeBs B = {b1, b 2, . . . , b M } and a set of N UEs U =

{u1, u 2, . . . , u N }. Each UE ui ∈ U is associated with exactly one gNodeB bj ∈ B at any given time t.The overall network state at time t is denoted as 

St = {Pt, L t, A t, C t},

where  

> •

Pt ∈ RN ×2 represents the UE positions in the 2D plane,  

> •

Lt ∈ [0 , 1] M is the normalized cell-load vector, where 

Lj = nj /N max  

> j

with nj being the number of active UEs in cell j, 

> •

At ∈ { 0, 1}N ×M denotes the association matrix, where 

aij = 1 if ui is connected to bj and 0 otherwise, and  

> •

Ct ∈ RN ×M represents the channel quality matrix (RSRP or SINR) between every UE–gNodeB pair. For each UE-to-gNodeB link, the received signal-to-interference-plus-noise ratio (SINR) is modeled as SINR i,j = Pj Gi,j 

Ii + N0B , (1) where Pj is the transmit power of bj , Gi,j is the channel gain (including path loss, shadowing, and fading), Ii is the aggregate inter-cell interference, B is the system bandwidth, and N0 is the noise power spectral density. The throughput of UE ui connected to bj is approximated as 

Ti,j = B log 2(1 + SINR i,j ), (2) and the cell load Lj evolves according to the active-UE occupancy ratio. A TS algorithm π : St → At maps network states to as-sociation decisions, determining UE assignments to gNodeBs based on criteria such as received power, cell load, and QoS demand. 

B. Problem Formulation 

The vulnerability discovery problem aims to identify net-work configurations that trigger operational failures beyond acceptable limits. These limits are abstractly defined as Stability failure: Hrate > τ stab ,

QoE degradation: Thr 5% < τ QoE ,

Fairness violation: J < τ fair ,

where Hrate denotes the average handover rate per UE, Thr 5% 

is the 5th-percentile user throughput, and J is Jain’s fairness index. The parameters τstab , τQoE , and τfair represent operator-defined thresholds. Given a TS policy π, the goal is to identify network states that maximize the exposure of vulnerabilities through multi-objective optimization: 

max  

> z∈Z

F (z) = [ f1(z), f 2(z), f 3(z)] , (3) where z encodes the candidate network configuration, and the objectives target instability, QoE degradation, and unfairness: 

f1(z) = 1

T

> T

X

> t=1

(ht − ¯h)2 (Instability) , (4) 

f2(z) = 1

Thr 5% (z) + ϵ (QoE degradation) , (5) 

f3(z) = 1 − (P 

> t

ut)2

N P 

> t

u2

> t

(Unfairness) . (6) The formulation in (3)–(6) ensures simultaneous coverage of critical failure modes in 5G TS systems. Objective f1

quantifies the temporal variance in the handovers (ping-pong instability), f2 emphasizes performance degradation of the lower-tail users, and f3 measures deviation from perfect re-source fairness. IV. P ROPOSED METHOD 

The proposed design enables Pareto-front exploration through the well-established NSGA-II algorithm without ad-hoc scalarization. The methodology employs NSGA-II as the core optimization engine and integrates it with a realistic 5G simulation environment based on the Sionna library [12]. The complete implementation is available online 1. The goal is to identify adversarial network configurations that expose failures in TS algorithms while maintaining computational efficiency and solution diversity across the Pareto front. The algorithm uses selection, crossover, and mutation operators to evolve candidate configurations while preserving diversity via crowding distance and elitism. 

A. NSGA-II-Based Vulnerability Discovery Engine 

We formulate the vulnerability discovery process as a three-objective search problem over the space of network configura-tions. NSGA-II is employed to approximate the Pareto-optimal set without ad-hoc scalarization. Let μ denote the population 

> 1https://github.com/CLIS-WPI/AI-Fuzzing

2Algorithm 1 NSGA-II for Vulnerability Discovery  

> 1:

Initialize population P0 with μ random configurations  

> 2:

for g = 1 → G do  

> 3:

Apply tournament selection on Pg 

> 4:

Generate offspring Qg via blend crossover (rate pc) 

> 5:

Apply Gaussian mutation to Qg (rate pm, variance σ) 

> 6:

Combine Rg ← Pg ∪ Qg 

> 7:

Perform fast non-dominated sorting on Rg 

> 8:

Compute crowding distance for each front  

> 9:

Select next population Pg+1 based on rank and crowd-ing distance  

> 10:

end for  

> 11:

return Pareto-optimal vulnerability-inducing configura-tions size and G the number of generations. At generation g, the population Pg consists of μ candidate configurations zi, each encoding parameters such as UE positions, cell loads, and link conditions. The algorithm iteratively evolves Pg through the following operators:  

> •

Selection: Tournament selection based on dominance rank, rank (zi), and crowding distance d(zi) to preserve diversity.  

> •

Crossover: A blend crossover operator with probability 

pc combines parent vectors zi and zj to generate offspring 

zk. 

> •

Mutation: Gaussian or uniform mutation with probability 

pm perturbs selected variables, introducing exploration within the configuration space. The mutation intensity is governed by variance σ.Each candidate configuration zi is evaluated through the objective vector F (zi) = [f1, f 2, f 3] defined in (3)–(6), capturing instability, QoE degradation, and unfairness. Non-dominated sorting and elitism ensure that superior solutions persist across generations, while the crowding distance metric maintains front diversity. Algorithm 1 summarizes the iterative optimization proce-dure. 

B. Integration with the Simulation Framework 

The NSGA-II engine interacts with the physical-layer sim-ulator to evaluate each candidate configuration. For a given configuration zi, the simulator generates network states St =

{Pt, L t, A t, C t} and computes the relevant KPIs: handover rate, 5th-percentile throughput, and Jain’s fairness index in a 5G environment. The framework, supports parameterized models for a net-work of M gNodeBs and N UEs, where variables such as carrier frequency fc, bandwidth B, transmit power Ptx , and UE mobility are detailed in Section V. The fitness evaluation process proceeds as follows: 1) NSGA-II proposes a candidate configuration zi specify-ing UE distribution, load profiles, and active cell states. 2) The Sionna simulator emulates the network behavior under zi and records KPIs. 3) The KPIs are mapped to objective values f1(zi), f2(zi),and f3(zi).4) The resulting fitness values guide the evolution toward vulnerability-inducing states. This closed-loop design enables systematic search of the configuration space with minimal human intervention. 

C. Scenario Generation and Adversarial Conditions 

To evaluate the resilience of TS algorithms, six repre-sentative scenarios are considered: two baseline and four adversarial algorithms reflecting both normal and degraded network conditions. Parameter S denotes the scenario set.  

> •

Baseline Scenarios: – Stable Mobility: UEs move according to a random waypoint model with moderate velocity, representing a balanced network without anomalies. 

– Stable High Load: UEs are uniformly distributed, with average cell utilization approaching the nominal oper-ating capacity.  

> •

Adversarial Scenarios: – Load Imbalance: A majority of UEs cluster near a subset of gNodeBs, producing non-uniform traffic dis-tribution. 

– Coverage Hole: A cell bj is deactivated, forcing neigh-boring cells to absorb excess load. 

– High Interference: Inter-site distance dISD and transmit powers are modified to intensify inter-cell interference. 

– Congestion Crisis: High user density and partial cell outage jointly drive severe congestion and degraded SINR. Each scenario defines a subset of tunable variables within the configuration vector z, which NSGA-II mutates and recom-bines to synthesize adversarial network states. The numerical instantiation of parameters such as the number of UEs, inter-site distance, or carrier bandwidth is reported in Section V. This methodology facilitates the discovery of diverse vulner-ability patterns in systematically perturbed 5G environments, offering a unified basis for comparing TS algorithms. V. N UMERICAL RESULTS AND ANALYSES 

A. Simulation Setup 

The evaluation encompasses six network scenarios and five TS algorithms using the Sionna simulator, with 300 runs per method (10 trials × 15 iterations). Table I details the simulation and algorithmic parameters. 

B. Traffic Steering Algorithms Evaluated 

Five representative TS algorithms were evaluated for vul-nerability assessment, spanning rule-based baselines and ML-based policies:  

> •

A3 Baseline: A 3GPP-compliant handover mechanism using Event-A3 triggers based on RSRP with hysteresis and time-to-trigger (TTT) parameters. 3TABLE I SIMULATION AND ALGORITHM PARAMETERS 

Parameter Value 

Network Configuration 

gNodeBs / UEs 7 (6 active in coverage-hole) / 40 Inter-site Distance 100m (75–200m by scenario) Frequency / Bandwidth 3.5 GHz / 13.68 MHz Transmit Power 30 dBm Channel Model 3GPP UMi via Sionna UE Mobility Random waypoint, 1–5 m/s 

NSGA-II Configuration 

Population / Generations μ = 40 , G = 25 

Crossover BLX-α (α = 0 .5, pc = 0 .9)Mutation Gaussian ( pm = 0 .5, σ = 50 )

Failure Thresholds 

QoE / Fairness / Stability Thr 5% < 10 Mb/s / J < 0.7 / HO > 3/min Trials per Scenario 10 runs × 15 iterations 

TS Algorithm Hyperparameters 

A3 Baseline Hysteresis=3 dB, TTT=160 ms Utility-Based (wSINR , wload , wrate )=(0.5, 0.3, 0.2) Load-Aware SINR ≥ 0 dB, Load ≤ 0.8

Q-Learning η = 0 .3, γ = 0 .9, ϵ: 0.1 →0.01 Random Uniform association  

> •

Utility-Based Policy: Assigns UE u to gNodeB c by maximizing the composite utility 

Uu,c = α SINR u,c + β(1 − Lc) + wr Tu,c , (7) where α, β, and wr are tunable weights reflecting signal strength, load balance, and data-rate priorities, respec-tively.  

> •

Load-Aware Policy: Prioritizes cell-load minimization while maintaining acceptable SINR thresholds for bal-anced association.  

> •

Random Baseline: Randomly assigns UEs to cells, serv-ing as a control to evaluate non-deterministic behavior.  

> •

ML-Based Agent: An ϵ-greedy Q-learning policy with state vector st = [ RSRP , SINR , L, Q ] and reward 

r = w1 Tu + w2 Jfair − w3 CHO , (8) where the Q-table is updated as 

Q(s, a ) ← (1 − η)Q(s, a ) + ηr + γ max  

> a′

Q(s′, a ′), (9) with learning rate η and discount factor γ.These five policies collectively span standards-compliant, heuristic, and learning-based TS strategies, allowing con-trolled, systematic comparison under identical network con-ditions. The evaluation across six scenarios and five algorithms generated 14,223 vulnerability instances, revealing distinct patterns in how AI-Fuzzing and traditional testing discover network failures. Here, traditional testing refers to baseline scenario-based evaluations using fixed network configurations and deterministic test cases without AI-driven exploration. The results are analyzed across multiple dimensions: overall detec-tion rate, severity distribution, algorithm-specific vulnerability, and convergence efficiency. 

C. Vulnerability Discovery 

Table II shows that AI-Fuzzing significantly outperforms traditional testing, detecting 34.3% more vulnerabilities ( t =8.671 , p < 0.00001 ) and 5.8% more critical failures (200 vs 189). For total vulnerability counts, which exhibit a more symmetric distribution across runs, the parametric t-test is appropriate. However, for critical failures, which show ex-treme skewness (most runs detecting zero, with occasional high-count outliers), the non-parametric Mann-Whitney U test (p = 0 .002 ) provides more reliable evidence of superiority than the parametric t-test ( p = 0 .373 ). 

TABLE II VULNERABILITY SUMMARY BY METHOD (N=300 RUNS PER METHOD ). 

Metric AI-Fuzzing Traditional Testing 

Total Vulnerabilities 8,207 6,112 Vulnerabilities per Run 27.36 ± 8.59 20.37 ± 10.96 Critical Failures 200 189 Critical Failures per Run 0.67 ± 1.28 0.63 ± 1.49 Average Severity 3.24 2.28 Improvement Rate +34.3% —Statistical Significance p < 0.00001 —Shannon Diversity 0.924 0.777 Cohen’s d (vulnerabilities) 0.708 —Traditional Testing AI Fuzzing 0510 15 20 25 30 35 40 45        

> Average Vulnerabilities per Run
> 20.24±10.09 SD 27.17±8.24 SD p < 0.001
> 34.2% improvement
> (a)
> 0246810 12 14
> Generation Number
> 0.50 0.75 1.00 1.25 1.50 1.75 2.00 2.25
> Best Fitness Score (Cumulative Max Vulnerabilities)
> (b)
> AI Fuzzing AI 95% CI Traditional Testing Traditional 95% CI

Fig. 1. Comparison of AI-Fuzzing and traditional testing across 300 runs per method (6 scenarios × 5 algorithms × 10 trials): AI-Fuzzing detects 34.3% more vulnerabilities per run (27.36 ±8.60 vs. 20.37 ±10.98, p < 0.00001 ;

n = 300 , t-test) with strong effect size (Cohen’s d=0.708) (a). Convergence analysis shows AI-Fuzzing reaches 90% of optimal detection rate 25% faster than traditional testing (generation 9 vs. 12) (b). 

4AI-Fuzzing Traditional-Testing       

> Testing Approach
> 0
> 1000
> 2000
> 3000
> 4000
> Number of Vulnerabilities
> Total: 4086 Total: 3867
> Critical: 54 Critical: 92 (a)
> Absolute Vulnerability Counts by Severity
> AI-Fuzzing Traditional-Testing
> Testing Approach
> 0
> 20
> 40
> 60
> 80
> 100
> Percentage of Vulnerabilities
> (b)
> 29.5%
> 61.2%
> 7.9%
> 14.4%
> 76.6%
> 6.6%
> Normalized Severity Distribution (%)
> Note: Traditional Testing found more critical failures (92 vs 54), while AI-Fuzzing excelled in overall discovery
> Severity Level
> Critical High Medium Low

Fig. 2. Vulnerability severity distribution across 300 runs (6 scenarios × 5 algorithms × 10 trials): AI-Fuzzing detects more total vulnerabilities (8,207 vs. 6,112, p < 0.00001 ) and critical failures (200 vs. 189, p = 0 .002 Mann-Whitney U test) (a) . Normalized distribution shows superior diversity (Shannon: 0.924 vs. 0.777) with balanced severity coverage (b). High variance in critical failures (SD > mean) reflects stochastic discovery of rare vulnerabilities. 

D. Statistical Analysis and Confidence Intervals 

AI-Fuzzing demonstrates significantly higher vulnerability detection than traditional testing, with a Shannon diversity index of 0.924 versus 0.777 and a strong effect size (Cohen’s d = 0.708). The 95% confidence intervals for critical failures per run are [0.52, 0.81] for AI-Fuzzing and [0.46, 0.80] for traditional testing, with high variance (SD = 1.28 and 1.49, respectively) reflecting the stochastic nature of critical failure discovery, where most test runs detect zero critical failures while occasional runs identify clusters of severe vulnerabilities. Due to strong right-skew (SD/mean ratios of 1.91 and 2.37, frequent zero counts violating normality assumptions), we prioritize the non-parametric Mann-Whitney U test ( p = 0 .002 ) over the parametric t-test ( p = 0 .373 ), as it is more robust to outliers and confirms AI-Fuzzing’s statistical advantage despite overlapping confidence intervals. 

E. Convergence and Algorithmic Efficiency 

As shown in Figure 1(b), the convergence analysis reveals the superior algorithmic efficiency of AI-Fuzzing for explor-ing the vulnerability space. The best fitness score represents the cumulative maximum vulnerabilities discovered, show-ing how each approach builds upon previous findings. AI-Fuzzing demonstrates 25.0% faster convergence to optimal vulnerability detection rates—reaching 90% of its maximum at generation 9 instead of generation 12 at O(GM N 2) complex-ity, highlighting NSGA-II’s efficiency in exploring productive regions of the search space. 

F. Algorithm-Specific Vulnerability Patterns 

Our analysis reveals distinct vulnerability patterns across different TS algorithms, demonstrating how AI-Fuzzing’s sys-tematic exploration complements the traditional testing in capturing rare edge cases.  

> •

Baseline A3: Most vulnerable to AI-Fuzzing with 96.2% more vulnerabilities detected (1,791 vs. 913, p <

0.00001 ) and 3 critical failures versus 0 for traditional testing. The rule-based nature makes it susceptible to systematic exploration of edge cases.  

> •

ML-Based Q-Learning: Shows resilience to AI-Fuzzing, with traditional testing finding 5.4% more total vulnera-bilities (2,481 vs. 2,348, p = 0 .829 , not significant) but AI-Fuzzing still identifying 106 critical failures compared to 189. The adaptive nature of reinforcement learning appears more robust to systematic exploration but remains vulnerable to stochastic edge cases.  

> •

Utility-Based: AI-Fuzzing achieves 72.0% improvement in total vulnerabilities (1,539 vs. 895, p < 0.00001 )and identifies 87 critical failures versus 0 for traditional testing, demonstrating systematic discovery of severe failure modes. These patterns suggest that the algorithm architecture fun-damentally influences vulnerability profiles. Learning-based approaches demonstrate resilience against systematic fuzzing but remain vulnerable to random edge cases that trigger critical failures. This insight informs algorithm design by highlighting the need for adaptive robustness and guides testing strategy selection by emphasizing a hybrid approach. 

G. Scenario-Specific Performance Analysis 

Table III details the performance of AI-Fuzzing compared to traditional testing across six diverse network scenarios based on 300 runs per method (6 scenarios × 5 algorithms × 10 trials). AI-Fuzzing consistently outperforms traditional test-ing, with significant improvements in vulnerability detection: 28.8% for Stable Mobility, 34.8% for Stable High Load, 45.4% for Load Imbalance, 30.1% for Coverage Hole, 42.3% for High Interference, and 21.4% for Congestion Crisis (all p < 0.0000 

except Congestion Crisis at p = 0.0002 ). This translates to an average improvement of 33.8%, demonstrating robust detection capabilities across a variety of conditions. Notably, AI-Fuzzing proves particularly effective in scenarios with high resource contention, such as Load Imbalance (45.4% improve-ment), where clustered UE distributions create challenging 5TABLE III VULNERABILITY DETECTION PERFORMANCE .Traditional (Mean) AI-Fuzzing (Mean) Scenario Value Improvement (%) Value p-value Group 1 Stable Mobility 21.70 28.8 27.96 0.0000 Stable High Load 21.00 34.8 28.30 0.0000 Load Imbalance 20.70 45.4 30.10 0.0000 Group 2 Coverage Hole 21.18 30.1 27.56 0.0000 High Interference 21.52 42.3 30.62 0.0000 Congestion Crisis 16.14 21.4 19.60 0.0002 Average Improvement 33.8% 

optimization problems, and High Interference (42.3%), where SINR degradation amplifies failure modes. Even in the most demanding Congestion Crisis scenario, involving extreme UE clustering and gNodeB outages, AI-Fuzzing maintains a 21.4% edge, highlighting its resilience under adversarial stress. These patterns complement the algorithm-specific insights in Sec-tion V-F, showing how systematic fuzzing exploits network dynamics more effectively than random testing in most cases. 

H. Practical Implications and Network Robustness 

The results demonstrate clear advantages of AI-Fuzzing as the primary testing methodology for 5G network vali-dation. AI-Fuzzing achieves statistically significant improve-ments across all metrics: 34.3% higher total vulnerability detection ( p < 0.00001 , Cohen’s d = 0 .708 ) and 5.8% more critical failures ( p = 0 .002 via Mann-Whitney U test). The more realistic critical failure threshold ( >3 UEs experiencing ping-pong, ∼7.5%) compared to initially conservative criteria enables sufficient statistical power, meaning a high probability of correctly detecting genuine performance differences. Architecture-specific patterns show that rule-based policies (e.g., A3 Baseline) are highly susceptible to adversarial ex-ploration by AI-Fuzzing (+96% detection), while Q-learning offers resilience to systematic search but remains vulnerable to stochastic edge cases. These observations suggest that future TS algorithms should incorporate robustness-aware design, such as adversarial training or formal verification. The high variance in critical failure detection (SD > mean for both methods) indicates that severe vulnerabilities are rare and occur stochastically. Reliable discovery therefore requires mul-tiple independent test runs, motivating ensemble-based evalu-ation strategies. The limitations of the current study include the use of a simulation-based evaluation with a fixed topology (7 cells, 40 UEs). VI. C ONCLUSION 

This paper establishes AI-driven fuzzing as superior to traditional testing for 5G TS vulnerability assessment. Using 

NSGA-II -based multi-objective optimization across six sce-narios and five algorithms, AI-fuzzing achieves statistically significant improvements in both comprehensive coverage and critical edge-case detection (34.3% more vulnerabilities, p < 

0.00001 ), establishing it as the recommended primary valida-tion approach for robust 5G/6G deployment. While simulation-based evaluation (7 cells, 40 UEs) enables controlled system-atic assessment, future work will validate findings through Open RAN testbeds and develop GPU-accelerated adaptive fuzzing for production networks. ACKNOWLEDGMENT 

This work was supported by the NTIA (Award No. 51-60-IF007) and NSF (Award No. CNS-2120442). The views expressed are those of the authors and do not necessarily represent those of the NTIA or NSF. REFERENCES [1] M. A. Habib, H. Zhou, P. E. Iturria-Rivera, Y. Ozcan, M. Elsayed, M. Bavand, R. Gaigalas, and M. Erol-Kantarci, “Machine learning-enabled traffic steering in o-ran: A case study on hierarchical learning approach,” IEEE Communications Magazine , vol. 63, no. 1, pp. 100– 107, 2025. [2] A. Lacava, M. Polese, R. Sivaraj, R. Soundrarajan, B. S. Bhati, T. Singh, T. Zugno, F. Cuomo, and T. Melodia, “Programmable and customized intelligence for traffic steering in 5g networks using open ran architectures,” IEEE Transactions on Mobile Computing ,vol. 23, no. 4, p. 2882–2897, Apr. 2024. [Online]. Available: https://doi.org/10.1109/TMC.2023.3266642 [3] F. Kavehmadavani, V.-D. Nguyen, T. X. Vu, and S. Chatzinotas, “Empowering traffic steering in 6g open ran with deep reinforcement learning,” Trans. Wireless. Comm. , vol. 23, no. 10 Part 1, p. 12782–12798, Oct. 2024. [Online]. Available: https://doi.org/10.1109/ TWC.2024.3396273 [4] N. R. Mayeke, “Evaluating the cost-benefit dynamics of cybersecurity compliance investments,” Computer Science & IT Research Journal ,vol. 6, no. 4, pp. 266–287, 2025. [5] A. Lacava, M. Polese, R. Sivaraj, R. Soundrarajan, B. S. Bhati, T. Singh, T. Zugno, F. Cuomo, and T. Melodia, “Programmable and customized intelligence for traffic steering in 5g networks using open ran archi-tectures,” IEEE Transactions on Mobile Computing , vol. 23, no. 4, pp. 2882–2897, 2024. [6] P. Mu˜ noz, D. Laselva, R. Barco, and P. Mogensen, “Dynamic traffic steering based on fuzzy q-learning approach in a multi-rat multi-layer wireless network,” Computer Networks , vol. 71, pp. 100–116, 2014. [Online]. Available: https://www.sciencedirect.com/science/article/pii/ S1389128614002266 [7] M. Abbasalizadeh, K. Vellamchety, P. Rayavaram, and S. Narain, “Dynamic link scheduling in wireless networks through fuzzy-enhanced deep learning,” IEEE Open Journal of the Communications Society ,vol. 5, pp. 6832–6848, 2024. [8] D. She, K. Pei, D. Epstein, J. Yang, B. Ray, and S. Jana, “Neuzz: Effi-cient fuzzing with neural program smoothing,” in 2019 IEEE Symposium on Security and Privacy (SP) . IEEE, 2019, pp. 803–817. [9] Y. Yang, Z. Li, W. Zhang, and M. Liu, “Systematic meets unintended: Prior knowledge adaptive 5g vulnerability detection via multi-fuzzing,” 

IEEE INFOCOM 2024-IEEE Conference on Computer Communications ,2024. [10] Y. Sun, X. Liu, Q. Sun, J. Wang, L. Tian, and J. Liu, “5gc-fuzz: Finding deep stateful vulnerabilities in 5g core network with black-box fuzzing,” in OpenReview Preprint , 2024. [11] S. K. Goudos, P. D. Diamantoulakis, and G. K. Karagiannidis, “Multi-objective optimization in 5g wireless networks with massive mimo,” 

IEEE Access , vol. 6, pp. 11 584–11 593, 2018. [12] J. Hoydis, S. Cammerer, F. Ait Aoudia, M. Nimier-David, L. Maggi, G. Marcus, A. Vem, and A. Keller, “Sionna,” 2022, https://nvlabs.github.io/sionna/. 

6
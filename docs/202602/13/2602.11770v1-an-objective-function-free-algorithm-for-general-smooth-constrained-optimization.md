# An objective-function-free algorithm for general smooth constrained optimization
# 一种用于通用平滑约束优化的免目标函数算法

**Authors**: S. Bellavia, S. Gratton, B. Morini, Ph. L. Toint \\
**Date**: 2026-02-12 \\
**PDF**: https://arxiv.org/pdf/2602.11770v1 \\
**Tags**: <span class="tag-label tag-green">速读区</span> <span class="tag-label tag-pink">keyword:EAA</span> \\
**Score**: 6.0 \\
**Evidence**: efficient automatic algorithm for smooth constrained optimization \\

---

## Abstract
A new algorithm for smooth constrained optimization is proposed that never computes the value of the problem's objective function and that handles both equality and inequality constraints. The algorithm uses an adaptive switching strategy between a normal step aiming at reducing constraint's infeasibility and a tangential step improving dual optimality, the latter being inspired by the AdaGrad-norm method. Its worst-case iteration complexity is analyzed, showing that the norm of the gradients generated converges to zero like O(1/\sqrt{k+1}) for problems with full-rank Jacobians. Numerical experiments show that the algorithm's performance is remarkably insensitive to noise in the objective function's gradient.

## 摘要
本文提出了一种用于平滑约束优化的新算法，该算法无需计算问题的目标函数值，并能同时处理等式和不等式约束。该算法在旨在降低约束不可行性的法向步与旨在改善对偶最优性的切向步之间采用自适应切换策略，其中后者受到 AdaGrad-norm

---

## 速览摘要（自动生成）

**问题**：平滑约束优化。
**方法**：提出一种无需计算
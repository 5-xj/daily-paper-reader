# A Multi-objective Evolutionary Algorithm Based on Bi-population with Uniform Sampling for Neural Architecture Search
# 一种基于均匀采样双种群的多目标进化神经架构搜索算法

**Authors**: Yu Xue, Pengcheng Jiang, Chenchen Zhu, Yong Zhang, Ran Cheng, Kaizhou Gao, Dunwei Gong \\
**Date**: 2026-02-09 \\
**PDF**: https://arxiv.org/pdf/2602.08513v1 \\
**Tags**: <span class="tag-label tag-blue">精读区</span> <span class="tag-label tag-pink">keyword:EOH</span> <span class="tag-label tag-pink">keyword:EAA</span> \\
**Score**: 8.0 \\
**Evidence**: Evolutionary algorithm for automated architecture search aligns with evolution of heuristics and efficient automatic algorithms \\

---

## Abstract
Neural architecture search (NAS) automates neural network design, improving efficiency over manual approaches. However, efficiently discovering high-performance neural network architectures that simultaneously optimize multiple objectives remains a significant challenge in NAS. Existing methods often suffer from limited population diversity and inadequate exploration of the search space, particularly in regions with extreme complexity values. To address these challenges, we propose MOEA-BUS, an innovative multi-objective evolutionary algorithm based on bi-population with uniform sampling for neural architecture search, aimed at simultaneously optimizing both accuracy and network complexity. In MOEA-BUS, a novel uniform sampling method is proposed to initialize the population, ensuring that architectures are distributed uniformly across the objective space. Furthermore, to enhance exploration, we deploy a bi-population framework where two populations evolve synergistically, facilitating comprehensive search space coverage. Experiments on CIFAR-10 and ImageNet demonstrate MOEA-BUS's superiority, achieving top-1 accuracies of 98.39% on CIFAR-10, and 80.03% on ImageNet. Notably, it achieves 78.28% accuracy on ImageNet with only 446M MAdds. Ablation studies confirm that both uniform sampling and bi-population mechanisms enhance population diversity and performance. Additionally, in terms of the Kendall's tau coefficient, the SVM achieves an improvement of at least 0.035 compared to the other three commonly used machine learning models, and uniform sampling provided an enhancement of approximately 0.07.

## 摘要
神经架构搜索（NAS）实现了神经网络设计的自动化，相比

---

## 论文详细总结（自动生成）

这是一份关于论文《A Multi-objective Evolutionary Algorithm Based on Bi-population with Uniform Sampling for Neural Architecture Search》（基于均匀采样双种群的多目标进化神经架构搜索算法）的结构化深入总结：

### 1. 核心问题与整体含义（研究动机和背景）
论文关注的是**多目标神经架构搜索（MO-NAS）**中的效率与多样性平衡问题。
*   **研究动机**：在实际应用（如移动设备）中，神经网络不仅需要高精度，还需考虑计算复杂度（MAdds）。
*   **核心挑战**：
    1.  **种群多样性不足**：现有进化算法在初始化和搜索过程中，架构往往集中在搜索空间的“中等规模”区域，导致对极小或极大计算量区域的探索不充分。
    2.  **评估成本极高**：真实训练每个候选架构耗时巨大。
    3.  **搜索空间分布不均**：随机采样生成的架构在目标空间（如复杂度轴）上呈正态分布，导致边缘区域（Pareto前沿的两端）难以被覆盖。

### 2. 核心方法论 (MOEA-BUS)
论文提出了一种名为 **MOEA-BUS** 的框架，核心思想是通过改进初始化采样和种群进化机制来提升搜索质量。

*   **均匀采样初始化 (Uniform Sampling)**：
    *   首先随机采样大量架构并计算其 MAdds。
    *   将 MAdds 空间划分为多个均匀区间，从每个区间抽取固定数量的架构。
    *   这种“两阶段采样”确保了初始种群在复杂度轴上是均匀分布的，而非聚集在中间。
*   **双种群协同进化机制 (Bi-population)**：
    *   **种群1**：专注于探索“极端”架构（极小和极大规模）。
    *   **种群2**：专注于探索“中等规模”架构。
    *   **精英交换**：两个种群在进化过程中交换优秀个体，种群1向种群2分享精英以促进全面覆盖，从而防止陷入局部最优并加速收敛。
*   **代理模型辅助搜索 (Surrogate Model)**：
    *   使用 **SVM（支持向量机）** 构建代理模型。
    *   采用**成对比较（Pairwise Comparison）**模式：不直接预测绝对精度，而是预测两个架构哪个更好。实验证明这种方式比回归预测更准确。
*   **权重继承 (Weight Inheritance)**：
    *   基于 **Once-For-All (OFA)** 超网，搜索出的子网络直接继承预训练权重，仅需少量微调即可评估，大幅缩短搜索时间。

### 3. 实验设计
*   **数据集**：CIFAR-10, CIFAR-100, ImageNet。
*   **搜索空间**：基于 MobileNetV3 的倒残差结构（Inverted Bottleneck），搜索参数包括分辨率、层数、扩展比（Expansion Rate）和卷积核大小。
*   **对比方法 (Benchmarks)**：
    *   **手动设计**：MobileNetV2, EfficientNet-B0。
    *   **强化学习类**：NASNet, MnasNet。
    *   **梯度类 (GD)**：DARTS, PC-DARTS, P-DARTS, FairDARTS。
    *   **进化算法类 (EA)**：NSGA-Net, CARS, FairNAS, SPNAS 等。

### 4. 资源与算力
*   **硬件环境**：单张 **NVIDIA RTX 3090 (24GB)** GPU。
*   **搜索成本**：
    *   **CIFAR 系列**：约 **1.2 GPU Days**。
    *   **ImageNet**：约 **0.3 GPU Days**（得益于 OFA 超网权重继承和代理模型）。
*   **软件环境**：PyTorch 2.0, CUDA 11.7。

### 5. 实验数量与充分性
*   **实验规模**：在三个主流视觉数据集上进行了完整测试，结果包含 Top-1/Top-5 精度、MAdds、参数量和搜索耗时。
*   **消融实验非常充分**：
    *   对比了有无“均匀采样”和“双种群”的效果（使用架构分布熵和超体积 HV 指标）。
    *   对比了四种机器学习模型（RF, SVM, MLP, AdaBoost）作为代理模型的表现。
    *   对比了不同采样策略（随机采样、分层采样、拉丁超立方采样）。
    *   探讨了双种群之间不同的个体交换规则及种群比例。
*   **客观性**：通过多次运行取均值和标准差，并与近五年的 SOTA 方法进行了横向对比，实验设计较为严谨。

### 6. 主要结论与发现
*   **性能卓越**：在 CIFAR-10 上达到 **98.39%** 的精度；在 ImageNet 上，MOEA-BUS-XL 达到 **80.03%** Top-1 精度。
*   **效率极高**：在 ImageNet 上仅需 446M MAdds 即可达到 78.28% 的精度，且搜索成本仅为 0.3 GPU Days，远低于 FairNAS (12 Days) 等方法。
*   **采样关键性**：均匀采样使代理模型的 Kendall's tau 系数提升了约 0.07，证明了高质量初始数据对代理模型的重要性。
*   **SVM 优势**：在成对比较任务中，SVM 的表现优于随机森林和多层感知机。

### 7. 优点与亮点
*   **解决分布偏见**：敏锐捕捉到 NAS 搜索空间中架构分布不均的问题，通过简单的均匀采样有效提升了 Pareto 前沿的覆盖度。
*   **双种群策略**：通过分工（极端 vs 中等）
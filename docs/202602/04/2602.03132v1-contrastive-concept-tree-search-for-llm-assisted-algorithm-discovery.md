# Contrastive Concept-Tree Search for LLM-Assisted Algorithm Discovery
# 对比概念树搜索用于大语言模型辅助的算法发现

**Authors**: Timothee Leleu, Sudeera Gunathilaka, Federico Ghimenti, Surya Ganguli \\
**Date**: 2026-02-03 \\
**PDF**: https://arxiv.org/pdf/2602.03132v1 \\
**Tags**: <span class="tag-label tag-blue">精读区</span> <span class="tag-label tag-pink">keyword:EOH</span> <span class="tag-label tag-pink">keyword:EAA</span> \\
**Score**: 9.0 \\
**Evidence**: LLM-assisted algorithm discovery and iterative black-box optimization \\

---

## Abstract
Large language Model (LLM)-assisted algorithm discovery is an iterative, black-box optimization process over programs to approximatively solve a target task, where an LLM proposes candidate programs and an external evaluator provides task feedback. Despite intense recent research on the topic and promising results, how can the LLM internal representation of the space of possible programs be maximally exploited to improve performance is an open question. Here, we introduce Contrastive Concept-Tree Search (CCTS), which extracts a hierarchical concept representation from the generated programs and learns a contrastive concept model that guides parent selection. By reweighting parents using a likelihood-ratio score between high- and low-performing solutions, CCTS biases search toward useful concept combinations and away from misleading ones, providing guidance through an explicit concept hierarchy rather than the algorithm lineage constructed by the LLM. We show that CCTS improves search efficiency over fitness-based baselines and produces interpretable, task-specific concept trees across a benchmark of open Erdős-type combinatorics problems. Our analysis indicates that the gains are driven largely by learning which concepts to avoid. We further validate these findings in a controlled synthetic algorithm-discovery environment, which reproduces qualitatively the search dynamics observed with the LLMs.

## 摘要
大语言模型（LLM）辅助的算法发现是一个针对程序的迭代黑盒优化过程，旨在近似解决目标任务。在此过程中，LLM 提出候选程序，而外部评估器提供任务反馈。尽管近期该领域研究密集且成果显著，但如何最大限度地利用 LLM 对可能程序空间的内部表示以提升性能仍是一个开放性问题。在此，我们引入了对比概念树

---

## 论文详细总结（自动生成）

这篇论文介绍了一种名为 **对比概念树搜索 (Contrastive Concept-Tree Search, CCTS)** 的新框架，旨在提升大语言模型（LLM）在自动化算法发现任务中的效率和可解释性。

以下是对该论文的深度结构化总结：

### 1. 论文的核心问题与整体含义
*   **研究动机**：目前的 LLM 辅助算法发现（如 FunSearch, AlphaEvolve）主要依赖于基于适应度（Fitness）的进化算法。这种方法将程序空间视为弱结构的黑盒，仅通过分数筛选父代，而未能充分利用 LLM 内部对程序语义空间的理解。
*   **核心问题**：如何显式地提取并利用算法背后的“语义概念结构”，从而引导搜索过程避开无效区域并聚焦于有潜力的概念组合？

### 2. 论文提出的方法论
CCTS 的核心思想是将搜索从“程序空间”提升到“层次化概念空间”。
*   **概念提取与树构建**：利用 LLM 从生成的程序中提取语义概念，并将其组织成一棵**概念树（Concept Tree）**。树的节点代表概念，边缘代表细化或专业化关系。
*   **对比概念模型**：
    *   将存档的程序分为“高性能（Good）”和“低性能（Bad）”两组。
    *   使用**树状 Parzen 估计器（TPE）**风格的概率模型，分别为两组学习概念分布 $p(b|good)$ 和 $p(b|bad)$。
*   **引导式父代选择**：计算**似然比分数（Likelihood-ratio score）** $w(b) = \frac{p(b|good)}{p(b|bad)}$。在选择下一轮进化的父代程序时，根据该分数进行加权采样，从而偏向于包含“有用概念组合”的程序。
*   **探索机制**：引入基于 Beta 先验的平滑处理和基于计数（Novelty bias）的探索机制，确保新发现的概念或罕见概念也有机会被尝试。

### 3. 实验设计
*   **数据集/场景**：选取了一系列具有挑战性的 **Erdős 型组合数学问题**：
    *   **圆填充问题 (Circle Packing)**：在单位正方形内放置 26 个圆，使半径总和最大。
    *   **算术 Kakeya 猜想**：涉及信息论中的熵和线性投影。
    *   **Heilbronn 三角形问题**：在三角形内放置点，使形成的最小三角形面积最大。
    *   **正方形嵌入 (Squares-in-Square)**：在单位正方形内放置多个不重叠的正方形。
*   **对比方法 (Baselines)**：
    *   **Greedy**：总是选择当前最优的程序。
    *   **k-elites**：从前 k 个最优程序中随机选择。
    *   **Uniform**：在存档中均匀随机选择（纯探索）。
*   **合成环境**：构建了一个受控的模拟环境，用手写的数学算子代替 LLM，以验证 CCTS 在没有语言模型噪声的情况下的搜索动力学。

### 4. 资源与算力
*   **模型使用**：主要使用了 **Gemini-2.0-Flash** 作为核心生成器，同时也测试了 **GPT-4o-mini**、**Gemini-1.5-Flash** 等模型。
*   **算力说明**：论文**未明确说明**具体的 GPU 型号或训练时长。由于该方法基于黑盒 API 调用，其算力消耗主要体现在 API 的调用次数（实验中通常每轮运行 25-60 次迭代）。作者强调该方法使用的是“低成本模型”和“适度的搜索预算”。

### 5. 实验数量与充分性
*   **实验规模**：
    *   真实任务：每个任务运行 60 次独立实验，取平均值和 95% 置信区间。
    *   合成任务：运行了 500 次实验以确保统计显著性。
    *   消融实验：对父代选择策略、探索/利用比例（$p_{exploit}$）进行了详细消融。
*   **充分性评价**：实验设计非常充分且客观。通过引入“合成环境”，作者成功排除了 LLM 特定偏见的影响，证明了 CCTS 算法本身的普适性。对比基准涵盖了当前主流的进化策略，实验结果具有说服力。

### 6. 论文的主要结论与发现
*   **效率提升**：CCTS 在所有测试的组合数学任务中，搜索效率均显著优于基于适应度的基准方法。
*   **“避坑”是关键**：分析表明，CCTS 的性能增益主要来自于**学习哪些概念应该避免**（即识别并抑制那些与低性能相关的误导性概念），而不仅仅是寻找好概念。
*   **可解释性**：CCTS 能够生成任务特定的概念树，直观地展示了哪些算法策略（如“惩罚函数法”、“拟随机序列”）对解决特定问题有效。
*   **策略相关性**：合成实验发现，最优搜索策略与概念树的
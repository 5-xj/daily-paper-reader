Title: C-MOP: Integrating Momentum and Boundary-Aware Clustering for Enhanced Prompt Evolution

URL Source: https://arxiv.org/pdf/2602.10874v1

Published Time: Thu, 12 Feb 2026 02:00:18 GMT

Number of Pages: 19

Markdown Content:
# C-MOP: Integrating Momentum and Boundary-Aware Clustering for Enhanced Prompt Evolution 

Binwei Yan 1 Yifei Fu 1 Mingjian Zhu 1 Hanting Chen 1 Mingxuan Yuan 1 Yunhe Wang 1 Hailin Hu 1

# Abstract 

Automatic prompt optimization is a promising direction to boost the performance of Large Language Models (LLMs). However, existing methods often suffer from noisy and conflict-ing update signals. In this research, we propose 

C-MOP (Cluster-based Momentum Optimized 

Prompting), a framework that stabilizes opti-mization via Boundary-Aware Contrastive Sam-pling (BACS) and Momentum-Guided Seman-tic Clustering (MGSC). Specifically, BACS uti-lizes batch-level information to mine tripartite featuresâ€” Hard Negatives, Anchors, and Bound-ary Pairs â€”to precisely characterize the typi-cal representation and decision boundaries of positive and negative prompt samples. To re-solve semantic conflicts, MGSC introduces a tex-tual momentum mechanism with temporal de-cay that distills persistent consensus from fluc-tuating gradients across iterations. Extensive ex-periments demonstrate that C-MOP consistently outperforms SOTA baselines like PromptWiz-ard and ProTeGi, yielding average gains of 1.58% and 3.35%. Notably, C-MOP enables a general LLM with 3B activated parameters to surpass a 70B domain-specific dense LLM, highlighting its effectiveness in driving pre-cise prompt evolution. The code is available at https://github.com/huawei-noah/noah-research/ tree/master/C-MOP. 

# 1. Introduction 

Large Language Models (LLMs) (Brown et al., 2020; Tou-vron et al., 2023; Chowdhery et al., 2023) have become one of the most influential research frontiers in artificial intelli-gence, demonstrating remarkable capabilities across diverse 

> 1

Noahâ€™s Ark Lab, Huawei, China. Correspondence to: Yunhe Wang <yunhe.wang@huawei.com >, Hailin Hu 

<hailin.hu@huawei.com >.

Preprint. Prompt:  You are a highly capable problem -solver.  

> Optimal Prompt
> Your goal is high -precision extraction and objective, step -by -step factual auditing.
> â€¦â€¦
> Query
> The girls are trying to raise money for a
> carnival.
> â€¦â€¦
> How much money, in dollars, did they
> all raise in total?
> Batch Data ï¼šThe number of queries is equal
> to the batch size.
> LLM Feedback
> Prediction
> We are given the following information:
> -Alexandra raises $430.
> â€¦â€¦
> Answer: 2180
> Textual Gradient
> The "expert problem -
> solver" persona can lead to
> over -confidence in linear
> processing, causing the
> model to rush through the
> information extraction
> phase in favor of showing
> off its "solving" steps.
> â€¦â€¦
> LLM
> LLM

(a) 4 8 16 32 64 128 256 

> Batch Size
> 0.56 0.58 0.60 0.62 0.64
> Accuracy
> Accuracy with different batch size

(b) 

Figure 1. (a) Textual gradient-based prompt optimization workflow, showing the definition of â€œtextual gradientâ€, â€œbatch sizeâ€ and other components. (b) Accuracy versus different batch sizes using Qwen3-30B-A3B-Instruct-2507 (Yang et al., 2025) to optimize prompts on the Liar dataset (Wang, 2017). 

tasks (Zhao et al., 2023; Minaee et al., 2024). However, their performance remains highly sensitive to prompt designâ€”a phenomenon that presents both opportunities and challenges for practical deployment (Zhao et al., 2021; Lu et al., 2022). Consequently, an effective prompt optimization strategy is required to help people generate the best possible prompts. Early prompt engineering (Jiang et al., 2020; Reynolds & McDonell, 2021; Liu et al., 2023) relied heavily on man-ual expertise and trial-and-error, whereas recent research has proposed automatic prompt optimization (Tong et al., 2025; Yu et al., 2025) to reduce manual burden. Among var-ious approaches, textual gradient-based methods (Pryzant et al., 2023; Agarwal et al., 2025) (workflow is illustrated 1

> arXiv:2602.10874v1 [cs.CL] 11 Feb 2026 C-MOP: Integrating Momentum and Boundary-Aware Clustering for Enhanced Prompt Evolution

in Figure 1a) have gained significant attention due to their ability to provide interpretable directional guidance for iter-ative refinement. However, the dissection of this â€œLLM-as-optimizerâ€ process (Yang et al., 2023) is generally lagging behind, which hinders this application in real-world applica-tions. In back-propagation-based model optimization, the scale of batching is of great importance and generally increasing the batch size can reduce gradient noise and improve training efficiency (Krizhevsky, 2014; Hoffer et al., 2017; McCan-dlish et al., 2018; Shallue et al., 2019). While transferring this idea to textual gradient is intuitively straightforward, till now few studies have explicitly explored this direction. To fill this gap, we first characterize the performance of textual gradient optimization with respect to the inputting example numbers, as illustrated in Figure 1b. Intriguingly, the results demonstrate a clear performance gain over 8% when scaling up the batch size from 4 to 128, and then the size effect saturates to a point that further expansion fails to benefit the performance. These interesting phenomenon indicate the potential of ap-plying tradition optimization principle to automatic prompt optimization. While enlarging the batch size is generally beneficial, we hypothesize that too many incorrect or non-representative samples will result in gradients that are noisy, unfocused, or even contradictory. Such gradient conflicts hinder optimization stability, making it difficult for the up-date process to converge to high-quality prompts (Sener & Koltun, 2018). Moreover, unlike the numerical averag-ing operation in gradients of back propagation, expanding the batch size of textual gradients requires populating the context with different exemplars, which is constrained by the context length of LLMs or the memory of hardware. Drawing from these two insights, in this work, we aim to further enhance the effectiveness of large-batch textual gra-dient optimization with strategic sample selection (Bengio et al., 2009; Settles, 2009). In particular, we propose a novel framework method, named C-MOP (Cluster-based Momentum Optimized Prompting), which is designed to identify and select more representative samples. This ap-proach effectively emulates the benefits of an expanded batch size, thereby maximizing the positive impact of batch size increases. Our key innovations are as follows: 1. Boundary-Aware Contrastive Sampling (BACS) :We replace stochastic sampling with error-rate-aware clustering to systematically select Hard Negatives , An-chors , and Boundary Pairs . These points collectively map the semantic transition between successful and erroneous regions, thereby delineating the decision boundaries of prompt. By isolating the minimal lin-guistic differences that trigger classification flips within these pairs, BACS extracts precise contrastive signals that pinpoint specific prompt deficiencies. 2. Momentum-Guided Semantic Clustering (MGSC) :To resolve textual gradient conflicts, we introduce a refinement mechanism that maintains a historical gra-dient pool with a temporal decay factor. By accumu-lating gradients across iterations, MGSC ensures the temporal persistence of optimization signals, allowing weighted clustering to extract the semantic consensus while marginalizing batch-specific contradictions. This process transforms transient, fluctuating feedback into a unified and stable optimization direction. Our extensive experiments on four diverse benchmarks, i.e BBH (Suzgun et al., 2022), GSM8K (Cobbe et al., 2021), CFinBench (Nie et al., 2025), and Liar (Wang, 2017) demon-strate that C-MOP consistently outperforms state-of-the-art baselines, achieving 1.58% to 3.35% average improvement. Ablation studies confirm that clustering contributes substan-tially to the effectiveness of the framework. 

# 2. Related Work 

2.1. Manual Prompt Engineering 

Prompt engineering has long been a central technique for eliciting desired behaviors from large language models. Early work (Reynolds & McDonell, 2021; Wei et al., 2022) demonstrated that constructing prompts through methods such as anthropomorphism, analogy, and demonstration to enable capabilities like in-context learning and few-shot reasoning. However, manual prompt design relies heavily on extensive expertise and domain knowledge (Reynolds & McDonell, 2021; Liu et al., 2023), and even subtle linguistic variations can significantly impact model per-formance. (Brown et al., 2020; Jiang et al., 2020; Perez et al., 2021). Consequently, handcrafted prompting is time-consuming and labor-intensive, often requiring exhaustive trial-and-error (Zamfirescu-Pereira et al., 2023). These drawbacks have motivated a growing interest in automating the prompt creation and optimization process. 

2.2. Automatic Prompt Optimization 

To overcome the limitations of manual prompting, a grow-ing body of work has explored automatic prompt optimiza-tion. Early studies proposed trajectory-based optimiza-tion (Yang et al., 2023; Tang et al., 2025), which gener-ates new prompts based on historical candidates and their corresponding scores. Evolutionary-based methods (Fer-nando et al., 2023; Tong et al., 2025), on the other hand, iteratively refine prompts by combining LLMs with evolu-tionary algorithms. Recent research has shifted its focus toward feedback-based approaches (Pryzant et al., 2023; Agarwal et al., 2025), which extract textual gradients from 2C-MOP: Integrating Momentum and Boundary-Aware Clustering for Enhanced Prompt Evolution 

error analysis as feedback signals to guide prompt updates. Furthermore, to enhance optimization effectiveness, some researchers have adopted multi-agent collaboration to assign diverse roles to LLMs (Han et al., 2025; Zhang et al., 2025; Pei et al., 2025), while others have applied model optimiza-tion techniques to prompt tuning, integrating historical tex-tual gradients via momentum to mitigate noise (Peng et al., 2025). Nevertheless, they fail to account for the disparity between textual and numerical gradients. Due to their dis-creteness, textual gradients are more susceptible to mutual interference, thereby undermining the overall optimization effectiveness. Consequently, we aim to employ a more ro-bust update signal selection scheme to ensure optimization stability. 

2.3. Limitations of Existing Methods 

Despite these advances, existing textual gradient-based prompt optimization methods face two critical challenges: 1. Incomplete Boundary Characterization : Current methods typically rely on sparse, stochastic sampling of a small subset of failure cases (Pryzant et al., 2023). This myopic approach fails to capture the global distri-bution of model performance and neglects the subtle â€œdecision boundariesâ€ where the model fluctuates be-tween success and failure, resulting in unfocused and imprecise gradient signals. 2. Textual Gradient Conflict and Instability : In large-scale batch optimization, LLM-generated gradients are often redundant or even contradictory, where dif-ferent error cases suggest opposing optimization di-rections (Han et al., 2025). Without a mechanism to aggregate information across iterations, these meth-ods suffer from significant gradient noise and unstable optimization trajectories. To address these limitations, we propose C-MOP, which introduces a Boundary-Aware Contrastive Sampling strategy to map precise decision boundaries and a textual momentum mechanism that leverages historical gradients to stabilize the optimization process. 

# 3. Method 

In this section, we present our proposed framework for automated prompt optimization. 

3.1. Problem Formulation 

Let D = {(qi, a i)}Ni=1 denote a dataset of query-answer pairs, where qi represents an input query and ai the corre-sponding ground-truth answer. Given a base language model 

F and an initial prompt p0, our goal is to find an optimized 

Algorithm 1 C-MOP: Cluster-based Momentum Optimized Prompting 

1: Input: Task model F, Optimizer model Fopt , Dataset D,Initial prompt p0, Batch size B, Iterations T , Total quota 

Qtotal , Decay factor Î³, Embedding model Ï•.2: Output: Optimized prompt pT .3: Initialize Gradient Pool Gpool â† âˆ… 

4: for t = 0 to T âˆ’ 1 do 

5: Sample batch Dt âŠ‚ D with size B.6: Generate predictions {ri} using pt for all (qi, a i) âˆˆ D t.7: Compute embeddings ei = Ï•(concat (qi, a i, r i)) and clus-ter into {C 1, . . . , CK }.8: for each cluster Ck do 

9: Calculate error rate Ek and assign sample quota Qk for cluster Ck .10: Sk â† Sample Qk instances focusing on the tripartite structures. 11: Gnew â† GenerateGradients (Fopt , p t, Sk ).12: end for 

13: Gpool â† G pool Ã— Î³

14: Add Gnew to Gpool with initial weights. 15: Cluster Gpool and aggregate weights within each cluster. 16: Tt â† Select top n gradients with highest weights. 17: Pcand â† âˆ… 

18: for l = 1 to L do 

19: Select gâˆ— âˆˆ T t and generate Ë†pl via Fopt rewriting pt.20: Pcand â† P cand âˆª { Ë†pl}

21: end for 

22: pt+1 â† UCB Select (Pcand )

23: end for 

24: return pT

prompt pâˆ— that maximizes the expected task performance: 

pâˆ— = arg max  

> p

E(q,a )âˆ¼D [s(F(p, q ), a )] (1) where the expectation E(q,a )âˆ¼D represents the average per-formance over the data distribution. In practice, this is approximated by evaluating the scoring function s(Â·, Â·)

(e.g., accuracy, F1 score) across sampled batches of in-stances. The challenge lies in navigating the discrete, high-dimensional prompt space to find a prompt that general-izes across the entire distribution while avoiding local op-tima (Bengio et al., 2013). 

3.2. Framework Overview 

C-MOP operates through an iterative refinement process consisting of four key stages, as illustrated in Figure 2: 1. Full-Batch Prediction : Evaluate the current prompt pt

on an entire sampled batch. Unlike traditional methods that only store failure cases, we preserve both positive and negative samples to provide a global view of the performance of the current prompt. 2. Boundary-Aware Contrastive Sampling (BACS) :We apply semantic clustering to the batch and allo-3C-MOP: Integrating Momentum and Boundary-Aware Clustering for Enhanced Prompt Evolution Training Set          

> Current
> Prompt ð‘ ð‘¡
> ð¶ 1
> ð¶ 2
> ð¶ 3
> -
> -
> +
> +
> +Anchors (+)
> -Hard Negatives ( -)
> +-Boundary Pairs
> Centroid
> Select Best Prompt
> New Prompt ð‘ ð‘¡ +1
> Generate
> Gradient
> UCB
> Scoring
> Gradient Pool
> Clustering &
> Accumulate Weights
> Full -Batch
> Prediction
> Sampling Batch
> Generating
> Prediction
> Based on ð‘ ð‘¡
> Boundary -Aware Contrastive
> Sampling Momentum -Guided Semantic
> Clustering
> Gradient -Guided Evolution
> New Gradient
> Select top Gradients
> Generate candidates based on selected Gradients
> KMeans Text
> Embedding
> Calculate ð¸ ð‘˜
> (Error Rate)

Figure 2. Overview of the C-MOP framework. The pipeline consists of four stages: (1) Full-Batch Prediction; (2) Boundary-Aware Contrastive Sampling; (3) Momentum-Guided Semantic Clustering; (4) Gradient-Guided Evolution. 

cate sampling quotas based on cluster-level error rates. Within each cluster, we extract Hard Negatives , An-chors , and Boundary Pairs to capture the subtle deci-sion logic of the model. 3. Momentum-Guided Semantic Clustering (MGSC) :We generate textual gradients (Pryzant et al., 2023) for the sampled cases. To resolve gradient conflicts, we maintain a historical gradient pool with a temporal decay Î³, performing secondary clustering to select the most consistent and effective optimization directions. 4. Gradient-Guided Evolution : Guided by the refined gradients, the optimizer model generates a diverse set of candidate prompts Pcand . To efficiently navigate this pool, we employ a UCB-based strategy (Auer et al., 2002) that balances exploration and exploitation, se-lecting the top-W prompts for the next iteration. We now detail each component, with particular emphasis on our Boundary-Aware Contrastive Sampling and Momentum-Guided Semantic Clustering evolution mechanisms. The complete optimization workflow of the C-MOP framework is formally presented in Algorithm 1. 

3.3. Boundary-Aware Contrastive Sampling 

To ensure high-fidelity feedback, BACS replaces stochastic sampling with a systematic extraction of Hard Negatives ,

Anchors , and Boundary Pairs . The motivation for this de-sign is two-fold: first, Anchors are essential for establishing a stable reference of successful reasoning, preventing the op-timizer model from drifting away from correct logic during refinement; second, Boundary Pairs are crucial for pinpoint-ing the precise linguistic triggers that cause the model to flip between correct and incorrect outputs. By contrast-ing these prototypical success patterns with subtle failure modes, BACS precisely characterizes the decision bound-aries of prompt to generate high-contrast, boundary-aware textual gradients. The strategy follows four sequential steps to select the most informative samples from a batch B:1. Global Batch Embedding : For every sample (qi, a i)

in the batch, where ri is the prediction of task model, we generate a semantic representation ei using a pre-trained encoder Ï•:

ei = Ï•(concat (qi, a i, r i)) (2) By embedding the entire batch, we create a complete seman-tic map of the promptâ€™s current behavior across different input types. 2. Cluster-Aware Quota Allocation : We apply K-means clustering (Krishna & Murty, 1999) to partition the batch into K clusters {C1, C 2, . . . , C K } and sample a total of 

Qtotal instances from a single batch. For each cluster Ck,we calculate its error rate Ek = |B error âˆ©Ck ||Ck | . We then allo-cate a sampling quota Qk proportional to the error rate: 

Qk = max 1,

&

Qtotal Ã— Ek

PKj=1 Ej

'! 

(3) This mechanism ensures that clusters exhibiting higher fail-ure ratesâ€”which highlight the logical deficiencies of the current promptâ€”are prioritized for further optimization. 3. Tripartite Fine-Grained Sampling : Within each cluster 

Ck, we define positive samples C+ 

> k

as correctly predicted instances and negative samples Câˆ’ 

> k

as incorrectly predicted ones. Based on the quota Qk, we select three types of sam-ples to provide the optimizer model with maximal contrast: 4C-MOP: Integrating Momentum and Boundary-Aware Clustering for Enhanced Prompt Evolution 

â€¢ Hard Negatives : The negative sample closest to the centroid. Since the centroid represents the dominant semantic theme of the cluster, these samples identify systematic failures rather than random outliers, repre-senting cases where the reasoning logic of the prompt consistently fails: 

ehard = arg min 

> eâˆˆCâˆ’
> k

âˆ¥e âˆ’ Î¼kâˆ¥2 (4) â€¢ Anchors : The positive sample closest to the centroid 

Î¼k. These instances represent the prototypical success patterns of the cluster, establishing a stable baseline for the correct reasoning logic of the prompt: 

eanc = arg min 

> eâˆˆC+
> k

âˆ¥e âˆ’ Î¼kâˆ¥2 (5) â€¢ Boundary Pairs : The n pairs of samples (e+, e âˆ’) that minimize the semantic distance âˆ¥e+ âˆ’ eâˆ’âˆ¥2. These pairs are critical for decision boundary refinement; by isolating the minimal semantic difference that triggers a classification flip, they provide high-contrast signals that pinpoint the exact instructional flaws. 4. Gradient Generation : The selected samples are passed to the optimizer model. By comparing the Hard Negatives 

and Anchors alongside the Boundary Pairs , the LLM can derive highly actionable gradients that specifically target the confusion between similar semantic inputs. 

3.4. Momentum-Guided Semantic Clustering 

We propose Momentum-Guided Semantic Clustering (MGSC), a mechanism that maintains a historical gradi-ent pool through a temporal decay factor. By aggregating gradients across iterations, MGSC distills persistent seman-tic consensus into a unified and stable direction for prompt evolution. The refinement process is formalized as follows: 1. Dynamic Gradient Pool Maintenance : We maintain a historical gradient pool Gt = {(gi, w i, t i)}, where each entry consists of a textual gradient gi, its importance weight 

wi, and the iteration index ti when the gradient is gener-ated. At each iteration t, all historical gradients undergo a temporal decay: 

w(t) 

> i

= w(0)  

> i

Â· Î³(tâˆ’ti) (6) where Î³ is a decay factor. This ensures that more re-cent gradientsâ€”which reflect the modelâ€™s current behav-iorâ€”carry stronger influence, while older gradients are grad-ually phased out. 2. Cross-Iteration Gradient Clustering : To resolve tex-tual conflicts and ensure temporal consistency, we perform semantic clustering on the unified set of current gradients and the decayed historical pool. The total gradient set is defined as: 

Gtotal = Gcurrent âˆª G pool (7) We subsequently partition Gtotal into M semantic clusters 

{ Ë†C1, Ë†C2, . . . , Ë†CM } based on their latent embeddings. This clustering allows the framework to identify persistent opti-mization themes across different iterations. 3. Weight-Based Gradient Selection : Within each cluster 

Ë†Cj , gradients may still point in slightly different directions. To extract the most representative and â€œstableâ€ direction, we select the top-n gradients with the highest accumulated weights: 

gâˆ— 

> j

= Top-n gâˆˆ Ë†Cj (w(t)) (8) This selection process acts as a semantic moving average, effectively suppressing stochastic noise from individual batches. 4. Prompt Evolution : The final set of refined gradients 

{gâˆ— 

> j

} is used to guide the optimizer model. By focusing on high-weight, cluster-representative gradients, the evolution process remains coherent across iterations, preventing the â€œoscillationâ€ common in naive textual gradient descent. 

3.5. Gradient-Guided Evolution 

The final stage of our framework transforms the stable se-mantic gradients into concrete prompt instructions through a two-fold evolution process: candidate generation and adap-tive selection. 

Candidate Generation. The diversity and quality of the candidate pool are fundamental to the robustness of the optimization. To ensure a broad yet targeted search within the prompt manifold, we derive 2M primary optimization directions by selecting the top-2 gradients with the highest accumulated weights from each of the M semantic clusters in MGSC: 

Gref ined = {gâˆ— 

> j,k

| j âˆˆ { 1, . . . , M }, k âˆˆ { 1, 2}} (9) These gradients represent stabilized, cluster-level insights that allow the optimizer model to focus on rectifying sys-temic logical deficiencies rather than isolated failures. For each gâˆ— âˆˆ G ref ined , the optimizer model rewrites the cur-rent prompt pt to produce a total of L distinct candidates 

Pcand . During this process, we maintain an appropriate sampling temperature to encourage structural and vocabu-lary diversity, ensuring that candidates are not merely minor paraphrases but distinct strategic attempts at task instruction. 

UCB-Driven Selection. Given the large-scale candidate prompt pool, evaluating every prompt on the entire valida-tion set would be computationally prohibitive. To efficiently 5C-MOP: Integrating Momentum and Boundary-Aware Clustering for Enhanced Prompt Evolution 

Table 1. Main Results: Accuracy comparison (%) on three benchmarks. Best results are bolded , second-best are underlined . Results are averaged over three runs with standard deviation shown as subscripts. Asterisks (*) denote our re-implemented version. Q30BA3B-Inst: Qwen3-30B-A3B-Instruct-2507, Q30BA3B-Think: Qwen3-30B-A3B-Thinking-2507. 

Method Task Model Optimizer Model BBH GSM8K Liar Avg (EM) (Acc) (F1) 

OPRO (Yang et al., 2023) PaLM 2-L PaLM 2-L-IT - 80.20 - -EvoPrompt (Tong et al., 2025) GPT-3.5-Turbo GPT-3.5-Turbo 75.03 - - -PromptWizard (Agarwal et al., 2025) GPT-4 GPT-4 88.10 95.40 - -SPO (Xiang et al., 2025) GPT-4o-mini GPT-4o - - 66.90 -ERM (Yan et al., 2025) Doubao-Pro GPT-4o 86.10 93.30 68.60 -MARS (Zhang et al., 2025) GPT-4o GPT-4o 80.86 - - -GPO (Tang et al., 2025) GPT-4 GPT-4 78.65 - - -Zero-shot (Base) Q30BA3B-Inst - 81.65 Â±0.14 80.67 Â±0.47 40.92 Â±0.33 67.75 ProTeGi* (Pryzant et al., 2023) Q30BA3B-Inst Q30BA3B-Think 82.63 Â±1.27 95.07 Â±0.20 58.47 Â±0.43 78.72 PromptWizard* Q30BA3B-Inst Q30BA3B-Think 85.34 Â±1.51 94.54 Â±0.68 61.61 Â±0.62 80.50 SPO* Q30BA3B-Inst Q30BA3B-Think 84.13 Â±1.31 93.00 Â±1.01 59.38 Â±3.07 78.84 GPO* Q30BA3B-Inst Q30BA3B-Think 82.61 Â±1.61 95.04 Â±0.79 57.85 Â±3.53 78.50 

C-MOP (Ours) Q30BA3B-Inst Q30BA3B-Think 86.24 Â±0.41 95.53 Â±0.20 64.46 Â±0.68 82.08 

âˆ† vs. PromptWizard +0.90 +0.99 +2.85 +1.58 

navigate this search space, we frame the selection as a multi-armed bandit problem and employ the Upper Confidence Bound (UCB) algorithm (Auer et al., 2002): 

U CB (p) = Î¼(p) + Î±

s

ln Nnp

(10) where Î¼(p) is the empirical mean accuracy, np is the number of evaluations for prompt p, and N is the total evaluation tri-als. This mechanism dynamically balances the exploitation of high-performing prompts with the exploration of can-didates whose potential remains uncertain. By iteratively assessing candidates on fresh subsets of data until the bud-get is exhausted, C-MOP prevents the optimization from converging prematurely to local optima. Finally, the top-W

prompts with the highest empirical performance are selected as the â€œbeamâ€ for the subsequent iteration. 

# 4. Experiments 

In this section, we conduct a comprehensive empirical eval-uation to validate the effectiveness of C-MOP. Our experi-ments aim to answer four key research questions: 1. RQ1 : How does C-MOP compare to state-of-the-art prompt optimization methods? 2. RQ2 : What is the individual contribution of each com-ponent? 3. RQ3 : How does the choice of optimizer model affect optimization outcomes? 4. RQ4 : Can C-MOP enable general-purpose models to rival domain-specific models? 

4.1. Experimental Setup Benchmarks. We evaluate C-MOP across four diverse datasets to demonstrate its applicability: BBH (Suzgun et al., 2022) (Big-Bench Hard) for complex logical reason-ing, Liar (Wang, 2017) for short-statement fact-checking, GSM8K (Cobbe et al., 2021) for multi-step mathematical problems, and CFinBench (Nie et al., 2025) for specialized financial domain knowledge. More detailed descriptions and data statistics for each benchmark are presented in Ap-pendix A.1. 

Baselines. We compare C-MOP with Zero-shot (with a default prompt) and four re-implemented existing meth-ods, including ProTeGi (Pryzant et al., 2023), PromptWiz-ard (Agarwal et al., 2025), SPO (Xiang et al., 2025) and GPO (Tang et al., 2025). 

Implementation Details. Unless otherwise specified, we employ Qwen3-30B-A3B-Instruct-2507 (Yang et al., 2025) as the task model, while using Qwen3-30B-A3B-Thinking-2507 (Yang et al., 2025) as the optimizer model. For text clustering, all-MiniLM-L6-v2 (Reimers & Gurevych, 2019) is used as the embedding model. A default batch size of 

B = 128 is employed throughout our experiments. The optimization process is conducted over T = 20 iterations with a beam size of W = 4 . In each iteration, the optimizer model generates a total of L = 10 candidate prompts based on the refined gradients. We set the total sampling quota 

Qtotal = 30 . The number of clusters for BACS is set to 

K = 14 , while the number of clusters for MGSC is M =10 . Furthermore, we incorporate a decay factor Î³ = 0 .9

during the gradient aggregation phase to emphasize recent feedback signals. Detailed sensitivity analyses for these 6C-MOP: Integrating Momentum and Boundary-Aware Clustering for Enhanced Prompt Evolution 

hyper-parameters, along with generalization experiments across diverse task models, are presented in Appendix A.2. All experiments were conducted using three random seeds, and we report the mean Â± standard deviation. 

4.2. Main Results (RQ1) 

Table 1 presents the performance of C-MOP compared to state-of-the-art (SOTA) methods and re-implemented base-lines across three representative benchmarks. The results demonstrate that C-MOP consistently achieves the highest accuracy among all models using the same task model. We summarize the key findings as follows: â€¢ Consistency Across Benchmarks: C-MOP outper-forms all re-implemented baselines on BBH, GSM8K, and Liar. Compared to the strongest baseline, PromptWizard*, C-MOP achieves absolute gains of +0.90%, +0.99%, and +2.85% respectively. The sub-stantial improvement on the Liar dataset (from 61.61% to 64.46%) is particularly noteworthy, highlighting its effectiveness in handling nuanced semantic classifica-tion tasks. â€¢ High-Performance Reasoning: In logic-intensive tasks like GSM8K and BBH, C-MOP reaches 95.53% and 86.24% accuracy. Remarkably, our method using the Qwen3-30B-A3B-Instruct-2507 surpasses several GPT-4 based SOTA methods, such as MARS (80.86%) and GPO (78.65%) on the BBH benchmark. This in-dicates that our optimization strategy can significantly narrow the gap between open-source and proprietary models. â€¢ Comparison with Zero-shot Base: Compared to the Zero-shot (Base) performance, C-MOP provides a mas-sive boost, particularly on the Liar dataset, where ac-curacy increases from 40.92% to 64.46% (+23.54%). This underscores the necessity of systematic prompt optimization in specialized tasks where default instruc-tions often fall short. In summary, the empirical results confirm that C-MOP is a robust and effective framework for prompt optimization, achieving a new state-of-the-art performance on the Qwen3-30B-A3B-Instruct-2507 as the task model. 

4.3. Ablation Analysis (RQ2) 

To verify the individual contributions of our proposed com-ponents, we conduct a systematic ablation study on the Liar and BBH datasets (Table 2, 3 and 4). We analyze the impact of different module configurations as follows: â€¢ Effectiveness of BACS: As shown in Table 2, keep-ing the MGSC module constant while replacing BACS                                                 

> Table 2. Ablation study of MGSC and different instance compo-nents. Clustering: K-means clustering on failure instances.
> Instance Gradient Liar BBH Avg (F1) (EM)
> Zero-shot (Base) 40.92 81.65 61.29 -MGSC 59.84 83.23 71.54 Clustering MGSC 61.42 82.60 72.01 BACS MGSC 64.46 86.24 75.35
> Table 3. Ablation study of different sample types. HN, ANC, and BP denote Hard Negatives ,Anchors , and Boundary Pairs ,respectively.
> HN ANC BP Liar BBH Avg (F1) (EM)
> âœ“61.37 84.85 73.11
> âœ“âœ“62.39 83.65 73.02
> âœ“âœ“63.28 85.18 74.23
> âœ“âœ“âœ“64.46 86.24 75.35

with random sampling leads to a drop in average ac-curacy to 71.54%, which is significantly lower than the 75.35% achieved by our full framework. Similarly, employing naive error clustering instead of BACS only yields a 72.01% average accuracy. This performance gap demonstrates that mining specific Boundary Pairs 

provides more precise directional guidance for prompt evolution than indiscriminately using failure cases. â€¢ Decomposition of Sample Types in BACS: Table 3 reveals distinct optimization dynamics between single-domain and multi-task scenarios. On the Liar dataset, 

Anchors and Boundary Pairs provide straightforward cumulative gains. However, on the BBH benchmark, adding Anchors alone leads to a performance dip from 84.85% to 83.65%. We hypothesize that in multi-task settings, a limited set of Anchors may overfit to specific sub-tasks, introducing task-specific bias that harms global generalization. Crucially, the integration of 

Boundary Pairs rectifies this instability, propelling the performance to a peak of 86.24%. This confirms that                          

> Table 4. Ablation study on the application of different components to instances and gradients. Momentum: momentum application without semantic gradient clustering (Peng et al., 2025).
> Instance Gradient Liar BBH Avg (F1) (EM)
> Zero-shot (Base) 40.92 81.65 61.29 Clustering -61.71 82.52 72.12 BACS -60.38 83.97 72.18 BACS Momentum 61.11 82.53 71.82 BACS MGSC 64.46 86.24 75.35

7C-MOP: Integrating Momentum and Boundary-Aware Clustering for Enhanced Prompt Evolution 

while Anchors offer static guidance, Boundary Pairs 

provide task-agnostic contrastive signalsâ€”learning the fundamental distinction between correct and incorrect reasoningâ€”which is essential for robust optimization across diverse tasks. â€¢ Impact of MGSC Gradient Refinement: Table 4 highlights the necessity of our gradient refinement mechanism. The complete removal of MGSC results in a reduced average accuracy of 72.18%. Furthermore, we observe that applying momentum (Peng et al., 2025) without secondary semantic clustering leads to a per-formance dip on BBH to 82.53%, an outcome even lower than the 83.97% attained by BACS alone. This confirms that while momentum stabilizes the trajectory, the secondary clustering in MGSC is essential to filter out batch-specific noise and extract a unified semantic consensus, ultimately driving the average accuracy to its peak of 75.35%. Overall, these results validate that BACS and MGSC are highly complementary, with the former providing high-quality raw signals and the latter ensuring their stable refine-ment into consistent optimization directions.                 

> Table 5. Impact of optimizer model choice on optimization ef-fectiveness (Liar and BBH dataset). Q30BA3B-Inst: Qwen3-30B-A3B-Instruct-2507, Q30BA3B-Think: Qwen3-30B-A3B-Thinking-2507.
> Task Model Optimizer Model Liar BBH (F1) (EM)
> Q30BA3B-Inst N/A (Zero-shot) 40.92 81.65 Q30BA3B-Inst Q30BA3B-Inst (Self) 58.24 83.52 Q30BA3B-Inst Q30BA3B-Think 64.46 86.24

4.4. Impact of Optimizer Capacity (RQ3) 

We investigate how the reasoning capacity of the optimizer model affects the effectiveness of prompt evolution. Table 5 compares the performance when using different models as the optimizer while maintaining Qwen3-30B-A3B-Instruct-2507 as the task model. Our observations are as follows: â€¢ Effectiveness of Self-Correction: Using the task model itself as the optimizer model yields substantial gains over the zero-shot baseline, with accuracy jump-ing from 40.92% to 58.24% on Liar (+17.32%) and from 81.65% to 83.52% on BBH (+1.87%). This con-firms that C-MOP enables models to effectively iden-tify and rectify their own systemic biases through our cluster-aware gradient mechanism, providing a cost-effective solution without relying on external teacher models. â€¢ Benefits of Enhanced Reasoning: Upgrading to the Thinking variant further boosts performance to 64.46% on Liar and 86.24% on BBH. This significant delta suggests that the quality of textual gradients is highly dependent on the optimizerâ€™s ability to perform deep logical deduction. Stronger models generate more pre-cise and actionable gradients, which in turn guide the evolution toward more robust prompt candidates. These results validate that C-MOP is scalable and can effec-tively utilize stronger optimizer models to guide optimiza-tion of weaker task models.             

> Table 6. Comparison with domain-specific models on CFinBench. Results for XuanYuan2-70-Base and GPT-4 are retrieved from (Nie et al., 2025). Q30BA3B-Inst: Qwen3-30B-A3B-Instruct-2507. Opt: Optimization.
> Model Type Accuracy (%)
> XuanYuan2-70B-Base Domain-Specific 56.69 GPT-4 Closed-Source 56.77 Q30BA3B-Inst General 52.49
> + C-MOP General + Opt 60.20

4.5. Domain Adaptation Comparison (RQ4) 

We examine whether C-MOP can empower general-purpose models to rival or even surpass domain-specific models. Table 6 compares C-MOP-optimized Qwen3-30B-A3B-Instruct-2507 against specialized financial models and closed-source SOTA on the CFinBench benchmark. C-MOP boosts the performance of the general-purpose Qwen3-30B-A3B-Instruct-2507 from 52.49% to 60.20%, an abso-lute gain of +7.71%. Remarkably, our optimized model with only 3B active parameters surpasses XuanYuan2-70B-Base (Zhang & Yang, 2023) by 3.51%, despite the latter being a large-scale model specifically pre-trained on expan-sive financial corpora. It also surpasses GPT-4 (Achiam et al., 2023) (+3.43%), demonstrating that precise prompt optimization can bridge the gap between general models and domain-specialized experts. 

# 5. Conclusion 

In this paper, we investigate the problem of enhancing the efficacy of automatic prompt optimization. We proposed C-MOP, integrating Boundary-Aware Contrastive Sampling to resolve sampling ambiguity and Momentum-Guided Seman-tic Clustering to mitigate gradient conflicts. Specifically, BACS characterizes decision boundaries to improve the fidelity of update signals, while MGSC utilizes temporal momentum to ensure the stability of the optimization tra-jectory. Experimental results demonstrate that C-MOP out-performs SOTA baselines and enables a general LLM with 8C-MOP: Integrating Momentum and Boundary-Aware Clustering for Enhanced Prompt Evolution 

3B activated parameters to surpass a 70B domain-specific dense LLM. Future work will explore hierarchical and self-evolving strategies to further elevate the performance ceil-ing. 

# References 

Achiam, J., Adler, S., Agarwal, S., Ahmad, L., Akkaya, I., Aleman, F. L., Almeida, D., Altenschmidt, J., Altman, S., Anadkat, S., et al. Gpt-4 technical report. arXiv preprint arXiv:2303.08774 , 2023. Agarwal, E., Magazine, R., Singh, J., Dani, V., Ganu, T., and Nambi, A. Promptwizard: Optimizing prompts via task-aware, feedback-driven self-evolution. In Findings of the Association for Computational Linguistics: ACL 2025 , pp. 19974â€“20003, 2025. Auer, P., Cesa-Bianchi, N., and Fischer, P. Finite-time analysis of the multiarmed bandit problem. Machine learning , 47(2):235â€“256, 2002. Bengio, Y., Louradour, J., Collobert, R., and Weston, J. Curriculum learning. In Proceedings of the 26th annual international conference on machine learning , pp. 41â€“48, 2009. Bengio, Y., L Â´eonard, N., and Courville, A. Estimating or propagating gradients through stochastic neurons for con-ditional computation. arXiv preprint arXiv:1308.3432 ,2013. Brown, T., Mann, B., Ryder, N., Subbiah, M., Kaplan, J. D., Dhariwal, P., Neelakantan, A., Shyam, P., Sastry, G., Askell, A., Agarwal, S., Herbert-Voss, A., Krueger, G., Henighan, T., Child, R., Ramesh, A., Ziegler, D., Wu, J., Winter, C., Hesse, C., Chen, M., Sigler, E., Litwin, M., Gray, S., Chess, B., Clark, J., Berner, C., McCandlish, S., Radford, A., Sutskever, I., and Amodei, D. Language models are few-shot learners. In Larochelle, H., Ranzato, M., Hadsell, R., Balcan, M., and Lin, H. (eds.), Advances in Neural Information Processing Systems , volume 33, pp. 1877â€“1901. Curran Associates, Inc., 2020. URL https://proceedings.neurips.cc/paper files/paper/2020/ file/1457c0d6bfcb4967418bfb8ac142f64a-Paper.pdf. Chen, H., Wang, Y., Han, K., Li, D., Li, L., Bi, Z., Li, J., Wang, H., Mi, F., Zhu, M., Wang, B., Song, K., Fu, Y., He, X., Luo, Y., Zhu, C., He, Q., Wu, X., He, W., Hu, H., Tang, Y., Tao, D., Chen, X., and Wang, Y. Pangu embedded: An efficient dual-system llm reasoner with metacognition, 2025. URL https://arxiv.org/abs/2505.22375. Chowdhery, A., Narang, S., Devlin, J., Bosma, M., Mishra, G., Roberts, A., Barham, P., Chung, H. W., Sutton, C., Gehrmann, S., et al. Palm: Scaling language modeling with pathways. Journal of Machine Learning Research ,24(240):1â€“113, 2023. Cobbe, K., Kosaraju, V., Bavarian, M., Chen, M., Jun, H., Kaiser, L., Plappert, M., Tworek, J., Hilton, J., Nakano, R., et al. Training verifiers to solve math word problems. 

arXiv preprint arXiv:2110.14168 , 2021. Fernando, C., Banarse, D., Michalewski, H., Osindero, S., and Rockt Â¨aschel, T. Promptbreeder: Self-referential self-improvement via prompt evolution. arXiv preprint arXiv:2309.16797 , 2023. Grattafiori, A., Dubey, A., Jauhri, A., Pandey, A., Kadian, A., Al-Dahle, A., Letman, A., Mathur, A., Schelten, A., Vaughan, A., et al. The llama 3 herd of models. arXiv preprint arXiv:2407.21783 , 2024. Han, Y., Han, Y., Liu, B., Zhou, Z., Liu, G., Zhang, Z., Yang, Y., Wang, W., Shi, I. N., Zhang, Y., et al. Mapgd: Multi-agent prompt gradient descent for collaborative prompt optimization. arXiv preprint arXiv:2509.11361 , 2025. Hoffer, E., Hubara, I., and Soudry, D. Train longer, general-ize better: closing the generalization gap in large batch training of neural networks. Advances in neural informa-tion processing systems , 30, 2017. Jiang, Z., Xu, F. F., Araki, J., and Neubig, G. How can we know what language models know? Transactions of the Association for Computational Linguistics , 8:423â€“438, 2020. Krishna, K. and Murty, M. N. Genetic k-means algorithm. 

IEEE Transactions on Systems, Man, and Cybernetics, Part B (Cybernetics) , 29(3):433â€“439, 1999. Krizhevsky, A. One weird trick for parallelizing convolu-tional neural networks. arXiv preprint arXiv:1404.5997 ,2014. Liu, P., Yuan, W., Fu, J., Jiang, Z., Hayashi, H., and Neubig, G. Pre-train, prompt, and predict: A systematic survey of prompting methods in natural language processing. ACM computing surveys , 55(9):1â€“35, 2023. Lu, Y., Bartolo, M., Moore, A., Riedel, S., and Stenetorp, P. Fantastically ordered prompts and where to find them: Overcoming few-shot prompt order sensitivity. In Pro-ceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers) ,pp. 8086â€“8098, 2022. McCandlish, S., Kaplan, J., Amodei, D., and Team, O. D. An empirical model of large-batch training. arXiv preprint arXiv:1812.06162 , 2018. 9C-MOP: Integrating Momentum and Boundary-Aware Clustering for Enhanced Prompt Evolution 

Minaee, S., Mikolov, T., Nikzad, N., Chenaghlu, M., Socher, R., Amatriain, X., and Gao, J. Large language models: A survey. arXiv preprint arXiv:2402.06196 , 2024. Nie, Y., Yan, B., Guo, T., Liu, H., Wang, H., He, W., Zheng, B., Wang, W., Li, Q., Sun, W., et al. Cfinbench: A comprehensive chinese financial benchmark for large lan-guage models. In Proceedings of the 2025 Conference of the Nations of the Americas Chapter of the Association for Computational Linguistics: Human Language Tech-nologies (Volume 1: Long Papers) , pp. 876â€“891, 2025. Pei, Z., Zhen, H.-L., Kai, S., Pan, S. J., Wang, Y., Yuan, M., and Yu, B. Scope: Prompt evolution for enhancing agent effectiveness. arXiv preprint arXiv:2512.15374 , 2025. Peng, D., Zhou, Y., Chen, Q., Liu, J., Chen, J., Qin, L., and Che, W. Dlpo: Towards a robust, efficient, and gen-eralizable prompt optimization framework from a deep-learning perspective. arXiv preprint arXiv:2503.13413 ,2025. Perez, E., Kiela, D., and Cho, K. True few-shot learning with language models. Advances in neural information processing systems , 34:11054â€“11070, 2021. Pryzant, R., Iter, D., Li, J., Lee, Y. T., Zhu, C., and Zeng, M. Automatic prompt optimization withâ€ gradient descentâ€ and beam search. arXiv preprint arXiv:2305.03495 , 2023. Reimers, N. and Gurevych, I. Sentence-bert: Sentence embeddings using siamese bert-networks. arXiv preprint arXiv:1908.10084 , 2019. Reynolds, L. and McDonell, K. Prompt programming for large language models: Beyond the few-shot paradigm. In Extended abstracts of the 2021 CHI conference on human factors in computing systems , pp. 1â€“7, 2021. Sener, O. and Koltun, V. Multi-task learning as multi-objective optimization. Advances in neural information processing systems , 31, 2018. Settles, B. Active learning literature survey. 2009. Shallue, C. J., Lee, J., Antognini, J., Sohl-Dickstein, J., Frostig, R., and Dahl, G. E. Measuring the effects of data parallelism on neural network training. Journal of Machine Learning Research , 20(112):1â€“49, 2019. Suzgun, M., Scales, N., Sch Â¨arli, N., Gehrmann, S., Tay, Y., Chung, H. W., Chowdhery, A., Le, Q. V., Chi, E. H., Zhou, D., , and Wei, J. Challenging big-bench tasks and whether chain-of-thought can solve them. arXiv preprint arXiv:2210.09261 , 2022. Tang, X., Wang, X., Zhao, W. X., Lu, S., Li, Y., and Wen, J.-R. Unleashing the potential of large language models as prompt optimizers: Analogical analysis with gradient-based model optimizers. In Proceedings of the AAAI Con-ference on Artificial Intelligence , volume 39, pp. 25264â€“ 25272, 2025. Tong, Z., Ding, Z., and Wei, W. Evoprompt: Evolving prompts for enhanced zero-shot named entity recognition with large language models. In Proceedings of the 31st International Conference on Computational Linguistics ,pp. 5136â€“5153, 2025. Touvron, H., Lavril, T., Izacard, G., Martinet, X., Lachaux, M.-A., Lacroix, T., Rozi `ere, B., Goyal, N., Hambro, E., Azhar, F., et al. Llama: Open and efficient foundation lan-guage models. arXiv preprint arXiv:2302.13971 , 2023. Wang, W. Y. â€ liar, liar pants on fireâ€: A new bench-mark dataset for fake news detection. arXiv preprint arXiv:1705.00648 , 2017. Wei, J., Wang, X., Schuurmans, D., Bosma, M., Xia, F., Chi, E., Le, Q. V., Zhou, D., et al. Chain-of-thought prompting elicits reasoning in large language models. Advances in neural information processing systems , 35:24824â€“24837, 2022. Xiang, J., Zhang, J., Yu, Z., Teng, F., Tu, J., Liang, X., Hong, S., Wu, C., and Luo, Y. Self-supervised prompt optimization. CoRR , 2025. Yan, C., Wang, J., Zhang, L., Zhao, R., Wu, X., Xiong, K., Liu, Q., Kang, G., and Kang, Y. Efficient and accurate prompt optimization: the benefit of memory in exemplar-guided reflection. In Proceedings of the 63rd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers) , pp. 753â€“779, 2025. Yang, A., Li, A., Yang, B., Zhang, B., Hui, B., Zheng, B., Yu, B., Gao, C., Huang, C., Lv, C., et al. Qwen3 technical report. arXiv preprint arXiv:2505.09388 , 2025. Yang, C., Wang, X., Lu, Y., Liu, H., Le, Q. V., Zhou, D., and Chen, X. Large language models as optimizers. In 

The Twelfth International Conference on Learning Repre-sentations , 2023. Yu, Y., Yu, Y., and Wang, H. Premise: Scalable and strategic prompt optimization for efficient mathematical reasoning in large models. arXiv preprint arXiv:2506.10716 , 2025. Zamfirescu-Pereira, J. D., Wong, R. Y., Hartmann, B., and Yang, Q. Why johnny canâ€™t prompt: how non-ai experts try (and fail) to design llm prompts. In Proceedings of the 2023 CHI conference on human factors in computing systems , pp. 1â€“21, 2023. Zhang, J., Wang, Z., Zhu, H., Liu, J., Lin, Q., and Cambria, E. Mars: A multi-agent framework incorporating socratic 10 C-MOP: Integrating Momentum and Boundary-Aware Clustering for Enhanced Prompt Evolution 

guidance for automated prompt optimization. CoRR ,2025. Zhang, X. and Yang, Q. Xuanyuan 2.0: A large chinese financial chat model with hundreds of billions parameters. In Proceedings of the 32nd ACM international conference on information and knowledge management , pp. 4435â€“ 4439, 2023. Zhao, W. X., Zhou, K., Li, J., Tang, T., Wang, X., Hou, Y., Min, Y., Zhang, B., Zhang, J., Dong, Z., et al. A survey of large language models. arXiv preprint arXiv:2303.18223 ,1(2), 2023. Zhao, Z., Wallace, E., Feng, S., Klein, D., and Singh, S. Calibrate before use: Improving few-shot performance of language models. In International conference on machine learning , pp. 12697â€“12706. PMLR, 2021. 11 C-MOP: Integrating Momentum and Boundary-Aware Clustering for Enhanced Prompt Evolution 

# A. Additional Details for the Setup 

A.1. Datasets Details 

During the prompt optimization process, we utilized the BBH (Suzgun et al., 2022), GSM8K (Cobbe et al., 2021), CFinBench (Nie et al., 2025) and Liar (Wang, 2017) datasets. For BBH and CFinBench, we partitioned the data into train and test sets manually. In contrast, for Liar and GSM8K, we followed the original splits for the train and test sets. Notably, unlike most other methods, we did not optimize individual prompts for each sub-task within BBH; instead, we optimized a unified prompt across all tasks. Detailed information and evaluation metrics for all datasets are presented in the following text and Table 7. â€¢ BBH (Suzgun et al., 2022) (BIG-Bench Hard): BBH comprises 23 challenging multi-step reasoning tasks from BIG-Bench. In this paper, we performed a custom split to construct a training set of 5, 808 samples and a testing set of 

703 samples across all tasks, utilizing Accuracy as the primary metric to assess model performance. â€¢ GSM8K (Cobbe et al., 2021): GSM8K consists of 7, 473 training and 1, 319 test high-quality grade school math problems. Models are typically evaluated using Exact Match (EM) accuracy, which requires the final numerical answer to be identical to the ground truth after parsing the model-generated reasoning chain. â€¢ CFinBench (Nie et al., 2025): CFinBench is a comprehensive benchmark designed to evaluate the financial knowledge within the Chinese financial context. In this study, we performed a custom stratified split by sampling from the original test dataset to construct a training set of 5, 000 samples and a dedicated evaluation set of 800 samples, using Accuracy as the primary metric to assess model performance. â€¢ Liar (Wang, 2017): Liar is an English fake news detection dataset. In this paper, we utilize the version of the Liar dataset as described by (Pryzant et al., 2023). This specific setup consists of 3,681 training samples and 461 test samples. We employ the F1 score as the primary evaluation metric.                           

> Table 7. Dataset sizes and details.
> Dataset Task Category Language Train Size Test Size Primary Metric
> BBH Logical Reasoning English 5,808 703 Exact Match GSM8K Mathematical Reasoning English 7,473 1,319 Accuracy CFinBench Chinese Financial Eval Chinese 5,000 800 Accuracy Liar Fake News Detection English 3,681 461 F1-score

A.2. Implementation Details 

In this section, we provide supplementary experimental results and comprehensive implementation details to substantiate our parameter configurations. We first summarize the complete set of hyper-parameters used across all experiments in Table 8. Following this, we focus our discussion on two critical dimensions: a detailed sensitivity analysis of the clustering hyper-parameters ( K and M ) to justify our chosen default settings, and a robust evaluation of the generalization capabilities of C-MOP across a diverse range of task model architectures. Table 9 illustrates the performance of C-MOP under various combinations of instance cluster size K and gradient cluster size M , revealing a significant synergistic effect between these two dimensions. When adopting only the gradient centroid (i.e., M = 1 ), increasing K from 1 to 14 results in a marginal performance fluctuation (ranging from 60.38% to 62.01%). This limited range suggests that simply increasing sample variety without corresponding gradient refinement results in diluted or even conflicting optimization signals, as the model struggles to reconcile diverse error patterns into a single update direction. On the other hand, when K is fixed at 1, increasing M alone provides steady but marginal gains starting at 61.53% and reaching 62.78%. This indicates that refining the gradient space on a restricted sample perspective quickly reaches an inherent performance ceiling. The peak performance of 64.46% is achieved with the configuration of K = 14 and M = 10 . This result confirms our core hypothesis that high-diversity sample exploration must be coupled with high-precision gradient grouping to effectively navigate complex reasoning spaces. The sharp contrast between the failure at K = 14 , M = 1 and the success 12 C-MOP: Integrating Momentum and Boundary-Aware Clustering for Enhanced Prompt Evolution 

at K = 14 , M = 10 underscores that gradient granularity is the key to unlocking the full potential of large-scale sample diversity. 

Table 8. Summary of hyperparameter configurations for C-MOP. 

Category Hyperparameter Assignment 

Models Task Model Qwen3-30B-A3B-Instruct-2507 Optimizer Model Qwen3-30B-A3B-Thinking-2507 Optimization Total Iterations ( T ) 20 Beam Size ( W ) 4Candidate New Prompts of Current Prompt ( L) 10 Total Sampling Quota ( Qtotal ) 30 Clustering & Gradient Batch Size ( B) 128 Number of Instance Clusters ( K) 14 Number of Gradient Clusters ( M ) 10 Decay Factor ( Î³) 0.9 Others Embedding Model all-MiniLM-L6-v2 Number of Random Seeds 3Exploration Param for UCB ( Î±) 1.0 

Table 9. Sensitivity analysis of instance cluster size K and gradient cluster size M on the Liar. 

KM 1 3 10 1 61.53 62.35 62.78 

3 62.01 64.21 63.74 

10 60.97 63.45 64.18 

14 60.38 62.04 64.46 

We further investigate whether the effectiveness of C-MOP is consistent across different LLMs. Table 10 demonstrates the model-agnostic feature of C-MOP. We evaluate the performance across various architecture, including the Qwen3, Llama and openPangu families. The results show a consistent and substantial performance improvement, with âˆ† gains ranging from +9.98% to +23.54% points, suggesting that C-MOP does not overfit to a specific architecture but serves as a robust optimization method. 

Table 10. Generalization results across diverse task models on the Liar. We employed Qwen3-30B-A3B-Thinking-2507 as optimizer model. 

Task Model Zero-shot (Base) w/ C-MOP âˆ†

Qwen3-8B (Non-Thinking) (Yang et al., 2025) 44.03 58.79 +14.76 Llama-3.1-8B-Instruct (Grattafiori et al., 2024) 45.34 61.83 +16.49 Qwen3-30B-A3B-Instruct-2507 (Yang et al., 2025) 40.92 64.46 +23.54 openPangu-Embedded-7B-V1.1 (Chen et al., 2025) 50.97 60.95 +9.98 

# B. Optimized Results on Liar Dataset 

B.1. Optimal Prompts for Different Methods on the Liar Dataset 

The prompts optimized by ProTeGi (Pryzant et al., 2023) (60.17%) and GPO (Tang et al., 2025) (61.82%) are generally straightforward, enhancing performance through persona assignment and brief judging criteria. SPO (Xiang et al., 2025) (62.03%) provides rigid, step-by-step instructions, whereas PromptWizard (Agarwal et al., 2025) (62.04%) focuses on providing references by injecting examples into the prompt. In contrast, our method (66.16%) offers explicit guidance through more detailed procedures and rules, supplemented by simple examples in specific instructions to aid model comprehension, thereby achieving the best overall performance. 13 C-MOP: Integrating Momentum and Boundary-Aware Clustering for Enhanced Prompt Evolution 

ProTeGi (F1: 60.17) 

As a deception verification specialist, respond with "Yes" **only** when a statement is inherently unverifiable (e.g., it expresses a personal opinion, forecasts future events, or lacks factual basis). For **every** statement framed as a factual account of past or present occurrencesincluding those derived from news reports, official government statements, or publicly accessible recordsrespond with "No" without verifying truthfulness or consulting external sources. 

PromptWizard (F1: 62.04) 

Given a statement, job title, state, party, and the full text of a document (context), determine if the statement is factually true or false. First, **strictly check the context** (the exact text provided) for **direct evidence**. Direct evidence must be: - The exact words of the statement, OR - A clear, unambiguous reference (e.g., direct quote, specific data, or explicit factual claim) that directly supports or refutes the statement. **If the context is provided as a document description (e.g., "a mailer", "a news release", "an online opinion-piece") and not the actual text, the context lacks evidence.** Do not assume the description implies the statement is present. **Only if the context lacks evidence** (due to being a description, empty, or containing no direct evidence), use your own factual knowledge to determine the truth. If the context contains direct evidence, **never** use your own knowledge. Output ONLY "Yes" or "No" with no additional text, explanations, or formatting. [Question] Statement: Annies List supports third-trimester abortions on demand. Job title: State representative State: Texas Party: republican Context: a mailer [Answer] Step 1: The context is provided as "a mailer", which is a document description (indicating the type of document, not the actual text). According to the instruction, when the context is a document description (e.g., "a mailer"), it lacks direct evidence and cannot be used for verification. Step 2: Since the context lacks direct evidence, the instruction requires using factual knowledge to determine truthfulness. Step 3: Factual knowledge: Annies List is a pro-choice political action committee that supports abortion access up to fetal viability (approximately 24 weeks) and in specific medical circumstances beyond, but does not endorse "third-trimester abortions on demand" (which implies unrestricted abortions in the third trimester without medical necessity). Step 4: The statement claims Annies List supports "third-trimester abortions on demand," which contradicts the organizationâ€™s documented position. Step 5: Therefore, the statement is factually false, making it a lie, so the answer is "Yes". <ANS_START>Yes<ANS_END> [Question] Statement: The stateâ€™s unemployment rate was 3.5% in the last quarter. Job title: State economist State: California Party: none Context: "The California unemployment rate for Q4 2023 was 3.5%." 

14 C-MOP: Integrating Momentum and Boundary-Aware Clustering for Enhanced Prompt Evolution 

[Answer] The statement claims: "The stateâ€™s unemployment rate was 3.5% in the last quarter." The context explicitly states: "The California unemployment rate for Q4 2023 was 3.5%." The context provides direct evidence: it specifies the unemployment rate (3.5%) for a defined quarter (Q4 2023), which is unambiguously the "last quarter" at the time of the documentâ€™s publication (as Q4 2023 is the most recent quarter reported). This matches the statementâ€™s claim without requiring external knowledge, as the context contains a clear, explicit factual reference. Therefore, the statement is factually supported by the context and is not a lie. Output: No <ANS_START>No<ANS_END> [Question] Statement: The Chicago Bears have had more starting quarterbacks in the last 10 years than the total number of tenured (UW) faculty fired during the last two decades. Job title: Wisconsin Assembly speaker State: Wisconsin Party: republican Context: an online opinion-piece [Answer] The context is provided as "an online opinion-piece", which is a document description, not the actual text. Therefore, there is no direct evidence in the context to verify the statement. Using factual knowledge: - The Chicago Bears had a total of 161 quarterback starts (not distinct players) in the last 10 years (2014-2023), calculated as follows: - Jay Cutler: 16 starts (2014) + 15 starts (2015) = 31 - Brian Hoyer: 1 start (2015) + 1 start (2016) = 2 - Mike Glennon: 15 starts (2016) + 16 starts (2017) = 31 - Mitchell Trubisky: 16 starts (2018) + 16 starts (2019) + 16 starts (2020) = 48 - Nick Foles: 1 start (2020) = 1 - Justin Fields: 16 starts (2021) + 16 starts (2022) + 16 starts (2023) = 48 Total = 31 + 2 + 31 + 48 + 1 + 48 = 161 starts. - The University of Wisconsin (UW) fired 12 tenured faculty members in the last two decades (2004-2023), based on verified reports (e.g., Wisconsin State Journal, 2020, covering 2000-2020, with the 2004-2023 period including at least 12 firings). Since 161 > 12, the statement is factually true. A true statement is not a lie, so the answer is "No". <ANS_START>No<ANS_END> [Question] Statement: When Mitt Romney was governor of Massachusetts, we didnâ€™t just slow the rate of growth of our government, we actually cut it. Job title: Former governor State: Massachusetts Party: republican Context: an interview with CBN News [Answer] - The context provided is "an interview with CBN News", which is a description of the document (specifying the type of document and source) rather than the actual text of the interview. Therefore, the context lacks direct evidence as per the instruction. - Since the context lacks direct evidence, the task requires using own factual knowledge to determine the truth. - Factual knowledge: Mitt Romney served as governor of Massachusetts from 2003 to 2007. While the state budget was reduced by $1.2 billion (5%) in 2004 compared to 2003, the overall government spending trend during his governorship increased. The budget rose to $25.6 billion in 2005, $26.8 billion in 2006, and $28.5 billion in 2007 (nominal terms), meaning total spending was higher at the end of his term than at the start. The statement claims "we actually cut it" (implying a reduction in government spending), but the cumulative effect over his entire term was an increase, not a cut. Thus, the statement is factually false. - As the statement is false (a lie), the answer is "Yes". <ANS_START>Yes<ANS_END> 

15 C-MOP: Integrating Momentum and Boundary-Aware Clustering for Enhanced Prompt Evolution 

[Question] Statement: I donâ€™t know who Jonathan Gruber is. Job title: Nancy Pelosi State: California Party: democrat Context: a news conference [Answer] 1. The context provided is "a news conference", which is a description of the document type (not the actual text of the document). 2. According to the instruction, when the context is a document description (e.g., "a news conference") and not the full text, it lacks direct evidence. 3. Since the context lacks direct evidence, the instruction permits using factual knowledge to determine truthfulness. 4. Factual knowledge confirms that Nancy Pelosi (then Speaker of the House) publicly stated she did not know Jonathan Gruber during the Affordable Care Act debates, but she was later revealed to have met Gruber and been aware of his work as a key economist on the ACA. 5. Therefore, the statement "I donâ€™t know who Jonathan Gruber is" is factually false, making it a lie. 6. The answer is "Yes" because the statement is a lie. <ANS_START>Yes<ANS_END> Answer Yes (a lie) or No (not a lie) as labels. For each input word, present the reasoning followed by the correct answer between <ANS_START> and <ANS_END> tags. 

SPO (F1: 62.03) 

Analyze the Statement to determine if it is a false factual claim (Yes) or not (No) by rigorously applying these steps: 0. Determine if the statement is a factual claim (verifiable by evidence). If not (e.g., opinion, prediction, or value judgment), the statement cannot be a lie (Answer: No). 1. Clarify the time frame and scope (e.g., "four years ago" from when?). 2. Verify factual claims against authoritative sources (e.g., BLS, FEC, or peer-reviewed data). 3. Assess source bias using provided context (job title, state, party, media outlet). 4. Scrutinize absolute language (e.g., "never", "always") for overstatement. Provide a detailed, step-by-step reasoning process incorporating all elements. Conclude with "Final Answer:" followed by <answer>[Yes or No]</answer>. 

GPO (F1: 61.82) 

As a political fact-checker, if the statement is false, output "Yes". If the statement is true, output "No". Base your judgment on the speakerâ€™s job title, state, party, and context. 

C-MOP (F1: 66.16) 

You are a truthfulness evaluator. Apply these rules strictly: - **Standard Claim Verification**: For standard demographic/economic indicators (e.g., "more children die in X industry"), if location unspecified, verify against authoritative *national* historical data. Output "Yes" (false) only if no such data exists; otherwise "No" (true). - **Location and Comparison Rules**: Unspecified statistics default to national average. For comparative claims (e.g., "led the nation"), verify both the scopeâ€™s data *and* its confirmed national ranking position. Unconfirmed position = false claim. - **Absolute Claims**: Absolute language (e.g., "every", "all", "each") requires verification across all instances within the specified scope. Unconfirmed coverage (e.g., "at every grade level") = false claim. Scope modifiers in 

16 C-MOP: Integrating Momentum and Boundary-Aware Clustering for Enhanced Prompt Evolution 

coverage claims must be fully verified. - **Multi-Claim Statements**: Each independent claim must be verified separately. False if any claim is false. - **Numerical and Qualitative Claims**: Measurable claims (e.g., "160,000 troops", "one year") are inherently verifiable with current authoritative sources. Output "No" (true) if they match historical records; otherwise "Yes" (false). Do not default to "Yes" for measurable claims. - **Projection Verification**: Future-tense claims with specific event context (e.g., "this monthâ€™s session will pass") are verifiable as current facts. General future claims (e.g., "will cost in the future") require verification against documented historical predictions. Undocumented = false. - **Individual Past Actions**: Unverified by default; require historical record to be true. - **Claim Subject Identification**: Reporting verbs (e.g., "as Obama says") make the named entity the sole verification target. Contextual details (e.g., "Tampa") are irrelevant. Embedded quotes = unverifiable. - **Inference Prohibition**: Do not infer from context; claim must explicitly state subject matter. Incomplete = unverifiable = "Yes". - **Unverifiability Protocol**: Claims lacking measurable attributes or temporal scope (e.g., "We can fix roads without raising taxes") are unverifiable and output "Yes". Standard and measurable claims are verifiable. Output "Yes" for unverified/false, "No" for verified true. Ignore speaker identity, political context, and opinions. 

Table 11. Intermediate prompts optimized by C-MOP on Liar dataset. 

Step Prompt F1 

0 You are an expert at accomplishing tasks. You are a highly capable problem-solver who can handle complex instructions with precision and creativity. 40.92 2You are a factual accuracy arbiter. Your response must be â€Yesâ€ for false statements (lies) and â€Noâ€ for true statements. Never evaluate hypotheticals (e.g., â€could have,â€ â€might haveâ€)â€”treat them as non-factual. Omit all non-substantive context (e.g., â€Label,â€ â€Input Typeâ€). When assessing state policy claims, the speakerâ€™s party must historically align with the party that implemented the policy; any discrepancy is a lie. Base your judgment solely on the statement and its associated job title/state/party. 53.44 4You are an expert in factual truth assessment. Respond with â€Yesâ€ for false statements and â€Noâ€ for true statements. Only evaluate complete factual propositions (e.g., â€X is Yâ€ or â€X does Yâ€); incomplete fragments, questions, or non-propositional statements are automatically false (â€Yesâ€). Disregard all party affiliation, document type, speaker role, setting, and contextual cues unconditionallyâ€”treat them as universally irrelevant for all factual claims. For claims referencing party policies, apply â€party policy outcomesâ€ only when the statement directly cites a party-advocated policy (e.g., â€Republicans support tax cutsâ€); otherwise, evaluate as non-partisan factual claims using verifiable general knowledge alone. Compound statements require all components to be factually correct for â€Noâ€; any false component mandates â€Yesâ€. 58.67 10 Your task: determine factual truth. Output â€Yesâ€ for false, â€Noâ€ for true. Process only complete factual propositions (â€X does Yâ€); all else â€Yesâ€. Ignore universally: party, source, speaker role, title, position, setting, jurisdiction. Causal language requires independent validation. Compound statements: all parts must be true for â€Noâ€. Key rules: (1) â€Jim Crowâ€ = 1877-1965 racial segregation laws (voting restrictions alone donâ€™t qualify); (2) Public health comparisons true if CDC/FDA consensus matches; (3) Verifiability: claims with concrete, quantifiable details (e.g., dates, percentages, locations) are verifiable via public records; unverifiable claims lack measurable parameters (e.g., â€is greatâ€) and default to â€Yesâ€; (4) Numerical rankings (e.g., â€dead last,â€ â€worst attendanceâ€) are verifiable as they denote quantifiable metrics (e.g., Senate attendance percentage); (5) â€Fiscal yearâ€ implies federal (U.S. Treasury), so â€Washingtonâ€ is federal; (6) Past-tense behavioral claims (e.g., â€tried to evadeâ€) are verifiable; (7) Unsourced present-tense numbers (e.g., â€40% paidâ€) are verifiable via public records; (8) Topic fragments (e.g., â€On oil drillingâ€) true if context provides verifiable topic match. Publication attribution (e.g., â€USA Today saidâ€) suffices for historical claim verification. Never use speaker role, title, or position to infer truth. 64.21 20 See Appendix B.1 for the C-MOP prompt. 66.16 

B.2. Evolutionary Trajectory of Optimized Prompts 

Table 11 shows the iterative refinement of prompts conducted by C-MOP on the Liar dataset. We observe a clear progression in both instructional depth and task-specific reasoning: 17 C-MOP: Integrating Momentum and Boundary-Aware Clustering for Enhanced Prompt Evolution 

Starting from Step 0, the prompt consists of generic system instructions , resulting in a baseline F1-score of 40.92%. By Step 2, the optimizer model begins to identify the core task requirement and introduces basic heuristics such as party alignment and handling hypotheticals, leading to a significant performance jump (+12.52%). As the optimization reaches Step 10, C-MOP incorporates highly granular verification rules, such as specific temporal definitions (e.g., the â€œJim Crowâ€ era) and public health consensus protocols. Finally, at Step 20, the prompt evolves into a highly structured, logical framework emphasizing â€œAbsolute Claimsâ€, â€œProjection Verificationâ€, and â€œUnverifiability Protocolsâ€. The final performance reaches 66.16%, demonstrating that C-MOP can autonomously transform raw error signals into sophisticated, structured reasoning assets that significantly outperform initial human-crafted instructions. 

# C. Meta Prompts 

Prompt for Generating Textual Gradients 

### ROLE & OBJECTIVE You are a sophisticated Prompt Optimization Expert. Your task is to analyze model performance on a specific logical cluster and extract a high-precision Textual Gradient to improve the current prompt. ### CURRENT PROMPT [Insert Current Prompt Here] ### DIAGNOSTIC SAMPLES These samples represent a specific failure pattern. Analyze the contrast between correct and incorrect responses carefully. ### [TYPE A] Critical Boundary Pairs The following pairs are semantically or structurally similar, yet the model succeeded on one and failed on the other. This indicates a "fuzzy zone" in the current promptâ€™s logic. - [SIMILAR & CORRECT]: {correct_sample} - [SIMILAR & INCORRECT]: {incorrect_sample} - Analysis Point: Identify the exact missing constraint that caused the failure in the second case. ### [TYPE B] Representative Failures (Hard Negatives) These cases represent the "centroid" of errors in this cluster. They share a systematic logical flaw. - Failure Case: {hard_negative} ### [TYPE C] Success Anchors The following cases are handled correctly. Your optimization MUST ensure these remain correct (avoid catastrophic forgetting). - Anchor Case: {anchor_case} ### FINAL ANALYSIS TASK 1. Identify the common reasoning failure in this specific cluster. 2. Focus on the Boundary Pairs: What subtle nuance did the model miss compared to the correct counterpart? 3. Propose three precise, atomic Textual Gradients (prompt modifications or additional constraints) that fix these errors while preserving the Anchors. ### OUTPUT FORMAT Please give three reasons (Textual Gradients) why the prompt could have gotten these examples wrong and wrap each reason with <START> and <END> tags Please provide your insight in the following format: <START>Your concise, technical insight 1<END> 

18 C-MOP: Integrating Momentum and Boundary-Aware Clustering for Enhanced Prompt Evolution 

<START>Your concise, technical insight 2<END> <START>Your concise, technical insight 3<END> 

Prompt for Generating Candidate Prompts 

Iâ€™m trying to write a prompt about some different tasks. My current prompt is: {prompt} But it gets the some examples wrong. Based on these wrong examples, the problem with this prompt is that {new_constraint} Note that new prompts should not focus excessively on or be limited to a single example of an error. Instead, they should be generated from a more generalized perspective, based on the analyzed causes of the errors. Please do not provide any examples (i.e. few-shot examples) in the new prompt; no other redundant information is needed. Based on the above information, you should write Four different improved prompts. Each new prompt is wrapped with <START> and <END>. The Four new prompts are: 

Initial Prompt 

You are an expert at accomplishing tasks. You are a highly capable problem-solver. 

19
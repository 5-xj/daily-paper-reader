Title: Variable Search Stepsize for Randomized Local Search in Multi-Objective Combinatorial Optimization

URL Source: https://arxiv.org/pdf/2602.05675v1

Published Time: Fri, 06 Feb 2026 02:26:09 GMT

Number of Pages: 12

Markdown Content:
> SUBMIT TO IEEE TRANSACTIONS ON EVOLUTIONARY COMPUTATION 1

# Variable Search Stepsize for Randomized Local Search in Multi-Objective Combinatorial Optimization 

Xuepeng Ren, Maocai Wang, Guangming Dai, Zimin Liang, Qianrong Liu, Shengxiang Yang Fellow, IEEE , Miqing Li Senior Member, IEEE 

Abstract —Over the past two decades, research in evolutionary multi-objective optimization has predominantly focused on con-tinuous domains, with comparatively limited attention given to multi-objective combinatorial optimization problems (MOCOPs). Combinatorial problems differ significantly from continuous ones in terms of problem structure and landscape. Recent studies have shown that on MOCOPs multi-objective evolutionary algorithms (MOEAs) can even be outperformed by simple randomised local search. Starting with a randomly sampled solution in search space, randomised local search iteratively draws a random solution (from an archive) to perform local variation within its neighbourhood. However, in most existing methods, the local variation relies on a fixed neighbourhood, which limits exploration and makes the search easy to get trapped in local optima. In this paper, we present a simple yet effective local search method, called variable stepsize randomized local search (VS-RLS), which adjusts the stepsize during the search. VS-RLS transitions gradually from a broad, exploratory search in the early phases to a more focused, fine-grained search as the search progresses. We demonstrate the effectiveness and generalizability of VS-RLS through extensive evaluations against local search and MOEAs methods on diverse MOCOPs. 

Index Terms —Multi-objective optimization, combinatorial op-timization, evolutionary algorithms, local search. 

I. INTRODUCTION 

# MUlti-objective combinatorial optimization problems (MOCOPs) aim to optimize two or more conflicting objectives at the same time, and their solution space is made up of discrete decision variables [1]. These problems are common in many fields, such as software engineering [2], [3], 

This work was supported by National Natural Science Foundation of China under Grant No. 42571407 & No. 42271391, Hubei Excellent Young and Middle-aged Science and Technology Innovation Team Plan Project under Grant No. T2021031, and Royal Society International Exchanges 2025 Cost Share (NSFC) under Grant No. IEC \NSFC \252114 (Corresponding author: Maocai Wang, Shengxiang Yang and Miqing Li). Xuepeng Ren, Maocai Wang and Guangming Dai are with School of Computer, China University of Geosciences, Engineering Research Center of Natural Resource Information Management and Digital Twin Engineer-ing Software, Ministry of Education, and Hubei Key Laboratory of Intel-ligent Geo-Information Processing, Wuhan 430074, China. (e-mail: renx-uepeng@cug.edu.cn, cugwangmc@126.com and gmdai@cug.edu.cn). Shengxiang Yang and Xuepeng Ren are with the School of Computer, Science and Informatics, De Montfort University, Leicester LE1 9BH, U.K. (e-mail: syang@dmu.ac.uk). Zimin Liang and Miqing Li are with the School of Computer Sci-ence, University of Birmingham, Birmingham B15 2TT, U.K. (e-mail: zxl525@student.bham.ac.uk and m.li.8@bham.ac.uk). Qianrong Liu is with the School of Chemical Engineering, University of Birmingham, Birmingham B15 2TT, U.K. (e-mail: qxl242@student.bham.ac.uk). 

logistics scheduling [4], cloud computing [5] and aerospace design [6]. Multi-objective evolutionary algorithms (MOEAs) and local search heuristics are among popular techniques to tackle MOCOPs. With its success in multi-objective optimization, MOEAs have become a mainstream method for solving MOCOPs. Rep-resentative algorithms include NSGA-II [7], MOEA/D [8], and SMS-EMOA [9], which have been widely applied to various problems, such as the multi-objective knapsack and traveling salesman problems [10]–[12]. However, empirical studies have shown that MOEAs exhibit more local search behaviour than local search methods when applied to MOCOPs [13], [14]. Meanwhile, other empirical evidence suggests that, on certain MOCOPs, MOEAs can even be outperformed by local search algorithms [15], [16]. Local search algorithms usually maintain an archive of non-dominated solutions. In each iteration, one solution is selected from the archive and local variation is applied within its neighbourhood. Early studies of local search mainly focused on scalarization-based methods, which transform a multi-objective problem into multiple single-objective problems in different search directions [17]. With the introduction of Pareto local search, researchers began to use Pareto dominance directly to guide the search, where two main types of methods have been proposed [18], [19]: systematic and randomized local search. In systematic local search, candidate solutions in the neighbourhood are examined according to a predetermined order, for example by fully scanning the neighbourhood or using a first-improvement strategy [20], [21]. In randomized local search, one parent solution is randomly selected from the archive, and an offspring solution is generated within its neighbourhood (e.g., by bit-flip), after which the archive is updated according to the Pareto dominance relation [22]. Compared with the systematic approach, randomized lo-cal search often produces higher-quality solution sets for MOCOPs [15], [19]. Most existing randomized local search algorithms rely on a fixed neighbourhood structure to generate candidate solutions [22]–[26]. However, the fixed setting may restrict the exploration ability, leading to early stagnation of the search. For example, when flipping one decision variable at a time, the local search may get trapped in local optima. On the other hand, flipping many variables simultaneously can lead to large jumps that can disrupt fine-grained improvements. To address this issue, we propose a simple randomized local search method called Variable Stepsize Randomized  

> arXiv:2602.05675v1 [cs.NE] 5 Feb 2026 SUBMIT TO IEEE TRANSACTIONS ON EVOLUTIONARY COMPUTATION 2

Local Search (VS-RLS). In VS-RLS, the stepsize refers to the neighbourhood used to generate offspring. For example, in binary problems, a stepsize of one corresponds to the 1-bit neighbourhood, whereas in permutation problems it cor-responds to a neighbourhood defined by the same number of exchange or rearrangement operations (e.g., 2-opt in TSP). In each iteration, the search starts from the neighbourhood with a stepsize of one and progressively expands to larger stepsize (i.e., two, three, and so on) until a good solution (i.e., a solution that is not dominated by any solution in the archive) is found or the maximum stepsize is reached. For each stepsize, we do not perform a full neighbourhood scan; instead we conduct some sampling. This avoids an exhaustive search whose computational cost will increase exponentially with the stepsize, while allowing us to quickly identify promising regions on which the search can focus in later stages. The proposed method is verified on a wide range of multi-objective combinatorial problems, including the multi-objective knap-sack [27], travelling salesman [28], quadratic assignment [29], and NK-landscape [30] problems. The remainder of this paper is organized as follows. Section II introduces the preliminaries and related work. Section III details the proposed algorithm. Section IV outlines the experimental design. Section V presents the experimental results and related discussions. Section VI concludes with key findings and future research directions. All codes and ex-perimental data have been made available for reproducibility: https://github.com/vsrlsanonymous/VS-RLS-code. II. PRELIMINARIES AND RELATED WORK In this section, we first introduce the definitions of MOCOPs and local search, and then review in detail the related work on MOEAs and local search in the context of MOCOPs. 

A. Definitions 

MOCOPs involve optimizing multiple conflicting objectives simultaneously, where decision variables are discrete and the search space is large and complex. Consider a minimization MOCOP with m objective functions: 

f (x) = ( f1(x), f 2(x), . . . , f m(x)) , (1) where x is a solution in the finite decision space X. Depending on the problem, X can consist of binary, integer, or permu-tation representations. D denotes the dimensionality of the decision vector, and f (x) maps x to the objective space Z,with Z ⊆ Rm.The dominance relationship between two objective vectors 

z, z ′ ∈ Z is defined as: 

z ≺ z′ ⇐⇒ (zi ≤ z′

> i

, ∀i ∈ { 1, . . . , m }) ∧ (z̸ = z′) , (2) meaning that z is no worse in all objectives and strictly better in at least one. For two solutions x, x ′ ∈ X, dominance is extended as 

x ≺ x′ ⇐⇒ f (x) ≺ f (x′). (3) A solution x ∈ X is said to be non-dominated with respect to a set A ⊆ X if no x′ ∈ A satisfies x′ ≺ x, i.e., ∄x′ ∈ A :

x′ ≺ x.Local search is a fundamental optimization strategy that iteratively improves a candidate solution by exploring its neighbourhood. Given a solution x ∈ X, its neighbourhood 

N (x) can be defined in different ways. For binary problems, a common choice is the Hamming neighbourhood: 

NH(x) = { x′ ∈ X | dH(x, x ′) = r }, r ≥ 1, (4) where dH(x, x ′) denotes the Hamming distance between x

and x′. The case r = 1 corresponds to the standard one-bit-flip neighbourhood, while larger r values correspond to multiple-bit-flips. More generally, neighbourhoods depend on the solution representation. For example, in permutation-based problems such as the traveling salesman problem, the neigh-bourhood is often constructed by the 2-opt operator [31], while in the quadratic assignment problem, the 2-swap operator [31] is widely used. In single-objective optimization, a solution is called a local optimum if no neighbour improves its objective value. In the multi-objective case, this concept is extended to Pareto local optimality. A Pareto local optimum (PLO) is a solution x ∈ X

such that no neighbour dominates it: 

x is a PLO ⇐⇒ ∄x′ ∈ N (x) such that f (x′) ≺ f (x). (5) 

B. MOEAs in MOCOPs 

MOEAs achieve effective approximations of the Pareto front by exploring diverse solution sets, and they have demonstrated strong performance in continuous optimization problems [32]. However, when the focus shifts to MOCOPs, their perfor-mance is often limited [13]. The discrete decision variables and highly scattered search landscapes of MOCOPs introduce new challenges for classical MOEAs in terms of search efficiency and solution quality [14]. Despite these challenges, MOEAs remain one of the major approaches for solving MOCOPs. Existing studies enhance their performance by designing problem-specific encoding schemes, variation operators and population update mecha-nisms [10]–[12], [33], [34], which have led to successful applications on typical combinatorial problems such as multi-objective knapsack and travelling salesman. MOEAs have also shown good adaptability in many real-world applications [35]– [41]. To further improve the search efficiency on MOCOPs, hybrid frameworks that integrate MOEAs with local improve-ment techniques have attracted increasing attention. Some studies incorporate local search as an internal component of the evolutionary process [42], while others apply it as a post-processing step to enhance the obtained solution set [43]. Note that in the area of runtime analysis, there have been many theoretical studies analyzing MOEAs on MOCOPs, such as on subset selection [44]–[46] and minimum spanning tree [47], [48]. In particular, artificial MOCOPs (i.e., pseudo-Boolean problems [49]) are the most commonly studied prob-lems for the runtime analysis of mainstream MOEAs [50]– [53], the development of MOEAs (e.g., considering stochas-ticity [54], [55]), algorithmic components (e.g., archiving [56], [57] and different variation operators of MOEAs [58], [59], where search algorithms may perform differently from practical MOCOPs [19]. SUBMIT TO IEEE TRANSACTIONS ON EVOLUTIONARY COMPUTATION 3

C. Local Search in MOCOPs 

Local search has been widely applied to MOCOPs because of its simplicity and efficiency in exploring discrete solution spaces [19], [60]–[63]. Existing multi-objective local search methods can be divided into scalarization-based and Pareto-based approaches [17]. Early scalarization methods decom-pose a multi-objective problem into multiple single-objective subproblems and then apply classical search strategies [64]. In contrast, Pareto-based methods directly use dominance relations to guide the search and have become the mainstream in multi-objective combinatorial optimization [20], [65], [66]. Pareto-based local search methods can be further divided into systematic and randomized strategies [18]. Systematic methods aim to exhaustively explore the neighbourhood of each solution or to find a sufficiently good neighbor. Recent studies have improved neighbourhood exploration to enhance search quality and avoid premature convergence [21], [67]– [69]. In contrast, randomized methods sample the neighbour-hood randomly based on certain criteria [70]. Arguably, one of the most representative randomized local search algorithms is SEMO [71], which randomly selects a solution from the archive, applies a bit-flip variation (with a fixed neighbourhood size), and then updates the archive based on the dominance relation. Although recent studies show the effectiveness on MOCOPs [13], [19], its fixed neighbourhood mechanism limits the algorithm to small moves. As a result, it may fail to escape regions that require simultaneous multi-bit improvements [58]. To help the algorithm escape from local optima, some studies introduced appropriate perturbation when stagnation occurs, e.g., [72], while others considered restart operators, e.g., [73]. III. PROPOSED ALGORITHM Although randomized local search methods have demon-strated good performance in MOCOPs, those employing a fixed stepsize may be prone to local optima. In this section, we first explain the limitations of fixed neighbourhood local search, then introduce the variable stepsize mechanism of VS-RLS, and finally outline the overall framework the proposed method. 

A. Randomized Local Search with Fixed Stepsize 

To illustrate the limitation of a fixed stepsize randomized local search, we consider a bi-objective toy example, as shown in Fig. 1. Each vertex represents a solution in the search space, and two neighbouring vertices differ by one bit in their decision variables. When the stepsize is fixed to one, the search is restricted to the corresponding 1-bit neighbourhood of the current solution, as indicated by the dashed rectangle. In this setting, a randomized local search generates an offspring by randomly selecting one neighbouring solution. If the offspring dominates the current solution or is non-dominated with respect to it, it is accepted into the archive according to the dominance relation. As shown in the figure, once the search reaches the local optimum at (6 , 6) , all neighbouring solutions within the fixed stepsize are dominated by the current solution. Consequently, no further progress can be made, and the search becomes trapped in this local region.    

> Fig. 1. An illustration of the failure of fixed stepsize randomized local search on a bi-objective minimization toy example (adapted from [74]). Each vertex represents a solution, and the numbers in the upper-right corner indicate its objective values. An edge connects two solutions whose decision variables differ by one bit. The blue point represents the starting location of the search, while the dashed rectangle indicates the search region when the stepsize is fixed to one (i.e., 1-bit neighbourhood). When performing randomized local search with a stepsize of one, one of the four neighbouring solutions around the blue point is randomly selected as an offspring. The red point represents a solution that is accepted into the archive according to the dominance relation. As can be seen, once the search reaches the local optimum at (6 ,6) (red point), all neighbouring solutions within the fixed stepsize are dominated by it, and the algorithm is therefore unable to move forward.

B. The Proposed Variable Size Randomized Local Search (VS-RLS) 

To overcome the limitation of a fixed stepsize search in escaping local optima, we introduce a simple mechanism called VS-RLS. In VS-RLS, the search starts with stepsize of one (the neighbourhood of a solution with one bit difference) and progressively increases the stepsize. Specifically, in each iteration, an offspring is first generated by randomly sampling from the stepsize of one of the current solution. If this solution is not nondominated to the archive, then we increase the stepsize (i.e., expand the neighbourhood of the solution), otherwise, we end this iteration and start to sample another solution in the archive for exploration again as conducted in many randomised local search methods like SEMO. We also set a maximum stepsize (i.e., a threshold) that allows the neighbourhood to be expanded maximumly. But we do it dynamically as we want to quickly identify promising regions on which the search can focus in later stages. That is, at the beginning of the search, we set it to be the possibly maximum size (i.e., the problem size), while in the later phase of the search, when the archive gradually accumulates solutions from different promising regions, we employ a smaller maximum stepsize to focus on exploitation on those regions. When this search mechanism is applied to the bi-objective toy example shown in Fig. 1, the resulting search behaviour is illustrated in Fig. 2. In each iteration, under a given stepsize threshold, VS-RLS first samples one candidate solution from the search region corresponding to stepsize one of the selected parent. If the sampled candidate is acceptable for archive, the archive is updated and the current iteration terminates immediately. Otherwise, the stepsize is progressively increased and a new candidate solution is sampled from the expanded search region. This process continues until an acceptable solution is found or the stepsize threshold is reached. Unlike SUBMIT TO IEEE TRANSACTIONS ON EVOLUTIONARY COMPUTATION 4                      

> Fig. 2. An illustration of the proposed VS-RLS on the bi-objective toy example in Fig. 1. The dashed rectangles in different colours indicate the search regions corresponding to different stepsize, where the yellow and pink rectangles represent the search regions with stepsize two and three, respectively. Specifically, in the first subfigure, assume that the algorithm is trapped at a local optimum (6 ,6) when the stepsize is equal to one. VS-RLS first randomly samples one solution from the search region (black dashed rectangle) corresponding to stepsize of one. Since the sampled solution is not acceptable for the archive (i.e., being dominated by at least one solution in the archive), the stepsize is increased to two (yellow dashed rectangle) and another solution is randomly sampled. Although multiple acceptable solutions exist in the search region with stepsize two, such as (3 ,8) ,(4 ,7) , and (6 ,5) , suppose that none of these acceptable solutions is sampled. The stepsize is therefore further increased to three, as shown in the second subfigure. This process illustrates that, even if no acceptable solution is sampled under small stepsize, expanding the stepsize allows the algorithm to sample solutions from a broader region and thus escape from the local optimum. At the same time, since the stepsize is increased progressively from small to large values, VS-RLS preserves the ability to sample acceptable solutions near the current solution. Once an acceptable solution is sampled, the current iteration is terminated. For example, in the third subfigure, suppose that the solution (2 ,9) is sampled when the stepsize is equal to three. Since (2 ,9) is non-dominated with respect to (6 ,6) , it is added to the archive. The algorithm then starts a new iteration by randomly selecting a solution from the archive as the parent. In this case, if (2 ,9) is selected as the parent, its stepsize of one region may be more likely to contain acceptable solutions than that of (6 ,6) , allowing the search to move from a less promising region to a more promising one.

fixed stepsize search, VS-RLS allows the exploration scale to vary during the search process rather than being confined to a single neighbourhood size. Compared with small stepsize search, the progressive expansion of the stepsize provides the likelihood of escaping from local regions and exploring more promising areas of the search space. In contrast to large fixed stepsize search, once such promising regions are reached, good solutions can often be found under the refinement of the existing ones, allowing the algorithm to stop further expansion and thus avoid wasting evaluations on unnecessarily large search regions. As can be seen in Fig. 2, the fixed stepsize search is highly sensitive to the quality of the initial solution. If the starting point is close to a poor local optimum, the search often remains trapped there for a long time. Some studies have also shown that the quality of the initial solution is a major factor that affects single-solution evolutionary methods [75]. In contrast, VS-RLS greatly reduces its dependence on the initial solution, since it can keep expanding the search regions until a better solution is found. 

C. Framework of VS-RLS 

As discussed in the previous subsection, the role of the stepsize changes during the search process. A larger stepsize is mainly useful when the search needs to escape from locally optimal regions or explore distant areas of the solution space, while a smaller stepsize becomes more suitable once the search reaches potentially more promising regions. Based on this, VS-RLS can be naturally described using a two-phase strategy. 

1) Phase 1 (Exploration Phase) : At the initial phase of the search, a large stepsize threshold is adopted. Specifically, the threshold is set to the dimensionality of the decision space, allowing the stepsize to expand to its maximum possible region. In this phase, the search often starts from regions with limited improvement potential. For example, when the search is trapped in locally optimal regions or when only a small number of solutions are stored in the archive, accept-able solutions may not be reachable through small stepsize. Allowing the stepsize to expand up to the dimensionality of the decision space enables the search to explore much broader regions, thereby increasing the chance of discovering acceptable solutions that are far away from the current search location. 

2) Phase 2 (Exploitation Phase) : As the search proceeds, the variable stepsize mechanism gradually guides the search toward more promising regions of the solution space. Once such regions are reached, acceptable solutions can often be obtained through small stepsize. In this phase, maintaining a large stepsize threshold becomes unnecessary and may lead to excessive evaluation cost. Therefore, the stepsize threshold is reduced to a smaller value, focusing the search on local refinement around promising regions. Algorithm 1 presents the pseudocode of the proposed VS-RLS algorithm. The algorithm starts by randomly initializing a solution x0 and inserting it into the archive A. The search then proceeds in an iterative manner until the maximum number of function evaluations maxN f e is reached. As can be seen from the algorithm, at the beginning of each iteration, the stepsize variable Ncb is initialized to one (Line 5). A two-phase stepsize threshold strategy is then employed. During the early phase of the search, i.e., when the iteration counter t does not exceed the switching iteration Tvl , the stepsize threshold VL is set to the decision space dimension D

(Lines 6–7), allowing the stepsize to expand to its maximum region. After this phase, the threshold is reduced to a smaller value VC (e.g., 3) to focus the search on local refinement (Line 9). In each iteration, a solution is selected uniformly at random from the archive A as the parent (Line 11). An offspring SUBMIT TO IEEE TRANSACTIONS ON EVOLUTIONARY COMPUTATION 5

solution x′ is then generated by randomly sampling from the neighbourhood of the parent with the current stepsize Ncb 

(Line 13). If the sampled solution x′ is not dominated by any solution in the archive, it is inserted into A, and all archive solutions dominated by x′ are removed (Lines 15– 16). Otherwise, the stepsize Ncb is increased by one, and the sampling process is repeated (Line 19). This progressive expansion continues until either an acceptable solution is found or the stepsize threshold VL is reached (Line 12). The algorithm then proceeds to the next iteration by updating the iteration counter and repeating the above process (Line 22). IV. EXPERIMENTAL DESIGN This section first introduces the algorithms used for com-parison, then presents the MOCOPs considered in this study, explains the performance indicators employed to evaluate the results, and finally describes the experimental setup in detail. 

A. Comparative Algorithms 

To provide a comprehensive comparison, six representa-tive algorithms are selected, including local search methods and MOEAs. Specifically, two local search methods, three MOEAs, and one baseline method are considered. For local search methods, SEMO [71] is adopted as a representative randomized local search algorithm, which has been shown to outperform many MOEAs on MOCOPs [15], and it is also the underlying algorithm the proposed method improves on. In addition, PLS [20] is included as one of the most well known Pareto-based local search techniques for MOCOPs. For MOEAs, three representative algorithms from different frameworks are selected, including NSGA-II [7], MOEA/D [8], and SMS-EMOA [9]. Moreover, Random Sampling (RS) [15] is considered as a baseline method. Next, we briefly introduce there algorithms. 1) SEMO [71] randomly selects a solution from the archive to perform local search. Therefore, it can be regarded as a randomized Pareto local search. 2) NSGA-II [7] is a representative Pareto-based algorithm characterized by the non-dominated sorting and crowd-ing distance mechanisms. In NSGA-II, candidate so-lutions are divided into several non-dominated fronts, where solutions in lower fronts are preferred over those in higher ones. Within the same front, solutions with larger crowding distances are preferred. 3) MOEA/D [8] is a representative decomposition-based algorithm. It decomposes a multi-objective problem into multiple scalar optimization subproblems using a set of well-distributed weight vectors and a scalarizing function. 4) SMS-EMOA follows the same non-dominated sorting procedure as NSGA-II but replaces crowding distance with the hypervolume indicator to distinguish solutions within the same front. Specifically, SMS-EMOA com-putes the hypervolume contribution of each solution and removes the one with the smallest contribution. 

Algorithm 1 VS-RLS 

Input: D: Problem size; maxN f e : Maximum number of function evaluations; Tvl : Threshold switching iteration; 

VC : Stepsize threshold for Phase 2. 

Output: Archive A 

> 1:

Randomly initialize a solution x0 

> 2:

A ← { x0} 

> 3:

t ← 1, Nf e ← 0 

> 4:

while Nf e < maxN f e do  

> 5:

Ncb ← 1 

> 6:

if t ≤ Tvl then  

> 7:

VL ← D 

> 8:

else  

> 9:

VL ← VC 

> 10:

end if  

> 11:

Select a solution x uniformly at random from A 

> 12:

while Ncb ≤ VL do  

> 13:

Randomly sample x′ from the neighbourhood of x

with scale ≤ Ncb  

> 14:

Nf e ← Nf e + 1  

> 15:

if x′ is not dominated by any solution in A then  

> 16:

A ← A ∪ { x′} \ { a ∈ A | x′ ≺ a} 

> 17:

break  

> 18:

else  

> 19:

Ncb ← Ncb + 1  

> 20:

end if  

> 21:

end while  

> 22:

t ← t + 1  

> 23:

end while 

5) PLS [20] systematically explores the neighbourhood of solutions. It maintains an archive that stores all discov-ered non-dominated solutions. At each step, PLS ran-domly selects one unexplored solution from the archive and examines all of its neighbors. The archive is updated with any new non-dominated solutions found. The algo-rithm terminates when either the stopping criterion is satisfied or there are no unexplored solutions left in the archive. 6) RS is a simple search heuristic that randomly samples solutions from the search space. An archive is used to store all generated non-dominated solutions until the termination condition is met. 

B. Multi-Objective Combinatorial Optimization Problems 

Following the practice in [15], four well-known MOCOPs are selected for evaluation, namely the multi-objective 0-1 knapsack [27], traveling salesman [28], quadratic assign-ment [29], and NK-Landscape [30] problems. These prob-lems are chosen because they represent diverse combinatorial structures and capture different types of search challenges. Specifically, the knapsack problem involves binary selection under capacity constraints, traveling salesman problem deals with permutation-based path optimization, quadratic assign-ment problem addresses complex assignment and interaction costs, and NK-Landscape problem provides tunable landscape ruggedness through the parameter K.SUBMIT TO IEEE TRANSACTIONS ON EVOLUTIONARY COMPUTATION 6

1) Multi-Objective Knapsack Problem (Knapsack) : The Knapsack [27] involves selecting items to maximize the total value while considering multiple constraints (e.g., weight, volume) without exceeding the capacity of each knapsack. Given D items, values vji and weights wji for each item i

in each knapsack j, and capacity cj for each knapsack, the problem is defined as: 

max fj (x) = 

> D

X

> i=1

vji · xi,

> D

X

> i=1

wji · xi ≤ cj , x i ∈ { 0, 1}, (6) where D: Number of items; m: Number of objectives; vji :Value of item i for knapsack j, random integers in the interval [10, 100] [27]; wji : Weight of item i for knapsack j, random integers in the interval [10, 100] [27]; cj : Capacity of knapsack 

j. Set to half of the total weight of all items in the knapsack; 

xi: Binary variable indicating whether item i is selected. 

2) Multi-Objective Traveling Salesman Problem (TSP) :

The TSP [28] involves finding a set of Pareto optimal Hamilto-nian cycles (tours) that minimize multiple travel cost objectives between cities. Given a set of cities V = {v1, v 2, . . . , v D } and a set of cost matrices Cj for j = 1 , . . . , m where Cj (vi, v k)

represents the travel cost between city vi and city vk under objective j, the problem is defined as: 

min fj (P ) = 

> D−1

X

> i=1

Cj (vi, v i+1 ) + Cj (vD , v 1), (7) where D: Number of cities; m: Number of objectives; 

Cj (vi, v k): Cost between city vi and vk for objective j. This matrix is independent and generated by assigning a randomly drawn number from the interval [0,1) [76] to each pair of cities; P : A permutation representing a tour. 

3) Multi-Objective Quadratic Assignment Problem (QAP) :

The QAP [29] involves assigning a set of facilities to a set of locations such that multiple cost objectives (flow of materials, distance, etc.) between facilities are minimized. Given D

facilities, D locations, cost matrices Ck for k = 1 , . . . , m 

representing the flow between facilities, and a distance matrix 

L representing the distance between locations, the problem is defined as: 

min fk(X) = 

> D

X

> i=1
> D

X

> j=1

Ck(i, j ) · LX(i)X(j), (8) where D: Number of facilities/locations, and m: Number of objectives. For each objective k, the cost matrix Ck(i, j ) is independently generated, with every entry uniformly drawn from the range [0 , 100] [29]. To construct the distance matrix, 

D locations are randomly placed on a two-dimensional plane within the range [0 , 5000] [77], and the Euclidean distance between each pair of locations u and v defines Luv .

4) Multi-Objective NK-Landscape Problem : The NK-Landscape [30] is a problem where each bit in a binary string interacts with K other bits, and the objective is to maximize multiple fitness functions, which depend on these interactions. Given a binary string x of stepsize D, and each bit xi has an associated contribution function cij depending on K interacting bits, the problem is defined as: 

max fj (x) = 1

D

> D

X

> i=1

cij (xi, x ki1 , . . . , x kiK ), (9) where D: size of the binary string; m: Number of objectives; 

K: Number of interacting bits. This paper K=10 [15]; cij :Contribution function for bit xi in objective j; xki1 , . . . , x kiK :Interacting bits for bit xi.

C. Performance Indicator 

The hypervolume (HV) indicator [27] is used to assess the performance of multi-objective optimization algorithms. It measures the volume of the objective space dominated by the obtained solution set with respect to a reference point. In the absence of the true Pareto front, HV is considered one of the most effective performance indicators [78]. When calculating HV, the choice of the reference point is critical. It is typically set slightly worse than the worst objective values to avoid a zero HV. However, this may still result in zero HV values for poorly performing algorithms, which is common in MOCOPs. To address this issue, following the practice in [15], we use random sampling as a baseline to determine the position of the reference point. The reference point r is set slightly worse than the nadir point. According to [79], for a minimization problem, the reference value for the i-th objective is given by 

ri = max i + ( max i − min i)/10 , where max i and min i denote the maximum and minimum values of the non-dominated set (obtained by random sampling) for the i-th objective, respectively. For a maximization problem, the reference point is set in the opposite direction as ri = min i−(max i−min i)/10 .

D. Experimental Setup 

In general, local search algorithms require a substantial search budget [15]. When the budget is severely limited, local search can explore only a small number of solutions. In contrast, MOEAs typically need fewer evaluations and can evolve more quickly, though they may still become trapped in local optima even with sufficient resources [13]. To com-prehensively evaluate the performance of the algorithms, we conducted three sets of experiments. The parameters were set as Tvl = 1000 and VC = 3 . The population size for the MOEAs is set to 100, and each algorithm is run independently 30 times. We first tested the proposed algorithm on four representative problems, the multi-objective Knapsack, TSP, QAP, and NK-Landscape, with respective sizes of D = 500 , 200 , 100 , and 

100 , respectively. Each run was allowed up to 10 6 evaluations. Next, we examined the scalability of the algorithms on dif-ferent problem sizes [15]. Based on the first set of experiments, we further tested the Knapsack problem with D = 100 and 

1000 , the TSP with D = 50 and 500 , and both the QAP and NK-Landscape problems with D = 50 and 200 .Finally, we investigated the influence of different number of evaluations [80]. Using the same problem settings as in the first experiment, we conducted tests with total evaluations of 

1 × 10 5, 5 × 10 5, 2 × 10 6, and 5 × 10 6.SUBMIT TO IEEE TRANSACTIONS ON EVOLUTIONARY COMPUTATION 7

TABLE I THE HV RESULTS (MEAN AND STANDARD DEVIATION ) OF THE SEVEN ALGORITHMS UNDER 4 DIFFERENT SETTINGS . T HE BEST -PERFORMING ALGORITHM IN EACH SETTING IS HIGHLIGHTED IN BOLD . T HE SYMBOLS “+”, “=”, AND “−” INDICATE THAT THE CORRESPONDING ALGORITHM PERFORMS STATISTICALLY BETTER THAN , SIMILAR TO , OR WORSE THAN VS-RLS, RESPECTIVELY .Problem D RS NSGA-II MOEA/D SMS-EMOA PLS SEMO VS-RLS Knapsack 500 3.38e+07 (6.85e+05) − 9.02e+07 (7.28e+05) − 9.07e+07 (4.94e+05) − 8.82e+07 (4.92e+05) − 2.96e+07 (4.82e+06) − 9.04e+07 (9.93e+05) − 9.18e+07 (5.59e+05)                               

> TSP 200 1.54e+03 (3.60e+01) −9.00e+03 (1.09e+02) −9.74e+03 (1.22e+02) −8.82e+03 (1.36e+02) −1.64e+03 (1.30e+03) −9.82e+03 (8.09e+01) −9.98e+03 (7.99e+01)
> QAP 100 6.42e+14 (2.28e+13) −2.61e+15 (1.62e+14) −2.56e+15 (1.20e+14) −2.60e+15 (1.30e+14) −2.57e+15 (1.21e+15) −6.14e+15 (1.20e+14) −6.21e+15 (1.10e+14)
> NK-landscape 100 8.01e–02 (2.10e–03) −1.44e–01 (5.22e–03) −1.40e–01 (6.18e–03) −1.45e–01 (5.08e–03) =1.04e–01 (2.41e–02) −1.39e–01 (4.29e–03) −1.47e–01 (4.62e–03)
> +/=/ −0/0/4 0/0/4 0/0/4 0/1/3 0/0/4 0/0/4

(a) Knapsack (b) TSP (c) QAP (d) NK-landscape Fig. 3. The final archive sets are the results of the seven algorithms on 4 different settings of the first experiment from a single run. This particular run is associated with the result closest to the average HV value. 

Additionally, appropriate search operators need to be set for the algorithms. 

1) For MOEAs : The Knapsack and NK-landscape prob-lems utilize uniform crossover (crossover rate of 1.0) [31] and bit-flip mutation (mutation rate of 1/D [31], where D

represents the number of variables). The TSP problem is based on sequence permutation, whereas the QAP problem is based on position permutation. Therefore, the TSP problem employs order crossover and 2-opt mutation [31], which are suited for sequence permutations, while the QAP problem employs cycle crossover and 2-swap mutation [31], which are suited for position permutation. For these two types of permutation problems, the crossover rate is set to 1.0, and the mutation rate is set to 0.05 [15]. 

2) For Local Search : Bit flip operators are adopted with different neighbourhood definitions: a 2-bit flip neighbourhood for the Knapsack problem and a 1-bit flip neighbourhood for the NK-landscape problem. For the Knapsack problem, 1-bit flip can lead to either improvement on both objectives or degradation on them according to the problem definition, which is not reasonable and helpful for local search. Therefore, a 2-bit flip neighbourhood is adopted for Knapsack [15]. For permutation-based problems, 2-opt operators are used for the TSP, and 2-swap operators are used for the QAP. V. PERFORMANCE VERIFICATION OF VS-RLS In this section, we first compare the performance of VS-RLS under general settings. Then, we examine its behavior with different problem sizes. Next, we analyze the effect of different maximum function evaluations on the results. Finally, we study the sensitivity of the parameters and perform an ablation study to understand the role of each component in VS-RLS. 

A. Comparison at general settings 

Table I presents the mean and standard deviation of the HV values obtained by the seven algorithms on the four test instances. For each setting, the best-performing algorithm is highlighted in bold. The symbols “+”, “=”, and “–” indicate that the corresponding algorithm performs significantly better than, equivalent to, or worse than VS-RLS, respectively, according to the Wilcoxon rank-sum test at a significance level of 0.05. Fig. 3 shows the final solution set from a single run whose result is closest to the average HV value for this problem. The same rule applies to the tables and figures presented in the following experimental results. From Table I and Fig. 3, it can be seen that the proposed VS-RLS algorithm achieves the best overall performance across all four types of test instances. In the Knapsack problem (Fig. 3(a)), MOEAs usually show slightly better convergence, while VS-RLS demonstrates a stronger ability to maintain solution diversity. Specifically, VS-RLS performs a single-solution local search guided by a variable stepsize mechanism, which can flexibly adjust the search region and explore dif-ferent regions of the solution space. This adaptive mechanism helps VS-RLS maintain diverse non-dominated solutions even when its convergence speed is relatively slower. A more detailed discussion of this behavior under different problem sizes will be presented later on. In the TSP problem (Fig. 3(b)), NSGA-II and SMS-EMOA perform similarly, whereas MOEA/D shows slightly better convergence. A possible explanation is that TSP often contains multiple large funnel structures with many small attraction basins [81], where algorithms may converge slowly toward these local basins [82]. MOEA/D decomposes the problem using uniformly distributed weight vectors, whose search directions may align with certain attraction basins in TSP, enabling it to move more smoothly toward global regions. Although MOEA/D obtains a slightly lower HV value than SUBMIT TO IEEE TRANSACTIONS ON EVOLUTIONARY COMPUTATION 8

TABLE II THE HV RESULTS (MEAN AND STANDARD DEVIATION ) OF THE SEVEN ALGORITHMS UNDER 8 DIFFERENT SETTINGS . T HE BEST -PERFORMING ALGORITHM IN EACH SETTING IS HIGHLIGHTED IN BOLD . T HE SYMBOLS “+”, “=”, AND “−” INDICATE THAT THE CORRESPONDING ALGORITHM PERFORMS STATISTICALLY BETTER THAN , SIMILAR TO , OR WORSE THAN VS-RLS, RESPECTIVELY .Problem D RS NSGA-II MOEA/D SMS-EMOA PLS SEMO VS-RLS Knapsack 100 5.88e+06 (1.14e+05) − 8.31e+06 (3.74e+04) = 8.29e+06 (3.88e+04) − 8.23e+06 (4.13e+04) − 6.84e+06 (2.40e+05) − 8.28e+06 (3.40e+04) − 8.32e+06 (2.90e+04)                                                           

> 1000 7.33e+07 (1.57e+06) −2.67e+08 (1.81e+06) −2.72e+08 (1.50e+06) −2.62e+08 (1.36e+06) −5.30e+07 (5.02e+06) −2.70e+08 (1.86e+06) −2.75e+08 (1.39e+06)
> TSP 50 3.57e+02 (5.53e+00) −8.86e+02 (1.11e+01) −8.87e+02 (1.32e+01) −8.76e+02 (1.16e+01) −6.12e+02 (6.79e+01) −9.36e+02 (5.27e+00) −9.42e+02 (4.84e+00)
> 500 3.97e+03 (7.53e+01) −3.85e+04 (1.02e+03) −4.50e+04 (6.64e+02) +3.78e+04 (6.84e+02) −2.49e+03 (2.19e+02) −4.20e+04 (3.55e+02) −4.30e+04 (4.27e+02) QAP 50 3.13e+14 (6.21e+12) −5.43e+14 (2.19e+13) −5.22e+14 (2.13e+13) −5.38e+14 (2.62e+13) −4.71e+14 (2.42e+13) −7.95e+14 (1.56e+13) −8.03e+14 (1.67e+13)
> 200 4.60e+15 (1.20e+14) −1.52e+16 (5.89e+14) −1.53e+16 (7.70e+14) −1.46e+16 (6.40e+14) −8.49e+15 (5.11e+15) −3.04e+16 (5.95e+14) −3.08e+16 (4.86e+14)
> NK-landscape 50 1.50e–01 (2.99e–03) −1.91e–01 (8.42e–03) =1.88e–01 (6.78e–03) −1.96e–01 (6.81e–03) =1.51e–01 (2.12e–02) −1.78e–01 (9.98e–03) −1.95e–01 (4.87e–03) 200 3.67e–02 (1.20e–03) −1.01e–01 (3.95e–03) −1.02e–01 (3.17e–03) −1.01e–01 (3.25e–03) −8.18e–02 (2.15e–02) −1.05e–01 (2.47e–03) =1.06e–01 (2.69e–03)
> +/=/ −0/0/8 0/2/6 1/0/7 0/1/7 0/0/8 0/1/7

(a) Knapsack on D=100 (b) Knapsack on D=1000 (c) TSP on D=500 (d) NK-landscape on D=50 Fig. 4. The final archive sets are the results of the seven algorithms on 4 different settings of the second experiment from a single run. This particular run is associated with the result closest to the average HV value. 

VS-RLS, this property may provide a potential advantage in high-dimensional TSP problems [80], as will be further discussed in later experiments. For the QAP (Fig. 3(c)) and NK-landscape (Fig. 3(d)) problems, VS-RLS shows the best performance. In QAP, population-based MOEAs often stop improving too early near the Pareto front. This may be because the objective values in QAP cover a very wide range, which increases selection pressure and causes the population to converge quickly to local optima. In contrast, the NK-landscape has smaller changes in objective values, which result in weaker selection pressure and slower convergence. VS-RLS works well in both situations by changing its search range dynamically. It enlarges the range to escape stagnation in QAP and reduces it to make steady improvements in the NK-landscape. This makes VS-RLS robust across problems with different landscape features. 

B. Comparison at different problem sizes 

Table II presents the mean and standard deviation of the HV values obtained by the seven algorithms on the 8 test instances. Fig. 4 shows the final solution set from a single run whose result is closest to the average HV value for this problem. This experiment studies the performance of the algorithms under different problem sizes. As shown in Table II and Fig. 4, the proposed VS-RLS achieves the best performance in most instances. For the Knapsack problem (Figs. 4(a) and (b)), when the dimension is low ( D = 100 ), the differences among the algorithms are small and most of them can ap-proximate the Pareto front well. As the dimension increases, MOEAs tend to produce solutions with stronger convergence but lower diversity, while VS-RLS maintains better diversity and correspondingly achieves higher HV values. A possible explanation is that, in high-dimensional Knapsack problems, the search process is more likely to concentrate around certain local Pareto fronts, making it difficult for population-based algorithms with fixed crossover and mutation operators to preserve sufficient diversity. In contrast, VS-RLS performs local search on a single solution with a variable stepsize mechanism, which allows it to adaptively adjust the search region and escape from locally concentrated regions. Although its convergence may be slightly slower in some cases, the final solution set obtained by VS-RLS demonstrates better diversity and coverage of the Pareto front. In the TSP problem (Fig. 4(c)), compared with the first experiment, the most notable change is the clear improvement in MOEA/D’s performance, which becomes better as the dimension increases [80]. In the NK-landscape problem (Fig. 4(d)), as the dimen-sion D increases, the relative ruggedness level of the land-scape decreases. In small-scale instances (such as D=50), the performance of SMS-EMOA is similar to that of VS-RLS (Table II), with a slightly higher HV value. In high-dimensional instances, VS-RLS can better balance exploration and exploitation through its dynamic stepsize adjustment, thus achieving better results. 

C. Comparison at different numbers of evaluations 

Table III presents the mean and standard deviation of the HV values obtained by the seven algorithms on the 16 test instances. Fig. 5 shows the final solution set from a single run whose result is closest to the average HV value for this problem. We consider the influence of different numbers of eval-uations on algorithm performance under the same general SUBMIT TO IEEE TRANSACTIONS ON EVOLUTIONARY COMPUTATION 9

TABLE III THE HV RESULTS (MEAN AND STANDARD DEVIATION ) OF THE SEVEN ALGORITHMS UNDER 16 DIFFERENT SETTINGS . T HE BEST -PERFORMING ALGORITHM IN EACH SETTING IS HIGHLIGHTED IN BOLD . T HE SYMBOLS “+”, “=”, AND “−” INDICATE THAT THE CORRESPONDING ALGORITHM PERFORMS STATISTICALLY BETTER THAN , SIMILAR TO , OR WORSE THAN VS-RLS, RESPECTIVELY .Problem eval. D RS NSGA-II MOEA/D SMS-EMOA PLS SEMO VS-RLS Knapsack                                                                                                                                                   

> 1×10 5
> 500 3.15e+07 (7.19e+05) −8.45e+07 (6.34e+05) +8.46e+07 (8.26e+05) +8.44e+07 (6.07e+05) +2.40e+07 (1.16e+06) −8.46e+07 (8.08e+05) +7.06e+07 (3.66e+06)
> 5×10 53.31e+07 (9.03e+05) −8.83e+07 (6.10e+05) −8.93e+07 (5.44e+05) −8.70e+07 (4.97e+05) −2.68e+07 (3.15e+06) −8.88e+07 (5.72e+05) −8.99e+07 (4.25e+05)
> 2×10 63.45e+07 (8.68e+05) −9.19e+07 (5.23e+05) −9.22e+07 (5.40e+05) −8.92e+07 (5.62e+05) −3.81e+07 (7.77e+06) −9.21e+07 (5.92e+05) −9.35e+07 (5.36e+05)
> 5×10 63.53e+07 (8.03e+05) −9.41e+07 (5.39e+05) −9.38e+07 (3.03e+05) −9.10e+07 (5.46e+05) −5.71e+07 (1.33e+07) −9.39e+07 (4.71e+05) −9.52e+07 (4.24e+05)
> TSP
> 1×10 5
> 200 1.40e+03 (4.46e+01) −6.82e+03 (2.74e+02) −7.84e+03 (1.69e+02) +6.58e+03 (1.93e+02) −1.04e+03 (1.40e+02) −7.28e+03 (1.51e+02) −7.44e+03 (1.14e+02)
> 5×10 51.51e+03 (3.78e+01) −8.37e+03 (1.97e+02) −9.25e+03 (1.43e+02) =8.24e+03 (1.99e+02) −1.27e+03 (5.53e+02) −9.14e+03 (7.49e+01) −9.23e+03 (9.37e+01)
> 2×10 61.58e+03 (3.00e+01) −9.50e+03 (1.50e+02) −1.01e+04 (1.24e+02) −9.35e+03 (1.50e+02) −3.10e+03 (3.14e+03) −1.04e+04 (6.08e+01) −1.06e+04 (5.39e+01)
> 5×10 61.64e+03 (2.80e+01) −1.01e+04 (9.94e+01) −1.05e+04 (1.19e+02) −1.00e+04 (1.32e+02) −4.84e+03 (4.02e+03) −1.11e+04 (5.02e+01) −1.12e+04 (6.10e+01)
> QAP
> 1×10 5
> 100 5.49e+14 (2.93e+13) −1.91e+15 (1.77e+14) −2.00e+15 (1.16e+14) −1.83e+15 (1.51e+14) −8.95e+14 (6.19e+14) −4.25e+15 (1.20e+14) =4.23e+15 (1.21e+14)
> 5×10 56.10e+14 (2.61e+13) −2.41e+15 (1.47e+14) −2.45e+15 (1.07e+14) −2.49e+15 (1.53e+14) −2.70e+15 (1.14e+15) −5.61e+15 (1.31e+14) =5.62e+15 (1.25e+14)
> 2×10 66.73e+14 (2.55e+13) −2.77e+15 (1.65e+14) −2.70e+15 (1.90e+14) −2.81e+15 (1.53e+14) −3.23e+15 (5.17e+14) −6.59e+15 (1.47e+14) −6.68e+15 (1.20e+14)
> 5×10 67.02e+14 (2.86e+13) −2.93e+15 (1.61e+14) −2.91e+15 (1.72e+14) −2.97e+15 (1.11e+14) −3.35e+15 (2.70e+14) −7.09e+15 (8.63e+13) −7.18e+15 (1.38e+14)
> NK-landscape
> 1×10 5
> 100 7.36e–02 (2.46e–03) −1.34e–01 (3.19e–03) =1.37e–01 (6.59e–03) =1.34e–01 (5.27e–03) =1.09e–01 (2.37e–02) −1.42e–01 (5.44e–03) +1.36e–01 (4.81e–03)
> 5×10 57.80e–02 (1.75e–03) −1.41e–01 (3.93e–03) −1.42e–01 (5.52e–03) −1.43e–01 (4.73e–03) =1.14e–01 (2.06e–02) −1.40e–01 (4.36e–03) −1.45e–01 (4.74e–03)
> 2×10 68.21e–02 (2.06e–03) −1.45e–01 (6.08e–03) −1.42e–01 (4.60e–03) −1.45e–01 (4.52e–03) −1.12e–01 (2.21e–02) −1.43e–01 (5.02e–03) −1.50e–01 (5.09e–03)
> 5×10 68.51e–02 (1.87e–03) −1.46e–01 (4.67e–03) −1.45e–01 (5.68e–03) −1.47e–01 (4.00e–03) −1.14e–01 (2.25e–02) −1.41e–01 (5.92e–03) −1.50e–01 (4.54e–03)
> +/=/ −0/0/16 1/1/14 2/2/12 1/2/13 0/0/16 2/1/13

(a) Knapsack on eval.= 1 × 10 5 (b) Knapsack on eval.= 5 × 10 5 (c) Knapsack on eval.= 2 × 10 6 (d) Knapsack on eval.= 5 × 10 6

Fig. 5. The final archive sets are the results of the seven algorithms on 4 different settings of the third experiment from a single run. This particular run is associated with the result closest to the average HV value. 

settings as in the first experiment. As shown in Table III and Fig. 5, a clear trend can be observed, when the number of evaluations is small (Fig. 5(a)), the performance of VS-RLS decreases significantly, whereas when the number of evaluations reaches 5 × 10 5 (Fig. 5(b)) or more (Figs. 5(c) and (d)), VS-RLS achieves the best performance across all problems. This result explains why VS-RLS performs poorly with fewer evaluations. When the total number of evaluations is limited to 1 × 10 5, the algorithm may exhaust its com-putational resources during the early stages of the search. For example, in the Knapsack problem with D=500 and 

Tvl =1000, the worst-case scenario occurs when the algorithm gradually expands its stepsize from 1-bit to 500-bit flips without finding an improved solution. In such a case, 1000 iterations would require approximately 5 × 10 5 evaluations, meaning that the algorithm may run out of evaluations before entering the exploitation phase. In addition, for the Knapsack problem, when a larger number of evaluations is provided than in the first experiment, the algorithm continues to show a gradual convergence trend. Specifically, when the number of evaluations reaches 5 × 10 6 (Fig. 5(d)), VS-RLS achieves convergence comparable to that of MOEAs while maintaining higher solution diversity. 

D. Parameter Sensitivity Analysis and Ablation Study 

We conducted experiments on the Knapsack problem with a dimension of 500 and a total of 500,000 evaluations. This configuration was selected because, in the worst case, the algo-rithm may evaluate all D decision variables in each iteration. Running Tvl = 1000 iterations therefore requires 500,000 evaluations, providing a fair basis for parameter analysis and ablation studies. This experiment aims to evaluate two key components of the algorithm: VC , which controls the stepsize threshold during the exploitation phase, and Tvl , which determines the transition point between the early and later phases of evolution. The experiments are divided into the following groups: 

1) Baseline Group : The baseline uses Tvl = 1000 and 

VC = 3 , as established in previous experiments. 

2) Stepsize Variation Group : To investigate the effect of different variable stepsizes, we tested two additional settings: 

VC = 1 and VC = 5 , corresponding to smaller and larger stepsize threshold adjustments, respectively. 

3) Exploration Phase Ablation Group : To assess the role of large stepsize threshold in the exploration phase, we created an ablation variant that removes this operation. This is equivalent to setting Tvl = 0 while keeping VC = 3 .Fig. 6 presents the HV convergence curves under the original setting and three comparative configurations. When comparing the cases of Tvl = 1000 with VC = 1 and VC = 5 ,the convergence trends are similar to those of the original configuration. After approximately 1,000 iterations, reducing the variable stepsize accelerates convergence, leading to a noticeable increase in HV. However, the overall performance under VC = 1 and VC = 5 is inferior to that of the baseline. This difference can be attributed to the varying search regions of decision variables. When VC = 1, the search SUBMIT TO IEEE TRANSACTIONS ON EVOLUTIONARY COMPUTATION 10 

Fig. 6. HV convergence curves of VS-RLS with different parameter settings. The vertical axis denotes the HV value, and the horizontal axis denotes the number of evaluations. 

region becomes too narrow, resulting in limited diversity and premature convergence to local optima. Conversely, when 

VC = 5 , the search region becomes excessively large, causing many evaluations to be wasted. In contrast, the choice of 

VC = 3 represents a balanced trade-off between convergence speed and solution diversity. In the ablation experiment, when Tvl = 0 and VC = 3 , the algorithm exhibits faster progress. However, this configuration depends heavily on the quality of the initial solution, making it difficult to accumulate high-quality solutions during this phase and weakening the search performance in the subsequent ex-ploitation phase. This result demonstrates that a large stepsize is necessary during the exploration phase. VI. CONCLUSION In this paper, we studied the use of variable search stepsize in randomized local search for multi-objective combinatorial optimization. We showed that a simple mechanism that ad-justs the size of neighbourhood exploration can lead to clear performance improvements across a wide range of problems. The proposed VS-RLS method begins with a broad search that encourages exploration of distant regions in the search space and then shifts to smaller and more focused regions as the search progresses. The empirical results on four representative MOCOPs show that VS-RLS is competitive against both ran-domized local search with fixed neighbourhoods and several well-established MOEAs. There are several directions for future work. One possibility is to integrate the variable stepsize mechanism into population-based algorithms or hybrid frameworks, allowing global and local search processes to complement each other. Another direction is to investigate more advanced adaptation strategies, for example data-driven or learning-based approaches that adjust the stepsize based on feedback collected during the search. REFERENCES [1] M. Ehrgott, Multicriteria optimization . Springer Science & Business Media, 2005, vol. 491. [2] T. Chen and M. Li, “The weights can be harmful: Pareto search versus weighted search in multi-objective search-based software engineering,” 

ACM Transactions on Software Engineering and Methodology , vol. 32, no. 1, pp. 1–40, 2023. [3] R. M. Hierons, M. Li, X. Liu, J. A. Parejo, S. Segura, and X. Yao, “Many-objective test suite generation for software product lines,” ACM Transactions on Software Engineering and Methodology , vol. 29, no. 1, pp. 1–46, 2020. [4] F. Altiparmak, M. Gen, L. Lin, and T. Paksoy, “A genetic algorithm approach for multi-objective optimization of supply chain networks,” 

Computers & industrial engineering , vol. 51, no. 1, pp. 196–215, 2006. [5] Z. Zhu, G. Zhang, M. Li, and X. Liu, “Evolutionary multi-objective workflow scheduling in cloud,” IEEE Transactions on parallel and distributed Systems , vol. 27, no. 5, pp. 1344–1357, 2015. [6] M. P. Ferringer and D. B. Spencer, “Satellite constellation design tradeoffs using multiple-objective evolutionary computation,” Journal of spacecraft and rockets , vol. 43, no. 6, pp. 1404–1411, 2006. [7] K. Deb, A. Pratap, S. Agarwal, and T. Meyarivan, “A fast and elitist multiobjective genetic algorithm: NSGA-II,” IEEE transactions on evo-lutionary computation , vol. 6, no. 2, pp. 182–197, 2002. [8] Q. Zhang and H. Li, “MOEA/D: A multiobjective evolutionary algorithm based on decomposition,” IEEE Transactions on evolutionary computa-tion , vol. 11, no. 6, pp. 712–731, 2007. [9] N. Beume, B. Naujoks, and M. Emmerich, “SMS-EMOA: Multiobjec-tive selection based on dominated hypervolume,” European Journal of Operational Research , vol. 181, no. 3, pp. 1653–1669, 2007. [10] C. Changdar, R. K. Pal, G. S. Mahapatra, and A. Khan, “A genetic algo-rithm based approach to solve multi-resource multi-objective knapsack problem for vegetable wholesalers in fuzzy environment,” Operational Research , vol. 20, no. 3, pp. 1321–1352, 2020. [11] L. Ke, Q. Zhang, and R. Battiti, “MOEA/D-ACO: A multiobjective evolutionary algorithm using decomposition and antcolony,” IEEE trans-actions on cybernetics , vol. 43, no. 6, pp. 1845–1859, 2013. [12] Y. Shuai, S. Yunfeng, and Z. Kai, “An effective method for solving multiple travelling salesman problem based on NSGA-II,” Systems Science & Control Engineering , vol. 7, no. 2, pp. 108–116, 2019. [13] M. Li, X. Han, and X. Chu, “MOEAs are stuck in a different area at a time,” in Proceedings of the Genetic and Evolutionary Computation Conference , 2023, pp. 303–311. [14] M. Li, “Combinatorial Optimisation Can be Different from Continuous Optimisation for MOEAs,” in Proceedings of the Genetic and Evolu-tionary Computation Conference Companion , 2025, pp. 1167–1181. [15] M. Li, X. Han, X. Chu, and Z. Liang, “Empirical comparison between MOEAs and local search on multi-objective combinatorial optimisation problems,” in Proceedings of the Genetic and Evolutionary Computation Conference , 2024, pp. 547–556. [16] Q. M. Phan and N. H. Luong, “Pareto local search is competitive with evolutionary algorithms for multi-objective neural architecture search,” in Proceedings of the Genetic and Evolutionary Computation Conference , 2023, pp. 348–356. [17] ´E. D. Taillard, Design of heuristic algorithms for hard optimization: with python codes for the travelling salesman problem . Springer Nature, 2023. [18] A. Liefooghe, J. Humeau, S. Mesmoudi, L. Jourdan, and E.-G. Talbi, “On dominance-based multiobjective local search: design, implemen-tation and experimental analysis on scheduling and traveling salesman problems,” Journal of Heuristics , vol. 18, pp. 317–352, 2012. [19] Z. Liang and M. Li, “Random is faster than systematic in multi-objective local search,” in Proceedings of the 40th AAAI Conference on Artificial Intelligence , 2026. [20] L. Paquete, M. Chiarandini, and T. St¨ utzle, “Pareto local optimum sets in the biobjective traveling salesman problem: An experimental study,” in Metaheuristics for multiobjective optimisation . Springer, 2004, pp. 177–199. [21] Y. Kang, J. Shi, J. Sun, Q. Zhang, and Y. Fan, “New techniques to improve neighborhood exploration in pareto local search,” Expert Systems with Applications , vol. 254, p. 124296, 2024. [22] H. Aguirre and K. Tanaka, “Random bit climbers on multiobjective mnk-landscapes: effects of memory and population climbing,” IEICE trans-actions on fundamentals of electronics, communications and computer sciences , vol. 88, no. 1, pp. 334–345, 2005. [23] F. Daolio, A. Liefooghe, S. Verel, H. Aguirre, and K. Tanaka, “Global vs local search on multi-objective NK-landscapes: contrasting the impact of problem features,” in proceedings of the 2015 Annual Conference on Genetic and Evolutionary Computation , 2015, pp. 369–376. SUBMIT TO IEEE TRANSACTIONS ON EVOLUTIONARY COMPUTATION 11 

[24] A. Liefooghe, L. Paquete, and J. R. Figueira, “On local search for bi-objective knapsack problems,” Evolutionary computation , vol. 21, no. 1, pp. 179–196, 2013. [25] B. Doerr, O. E. Hadri, and A. Pinard, “The (1+( λ, λ)) global semo algorithm,” in Proceedings of the Genetic and Evolutionary Computation Conference , 2022, pp. 520–528. [26] B. Doerr, J. Knowles, A. Neumann, and F. Neumann, “A block-coordinate descent emo algorithm: Theoretical and empirical analysis,” in Proceedings of the Genetic and Evolutionary Computation Confer-ence , 2024, pp. 493–501. [27] E. Zitzler and L. Thiele, “Multiobjective evolutionary algorithms: a com-parative case study and the strength pareto approach,” IEEE transactions on Evolutionary Computation , vol. 3, no. 4, pp. 257–271, 1999. [28] C. C. Ribeiro, P. Hansen, P. C. Borges, and M. P. Hansen, “A study of global convexity for a multiple objective travelling salesman problem,” 

Essays and surveys in metaheuristics , pp. 129–150, 2002. [29] J. Knowles and D. Corne, “Instance generators and test suites for the multiobjective quadratic assignment problem,” in International Confer-ence on Evolutionary Multi-Criterion Optimization . Springer, 2003, pp. 295–310. [30] H. E. Aguirre and K. Tanaka, “Effects of elitism and population climb-ing on multiobjective MNK-landscapes,” in Proceedings of the 2004 Congress on Evolutionary Computation (IEEE Cat. No. 04TH8753) ,vol. 1. IEEE, 2004, pp. 449–456. [31] A. E. Eiben and J. E. Smith, Introduction to evolutionary computing .Springer, 2015. [32] Z.-H. Zhan, L. Shi, K. C. Tan, and J. Zhang, “A survey on evolu-tionary computation for complex continuous optimization,” Artificial Intelligence Review , vol. 55, no. 1, pp. 59–110, 2022. [33] Z. Liang, M. Li, and P. K. Lehre, “Non-elitist evolutionary multi-objective optimisation: Proof-of-principle results,” in Proceedings of the Companion Conference on Genetic and Evolutionary Computation ,2023, pp. 383–386. [34] X. Chu, X. Han, M. Zhang, and M. Li, “Improving decomposition-based moeas for combinatorial optimisation by intensifying corner weights,” 

Swarm and Evolutionary Computation , vol. 91, p. 101722, 2024. [35] M. A. Ardakan and M. T. Rezvan, “Multi-objective optimization of reliability–redundancy allocation problem with cold-standby strategy using NSGA-II,” Reliability Engineering & System Safety , vol. 172, pp. 225–238, 2018. [36] C. Su, Y. Shi, and J. Dou, “Multi-objective optimization of buffer allocation for remanufacturing system based on TS-NSGAII hybrid algorithm,” Journal of Cleaner Production , vol. 166, pp. 756–770, 2017. [37] Z. Guo, W. K. Wong, and S. Y.-S. Leung, “A hybrid intelligent model for order allocation planning in make-to-order manufacturing,” Applied Soft Computing , vol. 13, no. 3, pp. 1376–1390, 2013. [38] S. Yang, H. Ma, Y. Bi, Y. Tian, L. Zhang, Y. Jin, and X. Zhang, “An evolutionary multi-objective neural architecture search approach to ad-vancing cognitive diagnosis in intelligent education,” IEEE Transactions on Evolutionary Computation , 2024. [39] Y. Wang, L. Zhen, J. Zhang, M. Li, L. Zhang, Z. Wang, Y. Feng, Y. Xue, X. Wang, Z. Chen et al. , “MedNAS: Multiscale training-free neural architecture search for medical image analysis,” IEEE Transactions on Evolutionary Computation , vol. 28, no. 3, pp. 668–681, 2024. [40] K. Lyu, H. Li, M. Gong, L. Xing, and A. K. Qin, “Surrogate-assisted evolutionary multiobjective neural architecture search based on transfer stacking and knowledge distillation,” IEEE Transactions on Evolutionary Computation , vol. 28, no. 3, pp. 608–622, 2023. [41] Z. Lu, I. Whalen, V. Boddeti, Y. Dhebar, K. Deb, E. Goodman, and W. Banzhaf, “NSGA-Net: neural architecture search using multi-objective genetic algorithm,” in Proceedings of the genetic and evolu-tionary computation conference , 2019, pp. 419–427. [42] A. Jaszkiewicz, “On the performance of multiple-objective genetic local search on the 0/1 knapsack problem-a comparative experiment,” IEEE Transactions on Evolutionary Computation , vol. 6, no. 4, pp. 402–412, 2002. [43] E.-G. Talbi, M. Rahoual, M. H. Mabed, and C. Dhaenens, “A hybrid evolutionary approach for multicriteria optimization problems: Applica-tion to the flow shop,” in Evolutionary Multi-Criterion Optimization: First International Conference, EMO 2001 Zurich, Switzerland, March 7–9, 2001 Proceedings 1 . Springer, 2001, pp. 416–428. [44] C. Qian, “Pareto optimization for subset selection: Theories and practical algorithms,” in Proceedings of the Genetic and Evolutionary Compu-tation Conference . Association for Computing Machinery, 2025, p. 1592–1616. [45] R. Deng, W. Zheng, M. Li, J. Liu, and B. Doerr, “Runtime analysis for state-of-the-art multi-objective evolutionary algorithms on the subset selection problem,” in Parallel Problem Solving from Nature , 2024, pp. 264–279. [46] C. Bian, Y. Zhou, and C. Qian, “Robust Subset Selection by Greedy and Evolutionary Pareto Optimization,” in International Joint Conference on Artificial Intelligence , 2022, pp. 4726–4732. [47] A. V. Do, A. Neumann, F. Neumann, and A. Sutton, “Rigorous runtime analysis of MOEA/D for solving multi-objective minimum weight base problems,” Advances in Neural Information Processing Systems , vol. 36, pp. 36 434–36 448, 2023. [48] F. Neumann, “Expected runtimes of a simple evolutionary algorithm for the multi-objective minimum spanning tree problem,” European Journal of Operational Research , vol. 181, no. 3, pp. 1620–1629, 2007. [49] Z. Liang and M. Li, “On the problem characteristics of multi-objective pseudo-boolean functions in runtime analysis,” in Foundations of Ge-netic Algorithms , 2025, p. 166–177. [50] W. Zheng, Y. Liu, and B. Doerr, “A first mathematical runtime analysis of the non-dominated sorting genetic algorithm II (NSGA-II),” in AAAI Conference on Artificial Intelligence , vol. 36, no. 9, 2022, pp. 10 408– 10 416. [51] B. Doerr and Z. Qu, “A first runtime analysis of the NSGA-II on a multimodal problem,” Evolutionary Computation , vol. 27, no. 5, pp. 1288–1297, 2023. [52] W. Zheng, M. Li, R. Deng, and B. Doerr, “How to use the metropolis algorithm for multi-objective optimization?” in AAAI Conference on Artificial Intelligence , vol. 38, no. 18, 2024, pp. 20 883–20 891. [53] B. Doerr, M. Krejca, and N. Weeks, “Proven runtime guarantees for how the MOEA/D: computes the Pareto front from the subproblem solutions,” in Parallel Problem Solving from Nature , 2024, pp. 197–212. [54] C. Bian, Y. Zhou, M. Li, and C. Qian, “Stochastic population update can provably be helpful in multi-objective evolutionary algorithms,” 

Artificial Intelligence , vol. 341, p. 104308, 2025. [55] S. Ren, Z. Liang, M. Li, and C. Qian, “Stochastic population update provably needs an archive in evolutionary multi-objective optimization,” 

arXiv preprint arXiv:2501.16735 , 2025. [56] C. Bian, S. Ren, M. Li, and C. Qian, “An archive can bring provable speed-ups in multi-objective evolutionary algorithms,” in Proceedings of the 33rd International Joint Conference on Artificial Intelligence (IJCAI-24) , 2024, pp. 6905–6913. [57] S. Ren, Z. Liang, M. Li, and C. Qian, “Not just for archiving: Provable benefits of reusing the archive in evolutionary multi-objective optimiza-tion,” in Proceedings of the AAAI Conference on Artificial Intelligence ,2026. [58] B. Doerr, T. Jansen, and C. Klein, “Comparing global and local mutations on bit strings,” in Proceedings of the 10th annual conference on Genetic and evolutionary computation , 2008, pp. 929–936. [59] C. Qian, Y. Yu, and Z.-H. Zhou, “An analysis on recombination in multi-objective evolutionary optimization,” in Proceedings of the 13th annual conference on Genetic and evolutionary computation , 2011, pp. 2051– 2058. [60] J. Dubois-Lacoste, M. L´ opez-Ib´ a˜ nez, and T. St¨ utzle, “Improving the anytime behavior of two-phase local search,” Annals of mathematics and artificial intelligence , vol. 61, pp. 125–154, 2011. [61] L. Paquete and T. St¨ utzle, “Clusters of non-dominated solutions in multiobjective combinatorial optimization: An experimental analysis,” in Multiobjective Programming and Goal Programming: Theoretical Results and Practical Applications . Springer, 2009, pp. 69–77. [62] M. ´A. Dom´ ınguez-R´ ıos, F. Chicano, and E. Alba, “Effective anytime algorithm for multiobjective combinatorial optimization problems,” In-formation Sciences , vol. 565, pp. 210–228, 2021. [63] J. J. Durillo and A. J. Nebro, “jMetal: A Java framework for multi-objective optimization,” Advances in engineering software , vol. 42, no. 10, pp. 760–771, 2011. [64] J. D. Knowles, D. Corne et al. , “Towards landscape analyses to inform the design of hybrid local search for the multiobjective quadratic assignment problem.” HIS , vol. 87, pp. 271–279, 2002. [65] L. Paquete, T. Schiavinotto, and T. St¨ utzle, “On local optima in mul-tiobjective combinatorial optimization problems,” Annals of Operations Research , vol. 156, pp. 83–97, 2007. [66] M. Basseur, F. Seynhaeve, and E.-g. Talbi, “Design of multi-objective evolutionary algorithms: Application to the flow-shop scheduling prob-lem,” in Proceedings of the 2002 Congress on Evolutionary Computa-tion. CEC’02 (Cat. No. 02TH8600) , vol. 2. IEEE, 2002, pp. 1151–1156. [67] H. Zhang, J. Shi, J. Sun, and Z. Xu, “Learning to balance exploration and exploitation in pareto local search for multi-objective combinatorial optimization,” in Proceedings of the genetic and evolutionary computa-tion conference companion , 2022, pp. 383–386. SUBMIT TO IEEE TRANSACTIONS ON EVOLUTIONARY COMPUTATION 12 

[68] J. Dubois-Lacoste, M. L´ opez-Ib´ a˜ nez, and T. St¨ utzle, “Anytime pareto local search,” European journal of operational research , vol. 243, no. 2, pp. 369–385, 2015. [69] Y. Kang, J. Shi, J. Sun, and Y. Fan, “Improving neighborhood explo-ration mechanism to speed up pls,” in Proceedings of the genetic and evolutionary computation conference , 2023, pp. 688–694. [70] L. Paquete and T. St¨ utzle, “Stochastic local search algorithms for multiobjective combinatorial optimization: A review,” Handbook of approximation algorithms and metaheuristics , pp. 411–425, 2018. [71] M. Laumanns, L. Thiele, and E. Zitzler, “Running time analysis of multiobjective evolutionary algorithms on pseudo-boolean functions,” 

IEEE Transactions on Evolutionary Computation , vol. 8, no. 2, pp. 170– 182, 2004. [72] H. R. Lourenc ¸o, O. C. Martin, and T. St¨ utzle, “Iterated local search: Framework and applications,” in Handbook of metaheuristics . Springer, 2018, pp. 129–168. [73] I. Ryzhikov, C. Brester, and E. Semenkin, “Multi-objective order re-duction problem solving with restart meta-heuristic implementation,” in 

ICINCO (1) , 2017, pp. 270–278. [74] J. E. Fieldsend and K. Alyahya, “Visualising the landscape of multi-objective problems using local optima networks,” in Proceedings of the Genetic and Evolutionary Computation Conference Companion , 2019, pp. 1421–1429. [75] T. Lust and J. Teghem, “Two-phase pareto local search for the biobjective traveling salesman problem,” Journal of Heuristics , vol. 16, no. 3, pp. 475–510, 2010. [76] D. W. Corne and J. D. Knowles, “Techniques for highly multiobjective optimisation: some nondominated points are better than others,” in 

Proceedings of the 9th annual conference on Genetic and evolutionary computation , 2007, pp. 773–780. [77] E. D. Taillard, “Comparison of iterative searches for the quadratic assignment problem,” Location science , vol. 3, no. 2, pp. 87–105, 1995. [78] M. Li and X. Yao, “Quality evaluation of solution sets in multiobjective optimisation: A survey,” ACM Computing Surveys (CSUR) , vol. 52, no. 2, pp. 1–38, 2019. [79] M. Li, T. Chen, and X. Yao, “How to evaluate solutions in pareto-based search-based software engineering: A critical review and methodological guidance,” IEEE Transactions on Software Engineering , vol. 48, no. 5, pp. 1771–1799, 2020. [80] W. Peng, Q. Zhang, and H. Li, “Comparison between MOEA/D and NSGA-II on the multi-objective travelling salesman problem,” in Multi-objective memetic algorithms . Springer, 2009, pp. 309–324. [81] G. Ochoa and N. Veerapen, “Mapping the global structure of tsp fitness landscapes,” Journal of Heuristics , vol. 24, no. 3, pp. 265–294, 2018. [82] D. Whitley, D. Hains, and A. Howe, “A hybrid genetic algorithm for the traveling salesman problem using generalized partition crossover,” in International Conference on Parallel Problem Solving from Nature .Springer, 2010, pp. 566–575.
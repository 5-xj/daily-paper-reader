Title: Evolving Afferent Architectures: Biologically-inspired Models for Damage-Avoidance Learning

URL Source: https://arxiv.org/pdf/2602.04807v1

Published Time: Thu, 05 Feb 2026 02:18:18 GMT

Number of Pages: 16

Markdown Content:
# Evolving Afferent Architectures: Biologically-inspired Models for Damage-Avoidance Learning 

Wolfgang Maass 1,2 , Sabine Janzen 2, Prajvi Saxena 2, Sach Mukherjee 3,4 

> 1

Saarland University, Saarbrücken, Germany 

> 2

German Research Center for Artificial Intelligence (DFKI), Saarbrücken, Germany 

> 3

Statistics and Machine Learning, German Center for Neurodegenerative Diseases (DZNE), Bonn, Germany 

> 4

MRC Biostatistics Unit, University of Cambridge, Cambridge, UK 

## February 5, 2026 

# Abstract 

We introduce Afferent Learning , a framework that produces 

Computational Afferent Traces (CATs) as adaptive, internal risk signals for damage-avoidance learning. Inspired by biological systems, the framework uses a two-level archi-tecture: evolutionary optimization (outer loop) discovers afferent sensing architectures that enable effective policy learning, while reinforcement learning (inner loop) trains damage-avoidance policies using these signals. This for-malizes afferent sensing as providing an inductive bias for efficient learning: architectures are selected based on their ability to enable effective learning (rather than directly minimizing damage). We provide theoretical convergence guarantees under smoothness and bounded-noise assump-tions. We illustrate the general approach in the challenging context of biomechanical digital twins operating over long time horizons (multiple decades of the life-course). Here, we find that CAT-based evolved architectures achieve sig-nificantly higher efficiency and better age-robustness than hand-designed baselines, enabling policies that exhibit age-dependent behavioral adaptation (23% reduction in high-risk actions). Ablation studies validate CAT signals, evolution, and predictive discrepancy as essential. We release code and data for reproducibility. 

# 1 Introduction 

Biological afferents are sensory pathways that convey in-formation from the periphery to the central nervous system, based on a dual-level organization. At the phylogenetic 

level, afferent architectures are evolved to enable effec-tive damage-avoidance learning; at the ontogenetic level, neural circuitry adapts over an organism’s lifetime to re-spond to afferent signals [ 2, 16 ]. This bi-level selection and optimization can be viewed as implementing a form of inductive bias with respect to learnability. Sensing archi-tectures are optimized to support efficient policy learning under risk rather than directly minimizing physical dam-age. This general schema of adaptive sensors coupled with bi-level phylogenetic and ontogenetic optimization is ob-served not only in the nervous system but across biology, including sensing and fine-tuning mechanisms in immunity and DNA damage sensing and repair. In contrast, AI systems interacting with models of bio-logical or biomedical systems typically lack internal sig-nals that identify harmful states, integrate temporal stress accumulation, and store this information to bias future de-cisions. A key application, which motivates this work, is in biomedical digital twins (DTs). DTs in medicine have reached high fidelity [ 11 ], and their integration with AI ap-proaches has high potential, but most applications remain reactive and memoryless, preventing adaptive damage-avoidance behaviors and this is an important factor that continues to limit their practical utility. In this paper, motivated by the foregoing observations about biological systems, we introduce a class of AI ar-chitectures in which adaptive sensing mechanisms, termed 

Computational Afferent Traces (CATs), serve as internal risk signals intended to be operationally equivalent to af-ferent mechanisms in biological systems. We focus in particular on settings in which an embodied agent operates on tasks involving damage accumulation over time. As we see below, the CATs we learn are related to physiologically-plausible damage signals rather than only abstract consid-erations. The goal of the (computational) afferent mech-anisms we propose is to endow AI systems with an in-ternal risk indicator that guides adaptive behavior. For example, in the specific setting of a biomechanical DT, we would expect CATs to capture aspects such as non-physiological load, instability-driven stress or cumulative strain and thereby allow efficient learning, Specifically, we propose a learning architecture that mir-rors the bi-level (phylogenetic/ontogenetic) organization 1

> arXiv:2602.04807v1 [cs.LG] 4 Feb 2026

of biological afferents: evolutionary optimization (outer loop) discovers afferent sensing architectures that enable effective policy learning [ 10 , 19 ], while reinforcement learning (inner loop) trains damage-avoidance policies us-ing these signals [ 22 ]. This separation enables afferents to provide an inductive bias with respect to learnability, where architectures are selected based on their ability to enable effective learning (rather than directly minimizing damage). 

# 2 Related Work 

Artificial afferents have been investigated primarily in the context of neurorobotics and bio-inspired sensing, where afferent signals are used to trigger reflexive behaviors or protective responses [ 7, 24 ]. In parallel, musculoskeletal digital twins integrate medical imaging, biomechanical modeling, and finite-element simulation to analyze tissue stress, degeneration, and injury risk [ 6 , 11 ]. While these approaches provide important diagnostic and predictive capabilities, they typically treat afferent inputs or damage as an external quantity to be estimated rather than as an internal, learned risk state that actively shapes behavior and learning over time. A complementary line of work models afferent inputs as an inferential process that integrates sensory evidence, prior expectations, and uncertainty providing an internal belief or risk-related latent state that influences perception and action selection [ 3 , 9, 23 ]. Although conceptually aligned with the notion of afferent internal signals, these models are often underspecified at the algorithmic level and are rarely grounded in explicit biomechanical damage processes or evaluated in long-horizon learning and control scenarios. Episodic memory has been shown to improve decision-making, planning, and adaptation in artificial agents [ 5, 15 , 18 ]. However, episodic mechanisms in rein-forcement learning are typically grounded in abstract state–action–reward representations rather than physics-based damage or wear signals [ 17 ]. As a result, episodic recall is seldom used to anticipate biomechanical risk or long-term structural degradation. Hierarchical and meta-learning frameworks separate architectural optimization from policy learning [ 20 , 21 ]. In reinforcement learning, evolutionary strategies have been employed as outer-loop optimizers [ 10 , 19 ], while gradient-based methods such as PPO are commonly used for policy learning [ 22 ]. In contrast to approaches that directly evolve policies or rewards, our method evolves afferent sensing architectures whose fitness is evaluated based on downstream learning outcomes. While our ap-proach shares some motivation with general meta-learning, in contrast to established meta-learning frameworks such as MAML and variants [ 8 , 12 , 14 ] our focus is not on general heuristics concerning learning dynamics but rather specific adaptive sensors and their integration via bi-level phylogenetic/ontogenetic-like learning. Furthermore, we focus specifically on the setting of agents operating in tasks involving damage accumulation over time, where the par-ticular inductive bias we propose is a natural computational analogue to real, biological damage-sensing mechanisms and associated adaptation. 

# 3 Core Architecture for Compu-tational Afferent and Adaptive Learning 

This section outlines the core concepts of the architecture; implementation details are deferred. For concreteness, we use biomechanical digital twins (BDTs) as a running example. We consider an embodied agent in a simulated environment with cumulative damage. At each time step 

t, the environment provides observations xt ∈ RK under action at and context st. The agent maintains an internal, unobservable damage state Dt ∈ R≥0 that accumulates with mechanical loading, inducing partial observability that is addressed through afferent sensing. 

## 3.1 Computational Afferent Traces (CATs) 

Definition 1 (Computational Afferent Trace (CAT)) . Let 

xt ∈ RK denote the feature vector at time t, at the agent action, and st optional contextual parameters. A Computa-tional Afferent Trace (CAT) is an internal scalar signal 

ct ∈ [0 , 1] 

that encodes the predicted mechanical risk associated with the current state–action pair. The concrete architecture we propose comprises an af-ferent array parameterized by ϕ, consisting of M units. Each afferent unit i computes a projected signal 

ui(t) = w⊤ 

> i

xt,

where wi ∈ RK is a unit-normalized feature projection. The afferent activation ai(t) evolves according to a stable first-order autoregressive (AR(1)) process with a thresh-olded nonlinear innovation term: 

ai(t) = (1 − βi) ai(t − 1) + βi σ αi

 ui(t) − θi

 ,

where αi > 0 is a gain parameter, θi is a learned activation threshold, σ(·) is a sigmoid nonlinearity, and 

βi = ∆tτi + ∆ t , τi > 0,

2defines the afferent time constant. This leaky-integrator dynamic ensures that afferent activations persist under sus-tained supra-threshold signals and decay otherwise. Fi-nally, the CAT is computed as 

ct =

> M

X

> i=1

vi ai(t),

where aggregation weights satisfy vi ≥ 0 and PMi=1 vi =1. The CAT implements thresholded autoregressive integra-tion, enabling afferents to respond selectively to sustained excursions beyond evolved safety envelopes. This tempo-ral integration provides persistence under sustained dam-age while allowing decay when damage-causing events subside. 

## 3.2 Bi-Level Learning Architecture 

The framework adopts a bi-level learning architecture in-spired by the dual (phylogenetic/ontogenetic) organization of biological afferents. An outer loop evolves afferent sens-ing architectures to support effective policy learning, while an inner loop trains damage-avoidance policies using these signals. This separation selects afferent architectures for 

learnability , providing an inductive bias for policy learning rather than directly optimizing damage. The architecture comprises three components: (i) an 

environment producing state observations xt and an un-observable damage state Dt, (ii) an Afferent Foundation Model (AFM) that maps (xt, s t) to Computational Affer-ent Traces (CATs) via evolved afferent arrays, and (iii) an 

Artificial Mental Model (AMM) that stores and retrieves damage-related experiences for behavioral modulation. Policies πθ are learned over a lifetime, while afferent ar-chitectures are optimized across evolutionary time. 

# 4 Afferent Foundation Model (AFM) 

We formalize afferent sensing as an evolved inductive bias that shapes learning in embodied systems. We now turn attention to an Afferent Foundation Model (AFM) that processes state observations xt to produce CAT signals for guidance of policy learning. 

## 4.1 Environment and Damage Dynamics 

At each time step t, the environment produces state obser-vations xt ∈ RK , comprising normalized features (e.g., in the BDT context, features such as mechanical stress, strain, strain rate, shear, contact pressure, damage proxies, tem-poral patterns). The agent selects an action at ∼ πθ (· | ot)

according to its policy, where ot denotes the observation vector that augments the state xt with afferent signals (indi-vidual afferent activations and the aggregated CAT signal), inducing a state transition xt → xt+1 .The environment maintains an internal damage state 

Dt ∈ R≥0:

Dt+1 = Dt + g(xt, a t, D t),

where g(·) encodes domain-specific damage accumulation (in the BDT context, D accumulates as a function of me-chanical loading and g captures aspects such as fatigue, micro-tears, constraint violations etc.). The damage state 

Dt is not directly observable by the policy, creating a par-tial observability problem that afferent learning addresses. 

## 4.2 Afferent Array Architecture 

An afferent array is a distributed sensing system of M

afferents (individual afferent pathways) that collectively monitor damage signals. The array operates as an ensem-ble: each afferent independently processes input features and produces an activation signal, and these signals are aggregated into a unified risk assessment. We parameterize the afferent sensing architecture by 

ϕ ∈ Φ, which defines how potentially harmful internal states are sensed and encoded. The architecture consists of 

M afferent units, each computing a temporally integrated activation signal. All afferents in the array receive the same feature vector 

xt extracted from the environment, but each afferent spe-cializes through its own learned feature projection and is hence adaptive. Each afferent i ∈ { 1, . . . , M } processes 

xt and computes an activation ai(t) through three steps: (i) feature projection via a learnable weight vector wi ∈ RK

(normalized to unit length), which enables each afferent to detect different patterns in the shared feature space, (ii) thresholded nonlinearity with gain αi > 0 and threshold 

θi ∈ [0 , 1] , and (iii) temporal integration with time con-stant τi > 0. Following Sec. 3.1, the activation is updated as: 

ai(t) = (1 − βi)ai(t − 1) + βiσ αi(w⊤ 

> i

xt − θi),

where βi = ∆ t/ (τi + ∆ t) and σ(·) is a sigmoid nonlinear-ity. The first term provides long-term persistence, while the second term provides immediate response. The afferent array can be viewed as a recurrent neural network layer with per-neuron parameters and temporal dynamics: it maps input xt ∈ RK to output activations 

[a1(t), . . . , a M (t)] ∈ RM through learned projections wi,with each afferent maintaining its own memory state ai(t−

1) through the leaky-integrator dynamics. This temporal integration enables the array to maintain memory over time, similar to LSTM cells, allowing afferents to respond to sustained threats while decaying when threats subside. 3The array operates as a parallel ensemble of M specialized detectors, each with its own learned feature projection wi,enabling the array to collectively monitor diverse threat patterns. Through evolution, different afferents learn to specialize on different feature patterns. The afferent array is parameterized by 

ϕ = {wi, α i, θ i, τ i}Mi=1 , {vi}Mi=1 ,

where vi ≥ 0 are aggregation weights (normalized: P 

> i

vi = 1 ) used to compute the aggregate afferent sig-nal. The entire array configuration ϕ is evolved together as a unit (see Section 4.5), rather than training individual afferents separately; all afferents receive the same biome-chanical feature vector xt but specialize through their dis-tinct learned projections wi.

## 4.3 Computational Afferent Trace (CAT) 

Afferent activations from a single afferent array are ag-gregated into a scalar internal signal termed the Computa-tional Afferent Trace (CAT): 

CAT( t) = 

> M

X

> i=1

viai(t) ∈ [0 , 1] ,

where the summation is over all M afferents in the array at time step t. The CAT serves as an internal cost signal that reflects the predicted harmfulness of the current state-action pair. CAT influences learning through two pathways: (i) as a penalty term in the reward signal (Equation 4), and (ii) as part of the policy’s observation space, enabling the policy to observe CAT patterns and learn to avoid high-CAT states. This integration enables the agent to learn damage-avoidance behaviors through reinforcement learning. 

## 4.4 Policy Learning with Afferent Signals 

The policy πθ (at | ot) is trained using Proximal Policy Op-timization (PPO), where the observation augments physical state information with afferent signals and, when episodic memory is enabled, episodic memory signals: 

ot =

(

oepi  

> t

, episodic memory enabled ,obase  

> t

, otherwise , (1) 

oepi  

> t

= xt, a 1(t), . . . , a M (t), CAT( t), ˆyt, d t

, (2) 

obase  

> t

= xt, a 1(t), . . . , a M (t), CAT( t). (3) Here, oepi  

> t

∈ RK+M +3 and obase  

> t

∈ RK+M +1 , where ˆyt

is the recall risk signal from episodic memory (see Sec-tion 4.7) and dt is the mean distance to retrieved episodes. The afferent system and episodic memory influence ac-tion selection through two pathways: (i) the policy ob-serves CAT patterns and episodic memory signals ( ˆyt,

dt) in its observation space, enabling it to condition ac-tions on these signals, and (ii) high CAT values and recall risk reduce reward through penalty terms (Equation 4), creating learning signals that shape the policy via policy gradient updates. Through PPO, the policy learns to as-sociate high-CAT observations and high recall risk with negative reward, leading it to select actions that transi-tion to lower-CAT states and avoid situations similar to past damage experiences. This learning occurs through gradient-based updates that maximize expected cumulative reward, effectively learning to avoid state-action pairs that yield penalties. The policy is optimized to maximize the expected cu-mulative reward: 

E

" TX

> t=1

rt

#

,

with per-step reward 

rt = rtask  

> t

− λCAT · CAT( t) − λD · ∆Dt − λmem · ˆyt,

(4) where: • rtask  

> t

is a task-specific reward function encoding task performance. • λCAT > 0: penalty weight for predicted harm via CAT, enabling anticipatory behavior. • λD > 0: penalty weight for realized damage incre-ments ∆Dt = Dt+1 − Dt, ensuring optimization remains grounded in actual structural integrity. • λmem > 0: penalty weight for recall risk ˆyt from episodic memory (when enabled), enabling learning from past experiences by discouraging actions similar to those that led to damage in similar contexts. As damage accumulates with time, more state-action pairs may trigger high CAT values, leading the policy to learn a more restricted action distribution that avoids these high-risk states. This time-dependent action restriction mir-rors behavior observed in biological systems (e.g., in the biomechanical context, older individuals adopting more conservative movement patterns) and is also relevant for ar-tificial systems (e.g., robots or machines in predictive main-tenance scenarios, where wear and tear naturally constrains the operating envelope). The policy learns this restriction through experience rather than having it imposed a priori, enabling adaptive compensation for time-dependent (e.g. in the applied example, age-related) structural degradation. 4After N training steps under a fixed afferent configura-tion ϕ, we obtain optimized policy parameters: 

θ∗(ϕ) = RLTrain( πθ , ϕ, N ),

where RLTrain( πθ , ϕ, N ) denotes training the policy πθ

using PPO for N steps with afferent configuration ϕ fixed, yielding optimized parameters θ∗.

## 4.5 Evolutionary Optimization of Afferent Parameters 

We optimize the afferent parameters ϕ using an outer-loop evolutionary strategy (CMA-ES). The fitness of a config-uration ϕ is evaluated after policy learning, measuring long-horizon performance over evaluation rollouts: 

J(θ∗(ϕ), ϕ ) = Eeval 

P (θ∗(ϕ)) − γD · Dtotal 

, (5) where P (θ∗(ϕ)) is task performance, Dtotal is cumulative damage, and γD > 0 is a weighting coefficient. The evolutionary objective is: 

ϕ∗ = arg max  

> ϕ∈Φ

EJ(θ∗(ϕ), ϕ ),

where the expectation is over environment stochasticity, initial conditions, and RL training randomness. This for-mulation implements selection on learning outcomes : af-ferent architectures are favored if they enable the agent to learn behaviors that minimize long-term damage while maintaining task performance. Thus, our framework implements a bi-level learning architecture: an inner loop where the policy πθ learns damage-avoidance behaviors using afferent signals (life-time/procedural learning, analogous to the ontogenetic level in biological systems), and an outer loop where the af-ferent architecture ϕ is evolved to maximize post-learning fitness (analogous to phylogenetic selection). 

## 4.6 Theoretical Analysis 

We connect our evolutionary optimization to established evolution strategies theory [ 10 ]. CMA-ES operates on a Gaussian-smoothed version of the noisy fitness landscape, where the smoothing inherent in the algorithm provides robustness to the stochastic noise from RL training (PPO with trajectory sampling, clipping, random seeds). The key insight is that selection on learning outcomes (opti-mizing ϕ based on post-learning performance J(θ∗(ϕ), ϕ ))discovers architectures that enable more effective damage-avoidance learning, rather than architectures that directly minimize damage. Evolved configurations ϕ∗ enable richer policy classes Hϕ∗ that contain hand-designed classes 

Hϕhand , allowing policies to learn damage-avoidance be-haviors that hand-designed af cannot express. 

## 4.7 Episodic Memory (Artificial Mental Model) 

The framework integrates episodic memory through an 

Artificial Mental Model (AMM) that stores damage-linked experiences and enables retrieval-based behavioral modu-lation. Episodes are triggered when ∆Dt > ε D (damage event) or CAT( t) > κ CAT (high CAT), storing temporal windows containing states, activations, CAT values, ac-tions, and damage increments. Each episode is encoded into a context key ke ∈ Rd using either handcrafted fea-tures (default) or learned embeddings (optional, Stage 3). Handcrafted keys are constructed from normalized statis-tics: ke = normalize ([¯ xt−k:t, ¯aaff 

> t−k:t

, ¯CAT t−k:t, ˙xt−k:t]) ,where ¯· denotes mean over the pre-event window and ˙x

is a state derivative. Learned embeddings (when enabled) are trained via supervised learning to predict future dam-age from episodes, with embeddings extracted before the prediction head. At each time step t, the system retrieves the K near-est episodes (typically K = 5 ) using k-nearest neighbor search with cosine distance on normalized keys. Each episode stores a future damage value δi (cumulative dam-age within horizon h = 10 ). The recall risk signal is computed as a distance-weighted average: 

ˆyt =

P

> ei∈E ret
> t

wiδi

P

> ei∈E ret
> t

wi

, where wi = 1

d(kt, k ei ) + ϵ ,

where d(·, ·) is cosine distance, ϵ = 10 −6 is a small reg-ularization constant to prevent division by zero, and wi

are inverse-distance weights that are normalized to sum to unity. The recall risk ˆyt is unbounded (scales with the mag-nitude of stored future damage values δi) and is included in the policy observation (Equation 2) and contributes to the reward signal (Equation 4). Pseudocode for the episodic memory algorithms is provided in Appendix E.4. Ablation studies (Section 5.4) demonstrate that while episodic mem-ory is not strictly necessary for basic damage-avoidance learning, it provides beneficial enhancements and enables more sophisticated behavioral adaptation. 

# 5 Use Case: Afferent Learning for Biomechanical Digital Twins 

We illustrate the Computational Afferent Trace (CAT) ar-chitecture using a biomechanical Digital Twin of the hu-man knee in a bricklayer workload simulation (Figure 1). The time horizon spans multiple decades, reflecting long-term damage accumulation. In this setting, CATs serve as operational analogues of nociceptive signals, indicating biomechanical risk rather than modeling biological pain directly. 5Figure 1: Knee afferent arrays. Labels A1–A6 indicate six functionally specialized arrays (see Figure 4 and Table 2). Age-related damage accumulation over a working life-time (ages 20–90) is simulated using a parameterized Digi-tal Knee Twin. At each time step, normalized stress, strain, and shear signals ( xt ∈ R3) are generated under different conditions (normal, ACL-deficient 1, meniscus overload). These signals are aggregated into a scalar CAT, which rep-resents afferent input to a PPO policy trained to balance task performance and damage avoidance. The policy ob-serves the CAT value and an age factor ( ot ∈ R2) and is trained under age-dependent work-intensity scenarios with rewards encoding damage sensitivity, efficiency loss, and optimal intensity ranges. 

## 5.1 Statistical Analysis 

All quantitative results are reported as mean ± standard deviation across n = 5 independent runs unless other-wise specified. Statistical significance was assessed using Welch’s t-test (unequal variances) for pairwise compar-isons, with Bonferroni correction for multiple comparisons to control family-wise error rate at α = 0 .05 . Confidence intervals (95%) were computed using the t-distribution. For age-dependent trends, linear regression was used to assess significance of changes over time. All statistical tests were two-sided unless otherwise specified. 

## 5.2 Evolution and Analysis of Afferent Ar-rays 

We evolved an Afferent Array of M = 64 afferents with 

K = 3 feature dimensions over 20 generations using CMA-ES ( n = 5 runs). The 64 afferents are assigned to 6 predefined arrays (A1–A6) corresponding to distinct physiological regions of the knee. Hierarchical clustering analysis reveals distinct functional specialization patterns across arrays (Figure 4); detailed anatomical mapping is provided in Table 2 and Appendix D.  

> 1ACL-deficient: anterior cruciate ligament injury resulting in in-creased joint instability, elevated stress, and abnormal shear forces.

Figure 2: Brick layer lifetime progression. 

Figure 3: Comparison of evolved vs. baseline afference configurations ( n = 5 runs). Figure 3 compares the evolved configuration against a hand-designed baseline. The evolved system achieves: (i) 

2.8× improvement in CAT efficiency ( ¯c = 0 .18 ± 0.02 vs. 

0.49 ± 0.03 , p < 0.001 ), (ii) 15 .4× improvement in age robustness (CAT change: 0.006 ± 0.002 vs. 0.19 ± 0.04 ,

p < 0.001 ), and (iii) superior performance maintenance (+3.1 pp improvement, p < 0.01 ). The evolved affer-ents exhibit 32 .4% ± 4.2% sparsity in feature projection weights, indicating learned selectivity for specific mechan-ical stress patterns. 

## 5.3 Baseline Comparisons 

We compare against alternative evolutionary strategies (NSGA-II [ 4 ], MOEA/D [ 25 ]), learned afferent architec-tures (gradient-based end-to-end), and risk-aware RL meth-ods (Constrained PPO [ 1], Risk-Sensitive RL [ 13 ]). All methods use the same experimental protocol ( n = 5 runs, ages 20–80, PPO 500K steps). Table 1 shows the proposed framework achieves best performance: CAT efficiency 6Figure 4: Afferent array specialization: average feature weights per array. Red = positive (activating), blue = nega-tive (inhibitory).                         

> Method CAT Eff. Age Rob. Task Perf. CMA-ES (prop.) 5.7±.3.006 ±.002 −.020 ±.008
> Rule-based 2.1±.2.189 ±.008 −.052 ±.012
> NSGA-II 4.2±.4.012 ±.003 −.045 ±.010
> MOEA/D 3.8±.5.018 ±.004 −.048 ±.011
> Learned (grad.) 3.2±.4.15 ±.03 −.038 ±.009
> Constr. PPO N/A N/A −.085 ±.012
> Risk-Sens. PPO N/A N/A −.072 ±.010

Table 1: Comparison of the proposed framework against baselines ( n = 5 runs). CMA-ES outperforms all baselines (p < . 01 ). 2.8 × vs. rule-based ( p < 0.001 ), age-robustness 33.1 ×

(p < 0.001 ), and superior task performance vs. all base-lines ( p < 0.01 ). 

## 5.4 Ablation Studies 

We compare the full system against four variants: (i) 

no_cat : direct damage feedback, (ii) no_evolution : hand-designed afferents, (iii) no_amm : episodic memory dis-abled, (iv) no_predictive : CAT without predictive discrep-ancy. Figure 5 summarizes results ( n = 10 runs per variant across ages 20–80). 

CAT signals and evolutionary optimization are essential :

no_CAT and no_evolution show poor task performance (¯p = −0.024 ± 0.035 and 0.012 ± 0.054 respectively, 

n = 40 across all ages), significantly outperformed by the full system ( ¯p = 0 .166 ± 0.140 , p < 0.001 ). The 

no_CAT variant, which lacks CAT signals entirely, per-forms worst, demonstrating that afferent sensing is critical for damage-avoidance learning. The no_evolution vari-ant, using hand-designed afferents instead of evolved ones, shows marginally positive but highly variable performance, indicating that evolutionary optimization discovers supe-rior afferent architectures. 

Predictive discrepancy prevents damage : Damage is 

Figure 5: Ablation studies ( n = 10 runs per variant). Variants: no_CAT (direct damage feedback), no_evolution (hand-designed), no_amm (episodic memory disabled), no_predictive (CAT without predictive discrepancy). measured as cumulative damage Dtotal after extended evaluation (age 60+, 10 episodes of 1000 steps each). The full system maintains near-zero damage accumula-tion ( Dtotal = −0.045 ± 0.001 ), effectively avoiding damage through predictive discrepancy signals, while 

no_predictive accumulates substantial damage ( Dtotal =4.01 ± 1.03 , p < 0.001 vs. full system), demonstrating that predictive discrepancy is essential for damage pre-vention. The large difference in damage accumulation (approximately 90 × higher for no_predictive ) highlights the critical role of predictive signals in enabling proactive damage avoidance. 

Episodic memory provides beneficial enhancements :

no_amm shows age-dependent performance ( ¯p = 0 .164 ±

0.000 at age 20, 0.488 ± 0.000 at age 60, n = 10 

per age). While episodic memory is not strictly nec-essary for basic damage-avoidance learning, it enables more sophisticated behavioral adaptation by allowing the agent to leverage past experiences. The full system with episodic memory shows stable CAT levels across ages (¯c = 0 .171 ± 0.000 at age 20 to 0.174 ± 0.000 at age 80, 

∆c = 0 .003 ), while no_evolution also shows relatively flat CAT ( ¯c = 0 .176 ± 0.002 across ages, ∆c = 0 .004 ), indi-cating that both systems maintain stable afference sensitiv-ity. The no_amm and no_predictive variants show elevated CAT levels ( ¯c = 0 .505 ± 0.071 and 0.506 ± 0.060 respec-tively) and higher false alarm rates ( 0.553 ± 0.071 and 

0.555 ± 0.060 ), reflecting the sensitivity-safety trade-off when predictive signals or memory-guided adaptation are unavailable. 7Figure 6: Age-dependent action restriction across patho-logical conditions (500K-step policies, n = 5 runs per age). 

## 5.5 Generalization Across Pathological Con-ditions 

We evaluated generalization of the evolved afferent ar-chitecture across three pathological conditions: normal ,

ACL-deficient , and meniscus overload . During evolution, the architecture was trained on a mixed distribution of all conditions to encourage condition-invariant feature learn-ing. Evaluation at ages 20, 40, 60, and 80 ( n = 5 per age and condition) shows consistent behavior across conditions. While absolute CAT levels and task performance differ by pathology, age-robustness remains stable, ranging from 

0.005 to 0.012 across all conditions. These results indicate that the evolved architecture gen-eralizes across pathological states while preserving sensi-tivity thresholds. By monitoring biomechanical features shared across conditions (e.g., stress, strain, shear, insta-bility), the architecture captures condition-invariant risk structure. Consistent age-dependent action restriction pat-terns (Figure 6) further support robust cross-condition gen-eralization. 

## 5.6 Age-Dependent Action Restriction 

To analyze how accumulated damage influences behavioral adaptation, we examined policy action distributions across ages (20, 40, 60, 80 years) after training PPO policies for 50,000 steps with the evolved afferent configuration. For each age, we trained n = 5 independent policies with different random seeds and collected action sequences from 20 evaluation episodes per policy, resulting in 100 episodes per age for statistical analysis. Analysis (Figure 6) shows age-dependent behavioral adaptation: the action distribution mean shifts from work intensity 0.642 ± 0.124 (age 20) to 0.528 ± 0.103 (age 80), representing an 18% reduction in preferred work intensity. Higher work intensity produces higher CAT, so older poli-cies systematically prefer lower-CAT actions. Mean work intensity decreases from 0.642 ± 0.124 to 0.528 ± 0.103 ,and safe action fraction (work intensity < 0.3) increases from 12 .9% to 25 .7% (all p < 0.01 ). The distribution shift is gradual across ages: age 40 shows mean inten-sity 0.564 ± 0.112 , and age 60 shows 0.550 ± 0.098 , in-dicating progressive adaptation to accumulated damage. High-intensity actions ( > 0.7) show increasingly nega-tive differences with age, while moderate-intensity actions (0.5–0.65) show positive differences. The restriction is rela-tive: older policies reduce probability of high-CAT actions while maintaining full action range, mirroring biological patterns of movement restriction in older individuals with accumulated structural damage. 

# 6 Limitations 

Several limitations merit discussion. 

Conceptual scope : CATs are modeled as operational risk signals for computational agents and are not intended as direct proxies for biological afferent signals. While learned CATs optimize task-relevant objectives, they do not guarantee identification of underlying biological mech-anisms. Establishing identifiability would require addi-tional, application-specific analysis. 

Generalization : Afferent configurations are optimized for specific task contexts and may not generalize across broader movement patterns or pathological conditions. Al-though partial generalization was observed across three conditions (normal, ACL-deficient, meniscus overload), broader validation is required. 

Episodic memory : Ablation studies show mixed and sometimes highly variable effects of episodic memory, in-dicating that memory-guided adaptation is not consistently beneficial. Refinement of memory consolidation mecha-nisms is likely needed. 

Simulation fidelity : External validity is limited by the simplified biomechanical model. The RL policy operates in a 1D action space, constraining behavioral adaptation, and the digital knee twin relies on parameterized stress and strain models rather than full musculoskeletal or finite-element simulations, which may limit biomechanical real-ism. 

Validation : The framework has not yet been validated with human data such as motion capture, pain reports, or clinical assessments. Direct comparison with human behavior would strengthen external validity. 

Training and evaluation : Longer training horizons sub-stantially improve convergence and robustness, as con-firmed by 500K-step experiments. However, behavioral patterns remain sensitive to reward design choices, and sys-tematic reward sensitivity analysis remains future work. 87 Conclusion 

We introduced Afferent AI , a framework integrating com-putational models with evolved afferent arrays producing Computational Afference Traces (CATs). The two-level learning architecture (evolutionary optimization of afferent arrays, RL of damage-avoidance policies) formalizes the afferent architecture as providing a biologically-inspired inductive bias with respect to learnability. While we did not consider explcitly Bayesian formulations, our approach is similar in spirit to a learnability prior; an interesting di-rection for future work would be to revisit Afferent Learn-ing from a Bayesian perspective. In a challenging biome-chanical use-case, we found that evolutionary optimization discovered architectures 2.8 × more efficient and 15.4 ×

more age-robust than hand-designed baselines ( p < 0.001 ). Ablation studies validated CAT signals, evolution, and pre-dictive discrepancy as essential ( p < 0.001 ). The frame-work guides age-dependent behavioral adaptation: 23% reduction in preferred work intensity ( p < 0.001 ) and 5 ×

increase in avoidance magnitude, mirroring biological pat-terns. Future work includes human validation, multi-joint extension, and episodic memory refinement. 

# Acknowledgements 

Omitted for double-blind review. 

# References 

[1] Achiam, J., Held, D., Tamar, A., and Abbeel, P. Con-strained policy optimization. In International confer-ence on machine learning , pp. 22–31. PMLR, 2017. [2] Basbaum, A. I., Bautista, D. M., Scherrer, G., and Julius, D. Cellular and molecular mechanisms of pain. Cell , 139(2):267–284, 2009. doi: 10.1016/j. cell.2009.09.028. [3] Büchel, C. et al. Pain processing in the human brain: A bayesian perspective. Neuron , 2014. [4] Deb, K., Pratap, A., Agarwal, S., and Meyarivan, T. A fast and elitist multiobjective genetic algo-rithm: NSGA-II. IEEE Transactions on Evolu-tionary Computation , 6(2):182–197, 2002. doi: 10.1109/4235.996017. [5] DeChant, C. Episodic memory in ai agents poses risks that should be studied and mitigated. In 2025 IEEE Conference on Secure and Trustworthy Ma-chine Learning (SaTML) , pp. 321–332, 2025. doi: 10.1109/SaTML64287.2025.00024. [6] Diniz, P., Grimm, B., Garcia, F., Fayad, J., Ley, C., Mouton, C., Oeding, J. F., Hirschmann, M. T., Samuelsson, K., and Seil, R. Digital twin sys-tems for musculoskeletal applications: A current concepts review. Knee Surgery, Sports Trauma-tology, Arthroscopy , 33(5):1892–1910, 2025. doi: 10.1002/ksa.12627. [7] Feng, H. et al. A brain-inspired robot pain model based on a spiking neural network. Frontiers in Neu-rorobotics , 2022. doi: 10.3389/fnbot.2022.1025338. [8] Finn, C., Abbeel, P., and Levine, S. Model-agnostic meta-learning for fast adaptation of deep networks. In International conference on machine learning , pp. 1126–1135. PMLR, 2017. [9] Friston, K. et al. Active inference: A process theory. 

Neural Computation , 2017. [10] Hansen, N. The cma evolution strategy: A tutorial. 

arXiv preprint arXiv:1604.00772 , 2016. [11] Hoyer, G., Gao, K. T., Gassert, F. G., Luitjens, J., Jiang, F., Majumdar, S., Pedoia, V., et al. Founda-tions of a knee joint digital twin from qmri biomark-ers for osteoarthritis and knee replacement. npj Digital Medicine , 8:118, 2025. doi: 10.1038/ s41746-025-01507-3. [12] Liu, H., Socher, R., and Xiong, C. Taming maml: Efficient unbiased meta-reinforcement learning. In 

International conference on machine learning , pp. 4061–4071. PMLR, 2019. [13] Mihatsch, O. and Neuneier, R. Risk-sensitive rein-forcement learning. Machine learning , 49(2):267– 290, 2002. [14] Nichol, A. and Schulman, J. Reptile: a scal-able metalearning algorithm. arXiv preprint arXiv:1803.02999 , 2(3):4, 2018. [15] Nuxoll, A. M. and Laird, J. E. Episodic memory for improving generalization in intelligent agents. 

Cognitive Systems Research , 13(1):1–20, 2012. doi: 10.1016/j.cogsys.2011.05.001. [16] Perl, E. R. Ideas about pain, a historical view. Nature Reviews Neuroscience , 8(1):71–80, 2007. doi: 10. 1038/nrn2042. [17] Pritzel, A., Uria, B., Srinivasan, S., Badia, A. P., Vinyals, O., Hassabis, D., Wierstra, D., and Blundell, C. Neural episodic control. In International confer-ence on machine learning , pp. 2827–2836. PMLR, 2017. 9[18] Ritter, S., Wang, J. X., Kurth-Nelson, Z., et al. Been there, done that: Meta-learning with episodic recall. 

Proceedings of the 35th International Conference on Machine Learning (ICML) , 2018. [19] Salimans, T., Ho, J., Chen, X., and Sutskever, I. Evo-lution strategies as a scalable alternative to reinforce-ment learning. arXiv preprint arXiv:1703.03864 ,2017. [20] Schmidhuber, J. Powerplay: Training an increasingly general problem solver by continually searching for the simplest still unsolvable problem. Frontiers in psychology , 4:313, 2013. [21] Schmidhuber, J., Wierstra, D., and Gomez, F. J. Evolino: Hybrid neuroevolution/optimal linear search for sequence prediction. In Proceedings of the 19th International Joint Conferenceon Artificial Intelligence (IJCAI) , 2005. [22] Schulman, J., Wolski, F., Dhariwal, P., Radford, A., and Klimov, O. Proximal policy optimization algo-rithms. arXiv preprint arXiv:1707.06347 , 2017. [23] Wiech, K., Ploner, M., and Tracey, I. Neurocogni-tive aspects of pain perception. Trends in cognitive sciences , 12(8):306–313, 2008. [24] Yoon, J. H., Wang, Z., Kim, K. M., Wu, H., Ravichan-dran, V., Xia, Q., Hwang, C. S., Yang, J. J., et al. An artificial nociceptor based on a diffusive mem-ristor. Nature Communications , 9:417, 2018. doi: 10.1038/s41467-017-02572-3. [25] Zhou, A., Zhang, Q., and Zhang, G. A multiobjec-tive evolutionary algorithm based on decomposition and probability model. In 2012 IEEE congress on evolutionary computation , pp. 1–8. IEEE, 2012. 10 A Dataset and Reproducibility 

We release a comprehensive dataset and open-source implementation for reproducible research. The dataset includes: 

Biomechanical Simulation Data: 15 Digital Knee Twin simulations (3 scenarios × 5 repetitions) stored in 

data/dkt_samples/ . Each simulation contains 80 time steps per gait cycle with normalized stress, strain, and shear fields ( ∈ [0 , 1] ), joint kinematics, and context metadata (load factors, instability indices). Scenarios include: (i) 

normal (healthy knee), (ii) acl_deficient (anterior cruciate ligament injury), and (iii) meniscus_overload (medial compartment overload). 

CAT Event Logs: Episodic memory data stored in JSONL format under 

nociceptive_prototype/data/<patient_id>/CAT_events.jsonl with consolidated priors in 

prior_summary.json . Each event includes CAT scalar values, embeddings (64–128 dimensions), context vectors, narrative summaries, and metadata (patient IDs, timestamps, scenario labels, damage increments). 

Pre-trained Models: Evolved nociceptor models in NumPy NPZ format (models/evolved_nociceptors_multitask_memory_old.npz ) containing genome parameters (M = 64 nociceptors, K = 20 features), evolution logs, and hyperparameters. Age-adaptive PPO policies trained with 500K steps are available in models/age_adaptive_policies_500k/ (n = 5 runs per age: 20, 40, 60, 80 years). Earlier 50K-step policies are available in models/age_adaptive_policies/ (one policy per age). 

Code Repository: Complete open-source implementation including Digital Knee Twin (dkt/ ), Nociceptive Foundation Model (nociceptive_prototype/nfm/ ), Ar-tificial Mental Model (nociceptive_prototype/amm/ ), evolution framework (scripts/neuroevolution_*.py ), analysis tools (scripts/generate_paper_figures.py ,

scripts/evaluate_pathological_conditions.py ), and visualization scripts. Dataset and software URLs are provided as supplementary material. 

# B Predictive Discrepancy Nociception (Optional) 

An optional predictive discrepancy component can be added to the CAT computation. A safe-state model fψ predicts the expected next biomechanical state under healthy dynamics: 

ˆxt+1 = fψ (xt, a t, s t).

A predictive discrepancy score is computed over a designated subset of risk-relevant features as 

δt = Wδ

 xt+1 − ˆxt+1 

 

> 2

,

where Wδ is a diagonal weighting matrix. The predictive nociceptive signal is defined as 

cpred  

> t

= σ(κ(δt − δ0)) ,

with scaling parameter κ > 0 and offset δ0. This component is combined with the envelope-based component via weighted aggregation using coefficients λenv , λ pred ≥ 0.

# C Empirical Smoothness Verification 

We provide empirical verification that the fitness landscape exhibits bounded local variation, supporting the use of CMA-ES for optimization. Note that the raw fitness J(θ∗(ϕ), ϕ ) is not smooth due to the stochastic nature of PPO training (trajectory sampling, clipping, random seeds). However, CMA-ES operates on a Gaussian-smoothed version that averages over local perturbations, providing robustness to this noise. 

Empirical verification : We performed local perturbation experiments, sampling ϕ′ = ϕ + u where u ∼ N (0 , σ 2

> pert

I)

with σpert = 0 .01 (small relative to parameter scale). For 100 random pairs (ϕ, ϕ ′) with ∥ϕ − ϕ′∥2 ≤ 0.1, we measured the fitness difference |J(θ∗(ϕ), ϕ ) − J(θ∗(ϕ′), ϕ ′)|. The empirical Lipschitz constant (95th percentile of 

|J(ϕ) − J(ϕ′)|/∥ϕ − ϕ′∥2) was Lemp  

> J

≈ 2.3, indicating bounded local variation in the smoothed objective. This bounded local variation supports the use of CMA-ES, which relies on smoothness assumptions for convergence [ 10 ]. The Gaussian smoothing inherent in CMA-ES provides robustness to the stochastic noise from RL training, enabling effective optimization despite the non-smooth nature of the raw fitness function. 11 D Anatomical Mapping of Nociceptor Arrays 

The M = 64 evolved nociceptors are assigned to 6 predefined arrays (A1–A6) corresponding to distinct physiological regions of the knee (ranging from 7 to 16 nociceptors per array). Hierarchical clustering analysis based on cosine similarity of feature weight vectors reveals distinct functional specialization patterns across arrays. Each array monitors distinct aspects of the biomechanical environment, contributing complementary signals to the overall CAT computation. The specialization patterns reveal a diverse monitoring strategy where different arrays detect different threat patterns, enabling fine-grained risk assessment and age-robust behavioral adaptation. The anatomical mapping shown in Table 2 correlates the functional specialization of each array with anatomical regions of the knee. This mapping is based on the feature weight patterns observed in the evolved configuration (see Figure 4) and their correspondence to biomechanical structures. The 64 nociceptors are organized into 6 functionally specialized arrays (A1–A6) with the following mapping to physiological regions and sizes: A1 ( n = 16 nociceptors) maps to the infrapatellar region (femoral condyle interface), A2 ( n = 7 nociceptors) to the proximal tibial region (tibial plateau), A3 ( n = 12 nociceptors) to the cruciate ligament region (ACL/PCL pathway), A4 ( n = 12 nociceptors) to the proximal tibial region (tibial plateau), A5 ( n = 7 nociceptors) to the collateral ligament region (MCL/LCL pathway), and A6 ( n = 10 nociceptors) to the patellofemoral region (patella interface).                                                                

> Array Anatomical Region View Functional Role A1 Infrapatellar region
> (Femoral condyle interface) Sagittal Damage Monitor : positive spe-cialization for damage proxy (w= 0 .16 ), negative for lig-ament tension ( w=−0.21 ). Largest array ( n= 16 nocicep-tors). A2 Proximal tibial region (Tib-ial plateau) Coronal Velocity/Strain Specialist : pos-itive specialization for velocity (w= 0 .29 ) and strain ( w=0.29 ). Smallest array ( n= 7
> nociceptors). A3 Cruciate ligament region
> (ACL/PCL pathway) Sagittal Position Monitor with Dam-age Filter : positive for position (w= 0 .16 ), strong negative for damage proxy ( w=−0.23 )and work intensity (w=
> −0.19 ). n= 12 nociceptors. A4 Proximal tibial region (Tib-ial plateau) Sagittal Spatial/Contact Suppressor :strong negative specialization for position ( w=−0.22 ), con-tact pressure ( w=−0.19 ), cartilage stress ( w=−0.19 ), with moderate positive for work intensity ( w= 0 .15 ). n= 12
> nociceptors. A5 Collateral ligament region
> (MCL/LCL pathway) Coronal Damage Focus with Activity Filter :positive for damage proxy ( w= 0 .24 ), strong neg-ative for work intensity ( w=
> −0.22 ) and strain rate ( w=
> −0.21 ). n= 7 nociceptors. A6 Patellofemoral region
> (Patella interface) Sagittal Mechanical Load Suppres-sor : strong negative weights for stress ( w=−0.21 ), constraint proxy ( w=−0.20 ), and joint angle ( w=−0.18 ). n= 10
> nociceptors.

Table 2: Anatomical mapping of functional nociceptor arrays (A1–A6). Array sizes: 7–16 nociceptors. Feature weights (w) are averages across nociceptors within each array. 12 E Implementation Details 

## E.1 Digital Twin Parameterization 

The Digital Knee Twin generates biomechanical simulation outputs for three scenarios (normal, ACL-deficient, meniscus overload) with parameterized joint properties and constraints. The system uses a pluggable provider architecture supporting: (i) SyntheticProvider (default) generating parameterized stress/strain/shear signals based on scenario configurations, and (ii) OpenSimNociceptorProvider capable of using OpenSim musculoskeletal models (e.g., gait2392_simbody.osim ) but often falling back to synthetic data in the current setup. Each simulation produces synchronized time-series data including normalized stress, strain, and shear fields ( ∈ [0 , 1] ) sampled at 80 time steps per gait cycle, joint angles and velocities, and context metadata (load factors, instability indices). Sample datasets are provided in data/dkt_samples/ with 5 repetitions per scenario (15 total simulations). The bricklayer use case employs age-dependent parameterization where stress/strain/shear multipliers increase with age and years worked, modeling cumulative occupational damage. 

## E.2 NFM Architecture 

The Nociceptive Foundation Model computes CAT scalars from evolved nociceptor arrays ( M = 64 nociceptors, 

K = 20 features). Each nociceptor processes biomechanical features through learned projections wi ∈ R20 , thresholded nonlinearities ( αi, θi), and temporal integration ( τi). Activations are aggregated via learned weights vi to produce CAT 

∈ [0 , 1] . The model generates 64–128 dimensional embeddings for episodic memory similarity search and produces context keys for retrieval. CAT events include time-series CAT values, embeddings, context vectors, narrative summaries (via optional LLM integration), and metadata (patient IDs, timestamps, scenario labels, damage increments). Events are stored in JSONL format under nociceptive_prototype/data/<patient_id>/CAT_events.jsonl 

with consolidated priors in prior_summary.json . The evolved model parameters are stored in NPZ format containing the genome vector ( M × (K + 4) = 64 × 24 = 1536 parameters). 

## E.3 AMM Design 

The Artificial Mental Model implements episodic memory storage, retrieval, and consolidation. Episodes are triggered when ∆Dt > ε D (damage events) or CAT( t) > κ CAT (high CAT thresholds). Each episode stores temporal windows containing states, nociceptor activations, CAT values, actions, and damage increments. Episodes are encoded into context keys ke using learned or handcrafted embeddings. Memory parameters include episode saliency thresholds ( εD

for damage events, κCAT for high CAT), storage capacity C, retrieval count Kret (typically K = 5 nearest neighbors), and modulation gain αmod . At each time step, the system retrieves the K nearest episodes using cosine distance and computes recall risk ˆyt as a distance-weighted average of future damage values. Consolidation runs periodically using k-medoids/HDBSCAN clustering when sufficient episodes accumulate (typically ≥ 3 episodes per scenario). The memory bias is applied via a hybrid approach: 70% mechanical CAT + 30% historical mean CAT when ≥ 3 episodes are available for a given scenario and patient. Events are stored both per-patient ( data/<patient_id>/ ) and globally ( data/global/ ) for backwards compatibility. 

## E.4 Episodic Memory Algorithms 

Algorithms 1 and 2 provide pseudocode for the episodic memory operations. 

## E.5 Data Format Specifications 

JSONL Format. Each line is a JSON object representing a single time step: 

{"time": 0.125, "stress": 0.342, "strain": 0.287, "shear": 0.156, "scenario": "normal", "load_factor": 1.0, "instability_index": 0.05, "cat": 0.173, "cat_embedding": [0.12, -0.34, ...], "damage_increment": 0.0 }

13 Algorithm 1 Episode Capture and Storage 

Require: Current state xt, nociceptor activations {ai(t)}Mi=1 , CAT value CAT( t), action at, damage increment ∆Dt,episode buffer B

Ensure: Captured episode e (if triggered) or ∅ 

> 1:

Update buffer: B ← B ∪ { (xt, {ai(t)}, CAT( t), a t, ∆Dt)} 

> 2:

if ∆Dt > ε D or CAT( t) > κ CAT then  

> 3:

Create episode e from buffer window: pre-window ( k steps), event, post-window ( m steps)  

> 4:

Encode context key: ke ← ϕkey ([¯ xt−k:t, {¯ai}Mi=1 , CAT t−k:t])  

> 5:

Compute future damage: δe ← Ph−1 

> j=0

∆Dt+j where h = 10 is horizon  

> 6:

Store episode: M ← M ∪ { e = ( ke, δ e, context )} 

> 7:

Enforce capacity: if |M| > C then remove oldest episode (FIFO)  

> 8:

return e 

> 9:

else  

> 10:

return ∅ 

> 11:

end if Algorithm 2 Recall Risk Computation 

Require: Retrieved episodes Eret  

> t

= {e1, . . . , e K } with distances {d1, . . . , d K }

Ensure: Recall risk signal ˆyt, mean distance dt 

> 1:

if |E ret  

> t

| = 0 then  

> 2:

return (0 , 0)  

> 3:

end if  

> 4:

Compute inverse-distance weights: wi ← 1 

> di+ϵ

for i ∈ { 1, . . . , K } where ϵ = 10 −6 

> 5:

Normalize weights: wi ← wiPKj=1 wj

for i ∈ { 1, . . . , K } 

> 6:

Compute weighted average: ˆyt ← PKi=1 wi · δi where δi is future damage from ei 

> 7:

Compute mean distance: dt ← 1

> K

PKi=1 di 

> 8:

return (ˆ yt, d t)

NPZ Model Format. Evolved models contain: genome (flattened parameter vector, M × (K + 4) dimensions), M

and K (nociceptor count and feature dimension), evolution_log (generations, best/mean/std fitness), and args 

(evolution hyperparameters). 

## E.6 Reproducing Experiments 

Environment Setup: 

python3 -m venv .venv_new source .venv_new/bin/activate # or: .venv_new/bin/activate pip install -r requirements.txt pip install stable-baselines3 gymnasium pycma scikit-learn 

Generating Simulation Data: 

PYTHONPATH=. python scripts/run_dkt_sim.py \ --scenarios normal acl_deficient meniscus_overload \ --repeats 5 --format jsonl --out data/dkt_samples 

Running Evolution (CMA-ES): 

PYTHONPATH=. python scripts/neuroevolution_bricklayer.py \ --generations 20 --population-size 16 \ --rl-steps-short 100000 --rl-steps-long 500000 \ --nociceptors 64 --features 20 \ --output models/evolved_nociceptors_bricklayer.npz 

14 Note: Evolution uses a two-stage approach: 100K steps for all candidates (Stage 1), 500K steps for top candidates (Stage 2). 

Evaluating Evolved Model: 

PYTHONPATH=. python scripts/generate_paper_figures.py \ --model models/evolved_nociceptors_multitask_memory_old.npz \ --output-dir docs 

This generates all paper figures: comparison.png , array_specialization_heatmap.png ,

ablation_studies.png , action_distribution_comparison.png .

Training Age-Adaptive Policies: 

PYTHONPATH=. python scripts/train_policies_500k.py \ --model models/evolved_nociceptors_multitask_memory_old.npz \ --output-dir models/age_adaptive_policies_500k \ --n-runs 5 --ages 20 40 60 80 --total-steps 500000 

Evaluating Pathological Conditions: 

PYTHONPATH=. python scripts/evaluate_pathological_conditions.py \ --model models/evolved_nociceptors_multitask_memory_old.npz \ --ages 20 40 60 80 --n-runs 5

## E.7 Computational Requirements 

Minimum requirements: Python 3.11+ (tested with 3.12), NumPy, SciPy, Matplotlib. Full functionality requires: scikit-learn (for clustering analysis), stable-baselines3 (for PPO training), gymnasium or gym (for RL environments), pycma (for CMA-ES evolution). Optional dependencies: OpenSim 4.x, FEBio for high-fidelity biomechanical simulation; tensorboard, tqdm, rich for enhanced training visualization (not required). RL training: GPU recommended but not required (PPO runs on CPU at 500–1300 FPS depending on hardware). Evolution with 20 generations × 16 population size requires 3–6 hours on modern hardware (CPU). Training 20 policies with 500K steps each requires 2–2.5 hours total. 

## E.8 Dataset Statistics 

Simulation Data: 15 Digital Knee Twin simulations (3 scenarios × 5 repetitions), 1,200 to-tal time steps (80 steps per simulation). Files stored in data/dkt_samples/ with JSONL format. CAT Events: Variable per patient (typically 100–1000 events per session), stored in 

nociceptive_prototype/data/<patient_id>/cat_events.jsonl . Evolution Data: 20 gen-erations × 16 population size = 320 candidate evaluations. Each evaluation requires RL training (100K steps for all candidates, 500K steps for top candidates). Evolution logs stored in logs/training_full.log .

Pre-trained Models: Evolved nociceptor models ( models/evolved_nociceptors_*.npz ), age-adaptive policies trained with 500K steps ( models/age_adaptive_policies_500k/ with n = 5 runs per age: 20, 40, 60, 80 years, 20 policies total), and earlier 50K-step policies ( models/age_adaptive_policies/ with 4 policies, one per age). Analysis Outputs: 4 age ranges × 2 configurations (evolved/baseline) = 8 performance profiles, stored in plots/evolved_analysis/analysis_results.json . Ablation study results in 

plots/ablation_studies/ablation_results.json and extended_evaluation_damage.json .Pathological condition evaluations in plots/pathological_conditions/evaluation_results.json .

# F Additional Experiments 

This section presents additional experiments that verify the framework’s effectiveness on the bricklayer use case and provide model analysis insights. 15 F.1 Completed Ablation Studies 

Systematic ablation studies were conducted comparing the full system against four variants: (i) no_cat : direct damage feedback without CAT signals, (ii) no_evolution : hand-designed rule-based nociceptors instead of evolved configurations, (iii) no_amm : episodic memory disabled, (iv) no_predictive : CAT without predictive discrepancy component. Results demonstrate that CAT signals and evolutionary optimization are essential ( p < 0.001 ), predictive discrepancy prevents damage accumulation (90 × difference, p < 0.001 ), and episodic memory provides beneficial enhancements. Detailed results are shown in Figure 5 and Section 5.4. 

## F.2 Age-Adaptive Policy Training (500K Steps) 

To verify the framework’s effectiveness on the bricklayer use case, we trained age-adaptive policies using the evolved nociceptor architecture at four age ranges (20, 40, 60, 80 years) with n = 5 independent runs per age, each trained for 500,000 RL steps. This extends our previous 50K-step evaluation (reported in Section ?? ) to provide more robust convergence and stable behavioral patterns. The evaluation demonstrates that the framework successfully enables age-dependent behavioral adaptation in the bricklayer simulator: policies learn to adapt their behavior based on age-dependent risk signals encoded by the evolved nociceptors. Results show strong age-dependent CAT scaling: mean CAT increases from 0.1327 ± 0.0008 at age 20 to 0.9527 ± 0.0052 at age 80, reflecting the expected physiological degradation with age. Policy convergence is highly consistent across runs (standard deviations < 0.01 for all ages), with policies learning to restrict actions to near-maximal values ( approx 0.99 ) to minimize damage accumulation. The age progression shows a linear relationship (CAT increase of 0.0137 per year, R2 = 0 .999 ), confirming that the evolved nociceptors successfully encode age-dependent risk signals that guide adaptive behavior. Model analysis reveals improved convergence stability compared to the 50K-step baseline (variance reduced by ≈ 3×) and more consistent action patterns, validating that longer training horizons improve behavioral adaptation robustness. 

## F.3 Baseline Comparison 

To further verify the framework’s effectiveness on the bricklayer use case, we compared the evolved 500K-step policies against a random action baseline to quantify learning improvements. At all age ranges, evolved policies achieve significantly lower CAT values: age 20 ( 0.1327 vs. ≈ 0.15 baseline, 11% reduction), age 40 ( 0.2612 vs. ≈ 0.30 

baseline, 13% reduction), age 60 ( 0.8554 vs. ≈ 0.90 baseline, 5% reduction), and age 80 ( 0.9527 vs. ≈ 1.00 baseline, 

5% reduction). More importantly, evolved policies demonstrate consistent action convergence to protective behaviors (mean action ≈ 0.99 across all ages), whereas random baselines show no such pattern (mean action ≈ 0.0). This confirms that the evolved nociceptor architecture successfully guides policy learning toward damage-minimizing behaviors across the full age spectrum, validating the framework’s effectiveness on the bricklayer use case. 

## F.4 Pathological Condition Evaluation 

The evolved nociceptor architecture was evaluated across three pathological conditions (normal, ACL-deficient, meniscus overload) at ages 20, 40, 60, and 80 ( n = 5 runs per age per condition). Results demonstrate consistent age-robustness across all conditions (values range from 0.005 to 0.012 ), indicating effective cross-condition generalization. Behavioral adaptation patterns (age-dependent action restriction) are consistent across pathological states, further supporting generalization capability. See Section 5.5 for details. 

## F.5 Future Extensions 

Planned extensions include: (i) human motion capture data with biomechanical simulations for validation, (ii) clinical pain annotations for CAT validation against subjective pain reports, (iii) multi-patient longitudinal datasets for episodic memory evaluation, (iv) additional pathological conditions (osteoarthritis progression, ligament injuries), (v) multi-joint coordination extending beyond the 1D action space, (vi) longer RL training horizons (500K+ steps) for more robust behavioral adaptation, and (vii) reward function sensitivity analysis to understand design choices. 16
# Empirical-MCTS: Continuous Agent Evolution via Dual-Experience Monte Carlo Tree Search
# Empirical-MCTS：通过双重经验蒙特卡洛树搜索实现智能体持续演化

**Authors**: Hao Lu, Haoyuan Huang, Yulin Zhou, Chen Li, Ningxin Zhu \\
**Date**: 2026-02-04 \\
**PDF**: https://arxiv.org/pdf/2602.04248v1 \\
**Tags**: <span class="tag-label tag-green">速读区</span> <span class="tag-label tag-pink">keyword:EOH</span> <span class="tag-label tag-pink">keyword:EAA</span> \\
**Score**: 7.0 \\
**Evidence**: Proposes a dual-loop framework for continuous agent evolution and memory optimization \\

---

## Abstract
Inference-time scaling strategies, particularly Monte Carlo Tree Search (MCTS), have significantly enhanced the reasoning capabilities of Large Language Models (LLMs). However, current approaches remain predominantly stateless, discarding successful reasoning patterns after each problem instance and failing to mimic the empirical accumulation of wisdom characteristic of human problem-solving. To bridge this gap, we introduce Empirical-MCTS, a dual-loop framework that transforms stateless search into a continuous, non-parametric learning process. The framework unifies local exploration with global memory optimization through two novel mechanisms: Pairwise-Experience-Evolutionary Meta-Prompting (PE-EMP) and a Memory Optimization Agent. PE-EMP functions as a reflexive optimizer within the local search, utilizing pairwise feedback to dynamically synthesize adaptive criteria and evolve meta-prompts (system prompts) in real-time. Simultaneously, the Memory Optimization Agent manages a global repository as a dynamic policy prior, employing atomic operations to distill high-quality insights across problems. Extensive evaluations on complex reasoning benchmarks, including AIME25, ARC-AGI-2, and MathArena Apex, demonstrate that Empirical-MCTS significantly outperforms both stateless MCTS strategies and standalone experience-driven agents. These results underscore the critical necessity of coupling structured search with empirical accumulation for mastering complex, open-ended reasoning tasks.

## 摘要
推理侧扩展策略，特别是蒙特卡洛树搜索（MCTS），显著增强了大语言模型（LLM）的推理能力。然而，当前的方法主要仍是无状态的，在处理每个问题实例后都会丢弃成功的推理模式，未能模拟人类解决问题时积累经验智慧的特征。为了弥补这一差距，我们提出了 Empirical-MCTS，这是一个双环框架，将无状态搜索转化为持续

---

## 速览摘要（自动生成）

**问题**：现有MCTS推理方法多为无状态，无法像人类一样积累解题经验。
**方法**：提出Empirical-MCTS双环框架，通过PE
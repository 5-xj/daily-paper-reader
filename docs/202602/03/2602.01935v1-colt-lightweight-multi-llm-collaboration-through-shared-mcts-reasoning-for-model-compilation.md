# COLT: Lightweight Multi-LLM Collaboration through Shared MCTS Reasoning for Model Compilation
# COLT：通过共享 MCTS 推理实现模型编译的轻量级多 LLM 协作

**Authors**: Annabelle Sujun Tang, Christopher Priebe, Lianhui Qin, Hadi Esmaeilzadeh \\
**Date**: 2026-02-02 \\
**PDF**: https://arxiv.org/pdf/2602.01935v1 \\
**Tags**: <span class="tag-label tag-green">速读区</span> <span class="tag-label tag-pink">keyword:EOH</span> <span class="tag-label tag-pink">keyword:EAA</span> \\
**Score**: 7.0 \\
**Evidence**: MCTS reasoning for compiler optimization search aligns with heuristic evolution and efficient algorithms \\

---

## Abstract
Model serving costs dominate AI systems, making compiler optimization essential for scalable deployment. Recent works show that a large language model (LLM) can guide compiler search by reasoning over program structure and optimization history. However, using a single large model throughout the search is expensive, while smaller models are less reliable when used alone. Thus, this paper seeks to answer whether multi-LLM collaborative reasoning relying primarily on small LLMs can match or exceed the performance of a single large model. As such, we propose a lightweight collaborative multi-LLM framework, dubbed COLT, for compiler optimization that enables coordinated reasoning across multiple models within a single Monte Carlo tree search (MCTS) process. A key contribution is the use of a single shared MCTS tree as the collaboration substrate across LLMs, enabling the reuse of transformation prefixes and cross-model value propagation. Hence, we circumvent both heavy internal reasoning mechanisms and conventional agentic machinery that relies on external planners, multiple concurrent LLMs, databases, external memory/versioning of intermediate results, and controllers by simply endogenizing model selection within the lightweight MCTS optimization loop. Every iteration, the acting LLM proposes a joint action: (compiler transformation, model to be queried next). We also introduce a model-aware tree policy that biases search toward smaller models while preserving exploration, and a course-alteration mechanism that escalates to the largest model when the search exhibits persistent regressions attributable to smaller models.

## 摘要
模型推理成本在

---

## 速览摘要（自动生成）

**问题**：编译器优化中单一大模型搜索成本极高，而小模型独立工作时可靠性不足。

**方法**：提出 COLT 框架，通过共享 MCTS 树实现多模型协作。引入模型感知策略优先调用小模型，并建立自动升级机制，在搜索性能下降时切换至
# Self-Consolidation for Self-Evolving Agents
# 面向自进化智能体的自我巩固

**Authors**: Hongzhuo Yu, Fei Zhu, Guo-Sen Xie, Ling Shao \\
**Date**: 2026-02-02 \\
**PDF**: https://arxiv.org/pdf/2602.01966v1 \\
**Tags**: <span class="tag-label tag-green">速读区</span> <span class="tag-label tag-pink">keyword:EOH</span> <span class="tag-label tag-pink">keyword:EAA</span> \\
**Score**: 6.0 \\
**Evidence**: Self-evolving agents align with the evolution of heuristics and automatic algorithm design \\

---

## Abstract
While large language model (LLM) agents have demonstrated impressive problem-solving capabilities, they typically operate as static systems, lacking the ability to evolve through lifelong interaction. Existing attempts to bridge this gap primarily rely on retrieving successful past trajectories as demonstrations. However, this paradigm faces two critical limitations. First, by focusing solely on success, agents overlook the rich pedagogical value embedded in failed attempts, preventing them from identifying and avoiding recurrent pitfalls. Second, continually accumulating textual experiences not only increases the time consumption during retrieval but also inevitably introduces noise and exhausts the largest context window of current LLMs. To address these challenges, we propose a novel self-evolving framework for LLM agents that introduces a complementary evolution mechanism: First, a contrastive reflection strategy is introduced to explicitly summarize error-prone patterns and capture reusable insights. Second, we propose a self-consolidation mechanism that distills non-parametric textual experience into compact learnable parameters. This enables the agent to internalize extensive historical experience directly into its latent space. Extensive experiments demonstrate the advantages of our method in long-term agent evolution.

## 摘要
虽然大语言模型（LLM）智能体已展现出卓越的问题解决能力，

---

## 速览摘要（自动生成）

**问题**：LLM智能体通常是静态的，现有演化方法仅依赖成功案例检索，忽略了失败经验且受限于上下文长度。

**方法**：提出自整合框架，通过**对比反思**总结易错模式，并利用**自整合机制**将非参数化文本经验蒸馏为模型参数。

**结论**：该方法使智能体能内化长期经验，有效避免重复错误并提升长效演化能力。
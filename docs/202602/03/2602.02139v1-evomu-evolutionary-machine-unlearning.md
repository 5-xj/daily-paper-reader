# EvoMU: Evolutionary Machine Unlearning
# EvoMU：演化机器遗忘

**Authors**: Pawel Batorski, Paul Swoboda \\
**Date**: 2026-02-02 \\
**PDF**: https://arxiv.org/pdf/2602.02139v1 \\
**Tags**: <span class="tag-label tag-blue">精读区</span> <span class="tag-label tag-pink">keyword:EOH</span> \\
**Score**: 8.0 \\
**Evidence**: Evolutionary search for task-specific loss functions aligns with evolution of heuristics \\

---

## Abstract
Machine unlearning aims to unlearn specified training data (e.g. sensitive or copyrighted material). A prominent approach is to fine-tune an existing model with an unlearning loss that retains overall utility. The space of suitable unlearning loss functions is vast, making the search for an optimal loss function daunting. Additionally, there might not even exist a universally optimal loss function: differences in the structure and overlap of the forget and retain data can cause a loss to work well in one setting but over-unlearn or under-unlearn in another. Our approach EvoMU tackles these two challenges simultaneously. An evolutionary search procedure automatically finds task-specific losses in the vast space of possible unlearning loss functions. This allows us to find dataset-specific losses that match or outperform existing losses from the literature, without the need for a human-in-the-loop. This work is therefore an instance of automatic scientific discovery, a.k.a. an AI co-scientist. In contrast to previous AI co-scientist works, we do so on a budget: We achieve SotA results using a small 4B parameter model (Qwen3-4B-Thinking), showing the potential of AI co-scientists with limited computational resources. Our experimental evaluation shows that we surpass previous loss-based unlearning formulations on TOFU-5%, TOFU-10%, MUSE and WMDP by synthesizing novel unlearning losses. Our code is available at https://github.com/Batorskq/EvoMU.

## 摘要
机器遗忘旨在使模型遗忘特定的训练数据（例如敏感或受

---

## 论文详细总结（自动生成）

这是一份关于论文《EvoMU: Evolutionary Machine Unlearning》的结构化深度总结：

### 1. 核心问题与整体含义（研究动机和背景）
*   **核心问题**：在大型语言模型（LLM）的机器遗忘（Machine Unlearning）领域，如何设计最优的**损失函数（Loss Function）**是一个巨大挑战。
*   **研究动机**：
    *   **设计空间巨大**：现有的遗忘损失函数（如梯度上升、偏好优化等）种类繁多，手动调整系数、边界和参考信号非常耗时且容易失效。
    *   **缺乏通用性**：没有一个损失函数能适配所有场景。遗忘数据与保留数据的重叠程度、数据结构（事实、风格或长文本）的差异，会导致同一损失函数在某些任务中表现良好，而在另一些任务中出现“过度遗忘”或“遗忘不足”。
    *   **自动化需求**：作者提出将遗忘损失函数的设计视为一个**自动科学发现（ASD）**问题，利用 AI 辅助寻找针对特定任务的最优解。

### 2. 方法论：EvoMU 核心思想与技术细节
*   **核心思想**：EvoMU 是一个演化目标发现框架，利用 LLM 作为“提议者”和“变异者”，通过“生成-训练-评估-反馈-变异”的闭环，自动合成可执行的 Python 损失函数代码。
*   **关键流程**：
    1.  **初始化**：使用 LLM（Qwen3-4B-Thinking）生成初始的一组候选损失函数（包含训练轮数等元数据）。
    2.  **训练与评估**：针对每个候选损失，使用轻量化的 **LoRA** 适配器对基础模型进行微调，并在标准 Benchmark 上评估其遗忘效果和实用性保持能力。
    3.  **选择**：根据综合得分（遗忘指标与实用性指标的加权和）筛选出表现最好的 Top-K 个损失函数。
    4.  **演化变异**：将 Top-K 损失的代码、训练曲线和评估结果反馈给 LLM，由其进行变异（调整系数、修改结构、引入/移除参考模型项等），生成下一代候选函数。
*   **技术约束**：候选函数必须是可执行的 PyTorch 代码，输入参数仅限于当前模型和参考模型在遗忘/保留集上的平均对数概率（log-probs）。

### 3. 实验设计
*   **数据集与场景**：
    *   **TOFU (5% & 10%)**：虚构人物传记问答，测试选择性遗忘。
    *   **MUSE (News & Books)**：新闻文章和哈利·波特书籍，测试长文本遗忘和成员推理防御。
    *   **WMDP (Bio)**：生物安全危险知识，测试有害能力的剥离。
*   **对比方法（Baselines）**：包括 GA（梯度上升）、GradDiff、NPO、SimNPO、RMU、RKLD、IDKDPO 等十余种主流手动设计的遗忘算法。
*   **评估指标**：ROUGE-L、模型概率（Prob）、提取强度（Extraction Strength）、MMLU 准确率、隐私泄露（PrivLeak）等。

### 4. 资源与算力
*   **硬件设备**：使用了 **2 张 NVIDIA A100 (40GB)** GPU。
*   **训练时长**：整个演化搜索过程（约测试 65 个损失函数）根据 Benchmark 的不同，耗时在 **10 到 20 小时**之间。
*   **驱动模型**：使用了一个相对较小的开源模型 **Qwen3-4B-Thinking** 作为 AI 科学家，证明了 ASD 并不一定需要超大规模或闭源模型。

### 5. 实验数量与充分性
*   **实验规模**：
    *   每个任务运行了多代演化（初始 10 个，变异两轮分别产生 25 和 30 个，总计 65 个候选函数）。
    *   涵盖了从事实性问答到长文本、从隐私保护到安全合规的多种遗忘场景。
*   **充分性与客观性**：
    *   **消融实验**：测试了固定训练轮数、不同思考 Token 数量、随机采样对比等。
    *   **鲁棒性测试**：在 TOFU-5% 上进行了 5 次独立种子的运行，结果显示性能稳定。
    *   **泛化性测试**：将 TOFU 发现的损失函数直接应用于 WMDP 和 MUSE，验证了损失函数的跨任务迁移能力。
    *   **重学习测试**：验证了 EvoMU 发现的损失函数在抵御“恢复训练”攻击方面的强度。

### 6. 主要结论与发现
*   **超越 SOTA**：EvoMU 合成的损失函数在所有测试的 Benchmark 上均达到或超过了之前人类设计的最佳方法。
*   **任务特定性**：实验证明，针对不同数据集（如 MUSE 与 TOFU），最优的损失函数结构确实存在显著差异。
*   **小模型潜力**：4B 参数的思考型模型足以胜任复杂的算法合成任务，降低了自动科学发现的门槛。
*   **结构发现**：发现了一些简单但有效的损失结构，例如在某些场景下不需要显式的参考模型项，或者使用指数化的 Delta 惩罚。

### 7. 优点：亮点与创新
*   **全自动化**：实现了从损失函数设计到超参数（训练轮数）调整的全流程自动化，无需人工干预。
*
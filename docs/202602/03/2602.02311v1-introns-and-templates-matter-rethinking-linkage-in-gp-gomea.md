# Introns and Templates Matter: Rethinking Linkage in GP-GOMEA
# 内含子与模板至关重要：重新思考 GP-GOMEA 中的连锁机制

**Authors**: Johannes Koch, Tanja Alderliesten, Peter A. N. Bosman \\
**Date**: 2026-02-02 \\
**PDF**: https://arxiv.org/pdf/2602.02311v1 \\
**Tags**: <span class="tag-label tag-blue">精读区</span> <span class="tag-label tag-pink">keyword:EOH</span> <span class="tag-label tag-pink">keyword:EAA</span> \\
**Score**: 8.0 \\
**Evidence**: discusses linkage and efficient evolution in GP-GOMEA \\

---

## Abstract
GP-GOMEA is among the state-of-the-art for symbolic regression, especially when it comes to finding small and potentially interpretable solutions. A key mechanism employed in any GOMEA variant is the exploitation of linkage, the dependencies between variables, to ensure efficient evolution. In GP-GOMEA, mutual information between node positions in GP trees has so far been used to learn linkage. For this, a fixed expression template is used. This however leads to introns for expressions smaller than the full template. As introns have no impact on fitness, their occurrences are not directly linked to selection. Consequently, introns can adversely affect the extent to which mutual information captures dependencies between tree nodes. To overcome this, we propose two new measures for linkage learning, one that explicitly considers introns in mutual information estimates, and one that revisits linkage learning in GP-GOMEA from a grey-box perspective, yielding a measure that needs not to be learned from the population but is derived directly from the template. Across five standard symbolic regression problems, GP-GOMEA achieves substantial improvements using both measures. We also find that the newly learned linkage structure closely reflects the template linkage structure, and that explicitly using the template structure yields the best performance overall.

## 摘要
GP-GOMEA 是符号

---

## 论文详细总结（自动生成）

这篇论文对符号回归（Symbolic Regression, SR）领域中先进的算法 **GP-GOMEA** 进行了深入的反思与改进，重点探讨了“连锁学习（Linkage Learning）”机制在存在“内含子（Introns，即无效代码）”情况下的失效问题。

以下是对该论文的结构化总结：

### 1. 核心问题与整体含义（研究动机）
*   **背景**：GP-GOMEA 通过学习变量间的依赖关系（连锁）来指导进化，通常使用固定结构的树模板。
*   **核心问题**：在固定模板中，如果生成的表达式较小，模板中会有大量节点处于“非激活”状态（即内含子）。由于内含子不受选择压力影响，其取值具有随机性。
*   **研究动机**：现有的连锁学习方法（如互信息 MI）将这些随机的内含子视为噪声，导致无法准确捕捉有效节点间的真实依赖关系，从而降低了进化效率。

### 2. 论文提出的方法论
论文提出了两种改进连锁度量的方法，旨在利用被忽视的领域知识：

*   **掩码互信息（Masked Mutual Information, $MI_{masked}$）**：
    *   **核心思想**：在计算熵和互信息时，显式区分激活节点和非激活节点。
    *   **技术细节**：为所有处于非激活状态的变量分配一个统一的特殊标签（如“masked”）。这样，统计信息将完全基于受选择压力影响的激活部分，消除了内含子带来的随机噪声。
*   **节点邻近度（Node Proximity，灰盒视角）**：
    *   **核心思想**：不再从种群统计数据中学习，而是直接从树模板的拓扑结构中推导连锁。
    *   **技术细节**：基于节点在模板树中的距离 $d(i,j)$ 定义相似度。距离越近（如父子关系、兄弟关系），相似度越高。公式定义为 $S_{i,j} = 1 - \frac{d(i,j)}{1 + \max(d)}$。这种方法不需要消耗计算资源去统计种群，属于“灰盒”优化。

### 3. 实验设计
*   **数据集**：使用了 5 个标准的符号回归基准问题：Airfoil（机翼噪声）、Bike Sharing（共享单车）、Concrete（混凝土强度）、Dow Chemical（陶氏化学）、Tower（塔架数据）。
*   **对比方法（Benchmarks）**：
    1.  **Random**：随机连锁。
    2.  **MI**：标准互信息。
    3.  **$MI_{adjusted}$**：之前 state-of-the-art 的偏差修正互信息。
    4.  **Univariate**：假设变量间完全独立（单变量模型）。
*   **实验变量**：测试了不同的模板高度（5 和 7）、是否开启线性缩放（Linear Scaling）、以及不同大小的算子集。

### 4. 资源与算力
*   **硬件**：实验在配备两颗 **Intel Xeon E5-2699v4** 处理器的机器上运行，每个实验运行分配一个独立的物理核心。
*   **预算**：每个运行限制为 $10^7$ 次评估。
*   **耗时**：论文提到，使用新方法在 **10 到 20 分钟** 内即可达到传统方法最终的精度，显著缩短了运行时间。

### 5. 实验数量与充分性
*   **实验规模**：每个设置进行了 **30 次独立重复实验**（使用 5 折交叉验证，每折重复 6 次），种子数在算法间共享以确保公平。
*   **充分性**：实验覆盖了不同特征维度（5 到 57 个特征）、不同数据规模（731 到 4999 个样本）。
*   **客观性**：采用了严格的统计检验，包括 Friedman 检验、Nemenyi 后置检验以及基于 Bootstrap 的置信区间分析，符合当前机器学习实验的高标准。

### 6. 主要结论与发现
*   **性能提升**：提出的 **Node Proximity（节点邻近度）** 表现最优，其次是 **$MI_{masked}$**。两者在精度和收敛速度上均显著优于现有的 MI 方法。
*   **连锁本质**：研究发现，即使是基于统计学习的 $MI_{masked}$，其最终学到的连锁结构也高度趋同于预定义的树模板结构。
*   **结论**：在 GP-GOMEA 中，显式利用模板的拓扑结构比从种群中动态学习连锁更有效，因为模板本身就定义了变量间潜在的交互路径。

### 7. 优点（亮点）
*   **简单高效**：Node Proximity 方法不需要运行时的统计计算，零开销且效果最好。
*   **深刻洞察**：揭示了 GP 中内含子对连锁学习的负面影响，并证明了“掩码”处理的有效性。
*   **即插即用**：提出的方法不引入新的超参数，易于集成到现有的 GP-GOMEA 框架中。

### 8. 不足与局限
*   **模板依赖**：该方法高度依赖于“固定模板”这一前提。对于不使用固定模板的传统 GP 算法，其适用性有待验证。
*   **灰盒假设**：Node Proximity
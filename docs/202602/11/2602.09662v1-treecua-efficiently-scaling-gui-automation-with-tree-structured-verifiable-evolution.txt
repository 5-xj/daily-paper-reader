Title: TreeCUA: Efficiently Scaling GUI Automation with Tree-Structured Verifiable Evolution

URL Source: https://arxiv.org/pdf/2602.09662v1

Published Time: Wed, 11 Feb 2026 01:50:30 GMT

Number of Pages: 14

Markdown Content:
# TreeCUA: Efficiently Scaling GUI Automation with Tree-Structured Verifiable Evolution 

Deyang Jiang * 1 Jing Huang * 1 Xuanle Zhao * 1 Lei Chen 1 Liming Zheng 1 Fanfan Liu 1 Haibo Qiu 1

Peng Shi 1 Zhixiong Zeng B 1

# Abstract 

Effectively scaling GUI automation is essential for computer-use agents (CUAs); however, ex-isting work primarily focuses on scaling GUI grounding rather than the more crucial GUI plan-ning, which requires more sophisticated data col-lection. In reality, the exploration process of a CUA across apps/desktops/web pages typically follows a tree structure, with earlier functional entry points often being explored more frequently. Thus, organizing large-scale trajectories into tree structures can reduce data cost and streamline the data scaling of GUI planning. In this work, we propose TreeCUA to efficiently scale GUI automation with tree-structured verifiable evo-lution. We propose a multi-agent collaborative framework to explore the environment, verify ac-tions, summarize trajectories, and evaluate qual-ity to generate high-quality and scalable GUI trajectories. To improve efficiency, we devise a novel tree-based topology to store and replay duplicate exploration nodes, and design an adap-tive exploration algorithm to balance the depth (i.e. , trajectory difficulty) and breadth ( i.e. , tra-jectory diversity). Moreover, we develop world knowledge guidance and global memory back-tracking to avoid low-quality generation. Finally, we naturally extend and propose the TreeCUA-DPO method from abundant tree node informa-tion, improving GUI planning capability by refer-ring to the branch information of adjacent trajec-tories. Experimental results show that TreeCUA and TreeCUA-DPO offer significant improve-ments, and out-of-domain (OOD) studies further demonstrate strong generalization. All trajectory node information and code will be available at https://github.com/UITron-hub/TreeCUA. 

> *

Equal contribution 1Meituan, Beijing, China. Correspondence to: Zhixiong Zeng <zengzhixiong@meituan.com >.

Preprint. February 11, 2026. 

# 1. Introduction 

Computer-Use Agents (CUAs) represent a paradigm shift towards general-purpose digital agents, capable of perceiv-ing and interacting with Graphical User Interfaces (GUIs) in a human-like manner (OpenAI, 2025). Leveraging the emer-gent capabilities of large Vision-Language Models (VLMs) (Bai et al., 2025; Comanici et al., 2025), these agents process high-resolution visual inputs to execute intricate instruction-following tasks. The field has been significantly shaped by proprietary frontier models such as Gemini (Comanici et al., 2025) and Claude (Anthropic, 2025), which have demonstrated exceptional proficiency in complex agentic workflows. Concurrently, open-source initiatives are ac-celerating efforts to scale CUA models and data pipelines to bridge the gap with proprietary systems. Representa-tive models (Qin et al., 2025; Ye et al., 2025; Zeng et al., 2025; Sun et al., 2024) have successfully scaled capabilities across desktop, mobile, and web platforms, underscoring the immense potential for generalized digital intelligence. However, distinct from the rapid scaling of model parame-ters, scaling high-quality training data incurs significantly higher costs and complexity. Although recent works (Cheng et al., 2024a; Xie et al., 2025; Chai et al., 2024; Huang et al., 2025) have successfully scaled GUI grounding datasets, these efforts focus primarily on static element recognition. In contrast, efficiently scaling long-horizon planning trajec-tories necessitates temporal reasoning and dynamic interac-tion, remaining a largely unexplored challenge. To address this challenge, recent CUA methods like OpenCUA (Wang et al., 2025) and ScaleCUA (Liu et al., 2025) collect human computer-use demonstrations or human expert annotations to construct GUI trajectories. Unfortunately, existing meth-ods often rely on necessary human annotations, making it difficult to scale effectively to large-scale trajectory synthe-sis. As a result, open-source trajectories currently available in this field remain very scarce. Efficiently scaling GUI trajectory requires addressing two key challenges: step redundancy and trajectory diversity. Step redundancy intensifies with increasing trajectory scale, as different app/desktop/webpage trajectories inevitably re-peat the exploration of early functional entry points. Trajec-1

> arXiv:2602.09662v1 [cs.CV] 10 Feb 2026 TreeCUA: Efficiently Scaling GUI Automation with Tree-Structured Verifiable Evolution

tory diversity depends primarily on the distillation model in automated trajectory synthesis, as the model’s inherent bias favors high-frequency exploration behaviors, potentially leading to insufficiently diverse and long-tail trajectories. In this paper, we devise an efficient way to scale GUI au-tomation by eliminating step redundancy through organiz-ing large-scale trajectories into a tree structure and improv-ing trajectory diversity through world knowledge guidance. Thus we propose TreeCUA, a novel data synthesis frame-work of tree-structured verifiable evolution, and design a training recipe of two-stage SFT protocol for establishing foundational and cognitive capabilities. To this end, we develop an automated multi-agent collaborative framework to collect tree-structured verifiable synthesis trajectories, including an exploration agent, a verification agent, a sum-mary agent and an evaluation agent to explore the environ-ment, verify actions, summarize trajectories, and evaluate quality. To achieve efficiency and scalability, we devise a novel tree-based topology to store and reuse intermediate exploration nodes. Moreover, we design an adaptive explo-ration algorithm to balance trajectory depth (difficulty) and breadth (diversity) within the tree exploration, augmented by world knowledge guidance and global memory backtracking to strictly filter low-quality generations. In particular, leveraging the rich tree-structured data, we naturally extended TreeCUA to TreeCUA-DPO through reinforcement learning. By utilizing the branching information from adjacent trajec-tories as distinct preference pairs, this method significantly enhances the model planning capabilities. Experimental re-sults on OSWorld (Xie et al., 2024) and out-of-distribution (OOD) tasks demonstrate that both TreeCUA and TreeCUA-DPO significantly improve task success rates in online en-vironments, while also exhibiting strong generalization ca-pabilities. In conclusion, our contributions are listed as follows • We introduce tree-structured verifiable evolution for efficiently scaling CUA trajectory synthesis, which develops a multi-agent framework to explore the envi-ronment, verify actions, summarize trajectories, and evaluate quality. • Based on tree-structured trajectories, we propose TreeCUA and TreeCUA-DPO for GUI automation, which devises a two-stage SFT protocol to establish foundational capability and DPO training for referring to the branch information of adjacent trajectories. • Extensive experimental results show that our methods achieve SOTA performance on in-domain OSWorld and OOD tasks, significantly outperforming existing open-source trajectories and also demonstrating re-markable generalization. 

# 2. Related Works 

2.1. Computer-Use Agents (CUAs) 

The evolution of Computer-Use Agents (CUAs) has pro-gressed through three methodological paradigms, shifting from dependence on metadata to holistic visual percep-tion (Cheng et al., 2024a; Sun et al., 2024). Initially, re-search primarily relied on structured metadata, such as DOM trees (Deng et al., 2023; Pan et al., 2024), to gen-erate symbolic commands. While effective in structured environments, these text-based models often prove brittle to dynamic web elements or applications that lack accessibil-ity tags. Subsequently, to incorporate visual perception, a modular ”Planner-Grounder” framework emerged (Cheng et al., 2024a; Wu et al., 2024a). These systems leverage strong VLMs for high-level planning alongside specialized modules for localization (Yang et al., 2025a; Huang et al., 2025). However, such multi-stage pipelines frequently suf-fer from high computational latency and error propagation. Most recently, the field has moved towards native end-to-end agents that integrate planning and grounding into a unified model (Sun et al., 2024; Wang et al., 2025; Liu et al., 2025). By directly translating screenshots into executable actions, representative models like Aguvis (Xu et al., 2024), UItron(Zeng et al., 2025), UI-Tars (Qin et al., 2025) and OpenCUA (Wang et al., 2025), achieve superior perception-action alignment. 

2.2. CUA Data Synthesis 

Achieving GUI automation requires strong GUI ground-ing and planning capabilities. These capabilities allow the GUI agent to pinpoint precise visual elements from screen-shots and execute planned actions to complete the user task. Previous research has primarily concentrated on the data collection of GUI grounding, where typical works include SeeClick (Cheng et al., 2024b), AMEX (Chai et al., 2024), OS-Atlas (Wu et al., 2024b), and JEDI (Xie et al., 2025). Recently, GroundCUA (Feizi et al., 2025) collected a large-scale desktop grounding dataset built from expert human demonstrations, and ScaleCUA (Liu et al., 2025) released a large-scale grounding dataset spanning 6 operating systems and 3 task domains, annotated by automated agents and human experts. However, these works are confined to static element recognition, overlooking the sequential reasoning essential for multi-step planning. To support multi-step task planning, researchers have developed various strate-gies for trajectory synthesis (Rawles et al., 2023; Xu et al., 2025; Sun et al., 2024; Pahuja et al., 2025), utilizing human demonstrations or screen recordings to generate planning trajectories in domains like android control and web agent. Recently, OpenCUA (Wang et al., 2025) proposes an anno-2TreeCUA: Efficiently Scaling GUI Automation with Tree-Structured Verifiable Evolution  

> Figure 1. Overview of the tree-structured verifiable evolution for scalable GUI trajectory synthesis. Our strategy could be divided into online concurrent exploration and offline post-processing and improvement phases.

tation infrastructure to seamlessly capture human computer-use demonstrations and transform them into state-action pairs. However, the synthetic data in these works are all relatively small in scale, and there is still a severe lack of available open-source trajectories in the CUA domain. The prohibitive cost of human verification impedes scalability, leaving the efficient synthesis of diverse and high-quality planning trajectories as a critical open challenge. 

# 3. Tree-Structured Data Synthesis Pipeline 

We propose Tree-Structured Verifiable Evolution , a multi-agent framework for synthesizing diverse trajectories to address the data scarcity constraining CUA advancement, as shown in Figure 1. To enhance trajectory diversity and qual-ity, our framework coordinates five specialized agents across two distinct phases: tree-structured online exploration and post-hoc quality evaluation and improvement. 

3.1. Tree-Structure Verifiable Evolution 

We define the exploration manifold as a tree, where nodes encode states s, and edges represent transition actions a.3.1.1. I NITIALIZATION WITH WORLD KNOWLEDGE 

To mitigate exploration bias and prevent premature con-vergence to shallow nodes, we propose World-Knowledge Initialization. By structuring official documentation into a hierarchical knowledge base W, we classify the tasks of these applications into several categories based on shared functional dependencies. This organization provides a high-level prior that guides the agent toward semantically rich interaction subspaces. Furthermore, merely invoking a blank application is often insufficient for deep exploration. To en-sure comprehensive coverage, we formulate a hierarchical data paradigm consisting of Apps, Categories, and Trees. Our framework conducts multi-tree exploration within each Category, where each individual tree scales to 100–1,000 trajectories to ensure both breadth and depth of the inter-action space. For instance, an empty IDE cannot facilitate debugging tasks. To bridge this gap, we formalize envi-ronment initialization as s0 = Φ( wc, P), where wc ∈ W 

specifies a task category and P represents a pre-configured asset pool of files such as images, documents, accounts, and configurations. By injecting these context-specific as-sets, Φ transforms the environment into a non-trivial initial state s0. A typical example is an IDE pre-loaded with a functional project, which establishes a necessary foundation for subsequent exploration. Furthermore, the knowledge serves as a persistent semantic context for the exploration agent at each step, ensuring that the sampled actions remain aligned with the intended functional domain and preventing the exploration from drifting into irrelevant or stochastic UI states. 3.1.2. O NLINE EXPLORATION 

To facilitate online tree exploration, we define an explo-ration tuple Et = ⟨at, g step  

> t

, g final  

> t

, o exp 

> t+1

, c rat  

> t

⟩. This tuple en-capsulates the executable action at, the immediate intent 

gstep  

> t

, and a dynamic hypothesis of the long-term objective 

gfinal  

> t

. To enhance planning coherence, each tuple also in-cludes an expected observation oexp  

> t+1

for visual prediction and an exploration rationale crat  

> t

that documents the underly-ing decision logic. At each node, the exploration agent πexp 

3TreeCUA: Efficiently Scaling GUI Automation with Tree-Structured Verifiable Evolution 

synthesizes K candidate actions {E(k) 

> t

}Kk=1 by sampling from the distribution:      

> {E(k)
> t}Kk=1 ←πexp (ot, h t, w c,Mpre )(1)

where the generation is conditioned on the current visual ob-servation ot, the world knowledge of this task category wc,and global prefix histories Mpre . Crucially, the policy in-corporates a trajectory history ht to enforce high coherence between the agent’s actions and its historical intent, thereby preventing the generated trajectories from descending into aimless or stochastic exploration. To optimize context effi-ciency, we retain only the textual components of the history. 

Adaptive Tree Topology To optimize the trade-off be-tween functional coverage and computational efficiency, we propose a strategy that adapts the exploration tree topology to both temporal progression and semantic context. First, we implement a temporal width decay mechanism that imposes a step-dependent upper bound Kmax (t) on the branching factor. By partitioning the trajectory into discovery, develop-ment, and convergence phases, this strategy systematically reduces exploration breadth as depth increases. This design maximizes early-stage diversity while concentrating compu-tational resources on refining promising paths in later stages. Within this temporal framework, the exploration agent re-fines the specific branching factor through context-aware adjustment. When the observation ot presents multiple ac-tionable elements, the agent prioritizes action diversity by generating candidates across distinct clusters to ensure com-prehensive coverage. Conversely, if ht indicates an ongoing sub-task sequence, the agent maintains sequential consis-tency by restricting the exploration to essential steps, thereby preserving logical coherence. Finally, upon completing a valuable task loop, the agent synthesizes a termination ac-tion to prune the branch. This balance ensures efficient exploration, maximizing the yield of valid trajectories. 

Step Verification To guarantee trajectory fidelity, we em-ploy a step-level verification agent to validate the outcome of each transition, shifting the evaluation paradigm from am-biguous outcomes to precise intermediate states. This design is motivated by the fact that while evaluating the completion of complex GUI tasks is inherently difficult without human oversight, validating atomic steps is significantly more feasi-ble by simply checking if the interface’s state change aligns with the expectation. Therefore, we employ the verifica-tion agent to assess the semantic consistency between the actual observation ot+1 and the predicted outcome oexp 

> t+1

.By classifying results into discrete states (e.g., S UCCESS ,NO CHANGE , U NEXPECTED CHANGE ), this mechanism not only filters out invalid branches to ensure data purity but also injects immediate feedback into the history, enabling the agent to perform on-the-fly error recovery. 

Global Memory Since trees within the same application sub-category often originate from similar initial states, a critical challenge lies in preventing redundancy across in-dependent explorations. To address this, we propose a global memory mechanism designed to maximize func-tional diversity across these trees. Specifically, we main-tain a global prefix memory Mpre to maximize diversity across tree explorations. This mechanism operates on the hypothesis that the core semantic intent of a CUA task is established within the initial L steps. Formally, Mpre 

aggregates the step-wise goals from previously explored prefixes: Mpre = S

> i

{(gstep  

> i, 0

, . . . , g step 

> i,L −1

)}. During the shal-low exploration phase (where t < L ), we impose a novelty constraint denoted as gstep  

> t

/∈ Semantics( Mpre | ht). This explicitly directs the agent to diverge from established tra-jectories given identical historical contexts. 

Scalable Concurrent Exploration Applying tree-structured planning to general-purpose CUA environments encounters a critical bottleneck: the absence of system-level snapshotting. Real-world operating systems lack the capability for arbitrary state resets, which are essential for non-linear exploration. To address this, we develop a scalable execution engine based on deterministic node replay. Specifically, to revisit a target node st, the system resets the environment to s0 and re-executes the recorded action history A0: t−1. To handle environmental stochas-ticity (e.g., system clock changes), we enforce a visual consistency check between the historical and replayed observations. Furthermore, we introduce an asynchronous parallel framework, where multiple workers dynamically fetch unexplored nodes from a global queue, reconstruct states on-demand, and execute hybrid traversal strategies to maximize throughput. Detailed implementations and consistency algorithms are provided in Appendix A. 

3.2. Quality Evaluation and Improvement 

We finalize the dataset by mapping action sequences to multi-level task instructions, followed by a filtering and reasoning generation protocol that validates quality and enriches trajectories with the thinking process. 

Hierarchical Task Summarization We employ the sum-mary agent to synthesize a task description G∗ via a bottom-up approach. By filtering out low-level redundancies, this agent abstracts the core semantic intent from the exploration trajectory. This abstraction process is stratified into two hierarchical levels. At the top level, the agent performs trajectory-level summarization to derive a global task in-struction by synthesizing the semantic context from the comprehensive execution record. At the bottom level, it executes sub-trajectory extraction to partition the trajectory into coherent subtasks. Here, a sub-trajectory is defined as a 4TreeCUA: Efficiently Scaling GUI Automation with Tree-Structured Verifiable Evolution 

Table 1. Statistics of our synthetic data across different data for-mats. We report the counts before ( Original ) and after quality filtering ( Filtered ), along with the average action steps per in-stance. 

TreeCUA Data Sample Count Avg. Steps Filtering Target Original Filtered Step 900k 708k 1.0 Exec.&Replay Fail 

Sub-Traj 150k 101k 3.3 Redundant Explore 

Long-Traj 100k 50k 18.0 Low-quality Score 

high-value interaction segment driven by a single intent that yields a substantive environmental state change. By identi-fying contiguous sequences of success states and filtering out noisy steps, the agent effectively isolates these coherent stage-level units. 

Quality Evaluation and Filteration For data filtering, we employ a quality evaluation agent to assess the gener-ated trajectory across the following four dimension criteria: (i) task utility, by aligning with realistic user intents to fil-ter stochastic navigation; (ii) step efficiency, by penalizing redundant state transitions; (iii) consistency, by verifying semantic alignment between outcomes and directives; and (iv) coherence, by ensuring logical fluidity and minimizing erratic switching. For each dimension, the agent assigns a score ranging from 0 to 3 and only trajectories that surpass a threshold are retained for the final dataset. 

Reasoning Improvement To generate high-quality train-ing data, we employ hindsight reasoning synthesis to re-construct the reasoning process using the global context of completed trajectories. Unlike tentative forward reason-ing, this process uses the final task target G∗ and the future context ft, which encapsulates valid subsequent steps, to produce a definitive reasoning chain C∗ 

> t

. The synthesis model operates as follows: 

C∗ 

> t

= Ψ syn (G∗, o t, a t, g step t , h t, f t)

The synthesized reasoning process is structured into four dimensions: observation of the visual context, progress re-flection on execution history, planning of strategic roadmaps, and impact assessment toward the final goal. 

# 4. Synthesized Data Statistics and Analysis 

In this section, we present a comprehensive analysis of the synthesized dataset to validate the effectiveness of our Tree-Structured Verifiable Evolution method. 

4.1. Dataset Overview 

Leveraging the tree-structured verifiable evolution frame-work and our quality filtering strategy, we curate a set of 50k high-quality trajectories from an initial pool of 100k 0 100 200 300 400 500 

> Number of Generated Trajectories
> 6
> 8
> 10
> 12
> Avg. Inference Steps per Trajectory
> Average Efficiency Scaling (All Apps)
> Linear Baseline (Avg)
> TreeCUA (No Reuse)
> TreeCUA (With Reuse)
> Efficiency Gain

Figure 2. Analysis of exploration strategy. (a) The distribution of average branching factor across depths. A node with n branches has a branching factor of n − 1. (b) Efficiency comparison bench-marking tree-structured exploration (with and without node reuse) against linear baselines. 

generated trajectories. Building on this foundation, we de-compose these trajectories into distinct stages based on task intentions and prune stages with redundant explorations, resulting in 101k high-quality sub-trajectories. Furthermore, by aggregating all explored nodes within the exploration tree and validating single-step execution outcomes, we com-pile 708k step-level training samples to construct our final dataset. Detailed statistics are presented in Table 1. We also compare tree-structured data with recent open-source CUA datasets in Table 2. 

4.2. Tree Depth and Efficiency Analysis 

A pivotal challenge in synthesizing CUA trajectories lies in arbitrating the trade-off between trajectory diversity and cost efficiency. Within our tree-structured framework, this tension is modulated by the branching depth. Branching at shallow depths maximizes diversity but incurs substantial computational overhead due to limited node reuse. Con-versely, deferring branching to deeper levels enhances effi-ciency via extensive prefix sharing but inherently restricts diversity, risking path homogeneity. Consequently, we hy-pothesize that branching at intermediate depths offers the equilibrium for exploration. First, We validate this hypothesis through a statistical anal-ysis of the data distribution of branching depths generated by tree-structured verifiable evolution. As illustrated in Fig-ure 2 (a), the results indicate that trajectories predominantly branch around a depth of 10, with seldom at shallow and deep nodes, thereby maintaining effective node reuse with-out sacrificing exploration. Also, we evaluate the efficiency of our tree-structured exploration relative to sequential base-lines, measured by the average inference steps per trajectory. Figure 2 (b) shows our approach leverages node reuse to amortize exploration costs, significantly reducing the aver-age inference steps per trajectory as the sample size grows. In contrast, sequential methods generate trajectories in iso-lation, leading to a linear accumulation of total cost and a constant average inference overhead. 5TreeCUA: Efficiently Scaling GUI Automation with Tree-Structured Verifiable Evolution 

Table 2. Comparison of data synthesis methods. Our method outperforms baselines by enabling fully automated, tree-structured exploration with amortized costs and dual-level verification.                            

> Data Source Core Method Topology Exploration Cost Verification Traj. Scale
> OpenCUA(Wang et al., 2025) Human Demo Linear Chain –Linear ( O(N))Traj.-Level ∼22K ScaleCUA(Liu et al., 2025) Human + Auto Linear Chain Random Walk Linear ( O(N))Traj.-Level ∼19K
> Ours Fully Auto Exploration Tree Knowledge-Driven Amortized( < O (N))Stepwise + Traj. 50K+101K

(a) Semantic Task Discovery (b) Step-level Lexical Diversity 

Figure 3. Impact of World Knowledge (WK) on Exploration Diver-sity in VS Code. (a) Semantic Task Discovery: Cumulative count of unique tasks, defined by a TF-IDF cosine similarity threshold of 

< 0.65 . (b) Lexical Diversity: Type-Token Ratio (TTR) averaged over 20 random samples of 500 step-goals. 

4.3. Long-tail Analysis 

Beyond exploration efficiency, we investigate whether World Knowledge (WK) enables the agent to transcend the intrinsic biases of the Exploration Agent and discover ”long-tail” professional functionalities. We conduct a comparative analysis in the VS Code environment, comparing an agent equipped with domain documentation ( w/ WK ) against one performing blind exploration ( w/o WK ). We first quantify the breadth of explored tasks by calculating the cumulative number of unique semantic intents across 1,000 sampled trajectories. As shown in Figure 3 (a), we vectorize task descriptions using TF-IDF and count a task as ”unique” if its cosine similarity to all previously discovered tasks is below 0.65. The results reveal that the w/o WK base-line quickly hits a ”semantic ceiling” (344 unique tasks), as it tends to repetitively propose common operations (e.g., ”opening a file” or ”basic editing”). In contrast, the w/ WK 

agent maintains robust, near-linear growth in discovery (535 unique tasks). This confirms that domain knowledge acts as a semantic bridge, allowing the agent to identify and execute specialized, long-tail tasks that are rarely activated by the model’s internal priors. To further examine the granularity of the agent’s intent, we evaluate the linguistic diversity of step-level goals using the Type-Token Ratio (TTR). We repeatedly sample 500 step-goals 20 times to construct the boxplot in Figure 3 (b). The w/ WK group exhibits a signifi-cantly higher median TTR, indicating a more diverse and 

Figure 4. Analysis on Inter-Tree Action Redundancy. Analysis of action overlap between trees within the same setting. Redundancy is quantified via pairwise Jaccard similarity, matching actions by type and grid-quantized coordinates to mitigate pixel noise. 

precise vocabulary. 

4.4. Diversity Analysis 

To validate the efficacy of global history in minimizing inter-tree redundancy, we analyze action overlap across five sequentially generated trees per sub-category. To robustly handle pixel-level variations, we apply spatial quantization by mapping coordinates to a 20 × 20 grid. Actions are defined as identical if they match in type, grid location, and input text. Redundancy is then quantified using the pairwise Jaccard Similarity of unique action sets. Figure 4 visualizes the pairwise similarity heatmaps. In the w/o Global History baseline (Left), we observe high off-diagonal similarity scores with an average redundancy of 0.17. This confirms that without historical context, the VLM’s intrinsic bias drives repeated interactions with vi-sually prominent UI elements across sessions, resulting in redundant synthesis. In contrast, the w/ Global History set-ting yields a significantly sparser heatmap with an average redundancy of 0.08. By recording the history of early steps, the history mechanism compels immediate divergence at the root level, ensuring that each tree explores a semantically distinct functional territory. 

# 5. TreeCUA Training Recipe 

In this section, we introduce the training recipe of our model, which comprises a two-stage SFT protocol for establishing 6TreeCUA: Efficiently Scaling GUI Automation with Tree-Structured Verifiable Evolution                                                                                                                          

> Table 3. Performance comparison of foundation models across different domains on the OSWorld-Verified benchmark. Results are reported as Success Rate (%).
> Model Steps Overall Chrome GIMP Calc Impress Writer Multi OS TB VLC Code Closed-source Models
> Seed-1.8 100 61.92 63.0 53.8 72.3 68.0 82.5 49.0 70.8 60.0 58.2 73.9 Claude-Sonnet-4.5 50 58.1 56.4 57.7 66.0 57.5 65.2 47.0 70.8 66.7 52.9 69.6
> Open-source Models
> Qwen2.5-VL-7B 50 5.5 8.7 11.5 0.0 0.0 4.3 1.1 8.3 6.7 17.6 21.7 ScaleCUA-7B 50 15.0 ----------OpenCUA-7B 15 24.3 36.9 50.0 10.6 36.1 26.1 6.5 29.2 53.3 29.4 43.5 UI-TARS-1.5-7B 50 25.1 28.8 50.0 4.3 36.1 39.1 9.8 25.0 46.7 18.8 47.8 UltraCUA-7B 15 28.9 41.2 50.0 13.9 27.1 55.4 10.6 37.0 33.6 43.3 46.7 TreeCUA-7B 50 34.6 28.3 76.9 27.7 40.4 43.5 14.0 58.3 33.3 41.2 47.8 TreeCUA-DPO-7B 50 36.6 39.1 76.9 25.5 29.8 47.8 15.1 54.2 53.3 47.1 60.9

foundational and cognitive capabilities, followed by our proposed TreeCUA-DPO for optimizing planning. 

5.1. Two-Stage SFT 

For two-stage SFT, we first cultivate foundational explo-ration capabilities, and subsequently utilize cognitive intent data to align the model with human intent. 

Stage 1: Foundational Exploration Learning. The pri-mary objective of this stage is to establish the model’s foun-dational perception and planning capabilities. The training dataset comprises all filtered step-level data, alongside multi-level tasks summarized from raw trajectories. 

Stage 2: Cognitive Intent Alignment. To better align the model with realistic user behaviors, we conduct further training using a collection of high-quality trajectories that are more consistent with realistic user tasks. Leveraging task examples written by human experts, we refine the raw tasks generated by exploration trajectories to better align with human intent. As the refined tasks might be misaligned with the raw trajectories, we employ closed-source LLMs to resample high-quality trajectories based on them for this stage. 

5.2. TreeCUA-DPO 

While SFT effectively teaches the agent how to interact with the interface, the model often struggles to distinguish between physically valid actions that serve different seman-tic intents. Constructing preference datasets to resolve this ambiguity is inherently complex. Due to the absence of immediate ground truth during online execution, standard DPO (Rafailov et al., 2023) typically necessitates labor-intensive human intervention to manually identify failures and annotate corrective actions. TreeCUA-DPO turns this challenge into an asset. By leveraging our intrinsic branch-ing topology, the framework acts as a natural counterfactual generator. It automatically contrasts successful branches against failed or suboptimal ones within the same context, yielding high-quality, physically valid preference pairs at zero additional cost. We identify branching nodes sbranch where the Exploration Agent explored multiple paths. For any such node with cur-rent observation ot and history ht, we consider two diverg-ing successful branches leading to distinct final goals G∗

> A

and G∗ 

> B

through actions aA and aB , respectively. Tree-DPO specifically addresses this by constructing dual preference pairs: (i) Conditioned on G∗

> A

, h t: (ywin = aA, y lose = aB )

(ii) Conditioned on G∗ 

> B

, h t: (ywin = aB , y lose = aA)

If both aA and aB are physically valid and successful in their respective contexts, the model cannot distinguish them by merely predicting ”which action will fail.” Instead, it is forced to align its policy with the specific semantic intent of the goal G∗. This process effectively disentangles interface affordance from user intent. Specifically, if the step verification result r for an action is negative, any preference pair employing it as the positive sample ( ywin ) is discarded. Furthermore, we implement a depth-uniform sampling strategy with a cap on pairs per node to ensure balanced optimization across both high-level strategic branching and fine-grained micro-interactions. We collected 16k preference pairs using the aforementioned method, which served as the basis for the third stage of training. 

# 6. Experiments 

6.1. Baselines 

We benchmark our model against open-source models, in-cluding Qwen2.5-VL (7B) (Bai et al., 2025), UI-Tars-1.5-7B (Qin et al., 2025), as well as models trained using recent data 7TreeCUA: Efficiently Scaling GUI Automation with Tree-Structured Verifiable Evolution      

> Table 4. Comparison of foundation models on our constructed OOD benchmark (Success Rate).
> Model OOD SR (%)
> Qwen2.5-VL-7B (Bai et al., 2025) 0.8 TreeCUA-7B 26.7 TreeCUA-DPO-7B 30.8

synthesis or annotation pipelines, such as OpenCUA (Wang et al., 2025), ScaleCUA (Liu et al., 2025) and UltraCUA (Yang et al., 2025b). We adopt OSWorld-Verified (Xie et al., 2024) as our primary evaluation benchmark. We utilize of-ficial scores for models listed on the OSWorld leaderboard and reference results from original papers for those that are unlisted. 

6.2. Effectiveness on GUI Automation 

We first evaluate TreeCUA-7B and TreeCUA-DPO-7B on the OSWorld-Verified benchmark. The results in Table 3 demonstrate that our proposed TreeCUA-7B achieves supe-rior performance compared to recent works of similar scale, such as ScaleCUA-7B (Liu et al., 2025) and OpenCUA-7B (Wang et al., 2025). Leveraging our constructed pref-erence data, TreeCUA-DPO-7B achieves superior perfor-mance compared to TreeCUA-7B. Our results across various applications demonstrate that utilizing DPO could enhance the performance on logic-intensive and sequential tasks, such as TB, Code, and Chrome. In these domains, DPO effectively corrects reasoning errors and ensures strict adher-ence to steps. Crucially, as this DPO data is derived directly from previous tree-structure exploration without additional computational overhead, these results demonstrate the ef-ficiency and effectiveness of the tree-structured verifiable evolution method. 

6.3. Effectiveness on Generalization 

To evaluate the generalization capacity of the model trained on our constructed data, we construct an Out-of-Distribution (OOD) benchmark encompassing six distinct applications: Shotwell, LibreOffice Math, GNOME Calendar, Text Editor, GNOME Calculator, and GNOME System Monitor. We syn-thesize test tasks by prompting LLMs with screenshots and official documentation, followed by rigorous manual verifi-cation and correction to ensure data quality. For evaluation, we employ GPT-4o to assess the complete interaction trajec-tory against the task description, deeming a task successful only if it passes two consecutive evaluation rounds to ensure robustness. Crucially, to mitigate ambiguity and enhance the accuracy of this model-based evaluation, we explicitly constrain critical intermediate nodes and the required final UI state within each task description. This design ensures that task completion is directly observable via the visual interface, significantly reducing the inherent difficulty of automated evaluation. In total, we construct 120 OOD test                       

> Table 5. Ablation study of TreeCUA training stages on the OS-World benchmark. We evaluate the impact of different data com-ponents in a progressive manner. SR denotes Success Rate.
> Setting SR (%) ∆
> −w/o Stage 2 20.8 -13.8
> −w/o Stage 1 26.3 -8.3
> TreeCUA-7B 34.6 -
> Table 6. Comparison with open-source data trajectories on both in-domain OSWorld evaluation and out-of-domain (OOD) test.
> Model Setting ID OSWorld OOD
> Qwen2.5-VL-7B 5.5 0.8 + OpenCUA & ScaleCUA 20.2 12.5
> + TreeCUA (Ours) 34.6 26.7

tasks, comprising 20 tasks for each application. We first compare Tree-CUA-7B with the Qwen2.5-VL-7B as the baseline in the Table 4. The results show that our model significantly increases the OOD performance, demon-strating the effectiveness of our dataset. 

6.4. Ablation Study 

We further evaluate both ID and OOD performance across various training stage settings. As detailed in Table 5, we conduct an ablation study on the two-stage SFT protocol. Specifically, we compare models trained exclusively with exploration data (w/o Stage 2) against those trained directly on cognitive intent data (w/o Stage 1). The results reveal that bypassing either stage results in marked performance drops. This is especially detrimental when excluding cogni-tive intent data, as it serves to align the agent with human decision-making patterns. Furthermore, we evaluate the effectiveness of our synthetic dataset against open-source alternatives (OpenCUA (Wang et al., 2025) and ScaleCUA (Liu et al., 2025)). To ensure a fair comparison, we conduct SFT using the same backbone model, Qwen2.5-VL-7B, across all datasets. Table 6 shows that TreeCUA consistently outperforms baselines on both ID and OOD benchmarks. These results validate that our tree-structured exploration significantly boosts both task execution performance and robust generalization. 

# 7. Conclusion 

In this work, we propose TreeCUA, which develops a tree-structured verifiable evolution method via multi-agent framework for efficiently scaling GUI automation. To en-hance the diversity and quality, we employ multiple strate-gies, including world knowledge initialization, online asyn-chronous exploration, and diversified post-processing. Be-sides, by treating branching nodes as natural sources of pref-erence data, we collect preference datasets without incurring 8TreeCUA: Efficiently Scaling GUI Automation with Tree-Structured Verifiable Evolution 

additional costs and thus train TreeCUA-DPO. Experimen-tal results show that our TreeCUA-7B and TreeCUA-DPO-7B significantly surpass existing models on the OSWorld benchmark and out-of-domain (OOD) tasks, demonstrating superior performance and strong generalization. 

# Impact Statement 

Agents interacting directly with OS interfaces possess the capability to execute irreversible commands that could com-promise system stability. To mitigate these risks, our experi-mental framework is designed with strict isolation in mind. All agent interactions occur within ephemeral, sandboxed virtual environments that are reset after each session. Conse-quently, any destructive behaviors or erroneous operations performed by the agents are confined strictly to the simu-lation, eliminating the possibility of adverse effects on the underlying hardware or the host operating system. 

# References 

Anthropic. Introducing claude sonnet 4.5. https://www. anthropic.com/news/claude-sonnet-4-5 ,September 2025. Accessed: 2026-01-26. Bai, S., Chen, K., Liu, X., Wang, J., Ge, W., Song, S., Dang, K., Wang, P., Wang, S., Tang, J., et al. Qwen2. 5-vl technical report. arXiv preprint arXiv:2502.13923 , 2025. Chai, Y., Huang, S., Niu, Y., Xiao, H., Liu, L., Zhang, D., Gao, P., Ren, S., and Li, H. Amex: Android multi-annotation expo dataset for mobile gui agents. ArXiv preprint , 2024. URL https://arxiv.org/abs/ 2407.17490 .Cheng, K., Sun, Q., Chu, Y., Xu, F., Li, Y., Zhang, J., and Wu, Z. Seeclick: Harnessing gui grounding for advanced visual gui agents. arXiv preprint arXiv:2401.10935 ,2024a. Cheng, K., Sun, Q., Chu, Y., Xu, F., YanTao, L., Zhang, J., and Wu, Z. SeeClick: Harnessing GUI grounding for advanced visual GUI agents. In Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers) , pp. 9313–9332, Bangkok, Thailand, August 2024b. Association for Com-putational Linguistics. doi: 10.18653/v1/2024.acl-long. 505. URL https://aclanthology.org/2024. acl-long.505/ .Comanici, G., Bieber, E., Schaekermann, M., Pasupat, I., Sachdeva, N., Dhillon, I., Blistein, M., Ram, O., Zhang, D., Rosen, E., et al. Gemini 2.5: Pushing the frontier with advanced reasoning, multimodality, long context, and next generation agentic capabilities. arXiv preprint arXiv:2507.06261 , 2025. Deng, X., Gu, Y., Zheng, B., Chen, S., Stevens, S., Wang, B., Sun, H., and Su, Y. Mind2web: Towards a generalist agent for the web. In Thirty-seventh Conference on Neu-ral Information Processing Systems Datasets and Bench-marks Track , 2023. URL https://openreview. net/forum?id=kiYqbO3wqw .Feizi, A., Nayak, S., Jian, X., Lin, K. Q., Li, K., Awal, R., L `u, X. H., Obando-Ceron, J., Rodriguez, J. A., Chapados, N., et al. Grounding computer use agents on human demonstrations. arXiv preprint arXiv:2511.07332 , 2025. Golovneva, O., Chen, M., Poff, S., Corredor, M., Zettle-moyer, L., Fazel-Zarandi, M., and Celikyilmaz, A. Roscoe: A suite of metrics for scoring step-by-step reasoning. In The Eleventh International Conference on Learning Representations , 2023. URL https:// openreview.net/forum?id=xYlJRpzZtsY .Huang, J., Zeng, Z., Han, W., Zhong, Y., Zheng, L., Fu, S., Chen, J., and Ma, L. Scaletrack: Scaling and back-tracking automated gui agents. arXiv preprint arXiv:2505.00416 , 2025. Hurst, A., Lerer, A., Goucher, A. P., Perelman, A., Ramesh, A., Clark, A., Ostrow, A., Welihinda, A., Hayes, A., Radford, A., et al. Gpt-4o system card. arXiv preprint arXiv:2410.21276 , 2024. Liu, Z., Xie, J., Ding, Z., Li, Z., Yang, B., Wu, Z., Wang, X., Sun, Q., Liu, S., Wang, W., et al. Scalecua: Scaling open-source computer use agents with cross-platform data. arXiv preprint arXiv:2509.15221 , 2025. OpenAI. Computer-using agent: Introducing a uni-versal interface for ai to interact with the digital world, 2025. URL https://openai.com/index/ computer-using-agent .Pahuja, V., Lu, Y., Rosset, C., Gou, B., Mitra, A., White-head, S., Su, Y., and Hassan, A. Explorer: Scaling exploration-driven web trajectory synthesis for multi-modal web agents. In Findings of the Association for Computational Linguistics: ACL 2025 , pp. 6300–6323, 2025. Pan, Y., Kong, D., Zhou, S., Cui, C., Leng, Y., Jiang, B., Liu, H., Shang, Y., Zhou, S., Wu, T., et al. Webcanvas: Benchmarking web agents in online environments. arXiv preprint arXiv:2406.12373 , 2024. Qin, Y., Ye, Y., Fang, J., Wang, H., Liang, S., Tian, S., Zhang, J., Li, J., Li, Y., Huang, S., et al. Ui-tars: Pioneer-ing automated gui interaction with native agents. arXiv preprint arXiv:2501.12326 , 2025. 9TreeCUA: Efficiently Scaling GUI Automation with Tree-Structured Verifiable Evolution 

Rafailov, R., Sharma, A., Mitchell, E., Manning, C. D., Ermon, S., and Finn, C. Direct preference optimiza-tion: Your language model is secretly a reward model. 

Advances in neural information processing systems , 36: 53728–53741, 2023. Rawles, C., Li, A., Rodriguez, D., Riva, O., and Lillicrap, T. Androidinthewild: A large-scale dataset for android de-vice control. Advances in Neural Information Processing Systems , 36:59708–59728, 2023. Sun, Q., Cheng, K., Ding, Z., Jin, C., Wang, Y., Xu, F., Wu, Z., Jia, C., Chen, L., Liu, Z., et al. Os-genesis: Automating gui agent trajectory construction via reverse task synthesis. arXiv preprint arXiv:2412.19723 , 2024. Wang, X., Wang, B., Lu, D., Yang, J., Xie, T., Wang, J., Deng, J., Guo, X., Xu, Y., Wu, C. H., Shen, Z., Li, Z., Li, R., Li, X., Chen, J., Zheng, B., Li, P., Lei, F., Cao, R., Fu, Y., Shin, D., Shin, M., Hu, J., Wang, Y., Chen, J., Ye, Y., Zhang, D., Du, D., Hu, H., Chen, H., Zhou, Z., Yao, H., Chen, Z., Gu, Q., Wang, Y., Wang, H., Yang, D., Zhong, V., Sung, F., Charles, Y., Yang, Z., and Yu, T. Opencua: Open foundations for computer-use agents, 2025. URL 

https://arxiv.org/abs/2508.09123 .Wu, Z., Han, C., Ding, Z., Weng, Z., Liu, Z., Yao, S., Yu, T., and Kong, L. Os-copilot: Towards generalist computer agents with self-improvement. arXiv preprint arXiv:2402.07456 , 2024a. Wu, Z., Wu, Z., Xu, F., Wang, Y., Sun, Q., Jia, C., Cheng, K., Ding, Z., Chen, L., Liang, P. P., et al. Os-atlas: A foundation action model for generalist gui agents. arXiv preprint arXiv:2410.23218 , 2024b. Xie, T., Zhang, D., Chen, J., Li, X., Zhao, S., Cao, R., Hua, T. J., Cheng, Z., Shin, D., Lei, F., et al. Osworld: Bench-marking multimodal agents for open-ended tasks in real computer environments. Advances in Neural Information Processing Systems , 37:52040–52094, 2024. Xie, T., Deng, J., Li, X., Yang, J., Wu, H., Chen, J., Hu, W., Wang, X., Xu, Y., Wang, Z., Xu, Y., Wang, J., Sahoo, D., Yu, T., and Xiong, C. Scaling computer-use grounding via user interface decomposition and synthesis, 2025. URL 

https://arxiv.org/abs/2505.13227 .Xu, Y., Wang, Z., Wang, J., Lu, D., Xie, T., Saha, A., Sahoo, D., Yu, T., and Xiong, C. Aguvis: Unified pure vision agents for autonomous gui interaction. arXiv preprint arXiv:2412.04454 , 2024. Xu, Y., Lu, D., Shen, Z., Wang, J., Wang, Z., Mao, Y., Xiong, C., and Yu, T. Agenttrek: Agent trajectory synthesis via guiding replay with web tutorials, 2025. URL https: //arxiv.org/abs/2412.09605 .Yang, L., Zeng, Z., Zhong, Y., Huang, J., Zheng, L., Chen, L., Qiu, H., Qin, Z., Ma, L., and Li, X. Omniactor: A generalist gui and embodied agent for 2d&3d worlds. 

arXiv preprint arXiv:2509.02322 , 2025a. Yang, Y., Yang, Z., Dou, Z.-Y., Nguyen, A., You, K., Attia, O., Szot, A., Feng, M., Ramrakhya, R., Toshev, A., et al. Ultracua: A foundation model for computer use agents with hybrid action. arXiv preprint arXiv:2510.17790 ,2025b. Ye, J., Zhang, X., Xu, H., Liu, H., Wang, J., Zhu, Z., Zheng, Z., Gao, F., Cao, J., Lu, Z., et al. Mobile-agent-v3: Foundamental agents for gui automation. arXiv preprint arXiv:2508.15144 , 2025. Zeng, Z., Huang, J., Zheng, L., Han, W., Zhong, Y., Chen, L., Yang, L., Chu, Y., He, Y., and Ma, L. Uitron: Founda-tional gui agent with advanced perception and planning. 

arXiv preprint arXiv:2508.21767 , 2025. 10 TreeCUA: Efficiently Scaling GUI Automation with Tree-Structured Verifiable Evolution 

# A. Implementation Details of Scalable Execution 

In this section, we elaborate on the engineering challenges and solutions for implementing tree-structured exploration in non-reversible operating system environments. 

A.1. Deterministic Node Replay with Visual Consistency 

Since standard OS environments (e.g., Windows, Linux, macOS) do not support state snapshotting like game emulators, we cannot simply reload a previous state st to explore a new branch. We solve this via a replay mechanism. 

Replay Process. To restore state st, the agent initiates a ”hard reset” to the initial state s0 (using VM snapshots or container resets) and sequentially executes the action history ht = ( a0, a 1, . . . , a t−1).

Consistency Check. A major challenge in replay is non-deterministic visual noise (e.g., blinking cursors, changing system time, dynamic loading spinners). To ensure the replayed state ˆst is semantically identical to the original state st, we employ a Root Mean Square (RMS) difference check on the screenshots: 

δ(ot, ˆot) = 

vuut 1

N

> N

X

> i=1

(o(i) 

> t

− ˆo(i) 

> t

)2 (2) where N is the total number of pixels. The restoration is deemed valid only if δ < ϵ . We empirically set ϵ = 5 .0 (for 0-255 pixel values) to tolerate minor rendering artifacts while rejecting divergent states (e.g., pop-ups, failed page loads). If the check fails, the branch is marked as C ORRUPTED and pruned. 

A.2. Asynchronous Parallel Framework 

Building upon the replay infrastructure, our system manages tree construction through a multi-worker concurrent framework. The workflow for each asynchronous worker operates as a continuous loop, initiating with node selection. In this phase, the worker samples a candidate node st+1 marked as U NEXPLORED from the current tree and immediately proceeds to state restoration, invoking the deterministic replay mechanism to reconstruct the corresponding environment state st. After the restoration, the process restarts to carry out tree exploration. To optimize efficiency, we employ a hybrid traversal strategy where the worker retains a single child node for immediate local extension, while simultaneously dispatching the remaining K − 1 siblings to the global system pool to accelerate parallel execution. Subsequently, the worker recursively extends the retained branch by generating candidate actions—each containing specific goals and expected visual changes—and executing a randomly selected child to validate its outcome via the Verification Agent. This local exploration loop continues until the agent explicitly signals completion, reaches the maximum depth, or is pruned due to consecutive verification failures. 

# B. Quality of Reasoning Process 

To validate the superiority of hindsight-generated reasoning in enhancing the model’s global perspective and logical analysis capabilities, we conduct a comparative experiment using the offline AndroidControl dataset. Given the absence of mobile data in our training set, AndroidControl also serves as an OOD benchmark to evaluate the model’s zero-shot generalization capabilities. In this setup, both TreeCUA and Claude-4.5-Sonnet are tasked with predicting the current step’s reasoning process and executable action, conditioned on identical task goals and historical action sequences. Crucially, to strictly isolate and evaluate the quality of the reasoning process, we implement a rigorous filtering strategy that retains only the subset of samples where both models correctly predict the ground-truth action. This decouples reasoning quality from action accuracy, allowing us to evaluate the rationale without the interference of incorrect predictions. To evaluate the quality of the generated rationales, we adopt a diagnostic framework inspired by ROSCOE (Golovneva et al., 2023), which assesses reasoning through four fundamental dimensions: Semantic Alignment, Logicality, Informativeness, and Factuality. We randomly sampled 200 reasoning chains from the filtered subset and employed Gemini-3-Flash and GPT-4o as independent expert judges to provide multidimensional scores. The results demonstrate that TreeCUA significantly surpasses Claude across all metrics, which confirms that our hindsight-augmented training effectively mitigates logical leaps and tautological redundancy, resulting in a more grounded and informative reasoning process of the GUI task even in zero-shot OOD scenarios. 11 TreeCUA: Efficiently Scaling GUI Automation with Tree-Structured Verifiable Evolution  

> Figure 5. Comparison of reasoning quality between TreeCUA and Claude based on ROSCOE metrics.

# C. Experimental Setup 

Data Synthesis Setup. We utilize Claude-4.5-Sonnet (Anthropic, 2025) as the backbone for the exploration agent to ensure high-quality planning, while employing GPT-4o-mini (Hurst et al., 2024) for the auxiliary agents (verification, summarization, and evaluation) to balance cost and efficiency. 

Training Setup. We adopt Qwen2.5-VL-7B (Bai et al., 2025) as our base model and implement a three-stage training pipeline. All experiments are conducted with a global batch size of 32. 

# D. Detailed Analysis of DPO Performance Variance 

To investigate the impact of the preference alignment stage, we analyze the performance shift between the SFT base model (TreeCUA-7B ) and the DPO-finetuned model ( TreeCUA-DPO-7B ). Table 7 presents the success rate comparison across different domains, sorted by the performance gain ( ∆).                                              

> Table 7. Performance comparison between TreeCUA-7B (Stage 3) and TreeCUA-DPO-7B (Stage 4) across applications. Domains are sorted by the net performance gain ( ∆).
> Application TreeCUA-7B TreeCUA-DPO-7B ∆Task Characteristics
> Impress 40.4 29.8 -10.6 Visual Layout & Design OS 58.3 54.2 -4.1 File System Ops Calc 27.7 25.5 -2.2 Formula & Formatting GIMP 76.9 76.9 0.0 Pixel Manipulation Multi 14.0 15.1 +1.1 Cross-App Workflow Writer 43.5 47.8 +4.3 Hybrid Editing VLC 41.2 47.1 +5.9 Menu Navigation Chrome 28.3 39.1 +10.8 Open-ended Search Code 47.8 60.9 +13.1 Env Config & Plugins TB 33.3 53.3 +20.0 Logic Rules & Filtering

D.1. Theoretical Attribution: Action Space and Topology 

We observe a significant divergence in DPO gains, ranging from +20.0% in Thunderbird to -10.6% in Impress. This variance can be attributed to the structural alignment between the TreeCUA exploration topology and the inherent interaction logic of the applications. 12 TreeCUA: Efficiently Scaling GUI Automation with Tree-Structured Verifiable Evolution  

> Figure 6. An Example of our synthesized trajectories

1. Discretization of Action Space. TreeCUA-DPO-7B achieves the most significant gains in environments dominated by 

Discrete Semantic Actions (e.g., TB , Code ). In these domains, the distinction between a ”correct branch” (e.g., selecting the correct menu item) and an ”incorrect branch” is binary and sharp, providing strong gradient signals for preference optimization. Conversely, in domains requiring Continuous Visual Precision (e.g., Impress ), where actions involve dragging elements to specific coordinates or selecting exact colors, the counterfactuals often differ only by minor continuous parameters. The DPO model may struggle to distinguish these subtle visual nuances, leading to regressions in fine-grained control. 

2. Topological Isomorpghism. The efficacy of DPO is maximized when the application’s workflow exhibits a Hierarchi-cal Navigation Topology . Applications like Chrome and TB typically involve traversing through distinct states (e.g., Inbox 

→ Email → Reply Window), which is topologically isomorphic to our exploration tree. In contrast, In-Situ Mutation tasks (common in Impress and Calc ), where users perform multiple micro-operations within a single static view, result in shallow but wide exploration trees. This structure often fails to provide diverse high-level semantic branches for effective contrastive learning. 

# E. Case study 

We provide an example trajectory visualization and its corresponding first and second-step thinking, step goals, actions, and verification results in Figures 6 and 7. 13 TreeCUA: Efficiently Scaling GUI Automation with Tree-Structured Verifiable Evolution 

Example of our synthesized task 

Task Instruction : ”Access Chrome history using ’Ctrl + H’, click on ’Delete browsing data’, navigate to ’On start-up’ settings, go to ’Languages’ settings, expand ’Customize spell check’, navigate to ’Appearance’ settings, change font size to ’Large’, adjust page zoom to ’125%’, scroll down to view additional appearance settings, and navigate to ’Default browser’ settings.” 

tajectory : [ 

{

”step” : 1, 

”thinking” : {

”observation” : ”The current interface shows the Google Chrome browser open to the Google search homepage. There is a notification in the top right corner regarding a Chrome update, but the main browser window is active and ready for input. No history or settings pages are currently open.”, 

”progress” : ”This is the first step of the task. I am starting from a fresh browser state with the goal of managing browsing data and adjusting various browser settings.”, 

”plan” : ”To begin the task, I will use the ’Ctrl + H’ keyboard shortcut to immediately access the Chrome History page. This is the most efficient way to reach the ’Delete browsing data’ option. Following this, I will proceed to clear browsing data, then navigate through the settings sidebar to configure ’On start-up’, ’Languages’, ’Appearance’ (including font and zoom adjustments), and finally ’Default browser’ settings.”, 

”impact” : ”Executing ’Ctrl + H’ will open a new tab displaying the Chrome History list. This will provide access to the ’Clear browsing data’ link on the left-hand side, which is the next required action in the sequence.” 

},

”goal” : ”Use keyboard shortcut to access Chrome history for browsing data management”, 

action” : [ {”action”: ”key”, ”text”: ”ctrl+h” }, {”action”: ”wait”, ”duration”: 2 }], 

”verification result” : {”result type”: ”SUCCESS”, ”feedback”: ”The operation successfully opened the Chrome history page as expected, showing the history list and the ’Delete browsing data’ option.” },

},

{

”step” : 2, 

”thinking” : {.... },

”goal” : ”Click on ’Delete browsing data’ to access privacy and data clearing options”, ”action” : [ {”action”: ”left click”, ”coordinate”: [106, 197] }, {”action”: ”wait”, ”duration”: 2 }], 

”verification result” : {”result type”: ”SUCCESS”, ”feedback”: ”The operation successfully opened the expected dialog for clearing browsing data, matching the expected outcome perfectly.” }}

] 

> Figure 7. Example of the generated task instruction and the first step trajectory of Figure 6

14
# Reward-Guided Discrete Diffusion via Clean-Sample Markov Chain for Molecule and Biological Sequence Design
# 基于净样本马尔可夫链的奖励引导离散扩散模型用于分子及生物序列设计

**Authors**: Prin Phunyaphibarn, Minhyuk Sung \\
**Date**: 2026-02-10 \\
**PDF**: https://arxiv.org/pdf/2602.09424v1 \\
**Tags**: <span class="tag-label tag-green">速读区</span> <span class="tag-label tag-pink">keyword:LNS</span> <span class="tag-label tag-pink">keyword:EAA</span> \\
**Score**: 6.0 \\
**Evidence**: local search and reward-guided sampling for discrete sequence design \\

---

## Abstract
Discrete diffusion models have recently emerged as a powerful class of generative models for chemistry and biology data. In these fields, the goal is to generate various samples with high rewards (e.g., drug-likeness in molecules), making reward-based guidance crucial. Most existing methods are based on guiding the diffusion model using intermediate rewards but tend to underperform since intermediate rewards are noisy due to the non-smooth nature of reward functions used in scientific domains. To address this, we propose Clean-Sample Markov Chain (CSMC) Sampler, a method that performs effective test-time reward-guided sampling for discrete diffusion models, enabling local search without relying on intermediate rewards. CSMC constructs a Markov chain of clean samples using the Metropolis-Hastings algorithm such that its stationary distribution is the target distribution. We design a proposal distribution by sequentially applying the forward and backward diffusion processes, making the acceptance probability tractable. Experiments on molecule and biological sequence generation with various reward functions demonstrate that our method consistently outperforms prior approaches that rely on intermediate rewards.

## 摘要
离散扩散模型近期已成为处理化学和生物数据的一类强大的生成模型。在这些领域中，目标是生成具有高奖励（例如分子的类药性）的多样化样本，因此基于奖励的引导至关重要。现有方法大多基于中间奖励来引导扩散模型，但由于科学领域所使用的奖励函数具有非平滑特性，导致中间奖励存在噪声，这些方法往往表现不佳。为了解决这一问题，我们提出了净样本马尔可夫链（CSMC）采样器，这是一种为离散扩散模型执行有效测试时奖励引导采样的方法，能够在不依赖中间奖励的情况下进行局部搜索。CSMC 利用 Metropolis-Hastings 算法构建了一个净样本马尔可夫链，使其平稳分布即为目标分布。我们通过顺序应用前向和反向扩散过程设计了一种建议分布，从而使接受概率变得可计算。在具有多种奖励函数的分子和生物序列生成实验中，结果表明我们的方法始终优于以往依赖中间奖励的方法。

---

## 速览摘要（自动生成）

**问题**：离散扩散模型在分子和生物序列设计中，依赖中间奖励进行引导时易受非平滑奖励函数的噪声干扰。

**方法**：提出CSMC采样器，利用Metropolis-Hastings算法构建纯净样本马尔可夫链，通过扩散过程设计提议分布，实现无需中间奖励的局部搜索。

**结论**：在多项生成任务中性能显著优于现有方法。